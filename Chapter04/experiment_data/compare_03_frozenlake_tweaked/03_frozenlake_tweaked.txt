



2020-05-07 01-25-55

0: loss=1.378, reward_mean=0.010, reward_bound=0.000, batch=1 
1: loss=1.375, reward_mean=0.010, reward_bound=0.000, batch=2 
2: loss=1.372, reward_mean=0.000, reward_bound=0.000, batch=2 
3: loss=1.373, reward_mean=0.030, reward_bound=0.000, batch=5 
4: loss=1.371, reward_mean=0.020, reward_bound=0.000, batch=7 
5: loss=1.369, reward_mean=0.000, reward_bound=0.000, batch=7 
6: loss=1.377, reward_mean=0.040, reward_bound=0.000, batch=11 
7: loss=1.375, reward_mean=0.020, reward_bound=0.000, batch=13 
8: loss=1.375, reward_mean=0.010, reward_bound=0.000, batch=14 
9: loss=1.374, reward_mean=0.000, reward_bound=0.000, batch=14 
10: loss=1.373, reward_mean=0.000, reward_bound=0.000, batch=14 
11: loss=1.373, reward_mean=0.010, reward_bound=0.000, batch=15 
12: loss=1.374, reward_mean=0.010, reward_bound=0.000, batch=16 
13: loss=1.372, reward_mean=0.040, reward_bound=0.000, batch=20 
14: loss=1.372, reward_mean=0.000, reward_bound=0.000, batch=20 
15: loss=1.372, reward_mean=0.010, reward_bound=0.000, batch=21 
16: loss=1.375, reward_mean=0.020, reward_bound=0.000, batch=23 
17: loss=1.373, reward_mean=0.020, reward_bound=0.000, batch=25 
18: loss=1.372, reward_mean=0.000, reward_bound=0.000, batch=25 
19: loss=1.371, reward_mean=0.020, reward_bound=0.000, batch=27 
20: loss=1.369, reward_mean=0.010, reward_bound=0.000, batch=28 
21: loss=1.369, reward_mean=0.000, reward_bound=0.000, batch=28 
22: loss=1.367, reward_mean=0.010, reward_bound=0.000, batch=29 
23: loss=1.370, reward_mean=0.020, reward_bound=0.000, batch=31 
24: loss=1.368, reward_mean=0.020, reward_bound=0.000, batch=33 
25: loss=1.367, reward_mean=0.030, reward_bound=0.000, batch=36 
26: loss=1.367, reward_mean=0.040, reward_bound=0.000, batch=40 
27: loss=1.367, reward_mean=0.000, reward_bound=0.000, batch=40 
28: loss=1.366, reward_mean=0.000, reward_bound=0.000, batch=40 
29: loss=1.365, reward_mean=0.010, reward_bound=0.000, batch=41 
30: loss=1.365, reward_mean=0.020, reward_bound=0.000, batch=43 
31: loss=1.365, reward_mean=0.010, reward_bound=0.000, batch=44 
32: loss=1.364, reward_mean=0.020, reward_bound=0.000, batch=46 
33: loss=1.362, reward_mean=0.010, reward_bound=0.000, batch=47 
34: loss=1.361, reward_mean=0.010, reward_bound=0.000, batch=48 
35: loss=1.359, reward_mean=0.030, reward_bound=0.000, batch=51 
36: loss=1.357, reward_mean=0.030, reward_bound=0.000, batch=54 
37: loss=1.356, reward_mean=0.020, reward_bound=0.000, batch=56 
38: loss=1.356, reward_mean=0.010, reward_bound=0.000, batch=57 
39: loss=1.355, reward_mean=0.000, reward_bound=0.000, batch=57 
40: loss=1.354, reward_mean=0.010, reward_bound=0.000, batch=58 
41: loss=1.353, reward_mean=0.030, reward_bound=0.000, batch=61 
42: loss=1.352, reward_mean=0.020, reward_bound=0.000, batch=63 
43: loss=1.350, reward_mean=0.020, reward_bound=0.000, batch=65 
44: loss=1.350, reward_mean=0.020, reward_bound=0.000, batch=67 
45: loss=1.349, reward_mean=0.030, reward_bound=0.000, batch=70 
46: loss=1.348, reward_mean=0.010, reward_bound=0.000, batch=71 
47: loss=1.348, reward_mean=0.000, reward_bound=0.000, batch=71 
48: loss=1.346, reward_mean=0.020, reward_bound=0.000, batch=73 
49: loss=1.346, reward_mean=0.020, reward_bound=0.000, batch=75 
50: loss=1.345, reward_mean=0.010, reward_bound=0.000, batch=76 
51: loss=1.343, reward_mean=0.010, reward_bound=0.000, batch=77 
52: loss=1.344, reward_mean=0.020, reward_bound=0.000, batch=79 
53: loss=1.342, reward_mean=0.040, reward_bound=0.000, batch=83 
54: loss=1.342, reward_mean=0.030, reward_bound=0.000, batch=86 
55: loss=1.344, reward_mean=0.030, reward_bound=0.000, batch=89 
56: loss=1.343, reward_mean=0.000, reward_bound=0.000, batch=89 
57: loss=1.343, reward_mean=0.030, reward_bound=0.000, batch=92 
58: loss=1.343, reward_mean=0.050, reward_bound=0.000, batch=97 
59: loss=1.343, reward_mean=0.020, reward_bound=0.000, batch=99 
60: loss=1.343, reward_mean=0.000, reward_bound=0.000, batch=99 
61: loss=1.341, reward_mean=0.030, reward_bound=0.000, batch=102 
62: loss=1.341, reward_mean=0.000, reward_bound=0.000, batch=102 
63: loss=1.339, reward_mean=0.020, reward_bound=0.000, batch=104 
64: loss=1.338, reward_mean=0.030, reward_bound=0.000, batch=107 
65: loss=1.338, reward_mean=0.040, reward_bound=0.000, batch=111 
66: loss=1.337, reward_mean=0.020, reward_bound=0.000, batch=113 
67: loss=1.336, reward_mean=0.010, reward_bound=0.000, batch=114 
68: loss=1.334, reward_mean=0.030, reward_bound=0.000, batch=117 
69: loss=1.333, reward_mean=0.000, reward_bound=0.000, batch=117 
70: loss=1.331, reward_mean=0.040, reward_bound=0.000, batch=121 
71: loss=1.330, reward_mean=0.010, reward_bound=0.000, batch=122 
72: loss=1.329, reward_mean=0.000, reward_bound=0.000, batch=122 
73: loss=1.329, reward_mean=0.020, reward_bound=0.000, batch=124 
74: loss=1.326, reward_mean=0.050, reward_bound=0.000, batch=129 
75: loss=1.326, reward_mean=0.030, reward_bound=0.000, batch=132 
76: loss=1.326, reward_mean=0.000, reward_bound=0.000, batch=132 
77: loss=1.323, reward_mean=0.060, reward_bound=0.000, batch=138 
78: loss=1.323, reward_mean=0.020, reward_bound=0.000, batch=140 
79: loss=1.322, reward_mean=0.020, reward_bound=0.000, batch=142 
80: loss=1.321, reward_mean=0.060, reward_bound=0.000, batch=148 
81: loss=1.320, reward_mean=0.020, reward_bound=0.000, batch=150 
82: loss=1.320, reward_mean=0.040, reward_bound=0.000, batch=154 
83: loss=1.320, reward_mean=0.040, reward_bound=0.000, batch=158 
84: loss=1.319, reward_mean=0.010, reward_bound=0.000, batch=159 
85: loss=1.318, reward_mean=0.010, reward_bound=0.000, batch=160 
86: loss=1.319, reward_mean=0.030, reward_bound=0.000, batch=163 
87: loss=1.319, reward_mean=0.030, reward_bound=0.000, batch=166 
88: loss=1.318, reward_mean=0.010, reward_bound=0.000, batch=167 
89: loss=1.317, reward_mean=0.040, reward_bound=0.000, batch=171 
90: loss=1.317, reward_mean=0.010, reward_bound=0.000, batch=172 
91: loss=1.316, reward_mean=0.040, reward_bound=0.000, batch=176 
92: loss=1.317, reward_mean=0.020, reward_bound=0.000, batch=178 
93: loss=1.317, reward_mean=0.040, reward_bound=0.000, batch=182 
94: loss=1.316, reward_mean=0.010, reward_bound=0.000, batch=183 
95: loss=1.316, reward_mean=0.040, reward_bound=0.000, batch=187 
96: loss=1.314, reward_mean=0.020, reward_bound=0.000, batch=189 
97: loss=1.314, reward_mean=0.000, reward_bound=0.000, batch=189 
98: loss=1.313, reward_mean=0.030, reward_bound=0.000, batch=192 
99: loss=1.312, reward_mean=0.020, reward_bound=0.000, batch=194 
100: loss=1.311, reward_mean=0.060, reward_bound=0.000, batch=200 
101: loss=1.310, reward_mean=0.030, reward_bound=0.000, batch=203 
102: loss=1.309, reward_mean=0.010, reward_bound=0.000, batch=204 
103: loss=1.308, reward_mean=0.030, reward_bound=0.000, batch=207 
104: loss=1.307, reward_mean=0.020, reward_bound=0.000, batch=209 
105: loss=1.306, reward_mean=0.020, reward_bound=0.000, batch=211 
106: loss=1.305, reward_mean=0.020, reward_bound=0.000, batch=213 
107: loss=1.305, reward_mean=0.010, reward_bound=0.000, batch=214 
108: loss=1.304, reward_mean=0.040, reward_bound=0.000, batch=218 
109: loss=1.304, reward_mean=0.020, reward_bound=0.000, batch=220 
110: loss=1.303, reward_mean=0.020, reward_bound=0.000, batch=222 
111: loss=1.301, reward_mean=0.010, reward_bound=0.000, batch=223 
112: loss=1.301, reward_mean=0.030, reward_bound=0.008, batch=226 
113: loss=1.300, reward_mean=0.010, reward_bound=0.000, batch=227 
114: loss=1.298, reward_mean=0.030, reward_bound=0.021, batch=229 
115: loss=1.295, reward_mean=0.030, reward_bound=0.065, batch=229 
116: loss=1.293, reward_mean=0.040, reward_bound=0.072, batch=227 
117: loss=1.293, reward_mean=0.030, reward_bound=0.087, batch=229 
118: loss=1.293, reward_mean=0.020, reward_bound=0.089, batch=228 
119: loss=1.287, reward_mean=0.060, reward_bound=0.109, batch=226 
120: loss=1.286, reward_mean=0.020, reward_bound=0.061, batch=228 
121: loss=1.284, reward_mean=0.040, reward_bound=0.122, batch=228 
122: loss=1.281, reward_mean=0.060, reward_bound=0.135, batch=228 
123: loss=1.279, reward_mean=0.040, reward_bound=0.150, batch=226 
124: loss=1.279, reward_mean=0.020, reward_bound=0.083, batch=228 
125: loss=1.279, reward_mean=0.010, reward_bound=0.017, batch=229 
126: loss=1.278, reward_mean=0.010, reward_bound=0.067, batch=230 
127: loss=1.278, reward_mean=0.030, reward_bound=0.167, batch=221 
128: loss=1.277, reward_mean=0.040, reward_bound=0.089, batch=224 
129: loss=1.277, reward_mean=0.050, reward_bound=0.185, batch=220 
130: loss=1.276, reward_mean=0.020, reward_bound=0.000, batch=222 
131: loss=1.276, reward_mean=0.020, reward_bound=0.000, batch=224 
132: loss=1.275, reward_mean=0.020, reward_bound=0.000, batch=226 
133: loss=1.273, reward_mean=0.040, reward_bound=0.058, batch=227 
134: loss=1.272, reward_mean=0.020, reward_bound=0.120, batch=229 
135: loss=1.272, reward_mean=0.050, reward_bound=0.174, batch=230 
136: loss=1.271, reward_mean=0.050, reward_bound=0.206, batch=232 
137: loss=1.269, reward_mean=0.030, reward_bound=0.206, batch=234 
138: loss=1.263, reward_mean=0.050, reward_bound=0.206, batch=227 
139: loss=1.257, reward_mean=0.040, reward_bound=0.229, batch=206 
140: loss=1.258, reward_mean=0.010, reward_bound=0.000, batch=207 
141: loss=1.258, reward_mean=0.020, reward_bound=0.000, batch=209 
142: loss=1.256, reward_mean=0.030, reward_bound=0.000, batch=212 
143: loss=1.254, reward_mean=0.030, reward_bound=0.000, batch=215 
144: loss=1.253, reward_mean=0.020, reward_bound=0.000, batch=217 
145: loss=1.251, reward_mean=0.030, reward_bound=0.000, batch=220 
146: loss=1.251, reward_mean=0.030, reward_bound=0.000, batch=223 
147: loss=1.249, reward_mean=0.040, reward_bound=0.091, batch=226 
148: loss=1.248, reward_mean=0.060, reward_bound=0.128, batch=228 
149: loss=1.247, reward_mean=0.050, reward_bound=0.156, batch=229 
150: loss=1.248, reward_mean=0.010, reward_bound=0.005, batch=230 
151: loss=1.246, reward_mean=0.030, reward_bound=0.206, batch=232 
152: loss=1.246, reward_mean=0.010, reward_bound=0.206, batch=233 
153: loss=1.243, reward_mean=0.050, reward_bound=0.229, batch=232 
154: loss=1.232, reward_mean=0.040, reward_bound=0.254, batch=197 
155: loss=1.231, reward_mean=0.000, reward_bound=0.000, batch=197 
156: loss=1.230, reward_mean=0.050, reward_bound=0.000, batch=202 
157: loss=1.230, reward_mean=0.050, reward_bound=0.000, batch=207 
158: loss=1.229, reward_mean=0.020, reward_bound=0.000, batch=209 
159: loss=1.228, reward_mean=0.070, reward_bound=0.021, batch=216 
160: loss=1.228, reward_mean=0.020, reward_bound=0.000, batch=218 
161: loss=1.229, reward_mean=0.030, reward_bound=0.000, batch=221 
162: loss=1.228, reward_mean=0.040, reward_bound=0.047, batch=224 
163: loss=1.226, reward_mean=0.040, reward_bound=0.063, batch=227 
164: loss=1.219, reward_mean=0.120, reward_bound=0.202, batch=229 
165: loss=1.219, reward_mean=0.050, reward_bound=0.229, batch=229 
166: loss=1.217, reward_mean=0.050, reward_bound=0.254, batch=226 
167: loss=1.215, reward_mean=0.040, reward_bound=0.256, batch=228 
168: loss=1.208, reward_mean=0.040, reward_bound=0.282, batch=201 
169: loss=1.208, reward_mean=0.030, reward_bound=0.000, batch=204 
170: loss=1.207, reward_mean=0.020, reward_bound=0.000, batch=206 
171: loss=1.207, reward_mean=0.020, reward_bound=0.000, batch=208 
172: loss=1.206, reward_mean=0.040, reward_bound=0.000, batch=212 
173: loss=1.206, reward_mean=0.020, reward_bound=0.000, batch=214 
174: loss=1.206, reward_mean=0.020, reward_bound=0.000, batch=216 
175: loss=1.204, reward_mean=0.050, reward_bound=0.049, batch=221 
176: loss=1.203, reward_mean=0.030, reward_bound=0.000, batch=224 
177: loss=1.204, reward_mean=0.060, reward_bound=0.150, batch=226 
178: loss=1.205, reward_mean=0.020, reward_bound=0.083, batch=228 
179: loss=1.202, reward_mean=0.060, reward_bound=0.206, batch=228 
180: loss=1.199, reward_mean=0.060, reward_bound=0.229, batch=228 
181: loss=1.201, reward_mean=0.050, reward_bound=0.254, batch=228 
182: loss=1.201, reward_mean=0.080, reward_bound=0.282, batch=228 
183: loss=1.185, reward_mean=0.040, reward_bound=0.314, batch=188 
184: loss=1.182, reward_mean=0.050, reward_bound=0.000, batch=193 
185: loss=1.181, reward_mean=0.080, reward_bound=0.000, batch=201 
186: loss=1.177, reward_mean=0.070, reward_bound=0.000, batch=208 
187: loss=1.178, reward_mean=0.040, reward_bound=0.000, batch=212 
188: loss=1.178, reward_mean=0.050, reward_bound=0.000, batch=217 
189: loss=1.177, reward_mean=0.050, reward_bound=0.020, batch=222 
190: loss=1.175, reward_mean=0.030, reward_bound=0.008, batch=225 
191: loss=1.172, reward_mean=0.080, reward_bound=0.122, batch=225 
192: loss=1.172, reward_mean=0.020, reward_bound=0.020, batch=227 
193: loss=1.169, reward_mean=0.050, reward_bound=0.150, batch=227 
194: loss=1.167, reward_mean=0.070, reward_bound=0.229, batch=228 
195: loss=1.167, reward_mean=0.020, reward_bound=0.231, batch=229 
196: loss=1.170, reward_mean=0.060, reward_bound=0.282, batch=224 
197: loss=1.173, reward_mean=0.080, reward_bound=0.314, batch=218 
198: loss=1.172, reward_mean=0.080, reward_bound=0.286, batch=222 
199: loss=1.171, reward_mean=0.010, reward_bound=0.000, batch=223 
200: loss=1.169, reward_mean=0.040, reward_bound=0.076, batch=226 
201: loss=1.168, reward_mean=0.050, reward_bound=0.241, batch=228 
202: loss=1.169, reward_mean=0.060, reward_bound=0.231, batch=229 
203: loss=1.167, reward_mean=0.020, reward_bound=0.114, batch=230 
204: loss=1.167, reward_mean=0.030, reward_bound=0.254, batch=229 
205: loss=1.162, reward_mean=0.060, reward_bound=0.349, batch=188 
206: loss=1.163, reward_mean=0.080, reward_bound=0.000, batch=196 
207: loss=1.163, reward_mean=0.070, reward_bound=0.000, batch=203 
208: loss=1.160, reward_mean=0.060, reward_bound=0.000, batch=209 
209: loss=1.162, reward_mean=0.090, reward_bound=0.083, batch=216 
210: loss=1.157, reward_mean=0.100, reward_bound=0.143, batch=221 
211: loss=1.159, reward_mean=0.060, reward_bound=0.167, batch=224 
212: loss=1.157, reward_mean=0.040, reward_bound=0.182, batch=227 
213: loss=1.156, reward_mean=0.020, reward_bound=0.148, batch=229 
214: loss=1.152, reward_mean=0.050, reward_bound=0.206, batch=227 
215: loss=1.153, reward_mean=0.030, reward_bound=0.220, batch=229 
216: loss=1.153, reward_mean=0.000, reward_bound=0.000, batch=229 
217: loss=1.150, reward_mean=0.050, reward_bound=0.239, batch=230 
218: loss=1.149, reward_mean=0.040, reward_bound=0.254, batch=225 
219: loss=1.149, reward_mean=0.090, reward_bound=0.282, batch=224 
220: loss=1.148, reward_mean=0.040, reward_bound=0.193, batch=227 
221: loss=1.146, reward_mean=0.050, reward_bound=0.272, batch=229 
222: loss=1.144, reward_mean=0.030, reward_bound=0.295, batch=230 
223: loss=1.146, reward_mean=0.090, reward_bound=0.314, batch=225 
224: loss=1.143, reward_mean=0.070, reward_bound=0.349, batch=221 
225: loss=1.141, reward_mean=0.050, reward_bound=0.167, batch=224 
226: loss=1.142, reward_mean=0.070, reward_bound=0.345, batch=227 
227: loss=1.141, reward_mean=0.090, reward_bound=0.380, batch=229 
228: loss=1.141, reward_mean=0.020, reward_bound=0.085, batch=230 
229: loss=1.128, reward_mean=0.060, reward_bound=0.387, batch=172 
230: loss=1.121, reward_mean=0.060, reward_bound=0.000, batch=178 
231: loss=1.122, reward_mean=0.030, reward_bound=0.000, batch=181 
232: loss=1.123, reward_mean=0.060, reward_bound=0.000, batch=187 
233: loss=1.123, reward_mean=0.050, reward_bound=0.000, batch=192 
234: loss=1.124, reward_mean=0.040, reward_bound=0.000, batch=196 
235: loss=1.124, reward_mean=0.050, reward_bound=0.000, batch=201 
236: loss=1.118, reward_mean=0.070, reward_bound=0.000, batch=208 
237: loss=1.117, reward_mean=0.060, reward_bound=0.000, batch=214 
238: loss=1.116, reward_mean=0.010, reward_bound=0.000, batch=215 
239: loss=1.115, reward_mean=0.040, reward_bound=0.000, batch=219 
240: loss=1.113, reward_mean=0.020, reward_bound=0.000, batch=221 
241: loss=1.115, reward_mean=0.060, reward_bound=0.047, batch=224 
242: loss=1.116, reward_mean=0.080, reward_bound=0.122, batch=226 
243: loss=1.119, reward_mean=0.080, reward_bound=0.150, batch=225 
244: loss=1.122, reward_mean=0.040, reward_bound=0.167, batch=226 
245: loss=1.121, reward_mean=0.060, reward_bound=0.206, batch=225 
246: loss=1.116, reward_mean=0.060, reward_bound=0.229, batch=225 
247: loss=1.111, reward_mean=0.090, reward_bound=0.260, batch=227 
248: loss=1.116, reward_mean=0.090, reward_bound=0.282, batch=218 
249: loss=1.112, reward_mean=0.040, reward_bound=0.008, batch=222 
250: loss=1.115, reward_mean=0.030, reward_bound=0.024, batch=225 
251: loss=1.118, reward_mean=0.050, reward_bound=0.109, batch=228 
252: loss=1.118, reward_mean=0.060, reward_bound=0.206, batch=228 
253: loss=1.118, reward_mean=0.080, reward_bound=0.314, batch=224 
254: loss=1.119, reward_mean=0.050, reward_bound=0.332, batch=227 
255: loss=1.121, reward_mean=0.020, reward_bound=0.057, batch=229 
256: loss=1.118, reward_mean=0.060, reward_bound=0.292, batch=230 
257: loss=1.120, reward_mean=0.070, reward_bound=0.349, batch=220 
258: loss=1.118, reward_mean=0.090, reward_bound=0.247, batch=224 
259: loss=1.118, reward_mean=0.010, reward_bound=0.000, batch=225 
260: loss=1.121, reward_mean=0.040, reward_bound=0.254, batch=226 
261: loss=1.121, reward_mean=0.090, reward_bound=0.316, batch=228 
262: loss=1.119, reward_mean=0.030, reward_bound=0.349, batch=228 
263: loss=1.118, reward_mean=0.050, reward_bound=0.224, batch=229 
264: loss=1.112, reward_mean=0.060, reward_bound=0.387, batch=205 
265: loss=1.114, reward_mean=0.040, reward_bound=0.000, batch=209 
266: loss=1.112, reward_mean=0.050, reward_bound=0.000, batch=214 
267: loss=1.112, reward_mean=0.050, reward_bound=0.000, batch=219 
268: loss=1.112, reward_mean=0.050, reward_bound=0.105, batch=223 
269: loss=1.109, reward_mean=0.020, reward_bound=0.000, batch=225 
270: loss=1.110, reward_mean=0.050, reward_bound=0.170, batch=227 
271: loss=1.110, reward_mean=0.060, reward_bound=0.202, batch=229 
272: loss=1.109, reward_mean=0.040, reward_bound=0.229, batch=229 
273: loss=1.113, reward_mean=0.050, reward_bound=0.282, batch=226 
274: loss=1.113, reward_mean=0.060, reward_bound=0.268, batch=228 
275: loss=1.109, reward_mean=0.050, reward_bound=0.314, batch=225 
276: loss=1.108, reward_mean=0.060, reward_bound=0.349, batch=225 
277: loss=1.106, reward_mean=0.030, reward_bound=0.356, batch=227 
278: loss=1.105, reward_mean=0.080, reward_bound=0.349, batch=228 
279: loss=1.106, reward_mean=0.030, reward_bound=0.234, batch=229 
280: loss=1.107, reward_mean=0.080, reward_bound=0.364, batch=230 
281: loss=1.107, reward_mean=0.110, reward_bound=0.387, batch=225 
282: loss=1.106, reward_mean=0.060, reward_bound=0.337, batch=227 
283: loss=1.105, reward_mean=0.030, reward_bound=0.288, batch=229 
284: loss=1.106, reward_mean=0.030, reward_bound=0.249, batch=230 
285: loss=1.106, reward_mean=0.000, reward_bound=0.000, batch=230 
286: loss=1.107, reward_mean=0.030, reward_bound=0.304, batch=231 
287: loss=1.105, reward_mean=0.070, reward_bound=0.314, batch=230 
288: loss=1.105, reward_mean=0.060, reward_bound=0.418, batch=231 
289: loss=1.094, reward_mean=0.060, reward_bound=0.430, batch=137 
290: loss=1.091, reward_mean=0.040, reward_bound=0.000, batch=141 
291: loss=1.095, reward_mean=0.050, reward_bound=0.000, batch=146 
292: loss=1.096, reward_mean=0.050, reward_bound=0.000, batch=151 
293: loss=1.098, reward_mean=0.040, reward_bound=0.000, batch=155 
294: loss=1.095, reward_mean=0.030, reward_bound=0.000, batch=158 
295: loss=1.095, reward_mean=0.040, reward_bound=0.000, batch=162 
296: loss=1.089, reward_mean=0.070, reward_bound=0.000, batch=169 
297: loss=1.091, reward_mean=0.080, reward_bound=0.000, batch=177 
298: loss=1.085, reward_mean=0.050, reward_bound=0.000, batch=182 
299: loss=1.088, reward_mean=0.060, reward_bound=0.000, batch=188 
300: loss=1.087, reward_mean=0.070, reward_bound=0.000, batch=195 
301: loss=1.090, reward_mean=0.050, reward_bound=0.000, batch=200 
302: loss=1.083, reward_mean=0.100, reward_bound=0.037, batch=210 
303: loss=1.083, reward_mean=0.060, reward_bound=0.000, batch=216 
304: loss=1.081, reward_mean=0.030, reward_bound=0.000, batch=219 
305: loss=1.082, reward_mean=0.050, reward_bound=0.060, batch=223 
306: loss=1.090, reward_mean=0.070, reward_bound=0.091, batch=226 
307: loss=1.089, reward_mean=0.020, reward_bound=0.049, batch=228 
308: loss=1.086, reward_mean=0.040, reward_bound=0.101, batch=229 
309: loss=1.083, reward_mean=0.050, reward_bound=0.135, batch=229 
310: loss=1.076, reward_mean=0.050, reward_bound=0.150, batch=228 
311: loss=1.081, reward_mean=0.050, reward_bound=0.185, batch=223 
312: loss=1.083, reward_mean=0.060, reward_bound=0.206, batch=223 
313: loss=1.084, reward_mean=0.040, reward_bound=0.166, batch=226 
314: loss=1.079, reward_mean=0.040, reward_bound=0.229, batch=221 
315: loss=1.080, reward_mean=0.070, reward_bound=0.254, batch=215 
316: loss=1.080, reward_mean=0.070, reward_bound=0.210, batch=220 
317: loss=1.080, reward_mean=0.070, reward_bound=0.229, batch=223 
318: loss=1.077, reward_mean=0.040, reward_bound=0.198, batch=226 
319: loss=1.075, reward_mean=0.090, reward_bound=0.282, batch=217 
320: loss=1.074, reward_mean=0.050, reward_bound=0.183, batch=222 
321: loss=1.072, reward_mean=0.040, reward_bound=0.245, batch=225 
322: loss=1.073, reward_mean=0.030, reward_bound=0.282, batch=226 
323: loss=1.075, reward_mean=0.110, reward_bound=0.314, batch=221 
324: loss=1.075, reward_mean=0.020, reward_bound=0.000, batch=223 
325: loss=1.073, reward_mean=0.070, reward_bound=0.178, batch=226 
326: loss=1.076, reward_mean=0.070, reward_bound=0.271, batch=228 
327: loss=1.076, reward_mean=0.050, reward_bound=0.349, batch=208 
328: loss=1.074, reward_mean=0.070, reward_bound=0.008, batch=215 
329: loss=1.075, reward_mean=0.060, reward_bound=0.082, batch=220 
330: loss=1.072, reward_mean=0.030, reward_bound=0.000, batch=223 
331: loss=1.075, reward_mean=0.130, reward_bound=0.254, batch=225 
332: loss=1.075, reward_mean=0.080, reward_bound=0.296, batch=227 
333: loss=1.072, reward_mean=0.070, reward_bound=0.349, batch=226 
334: loss=1.073, reward_mean=0.060, reward_bound=0.282, batch=227 
335: loss=1.085, reward_mean=0.080, reward_bound=0.387, batch=201 
336: loss=1.086, reward_mean=0.030, reward_bound=0.000, batch=204 
337: loss=1.075, reward_mean=0.090, reward_bound=0.122, batch=213 
338: loss=1.073, reward_mean=0.040, reward_bound=0.000, batch=217 
339: loss=1.069, reward_mean=0.070, reward_bound=0.147, batch=222 
340: loss=1.072, reward_mean=0.060, reward_bound=0.167, batch=223 
341: loss=1.074, reward_mean=0.080, reward_bound=0.244, batch=226 
342: loss=1.070, reward_mean=0.110, reward_bound=0.298, batch=228 
343: loss=1.071, reward_mean=0.050, reward_bound=0.314, batch=226 
344: loss=1.071, reward_mean=0.120, reward_bound=0.349, batch=224 
345: loss=1.071, reward_mean=0.070, reward_bound=0.282, batch=226 
346: loss=1.069, reward_mean=0.030, reward_bound=0.349, batch=226 
347: loss=1.068, reward_mean=0.070, reward_bound=0.351, batch=228 
348: loss=1.077, reward_mean=0.060, reward_bound=0.387, batch=218 
349: loss=1.077, reward_mean=0.120, reward_bound=0.353, batch=222 
350: loss=1.076, reward_mean=0.060, reward_bound=0.236, batch=225 
351: loss=1.075, reward_mean=0.060, reward_bound=0.289, batch=227 
352: loss=1.075, reward_mean=0.040, reward_bound=0.245, batch=229 
353: loss=1.074, reward_mean=0.040, reward_bound=0.239, batch=230 
354: loss=1.074, reward_mean=0.070, reward_bound=0.349, batch=230 
355: loss=1.074, reward_mean=0.060, reward_bound=0.387, batch=227 
356: loss=1.075, reward_mean=0.090, reward_bound=0.229, batch=228 
357: loss=1.073, reward_mean=0.060, reward_bound=0.282, batch=228 
358: loss=1.081, reward_mean=0.030, reward_bound=0.430, batch=194 
359: loss=1.080, reward_mean=0.050, reward_bound=0.000, batch=199 
360: loss=1.078, reward_mean=0.100, reward_bound=0.026, batch=209 
361: loss=1.080, reward_mean=0.050, reward_bound=0.000, batch=214 
362: loss=1.076, reward_mean=0.080, reward_bound=0.105, batch=220 
363: loss=1.067, reward_mean=0.120, reward_bound=0.185, batch=221 
364: loss=1.067, reward_mean=0.050, reward_bound=0.150, batch=224 
365: loss=1.068, reward_mean=0.040, reward_bound=0.206, batch=226 
366: loss=1.073, reward_mean=0.040, reward_bound=0.229, batch=224 
367: loss=1.071, reward_mean=0.070, reward_bound=0.280, batch=227 
368: loss=1.072, reward_mean=0.080, reward_bound=0.282, batch=224 
369: loss=1.073, reward_mean=0.080, reward_bound=0.305, batch=227 
370: loss=1.073, reward_mean=0.030, reward_bound=0.230, batch=229 
371: loss=1.073, reward_mean=0.030, reward_bound=0.278, batch=230 
372: loss=1.073, reward_mean=0.050, reward_bound=0.314, batch=225 
373: loss=1.076, reward_mean=0.080, reward_bound=0.349, batch=221 
374: loss=1.079, reward_mean=0.060, reward_bound=0.206, batch=223 
375: loss=1.077, reward_mean=0.080, reward_bound=0.349, batch=225 
376: loss=1.072, reward_mean=0.070, reward_bound=0.387, batch=219 
377: loss=1.072, reward_mean=0.080, reward_bound=0.239, batch=223 
378: loss=1.076, reward_mean=0.020, reward_bound=0.000, batch=225 
379: loss=1.073, reward_mean=0.060, reward_bound=0.254, batch=226 
380: loss=1.069, reward_mean=0.080, reward_bound=0.349, batch=226 
381: loss=1.071, reward_mean=0.050, reward_bound=0.335, batch=228 
382: loss=1.071, reward_mean=0.050, reward_bound=0.293, batch=229 
383: loss=1.069, reward_mean=0.060, reward_bound=0.387, batch=229 
384: loss=1.070, reward_mean=0.040, reward_bound=0.405, batch=230 
385: loss=1.072, reward_mean=0.030, reward_bound=0.418, batch=231 
386: loss=1.075, reward_mean=0.130, reward_bound=0.430, batch=217 
387: loss=1.078, reward_mean=0.030, reward_bound=0.000, batch=220 
388: loss=1.074, reward_mean=0.070, reward_bound=0.247, batch=224 
389: loss=1.077, reward_mean=0.040, reward_bound=0.254, batch=226 
390: loss=1.076, reward_mean=0.020, reward_bound=0.127, batch=228 
391: loss=1.076, reward_mean=0.040, reward_bound=0.254, batch=228 
392: loss=1.076, reward_mean=0.030, reward_bound=0.282, batch=228 
393: loss=1.075, reward_mean=0.040, reward_bound=0.349, batch=226 
394: loss=1.077, reward_mean=0.060, reward_bound=0.387, batch=224 
395: loss=1.077, reward_mean=0.100, reward_bound=0.426, batch=227 
396: loss=1.077, reward_mean=0.070, reward_bound=0.308, batch=229 
397: loss=1.076, reward_mean=0.060, reward_bound=0.360, batch=230 
398: loss=1.075, reward_mean=0.050, reward_bound=0.430, batch=224 
399: loss=1.073, reward_mean=0.110, reward_bound=0.282, batch=226 
400: loss=1.073, reward_mean=0.060, reward_bound=0.349, batch=227 
401: loss=1.071, reward_mean=0.050, reward_bound=0.267, batch=229 
402: loss=1.073, reward_mean=0.080, reward_bound=0.381, batch=230 
403: loss=1.078, reward_mean=0.030, reward_bound=0.157, batch=231 
404: loss=1.076, reward_mean=0.090, reward_bound=0.430, batch=229 
405: loss=1.076, reward_mean=0.050, reward_bound=0.478, batch=231 
406: loss=1.053, reward_mean=0.050, reward_bound=0.478, batch=103 
407: loss=1.054, reward_mean=0.040, reward_bound=0.000, batch=107 
408: loss=1.055, reward_mean=0.060, reward_bound=0.000, batch=113 
409: loss=1.058, reward_mean=0.060, reward_bound=0.000, batch=119 
410: loss=1.057, reward_mean=0.060, reward_bound=0.000, batch=125 
411: loss=1.053, reward_mean=0.040, reward_bound=0.000, batch=129 
412: loss=1.056, reward_mean=0.040, reward_bound=0.000, batch=133 
413: loss=1.056, reward_mean=0.040, reward_bound=0.000, batch=137 
414: loss=1.052, reward_mean=0.050, reward_bound=0.000, batch=142 
415: loss=1.058, reward_mean=0.090, reward_bound=0.000, batch=151 
416: loss=1.061, reward_mean=0.040, reward_bound=0.000, batch=155 
417: loss=1.064, reward_mean=0.030, reward_bound=0.000, batch=158 
418: loss=1.060, reward_mean=0.050, reward_bound=0.000, batch=163 
419: loss=1.058, reward_mean=0.030, reward_bound=0.000, batch=166 
420: loss=1.059, reward_mean=0.040, reward_bound=0.000, batch=170 
421: loss=1.060, reward_mean=0.060, reward_bound=0.000, batch=176 
422: loss=1.060, reward_mean=0.030, reward_bound=0.000, batch=179 
423: loss=1.059, reward_mean=0.050, reward_bound=0.000, batch=184 
424: loss=1.058, reward_mean=0.050, reward_bound=0.000, batch=189 
425: loss=1.057, reward_mean=0.040, reward_bound=0.000, batch=193 
426: loss=1.057, reward_mean=0.040, reward_bound=0.000, batch=197 
427: loss=1.060, reward_mean=0.040, reward_bound=0.000, batch=201 
428: loss=1.061, reward_mean=0.060, reward_bound=0.000, batch=207 
429: loss=1.057, reward_mean=0.090, reward_bound=0.051, batch=215 
430: loss=1.060, reward_mean=0.080, reward_bound=0.091, batch=220 
431: loss=1.058, reward_mean=0.060, reward_bound=0.118, batch=224 
432: loss=1.058, reward_mean=0.030, reward_bound=0.109, batch=227 
433: loss=1.057, reward_mean=0.060, reward_bound=0.132, batch=229 
434: loss=1.054, reward_mean=0.070, reward_bound=0.141, batch=230 
435: loss=1.047, reward_mean=0.080, reward_bound=0.167, batch=228 
436: loss=1.046, reward_mean=0.060, reward_bound=0.185, batch=228 
437: loss=1.043, reward_mean=0.070, reward_bound=0.206, batch=228 
438: loss=1.043, reward_mean=0.070, reward_bound=0.229, batch=221 
439: loss=1.037, reward_mean=0.090, reward_bound=0.254, batch=217 
440: loss=1.040, reward_mean=0.020, reward_bound=0.000, batch=219 
441: loss=1.040, reward_mean=0.050, reward_bound=0.087, batch=223 
442: loss=1.040, reward_mean=0.080, reward_bound=0.178, batch=226 
443: loss=1.036, reward_mean=0.070, reward_bound=0.241, batch=228 
444: loss=1.035, reward_mean=0.020, reward_bound=0.208, batch=229 
445: loss=1.026, reward_mean=0.060, reward_bound=0.282, batch=216 
446: loss=1.025, reward_mean=0.090, reward_bound=0.314, batch=205 
447: loss=1.025, reward_mean=0.110, reward_bound=0.194, batch=213 
448: loss=1.025, reward_mean=0.020, reward_bound=0.000, batch=215 
449: loss=1.024, reward_mean=0.110, reward_bound=0.260, batch=220 
450: loss=1.024, reward_mean=0.040, reward_bound=0.198, batch=224 
451: loss=1.025, reward_mean=0.080, reward_bound=0.311, batch=227 
452: loss=1.026, reward_mean=0.090, reward_bound=0.314, batch=226 
453: loss=1.024, reward_mean=0.060, reward_bound=0.349, batch=205 
454: loss=1.019, reward_mean=0.070, reward_bound=0.000, batch=212 
455: loss=1.019, reward_mean=0.060, reward_bound=0.007, batch=218 
456: loss=1.017, reward_mean=0.060, reward_bound=0.073, batch=222 
457: loss=1.014, reward_mean=0.100, reward_bound=0.229, batch=225 
458: loss=1.012, reward_mean=0.040, reward_bound=0.282, batch=226 
459: loss=1.010, reward_mean=0.050, reward_bound=0.284, batch=228 
460: loss=1.010, reward_mean=0.070, reward_bound=0.314, batch=226 
461: loss=1.010, reward_mean=0.040, reward_bound=0.289, batch=228 
462: loss=1.012, reward_mean=0.060, reward_bound=0.349, batch=226 
463: loss=1.012, reward_mean=0.050, reward_bound=0.331, batch=228 
464: loss=1.019, reward_mean=0.070, reward_bound=0.387, batch=186 
465: loss=1.017, reward_mean=0.060, reward_bound=0.000, batch=192 
466: loss=1.017, reward_mean=0.030, reward_bound=0.000, batch=195 
467: loss=1.022, reward_mean=0.040, reward_bound=0.000, batch=199 
468: loss=1.020, reward_mean=0.030, reward_bound=0.000, batch=202 
469: loss=1.022, reward_mean=0.070, reward_bound=0.000, batch=209 
470: loss=1.023, reward_mean=0.040, reward_bound=0.000, batch=213 
471: loss=1.017, reward_mean=0.050, reward_bound=0.000, batch=218 
472: loss=1.014, reward_mean=0.040, reward_bound=0.002, batch=222 
473: loss=1.012, reward_mean=0.080, reward_bound=0.109, batch=225 
474: loss=1.011, reward_mean=0.020, reward_bound=0.027, batch=227 
475: loss=1.010, reward_mean=0.080, reward_bound=0.185, batch=227 
476: loss=1.015, reward_mean=0.130, reward_bound=0.229, batch=226 
477: loss=1.015, reward_mean=0.040, reward_bound=0.153, batch=228 
478: loss=1.011, reward_mean=0.040, reward_bound=0.211, batch=229 
479: loss=1.013, reward_mean=0.070, reward_bound=0.254, batch=227 
480: loss=1.016, reward_mean=0.110, reward_bound=0.282, batch=224 
481: loss=1.017, reward_mean=0.030, reward_bound=0.089, batch=227 
482: loss=1.018, reward_mean=0.040, reward_bound=0.098, batch=228 
483: loss=1.017, reward_mean=0.030, reward_bound=0.260, batch=229 
484: loss=1.020, reward_mean=0.050, reward_bound=0.314, batch=224 
485: loss=1.017, reward_mean=0.080, reward_bound=0.349, batch=221 
486: loss=1.016, reward_mean=0.100, reward_bound=0.254, batch=224 
487: loss=1.017, reward_mean=0.040, reward_bound=0.271, batch=227 
488: loss=1.013, reward_mean=0.070, reward_bound=0.380, batch=229 
489: loss=1.012, reward_mean=0.060, reward_bound=0.387, batch=215 
490: loss=1.013, reward_mean=0.090, reward_bound=0.234, batch=220 
491: loss=1.011, reward_mean=0.050, reward_bound=0.228, batch=224 
492: loss=1.010, reward_mean=0.080, reward_bound=0.252, batch=227 
493: loss=1.008, reward_mean=0.070, reward_bound=0.277, batch=229 
494: loss=1.009, reward_mean=0.030, reward_bound=0.295, batch=230 
495: loss=1.007, reward_mean=0.050, reward_bound=0.349, batch=226 
496: loss=1.007, reward_mean=0.090, reward_bound=0.387, batch=225 
497: loss=1.007, reward_mean=0.060, reward_bound=0.289, batch=227 
498: loss=1.006, reward_mean=0.020, reward_bound=0.148, batch=229 
499: loss=1.005, reward_mean=0.070, reward_bound=0.328, batch=230 
500: loss=1.007, reward_mean=0.090, reward_bound=0.349, batch=230 
501: loss=1.007, reward_mean=0.050, reward_bound=0.376, batch=231 
502: loss=1.017, reward_mean=0.100, reward_bound=0.430, batch=182 
503: loss=1.016, reward_mean=0.070, reward_bound=0.000, batch=189 
504: loss=1.017, reward_mean=0.030, reward_bound=0.000, batch=192 
505: loss=1.018, reward_mean=0.040, reward_bound=0.000, batch=196 
506: loss=1.014, reward_mean=0.040, reward_bound=0.000, batch=200 
507: loss=1.012, reward_mean=0.080, reward_bound=0.000, batch=208 
508: loss=1.010, reward_mean=0.060, reward_bound=0.000, batch=214 
509: loss=1.011, reward_mean=0.060, reward_bound=0.031, batch=220 
510: loss=1.011, reward_mean=0.080, reward_bound=0.070, batch=224 
511: loss=1.011, reward_mean=0.040, reward_bound=0.096, batch=227 
512: loss=1.011, reward_mean=0.000, reward_bound=0.000, batch=227 
513: loss=1.004, reward_mean=0.090, reward_bound=0.185, batch=228 
514: loss=1.011, reward_mean=0.090, reward_bound=0.254, batch=228 
515: loss=1.016, reward_mean=0.050, reward_bound=0.282, batch=224 
516: loss=1.014, reward_mean=0.040, reward_bound=0.280, batch=227 
517: loss=1.011, reward_mean=0.030, reward_bound=0.277, batch=229 
518: loss=1.012, reward_mean=0.050, reward_bound=0.282, batch=228 
519: loss=1.007, reward_mean=0.090, reward_bound=0.314, batch=226 
520: loss=1.008, reward_mean=0.090, reward_bound=0.349, batch=220 
521: loss=1.009, reward_mean=0.040, reward_bound=0.095, batch=224 
522: loss=1.007, reward_mean=0.040, reward_bound=0.128, batch=227 
523: loss=1.003, reward_mean=0.070, reward_bound=0.314, batch=228 
524: loss=1.004, reward_mean=0.060, reward_bound=0.353, batch=229 
525: loss=1.005, reward_mean=0.040, reward_bound=0.343, batch=230 
526: loss=1.004, reward_mean=0.040, reward_bound=0.340, batch=231 
527: loss=1.009, reward_mean=0.040, reward_bound=0.387, batch=219 
528: loss=1.007, reward_mean=0.080, reward_bound=0.349, batch=222 
529: loss=1.004, reward_mean=0.050, reward_bound=0.314, batch=225 
530: loss=1.005, reward_mean=0.060, reward_bound=0.387, batch=223 
531: loss=1.005, reward_mean=0.040, reward_bound=0.144, batch=226 
532: loss=1.004, reward_mean=0.040, reward_bound=0.268, batch=228 
533: loss=1.004, reward_mean=0.070, reward_bound=0.314, batch=228 
534: loss=1.005, reward_mean=0.010, reward_bound=0.028, batch=229 
535: loss=1.007, reward_mean=0.010, reward_bound=0.113, batch=230 
536: loss=1.003, reward_mean=0.060, reward_bound=0.314, batch=230 
537: loss=1.003, reward_mean=0.050, reward_bound=0.376, batch=231 
538: loss=1.005, reward_mean=0.050, reward_bound=0.387, batch=231 
539: loss=1.009, reward_mean=0.050, reward_bound=0.430, batch=208 
540: loss=1.007, reward_mean=0.030, reward_bound=0.000, batch=211 
541: loss=1.004, reward_mean=0.030, reward_bound=0.000, batch=214 
542: loss=0.999, reward_mean=0.070, reward_bound=0.120, batch=220 
543: loss=1.000, reward_mean=0.020, reward_bound=0.000, batch=222 
544: loss=1.001, reward_mean=0.070, reward_bound=0.150, batch=224 
545: loss=1.003, reward_mean=0.010, reward_bound=0.000, batch=225 
546: loss=1.006, reward_mean=0.080, reward_bound=0.289, batch=227 
547: loss=1.006, reward_mean=0.050, reward_bound=0.282, batch=228 
548: loss=1.001, reward_mean=0.030, reward_bound=0.314, batch=224 
549: loss=1.000, reward_mean=0.040, reward_bound=0.182, batch=227 
550: loss=1.003, reward_mean=0.040, reward_bound=0.202, batch=229 
551: loss=1.003, reward_mean=0.030, reward_bound=0.215, batch=230 
552: loss=1.000, reward_mean=0.060, reward_bound=0.338, batch=231 
553: loss=1.003, reward_mean=0.030, reward_bound=0.349, batch=227 
554: loss=1.003, reward_mean=0.060, reward_bound=0.387, batch=224 
555: loss=1.005, reward_mean=0.050, reward_bound=0.252, batch=227 
556: loss=1.005, reward_mean=0.090, reward_bound=0.422, batch=229 
557: loss=1.005, reward_mean=0.050, reward_bound=0.430, batch=219 
558: loss=1.004, reward_mean=0.010, reward_bound=0.000, batch=220 
559: loss=1.008, reward_mean=0.020, reward_bound=0.000, batch=222 
560: loss=1.009, reward_mean=0.010, reward_bound=0.000, batch=223 
561: loss=1.005, reward_mean=0.060, reward_bound=0.235, batch=226 
562: loss=1.004, reward_mean=0.060, reward_bound=0.349, batch=226 
563: loss=1.005, reward_mean=0.050, reward_bound=0.335, batch=228 
564: loss=1.004, reward_mean=0.060, reward_bound=0.387, batch=227 
565: loss=1.003, reward_mean=0.030, reward_bound=0.284, batch=229 
566: loss=1.003, reward_mean=0.030, reward_bound=0.314, batch=229 
567: loss=1.003, reward_mean=0.050, reward_bound=0.387, batch=228 
568: loss=1.002, reward_mean=0.040, reward_bound=0.430, batch=227 
569: loss=1.002, reward_mean=0.080, reward_bound=0.387, batch=227 
570: loss=1.001, reward_mean=0.050, reward_bound=0.422, batch=229 
571: loss=1.001, reward_mean=0.050, reward_bound=0.314, batch=229 
572: loss=1.003, reward_mean=0.050, reward_bound=0.450, batch=230 
573: loss=1.003, reward_mean=0.090, reward_bound=0.464, batch=231 
574: loss=1.003, reward_mean=0.070, reward_bound=0.430, batch=231 
575: loss=1.016, reward_mean=0.050, reward_bound=0.478, batch=156 
576: loss=1.024, reward_mean=0.120, reward_bound=0.000, batch=168 
577: loss=1.021, reward_mean=0.070, reward_bound=0.000, batch=175 
578: loss=1.017, reward_mean=0.030, reward_bound=0.000, batch=178 
579: loss=1.014, reward_mean=0.020, reward_bound=0.000, batch=180 
580: loss=1.016, reward_mean=0.030, reward_bound=0.000, batch=183 
581: loss=1.015, reward_mean=0.020, reward_bound=0.000, batch=185 
582: loss=1.014, reward_mean=0.030, reward_bound=0.000, batch=188 
583: loss=1.009, reward_mean=0.030, reward_bound=0.000, batch=191 
584: loss=1.009, reward_mean=0.000, reward_bound=0.000, batch=191 
585: loss=1.012, reward_mean=0.050, reward_bound=0.000, batch=196 
586: loss=1.009, reward_mean=0.050, reward_bound=0.000, batch=201 
587: loss=1.011, reward_mean=0.070, reward_bound=0.000, batch=208 
588: loss=1.010, reward_mean=0.070, reward_bound=0.004, batch=215 
589: loss=1.004, reward_mean=0.080, reward_bound=0.068, batch=220 
590: loss=0.996, reward_mean=0.100, reward_bound=0.150, batch=219 
591: loss=1.001, reward_mean=0.110, reward_bound=0.206, batch=220 
592: loss=0.998, reward_mean=0.040, reward_bound=0.130, batch=224 
593: loss=0.997, reward_mean=0.020, reward_bound=0.000, batch=226 
594: loss=0.998, reward_mean=0.050, reward_bound=0.196, batch=228 
595: loss=1.000, reward_mean=0.100, reward_bound=0.231, batch=229 
596: loss=1.001, reward_mean=0.040, reward_bound=0.254, batch=223 
597: loss=1.000, reward_mean=0.040, reward_bound=0.261, batch=226 
598: loss=1.003, reward_mean=0.070, reward_bound=0.282, batch=222 
599: loss=1.002, reward_mean=0.050, reward_bound=0.135, batch=225 
600: loss=1.002, reward_mean=0.050, reward_bound=0.266, batch=227 
601: loss=1.002, reward_mean=0.020, reward_bound=0.183, batch=229 
602: loss=1.003, reward_mean=0.040, reward_bound=0.263, batch=230 
603: loss=1.009, reward_mean=0.060, reward_bound=0.314, batch=221 
604: loss=1.014, reward_mean=0.070, reward_bound=0.206, batch=224 
605: loss=1.018, reward_mean=0.090, reward_bound=0.311, batch=227 
606: loss=1.020, reward_mean=0.080, reward_bound=0.308, batch=229 
607: loss=1.018, reward_mean=0.040, reward_bound=0.265, batch=230 
608: loss=1.019, reward_mean=0.070, reward_bound=0.282, batch=230 
609: loss=1.018, reward_mean=0.080, reward_bound=0.314, batch=228 
610: loss=1.014, reward_mean=0.060, reward_bound=0.349, batch=217 
611: loss=1.013, reward_mean=0.090, reward_bound=0.254, batch=220 
612: loss=1.013, reward_mean=0.080, reward_bound=0.349, batch=223 
613: loss=1.015, reward_mean=0.050, reward_bound=0.358, batch=226 
614: loss=1.015, reward_mean=0.040, reward_bound=0.297, batch=228 
615: loss=1.014, reward_mean=0.080, reward_bound=0.353, batch=229 
616: loss=1.014, reward_mean=0.040, reward_bound=0.295, batch=230 
617: loss=1.013, reward_mean=0.080, reward_bound=0.365, batch=231 
618: loss=1.012, reward_mean=0.030, reward_bound=0.387, batch=206 
619: loss=1.021, reward_mean=0.080, reward_bound=0.044, batch=214 
620: loss=1.023, reward_mean=0.070, reward_bound=0.107, batch=220 
621: loss=1.019, reward_mean=0.100, reward_bound=0.180, batch=224 
622: loss=1.019, reward_mean=0.060, reward_bound=0.185, batch=226 
623: loss=1.016, reward_mean=0.070, reward_bound=0.241, batch=228 
624: loss=1.014, reward_mean=0.030, reward_bound=0.211, batch=229 
625: loss=1.013, reward_mean=0.060, reward_bound=0.254, batch=229 
626: loss=1.013, reward_mean=0.030, reward_bound=0.282, batch=229 
627: loss=1.010, reward_mean=0.090, reward_bound=0.314, batch=225 
628: loss=1.008, reward_mean=0.040, reward_bound=0.321, batch=227 
629: loss=1.009, reward_mean=0.080, reward_bound=0.314, batch=228 
630: loss=1.008, reward_mean=0.040, reward_bound=0.289, batch=229 
631: loss=1.006, reward_mean=0.070, reward_bound=0.349, batch=227 
632: loss=1.006, reward_mean=0.080, reward_bound=0.314, batch=227 
633: loss=1.005, reward_mean=0.050, reward_bound=0.249, batch=229 
634: loss=1.004, reward_mean=0.080, reward_bound=0.364, batch=230 
635: loss=1.005, reward_mean=0.110, reward_bound=0.387, batch=221 
636: loss=1.004, reward_mean=0.050, reward_bound=0.282, batch=223 
637: loss=1.002, reward_mean=0.030, reward_bound=0.169, batch=226 
638: loss=1.003, reward_mean=0.080, reward_bound=0.331, batch=228 
639: loss=1.003, reward_mean=0.070, reward_bound=0.392, batch=229 
640: loss=1.013, reward_mean=0.060, reward_bound=0.430, batch=197 
641: loss=1.011, reward_mean=0.060, reward_bound=0.000, batch=203 
642: loss=1.014, reward_mean=0.010, reward_bound=0.000, batch=204 
643: loss=1.011, reward_mean=0.040, reward_bound=0.000, batch=208 
644: loss=1.009, reward_mean=0.030, reward_bound=0.000, batch=211 
645: loss=1.008, reward_mean=0.010, reward_bound=0.000, batch=212 
646: loss=1.005, reward_mean=0.090, reward_bound=0.193, batch=218 
647: loss=1.002, reward_mean=0.060, reward_bound=0.144, batch=222 
648: loss=1.002, reward_mean=0.080, reward_bound=0.198, batch=225 
649: loss=1.007, reward_mean=0.060, reward_bound=0.254, batch=225 
650: loss=1.010, reward_mean=0.100, reward_bound=0.314, batch=223 
651: loss=1.011, reward_mean=0.060, reward_bound=0.322, batch=226 
652: loss=1.008, reward_mean=0.100, reward_bound=0.349, batch=222 
653: loss=1.007, reward_mean=0.050, reward_bound=0.314, batch=224 
654: loss=1.007, reward_mean=0.060, reward_bound=0.345, batch=227 
655: loss=1.008, reward_mean=0.070, reward_bound=0.342, batch=229 
656: loss=1.008, reward_mean=0.060, reward_bound=0.364, batch=230 
657: loss=1.012, reward_mean=0.090, reward_bound=0.387, batch=217 
658: loss=1.011, reward_mean=0.070, reward_bound=0.256, batch=222 
659: loss=1.010, reward_mean=0.050, reward_bound=0.191, batch=225 
660: loss=1.006, reward_mean=0.090, reward_bound=0.314, batch=226 
661: loss=1.002, reward_mean=0.080, reward_bound=0.349, batch=226 
662: loss=1.002, reward_mean=0.040, reward_bound=0.349, batch=227 
663: loss=1.005, reward_mean=0.080, reward_bound=0.387, batch=226 
664: loss=1.003, reward_mean=0.060, reward_bound=0.316, batch=228 
665: loss=1.003, reward_mean=0.060, reward_bound=0.357, batch=229 
666: loss=1.003, reward_mean=0.120, reward_bound=0.405, batch=230 
667: loss=1.005, reward_mean=0.080, reward_bound=0.418, batch=231 
668: loss=1.008, reward_mean=0.050, reward_bound=0.430, batch=215 
669: loss=1.010, reward_mean=0.070, reward_bound=0.149, batch=220 
670: loss=1.005, reward_mean=0.110, reward_bound=0.338, batch=224 
671: loss=1.005, reward_mean=0.040, reward_bound=0.197, batch=227 
672: loss=1.005, reward_mean=0.060, reward_bound=0.302, batch=229 
673: loss=1.005, reward_mean=0.040, reward_bound=0.278, batch=230 
674: loss=1.006, reward_mean=0.020, reward_bound=0.296, batch=231 
675: loss=1.007, reward_mean=0.070, reward_bound=0.349, batch=231 
676: loss=1.005, reward_mean=0.060, reward_bound=0.387, batch=223 
677: loss=1.003, reward_mean=0.060, reward_bound=0.280, batch=226 
678: loss=1.001, reward_mean=0.060, reward_bound=0.282, batch=227 
679: loss=1.006, reward_mean=0.050, reward_bound=0.387, batch=227 
680: loss=1.006, reward_mean=0.060, reward_bound=0.380, batch=229 
681: loss=1.005, reward_mean=0.040, reward_bound=0.309, batch=230 
682: loss=1.005, reward_mean=0.050, reward_bound=0.376, batch=231 
683: loss=1.006, reward_mean=0.030, reward_bound=0.387, batch=229 
684: loss=1.008, reward_mean=0.070, reward_bound=0.430, batch=221 
685: loss=1.008, reward_mean=0.030, reward_bound=0.000, batch=224 
686: loss=1.010, reward_mean=0.060, reward_bound=0.247, batch=227 
687: loss=1.009, reward_mean=0.100, reward_bound=0.302, batch=229 
688: loss=1.011, reward_mean=0.040, reward_bound=0.194, batch=230 
689: loss=1.010, reward_mean=0.080, reward_bound=0.338, batch=231 
690: loss=1.008, reward_mean=0.110, reward_bound=0.387, batch=230 
691: loss=1.008, reward_mean=0.040, reward_bound=0.304, batch=231 
692: loss=1.009, reward_mean=0.080, reward_bound=0.430, batch=226 
693: loss=1.009, reward_mean=0.100, reward_bound=0.349, batch=227 
694: loss=1.011, reward_mean=0.090, reward_bound=0.380, batch=229 
695: loss=1.012, reward_mean=0.020, reward_bound=0.364, batch=230 
696: loss=1.012, reward_mean=0.050, reward_bound=0.228, batch=231 
697: loss=1.008, reward_mean=0.050, reward_bound=0.387, batch=229 
698: loss=1.008, reward_mean=0.080, reward_bound=0.430, batch=229 
699: loss=1.008, reward_mean=0.040, reward_bound=0.380, batch=230 
700: loss=1.008, reward_mean=0.050, reward_bound=0.304, batch=231 
701: loss=1.009, reward_mean=0.080, reward_bound=0.430, batch=231 
702: loss=1.009, reward_mean=0.090, reward_bound=0.387, batch=231 
703: loss=1.009, reward_mean=0.030, reward_bound=0.349, batch=231 
704: loss=1.009, reward_mean=0.010, reward_bound=0.185, batch=231 
705: loss=1.004, reward_mean=0.050, reward_bound=0.478, batch=189 
706: loss=1.003, reward_mean=0.040, reward_bound=0.000, batch=193 
707: loss=1.009, reward_mean=0.070, reward_bound=0.000, batch=200 
708: loss=1.005, reward_mean=0.080, reward_bound=0.000, batch=208 
709: loss=1.005, reward_mean=0.090, reward_bound=0.100, batch=215 
710: loss=1.008, reward_mean=0.050, reward_bound=0.022, batch=220 
711: loss=1.006, reward_mean=0.060, reward_bound=0.106, batch=224 
712: loss=1.005, reward_mean=0.060, reward_bound=0.135, batch=226 
713: loss=1.006, reward_mean=0.110, reward_bound=0.206, batch=226 
714: loss=1.011, reward_mean=0.110, reward_bound=0.254, batch=224 
715: loss=1.013, reward_mean=0.060, reward_bound=0.282, batch=224 
716: loss=1.009, reward_mean=0.070, reward_bound=0.308, batch=227 
717: loss=1.008, reward_mean=0.050, reward_bound=0.308, batch=229 
718: loss=1.008, reward_mean=0.020, reward_bound=0.226, batch=230 
719: loss=1.001, reward_mean=0.070, reward_bound=0.314, batch=222 
720: loss=1.001, reward_mean=0.070, reward_bound=0.292, batch=225 
721: loss=0.999, reward_mean=0.100, reward_bound=0.321, batch=227 
722: loss=1.002, reward_mean=0.060, reward_bound=0.349, batch=223 
723: loss=1.003, reward_mean=0.030, reward_bound=0.066, batch=226 
724: loss=1.002, reward_mean=0.060, reward_bound=0.254, batch=227 
725: loss=1.009, reward_mean=0.080, reward_bound=0.387, batch=221 
726: loss=1.010, reward_mean=0.090, reward_bound=0.314, batch=224 
727: loss=1.006, reward_mean=0.120, reward_bound=0.387, batch=226 
728: loss=1.006, reward_mean=0.100, reward_bound=0.387, batch=227 
729: loss=1.007, reward_mean=0.050, reward_bound=0.422, batch=229 
730: loss=1.007, reward_mean=0.050, reward_bound=0.343, batch=230 
731: loss=1.007, reward_mean=0.070, reward_bound=0.365, batch=231 
732: loss=1.006, reward_mean=0.100, reward_bound=0.387, batch=230 
733: loss=1.007, reward_mean=0.080, reward_bound=0.430, batch=214 
734: loss=1.005, reward_mean=0.130, reward_bound=0.280, batch=220 
735: loss=1.005, reward_mean=0.070, reward_bound=0.282, batch=221 
736: loss=1.004, reward_mean=0.100, reward_bound=0.314, batch=224 
737: loss=1.005, reward_mean=0.050, reward_bound=0.216, batch=227 
738: loss=1.007, reward_mean=0.060, reward_bound=0.349, batch=227 
739: loss=1.007, reward_mean=0.040, reward_bound=0.356, batch=229 
740: loss=1.006, reward_mean=0.030, reward_bound=0.307, batch=230 
741: loss=1.007, reward_mean=0.020, reward_bound=0.274, batch=231 
742: loss=1.005, reward_mean=0.040, reward_bound=0.387, batch=229 
743: loss=1.007, reward_mean=0.040, reward_bound=0.381, batch=230 
744: loss=1.007, reward_mean=0.050, reward_bound=0.314, batch=230 
745: loss=1.007, reward_mean=0.080, reward_bound=0.387, batch=230 
746: loss=1.006, reward_mean=0.060, reward_bound=0.338, batch=231 
747: loss=1.005, reward_mean=0.090, reward_bound=0.430, batch=224 
748: loss=1.004, reward_mean=0.080, reward_bound=0.380, batch=227 
749: loss=1.003, reward_mean=0.030, reward_bound=0.340, batch=229 
750: loss=1.003, reward_mean=0.080, reward_bound=0.478, batch=231 
751: loss=1.002, reward_mean=0.070, reward_bound=0.478, batch=204 
752: loss=1.006, reward_mean=0.090, reward_bound=0.098, batch=213 
753: loss=1.007, reward_mean=0.040, reward_bound=0.000, batch=217 
754: loss=1.004, reward_mean=0.030, reward_bound=0.000, batch=220 
755: loss=1.002, reward_mean=0.060, reward_bound=0.200, batch=224 
756: loss=1.001, reward_mean=0.080, reward_bound=0.252, batch=227 
757: loss=0.999, reward_mean=0.040, reward_bound=0.225, batch=229 
758: loss=1.001, reward_mean=0.040, reward_bound=0.265, batch=230 
759: loss=1.001, reward_mean=0.030, reward_bound=0.266, batch=231 
760: loss=1.001, reward_mean=0.090, reward_bound=0.314, batch=228 
761: loss=0.998, reward_mean=0.070, reward_bound=0.349, batch=227 
762: loss=0.999, reward_mean=0.040, reward_bound=0.277, batch=229 
763: loss=0.998, reward_mean=0.070, reward_bound=0.387, batch=223 
764: loss=0.997, reward_mean=0.080, reward_bound=0.220, batch=226 
765: loss=0.999, reward_mean=0.040, reward_bound=0.178, batch=228 
766: loss=0.996, reward_mean=0.070, reward_bound=0.349, batch=227 
767: loss=0.995, reward_mean=0.100, reward_bound=0.387, batch=227 
768: loss=0.994, reward_mean=0.040, reward_bound=0.351, batch=229 
769: loss=0.995, reward_mean=0.040, reward_bound=0.324, batch=230 
770: loss=0.999, reward_mean=0.070, reward_bound=0.430, batch=222 
771: loss=0.999, reward_mean=0.060, reward_bound=0.302, batch=225 
772: loss=1.000, reward_mean=0.040, reward_bound=0.365, batch=227 
773: loss=0.998, reward_mean=0.050, reward_bound=0.351, batch=229 
774: loss=0.997, reward_mean=0.060, reward_bound=0.343, batch=230 
775: loss=0.997, reward_mean=0.050, reward_bound=0.340, batch=231 
776: loss=0.998, reward_mean=0.050, reward_bound=0.387, batch=230 
777: loss=0.998, reward_mean=0.060, reward_bound=0.314, batch=230 
778: loss=1.001, reward_mean=0.070, reward_bound=0.430, batch=225 
779: loss=1.000, reward_mean=0.070, reward_bound=0.273, batch=227 
780: loss=0.999, reward_mean=0.040, reward_bound=0.335, batch=229 
781: loss=0.998, reward_mean=0.040, reward_bound=0.349, batch=229 
782: loss=1.000, reward_mean=0.060, reward_bound=0.387, batch=227 
783: loss=1.001, reward_mean=0.080, reward_bound=0.414, batch=229 
784: loss=1.001, reward_mean=0.060, reward_bound=0.430, batch=228 
785: loss=1.000, reward_mean=0.070, reward_bound=0.435, batch=229 
786: loss=0.999, reward_mean=0.030, reward_bound=0.292, batch=230 
787: loss=1.001, reward_mean=0.080, reward_bound=0.464, batch=231 
788: loss=1.001, reward_mean=0.050, reward_bound=0.430, batch=231 
789: loss=1.001, reward_mean=0.070, reward_bound=0.430, batch=231 
790: loss=1.001, reward_mean=0.040, reward_bound=0.430, batch=231 
791: loss=1.002, reward_mean=0.040, reward_bound=0.478, batch=215 
792: loss=1.003, reward_mean=0.080, reward_bound=0.189, batch=220 
793: loss=1.001, reward_mean=0.120, reward_bound=0.222, batch=224 
794: loss=1.002, reward_mean=0.060, reward_bound=0.229, batch=226 
795: loss=1.000, reward_mean=0.060, reward_bound=0.282, batch=226 
796: loss=0.999, reward_mean=0.060, reward_bound=0.282, batch=227 
797: loss=1.000, reward_mean=0.080, reward_bound=0.245, batch=229 
798: loss=0.999, reward_mean=0.030, reward_bound=0.254, batch=229 
799: loss=1.000, reward_mean=0.040, reward_bound=0.295, batch=230 
800: loss=1.002, reward_mean=0.070, reward_bound=0.338, batch=231 
801: loss=1.001, reward_mean=0.060, reward_bound=0.349, batch=228 
802: loss=1.000, reward_mean=0.040, reward_bound=0.257, batch=229 
803: loss=1.000, reward_mean=0.070, reward_bound=0.364, batch=230 
804: loss=1.001, reward_mean=0.050, reward_bound=0.387, batch=226 
805: loss=0.999, reward_mean=0.090, reward_bound=0.409, batch=228 
806: loss=1.002, reward_mean=0.090, reward_bound=0.430, batch=224 
807: loss=0.999, reward_mean=0.030, reward_bound=0.314, batch=227 
808: loss=0.998, reward_mean=0.080, reward_bound=0.414, batch=229 
809: loss=1.000, reward_mean=0.120, reward_bound=0.430, batch=228 
810: loss=0.998, reward_mean=0.020, reward_bound=0.268, batch=229 
811: loss=0.998, reward_mean=0.040, reward_bound=0.292, batch=230 
812: loss=0.999, reward_mean=0.070, reward_bound=0.451, batch=231 
813: loss=0.999, reward_mean=0.040, reward_bound=0.387, batch=231 
814: loss=1.000, reward_mean=0.070, reward_bound=0.478, batch=221 
815: loss=0.999, reward_mean=0.070, reward_bound=0.387, batch=224 
816: loss=1.001, reward_mean=0.060, reward_bound=0.419, batch=227 
817: loss=1.000, reward_mean=0.060, reward_bound=0.422, batch=229 
818: loss=1.001, reward_mean=0.020, reward_bound=0.292, batch=230 
819: loss=0.999, reward_mean=0.070, reward_bound=0.430, batch=227 
820: loss=0.999, reward_mean=0.060, reward_bound=0.387, batch=228 
821: loss=1.000, reward_mean=0.040, reward_bound=0.357, batch=229 
822: loss=0.999, reward_mean=0.090, reward_bound=0.405, batch=230 
823: loss=0.998, reward_mean=0.040, reward_bound=0.430, batch=229 
824: loss=0.997, reward_mean=0.050, reward_bound=0.325, batch=230 
825: loss=0.996, reward_mean=0.060, reward_bound=0.418, batch=231 
826: loss=0.998, reward_mean=0.070, reward_bound=0.478, batch=227 
827: loss=0.998, reward_mean=0.090, reward_bound=0.387, batch=227 
828: loss=0.998, reward_mean=0.120, reward_bound=0.430, batch=228 
829: loss=0.999, reward_mean=0.080, reward_bound=0.484, batch=229 
830: loss=0.999, reward_mean=0.040, reward_bound=0.450, batch=230 
831: loss=0.999, reward_mean=0.050, reward_bound=0.429, batch=231 
832: loss=0.999, reward_mean=0.050, reward_bound=0.387, batch=231 
833: loss=0.999, reward_mean=0.040, reward_bound=0.478, batch=229 
834: loss=0.999, reward_mean=0.080, reward_bound=0.471, batch=230 
835: loss=0.999, reward_mean=0.060, reward_bound=0.439, batch=231 
836: loss=0.999, reward_mean=0.100, reward_bound=0.478, batch=230 
837: loss=0.999, reward_mean=0.070, reward_bound=0.501, batch=231 
838: loss=0.999, reward_mean=0.030, reward_bound=0.430, batch=231 
840: loss=0.912, reward_mean=0.060, reward_bound=0.000, batch=6 
841: loss=0.995, reward_mean=0.060, reward_bound=0.000, batch=12 
842: loss=0.981, reward_mean=0.010, reward_bound=0.000, batch=13 
843: loss=0.973, reward_mean=0.030, reward_bound=0.000, batch=16 
844: loss=0.977, reward_mean=0.060, reward_bound=0.000, batch=22 
845: loss=0.953, reward_mean=0.050, reward_bound=0.000, batch=27 
846: loss=0.954, reward_mean=0.040, reward_bound=0.000, batch=31 
847: loss=0.964, reward_mean=0.090, reward_bound=0.000, batch=40 
848: loss=0.946, reward_mean=0.050, reward_bound=0.000, batch=45 
849: loss=0.942, reward_mean=0.040, reward_bound=0.000, batch=49 
850: loss=0.935, reward_mean=0.070, reward_bound=0.000, batch=56 
851: loss=0.920, reward_mean=0.070, reward_bound=0.000, batch=63 
852: loss=0.911, reward_mean=0.090, reward_bound=0.000, batch=72 
853: loss=0.904, reward_mean=0.050, reward_bound=0.000, batch=77 
854: loss=0.908, reward_mean=0.110, reward_bound=0.000, batch=88 
855: loss=0.911, reward_mean=0.060, reward_bound=0.000, batch=94 
856: loss=0.903, reward_mean=0.100, reward_bound=0.000, batch=104 
857: loss=0.903, reward_mean=0.100, reward_bound=0.000, batch=114 
858: loss=0.906, reward_mean=0.080, reward_bound=0.000, batch=122 
859: loss=0.900, reward_mean=0.080, reward_bound=0.000, batch=130 
860: loss=0.892, reward_mean=0.090, reward_bound=0.000, batch=139 
861: loss=0.892, reward_mean=0.130, reward_bound=0.000, batch=152 
862: loss=0.889, reward_mean=0.110, reward_bound=0.000, batch=163 
863: loss=0.891, reward_mean=0.050, reward_bound=0.000, batch=168 
864: loss=0.892, reward_mean=0.130, reward_bound=0.000, batch=181 
865: loss=0.894, reward_mean=0.040, reward_bound=0.000, batch=185 
866: loss=0.893, reward_mean=0.050, reward_bound=0.000, batch=190 
867: loss=0.889, reward_mean=0.100, reward_bound=0.000, batch=200 
868: loss=0.886, reward_mean=0.050, reward_bound=0.000, batch=205 
869: loss=0.883, reward_mean=0.050, reward_bound=0.000, batch=210 
870: loss=0.884, reward_mean=0.130, reward_bound=0.055, batch=217 
871: loss=0.883, reward_mean=0.110, reward_bound=0.072, batch=221 
872: loss=0.883, reward_mean=0.050, reward_bound=0.089, batch=221 
873: loss=0.881, reward_mean=0.060, reward_bound=0.098, batch=222 
874: loss=0.885, reward_mean=0.030, reward_bound=0.033, batch=225 
875: loss=0.892, reward_mean=0.110, reward_bound=0.122, batch=221 
876: loss=0.890, reward_mean=0.110, reward_bound=0.135, batch=219 
877: loss=0.894, reward_mean=0.090, reward_bound=0.150, batch=215 
878: loss=0.892, reward_mean=0.090, reward_bound=0.124, batch=220 
879: loss=0.896, reward_mean=0.070, reward_bound=0.167, batch=215 
880: loss=0.883, reward_mean=0.110, reward_bound=0.185, batch=209 
881: loss=0.884, reward_mean=0.130, reward_bound=0.206, batch=204 
882: loss=0.885, reward_mean=0.090, reward_bound=0.109, batch=213 
883: loss=0.888, reward_mean=0.100, reward_bound=0.220, batch=219 
884: loss=0.887, reward_mean=0.060, reward_bound=0.141, batch=223 
885: loss=0.888, reward_mean=0.060, reward_bound=0.220, batch=226 
886: loss=0.886, reward_mean=0.060, reward_bound=0.229, batch=216 
887: loss=0.886, reward_mean=0.100, reward_bound=0.254, batch=196 
888: loss=0.887, reward_mean=0.050, reward_bound=0.000, batch=201 
889: loss=0.888, reward_mean=0.110, reward_bound=0.229, batch=210 
890: loss=0.888, reward_mean=0.060, reward_bound=0.000, batch=216 
891: loss=0.886, reward_mean=0.140, reward_bound=0.254, batch=220 
892: loss=0.885, reward_mean=0.050, reward_bound=0.162, batch=224 
893: loss=0.885, reward_mean=0.070, reward_bound=0.206, batch=226 
894: loss=0.886, reward_mean=0.080, reward_bound=0.268, batch=228 
895: loss=0.892, reward_mean=0.120, reward_bound=0.282, batch=199 
896: loss=0.888, reward_mean=0.100, reward_bound=0.035, batch=209 
897: loss=0.882, reward_mean=0.070, reward_bound=0.021, batch=216 
898: loss=0.885, reward_mean=0.070, reward_bound=0.077, batch=221 
899: loss=0.889, reward_mean=0.050, reward_bound=0.072, batch=224 
900: loss=0.890, reward_mean=0.110, reward_bound=0.150, batch=226 
901: loss=0.892, reward_mean=0.040, reward_bound=0.124, batch=228 
902: loss=0.891, reward_mean=0.090, reward_bound=0.185, batch=227 
903: loss=0.884, reward_mean=0.110, reward_bound=0.229, batch=227 
904: loss=0.889, reward_mean=0.070, reward_bound=0.254, batch=225 
905: loss=0.886, reward_mean=0.100, reward_bound=0.282, batch=225 
906: loss=0.883, reward_mean=0.140, reward_bound=0.314, batch=191 
907: loss=0.880, reward_mean=0.150, reward_bound=0.072, batch=203 
908: loss=0.881, reward_mean=0.070, reward_bound=0.000, batch=210 
909: loss=0.877, reward_mean=0.110, reward_bound=0.118, batch=217 
910: loss=0.880, reward_mean=0.080, reward_bound=0.132, batch=222 
911: loss=0.884, reward_mean=0.070, reward_bound=0.155, batch=225 
912: loss=0.886, reward_mean=0.090, reward_bound=0.189, batch=227 
913: loss=0.884, reward_mean=0.080, reward_bound=0.206, batch=226 
914: loss=0.886, reward_mean=0.110, reward_bound=0.254, batch=225 
915: loss=0.878, reward_mean=0.140, reward_bound=0.282, batch=223 
916: loss=0.879, reward_mean=0.080, reward_bound=0.314, batch=220 
917: loss=0.877, reward_mean=0.070, reward_bound=0.229, batch=223 
918: loss=0.877, reward_mean=0.080, reward_bound=0.211, batch=226 
919: loss=0.876, reward_mean=0.080, reward_bound=0.254, batch=227 
920: loss=0.886, reward_mean=0.100, reward_bound=0.349, batch=169 
921: loss=0.879, reward_mean=0.090, reward_bound=0.000, batch=178 
922: loss=0.881, reward_mean=0.080, reward_bound=0.000, batch=186 
923: loss=0.878, reward_mean=0.070, reward_bound=0.000, batch=193 
924: loss=0.871, reward_mean=0.100, reward_bound=0.000, batch=203 
925: loss=0.868, reward_mean=0.130, reward_bound=0.074, batch=212 
926: loss=0.867, reward_mean=0.150, reward_bound=0.167, batch=217 
927: loss=0.867, reward_mean=0.090, reward_bound=0.185, batch=219 
928: loss=0.866, reward_mean=0.060, reward_bound=0.172, batch=223 
929: loss=0.872, reward_mean=0.090, reward_bound=0.206, batch=223 
930: loss=0.870, reward_mean=0.080, reward_bound=0.229, batch=225 
931: loss=0.871, reward_mean=0.070, reward_bound=0.254, batch=226 
932: loss=0.876, reward_mean=0.150, reward_bound=0.282, batch=222 
933: loss=0.869, reward_mean=0.090, reward_bound=0.314, batch=210 
934: loss=0.863, reward_mean=0.080, reward_bound=0.112, batch=217 
935: loss=0.862, reward_mean=0.090, reward_bound=0.163, batch=222 
936: loss=0.868, reward_mean=0.140, reward_bound=0.282, batch=224 
937: loss=0.865, reward_mean=0.100, reward_bound=0.314, batch=225 
938: loss=0.864, reward_mean=0.040, reward_bound=0.296, batch=227 
939: loss=0.872, reward_mean=0.120, reward_bound=0.349, batch=215 
940: loss=0.868, reward_mean=0.100, reward_bound=0.199, batch=220 
941: loss=0.864, reward_mean=0.080, reward_bound=0.185, batch=224 
942: loss=0.867, reward_mean=0.090, reward_bound=0.280, batch=227 
943: loss=0.868, reward_mean=0.120, reward_bound=0.342, batch=229 
944: loss=0.869, reward_mean=0.100, reward_bound=0.349, batch=227 
945: loss=0.872, reward_mean=0.140, reward_bound=0.387, batch=168 
946: loss=0.868, reward_mean=0.110, reward_bound=0.000, batch=179 
947: loss=0.868, reward_mean=0.070, reward_bound=0.000, batch=186 
948: loss=0.857, reward_mean=0.140, reward_bound=0.026, batch=200 
949: loss=0.856, reward_mean=0.040, reward_bound=0.000, batch=204 
950: loss=0.858, reward_mean=0.100, reward_bound=0.047, batch=213 
951: loss=0.861, reward_mean=0.090, reward_bound=0.085, batch=219 
952: loss=0.867, reward_mean=0.090, reward_bound=0.135, batch=222 
953: loss=0.865, reward_mean=0.090, reward_bound=0.167, batch=223 
954: loss=0.867, reward_mean=0.100, reward_bound=0.220, batch=226 
955: loss=0.867, reward_mean=0.070, reward_bound=0.229, batch=227 
956: loss=0.864, reward_mean=0.100, reward_bound=0.254, batch=225 
957: loss=0.866, reward_mean=0.100, reward_bound=0.282, batch=218 
958: loss=0.869, reward_mean=0.120, reward_bound=0.314, batch=220 
959: loss=0.868, reward_mean=0.080, reward_bound=0.253, batch=224 
960: loss=0.867, reward_mean=0.090, reward_bound=0.342, batch=227 
961: loss=0.868, reward_mean=0.110, reward_bound=0.342, batch=229 
962: loss=0.871, reward_mean=0.120, reward_bound=0.349, batch=210 
963: loss=0.867, reward_mean=0.100, reward_bound=0.205, batch=217 
964: loss=0.865, reward_mean=0.070, reward_bound=0.158, batch=222 
965: loss=0.869, reward_mean=0.090, reward_bound=0.236, batch=225 
966: loss=0.868, reward_mean=0.040, reward_bound=0.159, batch=227 
967: loss=0.867, reward_mean=0.100, reward_bound=0.277, batch=229 
968: loss=0.871, reward_mean=0.130, reward_bound=0.314, batch=225 
969: loss=0.871, reward_mean=0.190, reward_bound=0.349, batch=226 
970: loss=0.871, reward_mean=0.110, reward_bound=0.314, batch=227 
971: loss=0.870, reward_mean=0.040, reward_bound=0.325, batch=229 
972: loss=0.868, reward_mean=0.110, reward_bound=0.387, batch=213 
973: loss=0.865, reward_mean=0.040, reward_bound=0.000, batch=217 
974: loss=0.870, reward_mean=0.140, reward_bound=0.314, batch=220 
975: loss=0.873, reward_mean=0.120, reward_bound=0.356, batch=224 
976: loss=0.875, reward_mean=0.090, reward_bound=0.280, batch=227 
977: loss=0.873, reward_mean=0.070, reward_bound=0.263, batch=229 
978: loss=0.871, reward_mean=0.130, reward_bound=0.387, batch=227 
979: loss=0.870, reward_mean=0.130, reward_bound=0.422, batch=229 
980: loss=0.871, reward_mean=0.080, reward_bound=0.405, batch=230 
981: loss=0.870, reward_mean=0.090, reward_bound=0.418, batch=231 
982: loss=0.854, reward_mean=0.130, reward_bound=0.430, batch=132 
983: loss=0.863, reward_mean=0.080, reward_bound=0.000, batch=140 
984: loss=0.849, reward_mean=0.130, reward_bound=0.000, batch=153 
985: loss=0.843, reward_mean=0.110, reward_bound=0.000, batch=164 
986: loss=0.835, reward_mean=0.090, reward_bound=0.000, batch=173 
987: loss=0.835, reward_mean=0.070, reward_bound=0.000, batch=180 
988: loss=0.827, reward_mean=0.100, reward_bound=0.000, batch=190 
989: loss=0.829, reward_mean=0.070, reward_bound=0.000, batch=197 
990: loss=0.824, reward_mean=0.060, reward_bound=0.000, batch=203 
991: loss=0.822, reward_mean=0.070, reward_bound=0.000, batch=210 
992: loss=0.818, reward_mean=0.060, reward_bound=0.000, batch=216 
993: loss=0.829, reward_mean=0.110, reward_bound=0.053, batch=221 
994: loss=0.832, reward_mean=0.080, reward_bound=0.098, batch=224 
995: loss=0.831, reward_mean=0.110, reward_bound=0.135, batch=219 
996: loss=0.827, reward_mean=0.090, reward_bound=0.150, batch=222 
997: loss=0.830, reward_mean=0.090, reward_bound=0.167, batch=219 
998: loss=0.831, reward_mean=0.100, reward_bound=0.185, batch=220 
999: loss=0.831, reward_mean=0.060, reward_bound=0.206, batch=225 
1000: loss=0.827, reward_mean=0.080, reward_bound=0.206, batch=226 
1001: loss=0.827, reward_mean=0.120, reward_bound=0.229, batch=227 
1002: loss=0.826, reward_mean=0.140, reward_bound=0.254, batch=222 
1003: loss=0.826, reward_mean=0.160, reward_bound=0.282, batch=213 
1004: loss=0.826, reward_mean=0.110, reward_bound=0.178, batch=219 
1005: loss=0.828, reward_mean=0.060, reward_bound=0.174, batch=223 
1006: loss=0.827, reward_mean=0.160, reward_bound=0.290, batch=226 
1007: loss=0.826, reward_mean=0.140, reward_bound=0.314, batch=209 
1008: loss=0.829, reward_mean=0.070, reward_bound=0.032, batch=216 
1009: loss=0.828, reward_mean=0.130, reward_bound=0.229, batch=220 
1010: loss=0.830, reward_mean=0.140, reward_bound=0.296, batch=224 
1011: loss=0.830, reward_mean=0.120, reward_bound=0.305, batch=227 
1012: loss=0.830, reward_mean=0.090, reward_bound=0.314, batch=226 
1013: loss=0.830, reward_mean=0.160, reward_bound=0.349, batch=209 
1014: loss=0.833, reward_mean=0.100, reward_bound=0.213, batch=216 
1015: loss=0.829, reward_mean=0.100, reward_bound=0.229, batch=220 
1016: loss=0.824, reward_mean=0.120, reward_bound=0.304, batch=224 
1017: loss=0.824, reward_mean=0.130, reward_bound=0.282, batch=226 
1018: loss=0.824, reward_mean=0.100, reward_bound=0.314, batch=221 
1019: loss=0.825, reward_mean=0.150, reward_bound=0.282, batch=223 
1020: loss=0.824, reward_mean=0.130, reward_bound=0.314, batch=225 
1021: loss=0.818, reward_mean=0.120, reward_bound=0.349, batch=224 
1022: loss=0.823, reward_mean=0.120, reward_bound=0.314, batch=226 
1023: loss=0.822, reward_mean=0.090, reward_bound=0.331, batch=228 
1024: loss=0.829, reward_mean=0.140, reward_bound=0.387, batch=195 
1025: loss=0.827, reward_mean=0.110, reward_bound=0.033, batch=206 
1026: loss=0.835, reward_mean=0.110, reward_bound=0.167, batch=213 
1027: loss=0.832, reward_mean=0.070, reward_bound=0.112, batch=219 
1028: loss=0.824, reward_mean=0.120, reward_bound=0.206, batch=222 
1029: loss=0.832, reward_mean=0.060, reward_bound=0.229, batch=220 
1030: loss=0.831, reward_mean=0.120, reward_bound=0.254, batch=223 
1031: loss=0.834, reward_mean=0.150, reward_bound=0.314, batch=220 
1032: loss=0.832, reward_mean=0.120, reward_bound=0.338, batch=224 
1033: loss=0.833, reward_mean=0.130, reward_bound=0.349, batch=224 
1034: loss=0.833, reward_mean=0.070, reward_bound=0.345, batch=227 
1035: loss=0.832, reward_mean=0.090, reward_bound=0.349, batch=228 
1036: loss=0.837, reward_mean=0.130, reward_bound=0.387, batch=218 
1037: loss=0.835, reward_mean=0.150, reward_bound=0.387, batch=221 
1038: loss=0.848, reward_mean=0.140, reward_bound=0.430, batch=177 
1039: loss=0.835, reward_mean=0.060, reward_bound=0.000, batch=183 
1040: loss=0.834, reward_mean=0.050, reward_bound=0.000, batch=188 
1041: loss=0.837, reward_mean=0.140, reward_bound=0.069, batch=201 
1042: loss=0.824, reward_mean=0.090, reward_bound=0.000, batch=210 
1043: loss=0.830, reward_mean=0.060, reward_bound=0.000, batch=216 
1044: loss=0.832, reward_mean=0.070, reward_bound=0.068, batch=221 
1045: loss=0.829, reward_mean=0.110, reward_bound=0.109, batch=224 
1046: loss=0.830, reward_mean=0.130, reward_bound=0.182, batch=227 
1047: loss=0.829, reward_mean=0.120, reward_bound=0.229, batch=226 
1048: loss=0.830, reward_mean=0.070, reward_bound=0.254, batch=227 
1049: loss=0.832, reward_mean=0.110, reward_bound=0.282, batch=226 
1050: loss=0.835, reward_mean=0.090, reward_bound=0.314, batch=219 
1051: loss=0.832, reward_mean=0.080, reward_bound=0.278, batch=223 
1052: loss=0.829, reward_mean=0.120, reward_bound=0.290, batch=226 
1053: loss=0.833, reward_mean=0.110, reward_bound=0.331, batch=228 
1054: loss=0.842, reward_mean=0.100, reward_bound=0.349, batch=215 
1055: loss=0.836, reward_mean=0.090, reward_bound=0.234, batch=220 
1056: loss=0.839, reward_mean=0.110, reward_bound=0.274, batch=224 
1057: loss=0.846, reward_mean=0.120, reward_bound=0.314, batch=226 
1058: loss=0.842, reward_mean=0.140, reward_bound=0.387, batch=218 
1059: loss=0.836, reward_mean=0.160, reward_bound=0.286, batch=222 
1060: loss=0.836, reward_mean=0.110, reward_bound=0.220, batch=225 
1061: loss=0.833, reward_mean=0.070, reward_bound=0.266, batch=227 
1062: loss=0.840, reward_mean=0.110, reward_bound=0.349, batch=228 
1063: loss=0.844, reward_mean=0.140, reward_bound=0.430, batch=212 
1064: loss=0.837, reward_mean=0.060, reward_bound=0.033, batch=218 
1065: loss=0.836, reward_mean=0.090, reward_bound=0.286, batch=222 
1066: loss=0.839, reward_mean=0.150, reward_bound=0.349, batch=222 
1067: loss=0.836, reward_mean=0.070, reward_bound=0.324, batch=225 
1068: loss=0.835, reward_mean=0.090, reward_bound=0.314, batch=226 
1069: loss=0.835, reward_mean=0.070, reward_bound=0.368, batch=228 
1070: loss=0.840, reward_mean=0.110, reward_bound=0.387, batch=224 
1071: loss=0.840, reward_mean=0.090, reward_bound=0.410, batch=227 
1072: loss=0.838, reward_mean=0.050, reward_bound=0.267, batch=229 
1073: loss=0.839, reward_mean=0.060, reward_bound=0.405, batch=230 
1074: loss=0.838, reward_mean=0.040, reward_bound=0.386, batch=231 
1075: loss=0.836, reward_mean=0.110, reward_bound=0.430, batch=226 
1076: loss=0.836, reward_mean=0.060, reward_bound=0.387, batch=226 
1077: loss=0.837, reward_mean=0.060, reward_bound=0.314, batch=227 
1078: loss=0.835, reward_mean=0.130, reward_bound=0.342, batch=229 
1079: loss=0.833, reward_mean=0.100, reward_bound=0.364, batch=230 
1080: loss=0.832, reward_mean=0.090, reward_bound=0.356, batch=231 
1081: loss=0.832, reward_mean=0.120, reward_bound=0.387, batch=231 
1082: loss=0.793, reward_mean=0.140, reward_bound=0.478, batch=100 
1083: loss=0.806, reward_mean=0.090, reward_bound=0.000, batch=109 
1084: loss=0.807, reward_mean=0.100, reward_bound=0.000, batch=119 
1085: loss=0.809, reward_mean=0.080, reward_bound=0.000, batch=127 
1086: loss=0.804, reward_mean=0.120, reward_bound=0.000, batch=139 
1087: loss=0.798, reward_mean=0.140, reward_bound=0.000, batch=153 
1088: loss=0.801, reward_mean=0.080, reward_bound=0.000, batch=161 
1089: loss=0.793, reward_mean=0.100, reward_bound=0.000, batch=171 
1090: loss=0.797, reward_mean=0.110, reward_bound=0.000, batch=182 
1091: loss=0.793, reward_mean=0.110, reward_bound=0.000, batch=193 
1092: loss=0.799, reward_mean=0.100, reward_bound=0.000, batch=203 
1093: loss=0.798, reward_mean=0.080, reward_bound=0.000, batch=211 
1094: loss=0.797, reward_mean=0.110, reward_bound=0.031, batch=217 
1095: loss=0.796, reward_mean=0.110, reward_bound=0.063, batch=222 
1096: loss=0.791, reward_mean=0.110, reward_bound=0.092, batch=225 
1097: loss=0.789, reward_mean=0.130, reward_bound=0.122, batch=225 
1098: loss=0.786, reward_mean=0.200, reward_bound=0.167, batch=226 
1099: loss=0.792, reward_mean=0.090, reward_bound=0.185, batch=225 
1100: loss=0.798, reward_mean=0.110, reward_bound=0.206, batch=225 
1101: loss=0.797, reward_mean=0.070, reward_bound=0.229, batch=215 
1102: loss=0.789, reward_mean=0.180, reward_bound=0.254, batch=206 
1103: loss=0.788, reward_mean=0.070, reward_bound=0.000, batch=213 
1104: loss=0.791, reward_mean=0.060, reward_bound=0.014, batch=219 
1105: loss=0.786, reward_mean=0.060, reward_bound=0.079, batch=223 
1106: loss=0.788, reward_mean=0.120, reward_bound=0.229, batch=224 
1107: loss=0.789, reward_mean=0.070, reward_bound=0.254, batch=223 
1108: loss=0.783, reward_mean=0.110, reward_bound=0.282, batch=207 
1109: loss=0.777, reward_mean=0.100, reward_bound=0.117, batch=215 
1110: loss=0.775, reward_mean=0.080, reward_bound=0.103, batch=220 
1111: loss=0.776, reward_mean=0.090, reward_bound=0.180, batch=224 
1112: loss=0.775, reward_mean=0.120, reward_bound=0.226, batch=227 
1113: loss=0.779, reward_mean=0.130, reward_bound=0.249, batch=229 
1114: loss=0.777, reward_mean=0.110, reward_bound=0.265, batch=230 
1115: loss=0.771, reward_mean=0.150, reward_bound=0.314, batch=207 
1116: loss=0.769, reward_mean=0.120, reward_bound=0.178, batch=215 
1117: loss=0.766, reward_mean=0.090, reward_bound=0.206, batch=219 
1118: loss=0.768, reward_mean=0.110, reward_bound=0.239, batch=223 
1119: loss=0.766, reward_mean=0.070, reward_bound=0.235, batch=226 
1120: loss=0.767, reward_mean=0.100, reward_bound=0.254, batch=227 
1121: loss=0.765, reward_mean=0.090, reward_bound=0.277, batch=229 
1122: loss=0.766, reward_mean=0.120, reward_bound=0.314, batch=226 
1123: loss=0.772, reward_mean=0.120, reward_bound=0.349, batch=193 
1124: loss=0.771, reward_mean=0.100, reward_bound=0.000, batch=203 
1125: loss=0.780, reward_mean=0.090, reward_bound=0.021, batch=212 
1126: loss=0.776, reward_mean=0.070, reward_bound=0.016, batch=218 
1127: loss=0.775, reward_mean=0.110, reward_bound=0.090, batch=222 
1128: loss=0.774, reward_mean=0.080, reward_bound=0.140, batch=225 
1129: loss=0.768, reward_mean=0.130, reward_bound=0.185, batch=225 
1130: loss=0.765, reward_mean=0.120, reward_bound=0.229, batch=225 
1131: loss=0.768, reward_mean=0.050, reward_bound=0.254, batch=222 
1132: loss=0.772, reward_mean=0.080, reward_bound=0.263, batch=225 
1133: loss=0.767, reward_mean=0.060, reward_bound=0.282, batch=226 
1134: loss=0.769, reward_mean=0.080, reward_bound=0.314, batch=224 
1135: loss=0.761, reward_mean=0.100, reward_bound=0.349, batch=218 
1136: loss=0.765, reward_mean=0.090, reward_bound=0.241, batch=222 
1137: loss=0.765, reward_mean=0.080, reward_bound=0.324, batch=225 
1138: loss=0.760, reward_mean=0.110, reward_bound=0.349, batch=225 
1139: loss=0.779, reward_mean=0.130, reward_bound=0.387, batch=186 
1140: loss=0.768, reward_mean=0.110, reward_bound=0.000, batch=197 
1141: loss=0.765, reward_mean=0.140, reward_bound=0.089, batch=209 
1142: loss=0.763, reward_mean=0.150, reward_bound=0.127, batch=216 
1143: loss=0.773, reward_mean=0.120, reward_bound=0.185, batch=219 
1144: loss=0.774, reward_mean=0.080, reward_bound=0.229, batch=216 
1145: loss=0.774, reward_mean=0.070, reward_bound=0.158, batch=221 
1146: loss=0.774, reward_mean=0.090, reward_bound=0.254, batch=216 
1147: loss=0.777, reward_mean=0.080, reward_bound=0.167, batch=220 
1148: loss=0.775, reward_mean=0.140, reward_bound=0.282, batch=221 
1149: loss=0.773, reward_mean=0.150, reward_bound=0.254, batch=224 
1150: loss=0.776, reward_mean=0.130, reward_bound=0.314, batch=223 
1151: loss=0.777, reward_mean=0.120, reward_bound=0.271, batch=226 
1152: loss=0.776, reward_mean=0.090, reward_bound=0.349, batch=221 
1153: loss=0.770, reward_mean=0.150, reward_bound=0.387, batch=210 
1154: loss=0.771, reward_mean=0.120, reward_bound=0.194, batch=217 
1155: loss=0.774, reward_mean=0.140, reward_bound=0.254, batch=221 
1156: loss=0.773, reward_mean=0.070, reward_bound=0.254, batch=223 
1157: loss=0.762, reward_mean=0.120, reward_bound=0.314, batch=224 
1158: loss=0.767, reward_mean=0.120, reward_bound=0.384, batch=227 
1159: loss=0.765, reward_mean=0.200, reward_bound=0.380, batch=229 
1160: loss=0.769, reward_mean=0.110, reward_bound=0.387, batch=225 
1161: loss=0.770, reward_mean=0.100, reward_bound=0.329, batch=227 
1162: loss=0.774, reward_mean=0.140, reward_bound=0.430, batch=180 
1163: loss=0.773, reward_mean=0.080, reward_bound=0.000, batch=188 
1164: loss=0.774, reward_mean=0.110, reward_bound=0.000, batch=199 
1165: loss=0.770, reward_mean=0.120, reward_bound=0.074, batch=209 
1166: loss=0.770, reward_mean=0.100, reward_bound=0.108, batch=216 
1167: loss=0.769, reward_mean=0.120, reward_bound=0.176, batch=221 
1168: loss=0.770, reward_mean=0.080, reward_bound=0.206, batch=222 
1169: loss=0.774, reward_mean=0.080, reward_bound=0.229, batch=221 
1170: loss=0.775, reward_mean=0.120, reward_bound=0.254, batch=222 
1171: loss=0.768, reward_mean=0.140, reward_bound=0.314, batch=218 
1172: loss=0.767, reward_mean=0.140, reward_bound=0.314, batch=221 
1173: loss=0.768, reward_mean=0.100, reward_bound=0.282, batch=224 
1174: loss=0.773, reward_mean=0.120, reward_bound=0.349, batch=210 
1175: loss=0.775, reward_mean=0.130, reward_bound=0.222, batch=217 
1176: loss=0.776, reward_mean=0.090, reward_bound=0.213, batch=222 
1177: loss=0.770, reward_mean=0.170, reward_bound=0.263, batch=225 
1178: loss=0.768, reward_mean=0.100, reward_bound=0.289, batch=227 
1179: loss=0.770, reward_mean=0.160, reward_bound=0.349, batch=225 
1180: loss=0.771, reward_mean=0.110, reward_bound=0.387, batch=213 
1181: loss=0.773, reward_mean=0.090, reward_bound=0.301, batch=219 
1182: loss=0.766, reward_mean=0.120, reward_bound=0.314, batch=220 
1183: loss=0.766, reward_mean=0.090, reward_bound=0.338, batch=224 
1184: loss=0.767, reward_mean=0.090, reward_bound=0.339, batch=227 
1185: loss=0.768, reward_mean=0.110, reward_bound=0.325, batch=229 
1186: loss=0.768, reward_mean=0.120, reward_bound=0.349, batch=229 
1187: loss=0.769, reward_mean=0.110, reward_bound=0.387, batch=220 
1188: loss=0.772, reward_mean=0.090, reward_bound=0.259, batch=224 
1189: loss=0.768, reward_mean=0.070, reward_bound=0.161, batch=227 
1190: loss=0.768, reward_mean=0.150, reward_bound=0.349, batch=226 
1191: loss=0.770, reward_mean=0.100, reward_bound=0.430, batch=206 
1192: loss=0.771, reward_mean=0.130, reward_bound=0.206, batch=213 
1193: loss=0.774, reward_mean=0.090, reward_bound=0.219, batch=219 
1194: loss=0.770, reward_mean=0.120, reward_bound=0.265, batch=223 
1195: loss=0.767, reward_mean=0.090, reward_bound=0.301, batch=226 
1196: loss=0.767, reward_mean=0.080, reward_bound=0.284, batch=228 
1197: loss=0.766, reward_mean=0.080, reward_bound=0.314, batch=225 
1198: loss=0.765, reward_mean=0.090, reward_bound=0.356, batch=227 
1199: loss=0.764, reward_mean=0.140, reward_bound=0.387, batch=222 
1200: loss=0.763, reward_mean=0.120, reward_bound=0.360, batch=225 
1201: loss=0.765, reward_mean=0.120, reward_bound=0.387, batch=224 
1202: loss=0.767, reward_mean=0.110, reward_bound=0.349, batch=226 
1203: loss=0.765, reward_mean=0.090, reward_bound=0.387, batch=226 
1204: loss=0.766, reward_mean=0.100, reward_bound=0.409, batch=228 
1205: loss=0.767, reward_mean=0.080, reward_bound=0.430, batch=225 
1206: loss=0.763, reward_mean=0.050, reward_bound=0.240, batch=227 
1207: loss=0.764, reward_mean=0.080, reward_bound=0.282, batch=228 
1208: loss=0.765, reward_mean=0.080, reward_bound=0.357, batch=229 
1209: loss=0.765, reward_mean=0.080, reward_bound=0.283, batch=230 
1210: loss=0.767, reward_mean=0.140, reward_bound=0.430, batch=228 
1211: loss=0.766, reward_mean=0.060, reward_bound=0.435, batch=229 
1212: loss=0.766, reward_mean=0.160, reward_bound=0.478, batch=231 
1213: loss=0.766, reward_mean=0.090, reward_bound=0.430, batch=231 
1214: loss=0.766, reward_mean=0.140, reward_bound=0.387, batch=231 
1215: loss=0.766, reward_mean=0.070, reward_bound=0.349, batch=231 
1216: loss=0.765, reward_mean=0.100, reward_bound=0.387, batch=231 
1217: loss=0.765, reward_mean=0.050, reward_bound=0.478, batch=151 
1218: loss=0.749, reward_mean=0.100, reward_bound=0.000, batch=161 
1219: loss=0.747, reward_mean=0.090, reward_bound=0.000, batch=170 
1220: loss=0.747, reward_mean=0.110, reward_bound=0.000, batch=181 
1221: loss=0.746, reward_mean=0.110, reward_bound=0.000, batch=192 
1222: loss=0.753, reward_mean=0.080, reward_bound=0.000, batch=200 
1223: loss=0.755, reward_mean=0.090, reward_bound=0.000, batch=209 
1224: loss=0.756, reward_mean=0.080, reward_bound=0.052, batch=216 
1225: loss=0.755, reward_mean=0.100, reward_bound=0.084, batch=221 
1226: loss=0.756, reward_mean=0.170, reward_bound=0.122, batch=223 
1227: loss=0.750, reward_mean=0.070, reward_bound=0.135, batch=223 
1228: loss=0.745, reward_mean=0.060, reward_bound=0.150, batch=222 
1229: loss=0.748, reward_mean=0.130, reward_bound=0.206, batch=226 
1230: loss=0.748, reward_mean=0.040, reward_bound=0.206, batch=224 
1231: loss=0.746, reward_mean=0.130, reward_bound=0.229, batch=222 
1232: loss=0.745, reward_mean=0.050, reward_bound=0.229, batch=224 
1233: loss=0.752, reward_mean=0.120, reward_bound=0.254, batch=216 
1234: loss=0.748, reward_mean=0.110, reward_bound=0.282, batch=212 
1235: loss=0.749, reward_mean=0.110, reward_bound=0.198, batch=218 
1236: loss=0.743, reward_mean=0.120, reward_bound=0.257, batch=222 
1237: loss=0.736, reward_mean=0.060, reward_bound=0.171, batch=225 
1238: loss=0.751, reward_mean=0.130, reward_bound=0.314, batch=211 
1239: loss=0.745, reward_mean=0.160, reward_bound=0.254, batch=217 
1240: loss=0.742, reward_mean=0.090, reward_bound=0.308, batch=222 
1241: loss=0.737, reward_mean=0.140, reward_bound=0.324, batch=225 
1242: loss=0.740, reward_mean=0.070, reward_bound=0.289, batch=227 
1243: loss=0.738, reward_mean=0.120, reward_bound=0.349, batch=205 
1244: loss=0.733, reward_mean=0.090, reward_bound=0.077, batch=213 
1245: loss=0.727, reward_mean=0.080, reward_bound=0.150, batch=218 
1246: loss=0.722, reward_mean=0.100, reward_bound=0.206, batch=221 
1247: loss=0.722, reward_mean=0.100, reward_bound=0.254, batch=224 
1248: loss=0.721, reward_mean=0.080, reward_bound=0.185, batch=226 
1249: loss=0.729, reward_mean=0.070, reward_bound=0.282, batch=226 
1250: loss=0.731, reward_mean=0.090, reward_bound=0.331, batch=228 
1251: loss=0.733, reward_mean=0.100, reward_bound=0.349, batch=223 
1252: loss=0.733, reward_mean=0.100, reward_bound=0.372, batch=226 
1253: loss=0.732, reward_mean=0.050, reward_bound=0.349, batch=227 
1254: loss=0.732, reward_mean=0.060, reward_bound=0.337, batch=229 
1255: loss=0.732, reward_mean=0.110, reward_bound=0.349, batch=229 
1256: loss=0.732, reward_mean=0.120, reward_bound=0.349, batch=229 
1257: loss=0.731, reward_mean=0.140, reward_bound=0.387, batch=212 
1258: loss=0.727, reward_mean=0.110, reward_bound=0.236, batch=218 
1259: loss=0.722, reward_mean=0.120, reward_bound=0.173, batch=222 
1260: loss=0.726, reward_mean=0.110, reward_bound=0.229, batch=224 
1261: loss=0.728, reward_mean=0.040, reward_bound=0.155, batch=227 
1262: loss=0.729, reward_mean=0.070, reward_bound=0.254, batch=228 
1263: loss=0.727, reward_mean=0.080, reward_bound=0.282, batch=227 
1264: loss=0.725, reward_mean=0.100, reward_bound=0.314, batch=226 
1265: loss=0.725, reward_mean=0.100, reward_bound=0.349, batch=225 
1266: loss=0.728, reward_mean=0.080, reward_bound=0.254, batch=226 
1267: loss=0.723, reward_mean=0.100, reward_bound=0.335, batch=228 
1268: loss=0.724, reward_mean=0.150, reward_bound=0.387, batch=224 
1269: loss=0.724, reward_mean=0.080, reward_bound=0.280, batch=227 
1270: loss=0.721, reward_mean=0.080, reward_bound=0.282, batch=227 
1271: loss=0.721, reward_mean=0.060, reward_bound=0.342, batch=229 
1272: loss=0.722, reward_mean=0.120, reward_bound=0.387, batch=229 
1273: loss=0.739, reward_mean=0.080, reward_bound=0.430, batch=200 
1274: loss=0.731, reward_mean=0.130, reward_bound=0.096, batch=210 
1275: loss=0.721, reward_mean=0.090, reward_bound=0.167, batch=216 
1276: loss=0.719, reward_mean=0.120, reward_bound=0.186, batch=221 
1277: loss=0.713, reward_mean=0.090, reward_bound=0.206, batch=223 
1278: loss=0.715, reward_mean=0.070, reward_bound=0.229, batch=224 
1279: loss=0.709, reward_mean=0.090, reward_bound=0.254, batch=224 
1280: loss=0.711, reward_mean=0.080, reward_bound=0.275, batch=227 
1281: loss=0.716, reward_mean=0.080, reward_bound=0.282, batch=227 
1282: loss=0.715, reward_mean=0.070, reward_bound=0.249, batch=229 
1283: loss=0.725, reward_mean=0.070, reward_bound=0.314, batch=228 
1284: loss=0.731, reward_mean=0.120, reward_bound=0.349, batch=224 
1285: loss=0.734, reward_mean=0.070, reward_bound=0.277, batch=227 
1286: loss=0.732, reward_mean=0.060, reward_bound=0.308, batch=229 
1287: loss=0.727, reward_mean=0.080, reward_bound=0.387, batch=222 
1288: loss=0.721, reward_mean=0.100, reward_bound=0.336, batch=225 
1289: loss=0.721, reward_mean=0.140, reward_bound=0.349, batch=226 
1290: loss=0.717, reward_mean=0.090, reward_bound=0.271, batch=228 
1291: loss=0.718, reward_mean=0.140, reward_bound=0.321, batch=229 
1292: loss=0.722, reward_mean=0.140, reward_bound=0.405, batch=230 
1293: loss=0.729, reward_mean=0.100, reward_bound=0.430, batch=215 
1294: loss=0.729, reward_mean=0.100, reward_bound=0.282, batch=218 
1295: loss=0.731, reward_mean=0.110, reward_bound=0.314, batch=221 
1296: loss=0.728, reward_mean=0.120, reward_bound=0.254, batch=224 
1297: loss=0.731, reward_mean=0.080, reward_bound=0.273, batch=227 
1298: loss=0.732, reward_mean=0.070, reward_bound=0.314, batch=227 
1299: loss=0.730, reward_mean=0.040, reward_bound=0.302, batch=229 
1300: loss=0.732, reward_mean=0.030, reward_bound=0.295, batch=230 
1301: loss=0.729, reward_mean=0.070, reward_bound=0.349, batch=227 
1302: loss=0.726, reward_mean=0.090, reward_bound=0.387, batch=227 
1303: loss=0.723, reward_mean=0.060, reward_bound=0.366, batch=229 
1304: loss=0.722, reward_mean=0.080, reward_bound=0.405, batch=230 
1305: loss=0.722, reward_mean=0.090, reward_bound=0.395, batch=231 
1306: loss=0.727, reward_mean=0.110, reward_bound=0.430, batch=223 
1307: loss=0.723, reward_mean=0.110, reward_bound=0.301, batch=226 
1308: loss=0.724, reward_mean=0.060, reward_bound=0.284, batch=228 
1309: loss=0.733, reward_mean=0.070, reward_bound=0.349, batch=228 
1310: loss=0.730, reward_mean=0.130, reward_bound=0.392, batch=229 
1311: loss=0.728, reward_mean=0.060, reward_bound=0.405, batch=230 
1312: loss=0.727, reward_mean=0.070, reward_bound=0.300, batch=231 
1313: loss=0.729, reward_mean=0.080, reward_bound=0.387, batch=231 
1314: loss=0.723, reward_mean=0.100, reward_bound=0.430, batch=228 
1315: loss=0.724, reward_mean=0.110, reward_bound=0.435, batch=229 
1316: loss=0.727, reward_mean=0.070, reward_bound=0.364, batch=230 
1317: loss=0.725, reward_mean=0.060, reward_bound=0.387, batch=230 
1318: loss=0.724, reward_mean=0.120, reward_bound=0.430, batch=229 
1319: loss=0.724, reward_mean=0.110, reward_bound=0.450, batch=230 
1320: loss=0.724, reward_mean=0.070, reward_bound=0.430, batch=230 
1321: loss=0.724, reward_mean=0.080, reward_bound=0.430, batch=230 
1322: loss=0.746, reward_mean=0.120, reward_bound=0.478, batch=185 
1323: loss=0.752, reward_mean=0.090, reward_bound=0.000, batch=194 
1324: loss=0.751, reward_mean=0.070, reward_bound=0.000, batch=201 
1325: loss=0.753, reward_mean=0.100, reward_bound=0.058, batch=210 
1326: loss=0.745, reward_mean=0.110, reward_bound=0.090, batch=217 
1327: loss=0.743, reward_mean=0.080, reward_bound=0.109, batch=223 
1328: loss=0.736, reward_mean=0.090, reward_bound=0.130, batch=226 
1329: loss=0.737, reward_mean=0.100, reward_bound=0.185, batch=227 
1330: loss=0.744, reward_mean=0.110, reward_bound=0.229, batch=227 
1331: loss=0.746, reward_mean=0.150, reward_bound=0.314, batch=222 
1332: loss=0.753, reward_mean=0.090, reward_bound=0.349, batch=218 
1333: loss=0.754, reward_mean=0.140, reward_bound=0.353, batch=222 
1334: loss=0.750, reward_mean=0.070, reward_bound=0.220, batch=225 
1335: loss=0.756, reward_mean=0.090, reward_bound=0.282, batch=226 
1336: loss=0.755, reward_mean=0.110, reward_bound=0.331, batch=228 
1337: loss=0.760, reward_mean=0.100, reward_bound=0.387, batch=217 
1338: loss=0.762, reward_mean=0.050, reward_bound=0.108, batch=222 
1339: loss=0.762, reward_mean=0.050, reward_bound=0.091, batch=225 
1340: loss=0.757, reward_mean=0.080, reward_bound=0.289, batch=227 
1341: loss=0.755, reward_mean=0.080, reward_bound=0.308, batch=229 
1342: loss=0.755, reward_mean=0.140, reward_bound=0.349, batch=227 
1343: loss=0.758, reward_mean=0.140, reward_bound=0.387, batch=228 
1344: loss=0.757, reward_mean=0.050, reward_bound=0.392, batch=229 
1345: loss=0.755, reward_mean=0.070, reward_bound=0.328, batch=230 
1346: loss=0.756, reward_mean=0.100, reward_bound=0.418, batch=231 
1347: loss=0.755, reward_mean=0.130, reward_bound=0.430, batch=212 
1348: loss=0.753, reward_mean=0.100, reward_bound=0.245, batch=218 
1349: loss=0.752, reward_mean=0.120, reward_bound=0.349, batch=221 
1350: loss=0.751, reward_mean=0.160, reward_bound=0.430, batch=221 
1351: loss=0.750, reward_mean=0.060, reward_bound=0.314, batch=224 
1352: loss=0.753, reward_mean=0.140, reward_bound=0.474, batch=227 
1353: loss=0.753, reward_mean=0.080, reward_bound=0.314, batch=228 
1354: loss=0.751, reward_mean=0.100, reward_bound=0.353, batch=229 
1355: loss=0.749, reward_mean=0.100, reward_bound=0.405, batch=230 
1356: loss=0.748, reward_mean=0.080, reward_bound=0.406, batch=231 
1357: loss=0.749, reward_mean=0.080, reward_bound=0.430, batch=230 
1358: loss=0.751, reward_mean=0.090, reward_bound=0.338, batch=231 
1359: loss=0.748, reward_mean=0.060, reward_bound=0.349, batch=231 
1360: loss=0.749, reward_mean=0.090, reward_bound=0.430, batch=231 
1361: loss=0.752, reward_mean=0.110, reward_bound=0.478, batch=207 
1362: loss=0.741, reward_mean=0.100, reward_bound=0.105, batch=215 
1363: loss=0.752, reward_mean=0.130, reward_bound=0.170, batch=220 
1364: loss=0.747, reward_mean=0.070, reward_bound=0.185, batch=223 
1365: loss=0.747, reward_mean=0.060, reward_bound=0.254, batch=225 
1366: loss=0.748, reward_mean=0.060, reward_bound=0.282, batch=225 
1367: loss=0.750, reward_mean=0.130, reward_bound=0.314, batch=225 
1368: loss=0.746, reward_mean=0.140, reward_bound=0.349, batch=226 
1369: loss=0.747, reward_mean=0.100, reward_bound=0.314, batch=227 
1370: loss=0.747, reward_mean=0.070, reward_bound=0.335, batch=229 
1371: loss=0.747, reward_mean=0.090, reward_bound=0.314, batch=229 
1372: loss=0.747, reward_mean=0.140, reward_bound=0.387, batch=227 
1373: loss=0.749, reward_mean=0.080, reward_bound=0.373, batch=229 
1374: loss=0.750, reward_mean=0.110, reward_bound=0.405, batch=230 
1375: loss=0.750, reward_mean=0.060, reward_bound=0.296, batch=231 
1376: loss=0.748, reward_mean=0.050, reward_bound=0.430, batch=223 
1377: loss=0.748, reward_mean=0.150, reward_bound=0.387, batch=223 
1378: loss=0.746, reward_mean=0.070, reward_bound=0.219, batch=226 
1379: loss=0.743, reward_mean=0.090, reward_bound=0.368, batch=228 
1380: loss=0.741, reward_mean=0.110, reward_bound=0.353, batch=229 
1381: loss=0.742, reward_mean=0.100, reward_bound=0.387, batch=228 
1382: loss=0.746, reward_mean=0.160, reward_bound=0.435, batch=229 
1383: loss=0.750, reward_mean=0.070, reward_bound=0.478, batch=231 
1384: loss=0.750, reward_mean=0.100, reward_bound=0.430, batch=231 
1385: loss=0.754, reward_mean=0.090, reward_bound=0.478, batch=217 
1386: loss=0.751, reward_mean=0.130, reward_bound=0.308, batch=222 
1387: loss=0.745, reward_mean=0.030, reward_bound=0.022, batch=225 
1388: loss=0.749, reward_mean=0.080, reward_bound=0.266, batch=227 
1389: loss=0.747, reward_mean=0.090, reward_bound=0.349, batch=226 
1390: loss=0.755, reward_mean=0.110, reward_bound=0.387, batch=226 
1391: loss=0.754, reward_mean=0.100, reward_bound=0.430, batch=223 
1392: loss=0.753, reward_mean=0.100, reward_bound=0.372, batch=226 
1393: loss=0.753, reward_mean=0.070, reward_bound=0.308, batch=228 
1394: loss=0.751, reward_mean=0.090, reward_bound=0.353, batch=229 
1395: loss=0.752, reward_mean=0.110, reward_bound=0.405, batch=230 
1396: loss=0.757, reward_mean=0.120, reward_bound=0.464, batch=231 
1397: loss=0.752, reward_mean=0.080, reward_bound=0.478, batch=223 
1398: loss=0.749, reward_mean=0.120, reward_bound=0.349, batch=225 
1399: loss=0.751, reward_mean=0.080, reward_bound=0.365, batch=227 
1400: loss=0.752, reward_mean=0.070, reward_bound=0.414, batch=229 
1401: loss=0.751, reward_mean=0.080, reward_bound=0.360, batch=230 
1402: loss=0.754, reward_mean=0.090, reward_bound=0.430, batch=227 
1403: loss=0.754, reward_mean=0.100, reward_bound=0.469, batch=229 
1404: loss=0.752, reward_mean=0.050, reward_bound=0.380, batch=230 
1405: loss=0.752, reward_mean=0.130, reward_bound=0.464, batch=231 
1406: loss=0.753, reward_mean=0.100, reward_bound=0.478, batch=225 
1407: loss=0.754, reward_mean=0.110, reward_bound=0.266, batch=227 
1408: loss=0.749, reward_mean=0.080, reward_bound=0.314, batch=228 
1409: loss=0.753, reward_mean=0.100, reward_bound=0.353, batch=229 
1410: loss=0.751, reward_mean=0.070, reward_bound=0.387, batch=229 
1411: loss=0.753, reward_mean=0.150, reward_bound=0.430, batch=227 
1412: loss=0.753, reward_mean=0.090, reward_bound=0.422, batch=229 
1413: loss=0.755, reward_mean=0.110, reward_bound=0.430, batch=229 
1414: loss=0.753, reward_mean=0.130, reward_bound=0.478, batch=231 
1415: loss=0.752, reward_mean=0.070, reward_bound=0.478, batch=228 
1416: loss=0.752, reward_mean=0.070, reward_bound=0.397, batch=229 
1417: loss=0.750, reward_mean=0.090, reward_bound=0.478, batch=231 
1418: loss=0.751, reward_mean=0.100, reward_bound=0.478, batch=230 
1419: loss=0.750, reward_mean=0.100, reward_bound=0.376, batch=231 
1420: loss=0.751, reward_mean=0.140, reward_bound=0.387, batch=230 
1421: loss=0.749, reward_mean=0.080, reward_bound=0.418, batch=231 
1422: loss=0.750, reward_mean=0.110, reward_bound=0.478, batch=231 
1424: loss=0.631, reward_mean=0.100, reward_bound=0.000, batch=10 
1425: loss=0.686, reward_mean=0.080, reward_bound=0.000, batch=18 
1426: loss=0.698, reward_mean=0.070, reward_bound=0.000, batch=25 
1427: loss=0.708, reward_mean=0.080, reward_bound=0.000, batch=33 
1428: loss=0.728, reward_mean=0.100, reward_bound=0.000, batch=43 
1429: loss=0.727, reward_mean=0.100, reward_bound=0.000, batch=53 
1430: loss=0.722, reward_mean=0.130, reward_bound=0.000, batch=66 
1431: loss=0.739, reward_mean=0.130, reward_bound=0.000, batch=79 
1432: loss=0.742, reward_mean=0.050, reward_bound=0.000, batch=84 
1433: loss=0.751, reward_mean=0.090, reward_bound=0.000, batch=93 
1434: loss=0.749, reward_mean=0.040, reward_bound=0.000, batch=97 
1435: loss=0.729, reward_mean=0.120, reward_bound=0.000, batch=109 
1436: loss=0.726, reward_mean=0.140, reward_bound=0.000, batch=123 
1437: loss=0.730, reward_mean=0.100, reward_bound=0.000, batch=133 
1438: loss=0.727, reward_mean=0.030, reward_bound=0.000, batch=136 
1439: loss=0.728, reward_mean=0.120, reward_bound=0.000, batch=148 
1440: loss=0.727, reward_mean=0.100, reward_bound=0.000, batch=158 
1441: loss=0.721, reward_mean=0.170, reward_bound=0.000, batch=175 
1442: loss=0.719, reward_mean=0.140, reward_bound=0.000, batch=189 
1443: loss=0.723, reward_mean=0.150, reward_bound=0.012, batch=202 
1444: loss=0.719, reward_mean=0.160, reward_bound=0.038, batch=209 
1445: loss=0.718, reward_mean=0.160, reward_bound=0.072, batch=213 
1446: loss=0.718, reward_mean=0.130, reward_bound=0.089, batch=216 
1447: loss=0.717, reward_mean=0.110, reward_bound=0.098, batch=218 
1448: loss=0.718, reward_mean=0.130, reward_bound=0.122, batch=218 
1449: loss=0.715, reward_mean=0.160, reward_bound=0.135, batch=214 
1450: loss=0.716, reward_mean=0.090, reward_bound=0.120, batch=220 
1451: loss=0.722, reward_mean=0.160, reward_bound=0.150, batch=212 
1452: loss=0.722, reward_mean=0.100, reward_bound=0.167, batch=210 
1453: loss=0.722, reward_mean=0.120, reward_bound=0.185, batch=206 
1454: loss=0.726, reward_mean=0.110, reward_bound=0.186, batch=214 
1455: loss=0.727, reward_mean=0.120, reward_bound=0.206, batch=201 
1456: loss=0.728, reward_mean=0.140, reward_bound=0.167, batch=210 
1457: loss=0.726, reward_mean=0.130, reward_bound=0.150, batch=216 
1458: loss=0.717, reward_mean=0.130, reward_bound=0.229, batch=194 
1459: loss=0.727, reward_mean=0.130, reward_bound=0.077, batch=206 
1460: loss=0.723, reward_mean=0.180, reward_bound=0.128, batch=214 
1461: loss=0.720, reward_mean=0.120, reward_bound=0.164, batch=220 
1462: loss=0.717, reward_mean=0.080, reward_bound=0.153, batch=224 
1463: loss=0.719, reward_mean=0.060, reward_bound=0.167, batch=225 
1464: loss=0.717, reward_mean=0.080, reward_bound=0.229, batch=226 
1465: loss=0.709, reward_mean=0.070, reward_bound=0.254, batch=201 
1466: loss=0.706, reward_mean=0.070, reward_bound=0.000, batch=208 
1467: loss=0.711, reward_mean=0.100, reward_bound=0.093, batch=215 
1468: loss=0.714, reward_mean=0.160, reward_bound=0.185, batch=219 
1469: loss=0.715, reward_mean=0.070, reward_bound=0.155, batch=223 
1470: loss=0.716, reward_mean=0.110, reward_bound=0.254, batch=224 
1471: loss=0.706, reward_mean=0.090, reward_bound=0.282, batch=189 
1472: loss=0.705, reward_mean=0.130, reward_bound=0.021, batch=202 
1473: loss=0.697, reward_mean=0.080, reward_bound=0.000, batch=210 
1474: loss=0.692, reward_mean=0.110, reward_bound=0.056, batch=217 
1475: loss=0.691, reward_mean=0.080, reward_bound=0.058, batch=223 
1476: loss=0.700, reward_mean=0.090, reward_bound=0.120, batch=226 
1477: loss=0.693, reward_mean=0.150, reward_bound=0.185, batch=226 
1478: loss=0.695, reward_mean=0.130, reward_bound=0.241, batch=228 
1479: loss=0.703, reward_mean=0.130, reward_bound=0.282, batch=222 
1480: loss=0.707, reward_mean=0.150, reward_bound=0.314, batch=189 
1481: loss=0.695, reward_mean=0.130, reward_bound=0.017, batch=202 
1482: loss=0.707, reward_mean=0.130, reward_bound=0.080, batch=210 
1483: loss=0.706, reward_mean=0.090, reward_bound=0.089, batch=216 
1484: loss=0.703, reward_mean=0.090, reward_bound=0.098, batch=218 
1485: loss=0.703, reward_mean=0.090, reward_bound=0.152, batch=222 
1486: loss=0.707, reward_mean=0.090, reward_bound=0.206, batch=226 
1487: loss=0.705, reward_mean=0.060, reward_bound=0.206, batch=225 
1488: loss=0.708, reward_mean=0.140, reward_bound=0.229, batch=224 
1489: loss=0.706, reward_mean=0.140, reward_bound=0.254, batch=224 
1490: loss=0.705, reward_mean=0.140, reward_bound=0.277, batch=227 
1491: loss=0.704, reward_mean=0.080, reward_bound=0.282, batch=216 
1492: loss=0.704, reward_mean=0.120, reward_bound=0.314, batch=216 
1493: loss=0.704, reward_mean=0.140, reward_bound=0.241, batch=221 
1494: loss=0.703, reward_mean=0.070, reward_bound=0.254, batch=223 
1495: loss=0.701, reward_mean=0.120, reward_bound=0.301, batch=226 
1496: loss=0.705, reward_mean=0.110, reward_bound=0.349, batch=172 
1497: loss=0.705, reward_mean=0.090, reward_bound=0.000, batch=181 
1498: loss=0.716, reward_mean=0.110, reward_bound=0.000, batch=192 
1499: loss=0.711, reward_mean=0.090, reward_bound=0.000, batch=201 
1500: loss=0.704, reward_mean=0.100, reward_bound=0.015, batch=210 
1501: loss=0.694, reward_mean=0.110, reward_bound=0.093, batch=217 
1502: loss=0.688, reward_mean=0.240, reward_bound=0.150, batch=221 
1503: loss=0.686, reward_mean=0.110, reward_bound=0.185, batch=221 
1504: loss=0.686, reward_mean=0.130, reward_bound=0.206, batch=221 
1505: loss=0.693, reward_mean=0.110, reward_bound=0.229, batch=218 
1506: loss=0.694, reward_mean=0.140, reward_bound=0.257, batch=222 
1507: loss=0.689, reward_mean=0.090, reward_bound=0.263, batch=225 
1508: loss=0.686, reward_mean=0.160, reward_bound=0.282, batch=219 
1509: loss=0.685, reward_mean=0.110, reward_bound=0.239, batch=223 
1510: loss=0.692, reward_mean=0.100, reward_bound=0.314, batch=214 
1511: loss=0.688, reward_mean=0.120, reward_bound=0.277, batch=220 
1512: loss=0.686, reward_mean=0.140, reward_bound=0.282, batch=222 
1513: loss=0.684, reward_mean=0.040, reward_bound=0.302, batch=225 
1514: loss=0.686, reward_mean=0.200, reward_bound=0.321, batch=227 
1515: loss=0.684, reward_mean=0.120, reward_bound=0.349, batch=213 
1516: loss=0.685, reward_mean=0.140, reward_bound=0.314, batch=218 
1517: loss=0.681, reward_mean=0.160, reward_bound=0.349, batch=220 
1518: loss=0.680, reward_mean=0.080, reward_bound=0.223, batch=224 
1519: loss=0.681, reward_mean=0.130, reward_bound=0.280, batch=227 
1520: loss=0.679, reward_mean=0.100, reward_bound=0.272, batch=229 
1521: loss=0.682, reward_mean=0.120, reward_bound=0.295, batch=230 
1522: loss=0.681, reward_mean=0.080, reward_bound=0.304, batch=231 
1523: loss=0.681, reward_mean=0.110, reward_bound=0.314, batch=227 
1524: loss=0.680, reward_mean=0.170, reward_bound=0.380, batch=229 
1525: loss=0.681, reward_mean=0.110, reward_bound=0.324, batch=230 
1526: loss=0.684, reward_mean=0.160, reward_bound=0.387, batch=168 
1527: loss=0.676, reward_mean=0.100, reward_bound=0.000, batch=178 
1528: loss=0.669, reward_mean=0.130, reward_bound=0.000, batch=191 
1529: loss=0.670, reward_mean=0.070, reward_bound=0.000, batch=198 
1530: loss=0.661, reward_mean=0.130, reward_bound=0.072, batch=207 
1531: loss=0.663, reward_mean=0.130, reward_bound=0.097, batch=215 
1532: loss=0.666, reward_mean=0.100, reward_bound=0.101, batch=220 
1533: loss=0.668, reward_mean=0.150, reward_bound=0.135, batch=222 
1534: loss=0.670, reward_mean=0.090, reward_bound=0.150, batch=219 
1535: loss=0.675, reward_mean=0.160, reward_bound=0.185, batch=222 
1536: loss=0.679, reward_mean=0.160, reward_bound=0.213, batch=225 
1537: loss=0.678, reward_mean=0.100, reward_bound=0.229, batch=225 
1538: loss=0.673, reward_mean=0.160, reward_bound=0.254, batch=226 
1539: loss=0.674, reward_mean=0.140, reward_bound=0.282, batch=220 
1540: loss=0.680, reward_mean=0.210, reward_bound=0.314, batch=211 
1541: loss=0.677, reward_mean=0.070, reward_bound=0.080, batch=216 
1542: loss=0.675, reward_mean=0.140, reward_bound=0.158, batch=221 
1543: loss=0.682, reward_mean=0.160, reward_bound=0.254, batch=224 
1544: loss=0.683, reward_mean=0.080, reward_bound=0.204, batch=227 
1545: loss=0.678, reward_mean=0.110, reward_bound=0.267, batch=229 
1546: loss=0.679, reward_mean=0.150, reward_bound=0.314, batch=229 
1547: loss=0.678, reward_mean=0.130, reward_bound=0.349, batch=224 
1548: loss=0.676, reward_mean=0.190, reward_bound=0.387, batch=211 
1549: loss=0.676, reward_mean=0.130, reward_bound=0.206, batch=217 
1550: loss=0.680, reward_mean=0.130, reward_bound=0.249, batch=222 
1551: loss=0.679, reward_mean=0.120, reward_bound=0.236, batch=225 
1552: loss=0.680, reward_mean=0.110, reward_bound=0.289, batch=227 
1553: loss=0.680, reward_mean=0.150, reward_bound=0.314, batch=227 
1554: loss=0.679, reward_mean=0.100, reward_bound=0.342, batch=229 
1555: loss=0.684, reward_mean=0.140, reward_bound=0.349, batch=228 
1556: loss=0.682, reward_mean=0.120, reward_bound=0.387, batch=225 
1557: loss=0.682, reward_mean=0.160, reward_bound=0.387, batch=226 
1558: loss=0.685, reward_mean=0.140, reward_bound=0.372, batch=228 
1559: loss=0.684, reward_mean=0.130, reward_bound=0.392, batch=229 
1560: loss=0.687, reward_mean=0.150, reward_bound=0.430, batch=130 
1561: loss=0.675, reward_mean=0.150, reward_bound=0.000, batch=145 
1562: loss=0.679, reward_mean=0.090, reward_bound=0.000, batch=154 
1563: loss=0.672, reward_mean=0.150, reward_bound=0.000, batch=169 
1564: loss=0.664, reward_mean=0.170, reward_bound=0.000, batch=186 
1565: loss=0.671, reward_mean=0.130, reward_bound=0.000, batch=199 
1566: loss=0.661, reward_mean=0.090, reward_bound=0.000, batch=208 
1567: loss=0.669, reward_mean=0.150, reward_bound=0.032, batch=215 
1568: loss=0.670, reward_mean=0.080, reward_bound=0.053, batch=220 
1569: loss=0.666, reward_mean=0.140, reward_bound=0.086, batch=224 
1570: loss=0.665, reward_mean=0.120, reward_bound=0.108, batch=227 
1571: loss=0.673, reward_mean=0.180, reward_bound=0.135, batch=228 
1572: loss=0.672, reward_mean=0.130, reward_bound=0.169, batch=229 
1573: loss=0.670, reward_mean=0.130, reward_bound=0.185, batch=227 
1574: loss=0.672, reward_mean=0.140, reward_bound=0.206, batch=224 
1575: loss=0.681, reward_mean=0.110, reward_bound=0.229, batch=219 
1576: loss=0.677, reward_mean=0.100, reward_bound=0.254, batch=218 
1577: loss=0.679, reward_mean=0.180, reward_bound=0.282, batch=211 
1578: loss=0.675, reward_mean=0.190, reward_bound=0.254, batch=217 
1579: loss=0.669, reward_mean=0.050, reward_bound=0.088, batch=222 
1580: loss=0.674, reward_mean=0.090, reward_bound=0.229, batch=223 
1581: loss=0.677, reward_mean=0.180, reward_bound=0.314, batch=210 
1582: loss=0.672, reward_mean=0.100, reward_bound=0.143, batch=217 
1583: loss=0.667, reward_mean=0.090, reward_bound=0.153, batch=222 
1584: loss=0.671, reward_mean=0.060, reward_bound=0.167, batch=223 
1585: loss=0.677, reward_mean=0.120, reward_bound=0.220, batch=226 
1586: loss=0.676, reward_mean=0.120, reward_bound=0.254, batch=227 
1587: loss=0.673, reward_mean=0.140, reward_bound=0.282, batch=227 
1588: loss=0.673, reward_mean=0.160, reward_bound=0.342, batch=229 
1589: loss=0.679, reward_mean=0.140, reward_bound=0.349, batch=207 
1590: loss=0.677, reward_mean=0.130, reward_bound=0.132, batch=215 
1591: loss=0.678, reward_mean=0.130, reward_bound=0.170, batch=220 
1592: loss=0.681, reward_mean=0.130, reward_bound=0.274, batch=224 
1593: loss=0.678, reward_mean=0.140, reward_bound=0.282, batch=224 
1594: loss=0.682, reward_mean=0.070, reward_bound=0.314, batch=225 
1595: loss=0.680, reward_mean=0.070, reward_bound=0.296, batch=227 
1596: loss=0.682, reward_mean=0.130, reward_bound=0.349, batch=225 
1597: loss=0.680, reward_mean=0.130, reward_bound=0.273, batch=227 
1598: loss=0.681, reward_mean=0.150, reward_bound=0.380, batch=229 
1599: loss=0.681, reward_mean=0.100, reward_bound=0.324, batch=230 
1600: loss=0.681, reward_mean=0.140, reward_bound=0.349, batch=230 
1601: loss=0.682, reward_mean=0.110, reward_bound=0.387, batch=209 
1602: loss=0.680, reward_mean=0.160, reward_bound=0.254, batch=214 
1603: loss=0.680, reward_mean=0.090, reward_bound=0.160, batch=220 
1604: loss=0.678, reward_mean=0.170, reward_bound=0.254, batch=223 
1605: loss=0.682, reward_mean=0.130, reward_bound=0.282, batch=223 
1606: loss=0.689, reward_mean=0.100, reward_bound=0.301, batch=226 
1607: loss=0.690, reward_mean=0.110, reward_bound=0.314, batch=227 
1608: loss=0.688, reward_mean=0.120, reward_bound=0.330, batch=229 
1609: loss=0.687, reward_mean=0.100, reward_bound=0.328, batch=230 
1610: loss=0.687, reward_mean=0.080, reward_bound=0.349, batch=229 
1611: loss=0.689, reward_mean=0.160, reward_bound=0.387, batch=226 
1612: loss=0.695, reward_mean=0.120, reward_bound=0.430, batch=189 
1613: loss=0.676, reward_mean=0.130, reward_bound=0.014, batch=202 
1614: loss=0.669, reward_mean=0.080, reward_bound=0.000, batch=210 
1615: loss=0.664, reward_mean=0.100, reward_bound=0.059, batch=217 
1616: loss=0.666, reward_mean=0.140, reward_bound=0.122, batch=219 
1617: loss=0.671, reward_mean=0.130, reward_bound=0.150, batch=221 
1618: loss=0.673, reward_mean=0.110, reward_bound=0.167, batch=224 
1619: loss=0.677, reward_mean=0.170, reward_bound=0.226, batch=227 
1620: loss=0.685, reward_mean=0.170, reward_bound=0.254, batch=228 
1621: loss=0.689, reward_mean=0.080, reward_bound=0.282, batch=225 
1622: loss=0.687, reward_mean=0.150, reward_bound=0.289, batch=227 
1623: loss=0.684, reward_mean=0.110, reward_bound=0.342, batch=229 
1624: loss=0.680, reward_mean=0.130, reward_bound=0.349, batch=222 
1625: loss=0.679, reward_mean=0.120, reward_bound=0.314, batch=224 
1626: loss=0.680, reward_mean=0.140, reward_bound=0.349, batch=225 
1627: loss=0.684, reward_mean=0.090, reward_bound=0.387, batch=216 
1628: loss=0.682, reward_mean=0.140, reward_bound=0.217, batch=221 
1629: loss=0.687, reward_mean=0.070, reward_bound=0.185, batch=223 
1630: loss=0.679, reward_mean=0.080, reward_bound=0.220, batch=226 
1631: loss=0.686, reward_mean=0.070, reward_bound=0.229, batch=227 
1632: loss=0.681, reward_mean=0.080, reward_bound=0.277, batch=229 
1633: loss=0.685, reward_mean=0.090, reward_bound=0.295, batch=230 
1634: loss=0.683, reward_mean=0.130, reward_bound=0.376, batch=231 
1635: loss=0.685, reward_mean=0.220, reward_bound=0.387, batch=226 
1636: loss=0.686, reward_mean=0.140, reward_bound=0.390, batch=228 
1637: loss=0.685, reward_mean=0.110, reward_bound=0.430, batch=210 
1638: loss=0.682, reward_mean=0.180, reward_bound=0.247, batch=217 
1639: loss=0.674, reward_mean=0.100, reward_bound=0.277, batch=222 
1640: loss=0.680, reward_mean=0.160, reward_bound=0.282, batch=224 
1641: loss=0.682, reward_mean=0.140, reward_bound=0.280, batch=227 
1642: loss=0.682, reward_mean=0.140, reward_bound=0.308, batch=229 
1643: loss=0.682, reward_mean=0.130, reward_bound=0.314, batch=227 
1644: loss=0.684, reward_mean=0.140, reward_bound=0.342, batch=229 
1645: loss=0.687, reward_mean=0.140, reward_bound=0.349, batch=229 
1646: loss=0.690, reward_mean=0.120, reward_bound=0.387, batch=228 
1647: loss=0.687, reward_mean=0.180, reward_bound=0.430, batch=225 
1648: loss=0.686, reward_mean=0.140, reward_bound=0.365, batch=227 
1649: loss=0.690, reward_mean=0.100, reward_bound=0.430, batch=228 
1650: loss=0.690, reward_mean=0.170, reward_bound=0.478, batch=230 
1651: loss=0.690, reward_mean=0.080, reward_bound=0.451, batch=231 
1652: loss=0.690, reward_mean=0.150, reward_bound=0.430, batch=231 
1653: loss=0.690, reward_mean=0.140, reward_bound=0.430, batch=231 
1654: loss=0.706, reward_mean=0.100, reward_bound=0.478, batch=113 
1655: loss=0.685, reward_mean=0.130, reward_bound=0.000, batch=126 
1656: loss=0.672, reward_mean=0.180, reward_bound=0.000, batch=144 
1657: loss=0.668, reward_mean=0.100, reward_bound=0.000, batch=154 
1658: loss=0.666, reward_mean=0.210, reward_bound=0.000, batch=175 
1659: loss=0.648, reward_mean=0.130, reward_bound=0.000, batch=188 
1660: loss=0.651, reward_mean=0.180, reward_bound=0.034, batch=200 
1661: loss=0.651, reward_mean=0.080, reward_bound=0.000, batch=208 
1662: loss=0.653, reward_mean=0.090, reward_bound=0.039, batch=215 
1663: loss=0.652, reward_mean=0.160, reward_bound=0.059, batch=220 
1664: loss=0.653, reward_mean=0.160, reward_bound=0.096, batch=224 
1665: loss=0.654, reward_mean=0.090, reward_bound=0.109, batch=225 
1666: loss=0.663, reward_mean=0.160, reward_bound=0.150, batch=222 
1667: loss=0.661, reward_mean=0.130, reward_bound=0.167, batch=223 
1668: loss=0.664, reward_mean=0.200, reward_bound=0.206, batch=225 
1669: loss=0.671, reward_mean=0.110, reward_bound=0.229, batch=223 
1670: loss=0.668, reward_mean=0.060, reward_bound=0.244, batch=226 
1671: loss=0.670, reward_mean=0.190, reward_bound=0.254, batch=227 
1672: loss=0.673, reward_mean=0.120, reward_bound=0.282, batch=221 
1673: loss=0.670, reward_mean=0.090, reward_bound=0.282, batch=224 
1674: loss=0.670, reward_mean=0.100, reward_bound=0.308, batch=227 
1675: loss=0.668, reward_mean=0.100, reward_bound=0.292, batch=229 
1676: loss=0.673, reward_mean=0.140, reward_bound=0.314, batch=215 
1677: loss=0.671, reward_mean=0.090, reward_bound=0.118, batch=220 
1678: loss=0.674, reward_mean=0.100, reward_bound=0.274, batch=224 
1679: loss=0.670, reward_mean=0.200, reward_bound=0.314, batch=224 
1680: loss=0.669, reward_mean=0.090, reward_bound=0.282, batch=226 
1681: loss=0.665, reward_mean=0.140, reward_bound=0.331, batch=228 
1682: loss=0.672, reward_mean=0.070, reward_bound=0.349, batch=192 
1683: loss=0.668, reward_mean=0.100, reward_bound=0.000, batch=202 
1684: loss=0.670, reward_mean=0.170, reward_bound=0.132, batch=211 
1685: loss=0.667, reward_mean=0.140, reward_bound=0.185, batch=217 
1686: loss=0.673, reward_mean=0.040, reward_bound=0.000, batch=221 
1687: loss=0.667, reward_mean=0.130, reward_bound=0.254, batch=223 
1688: loss=0.666, reward_mean=0.120, reward_bound=0.282, batch=223 
1689: loss=0.665, reward_mean=0.130, reward_bound=0.314, batch=220 
1690: loss=0.666, reward_mean=0.140, reward_bound=0.266, batch=224 
1691: loss=0.663, reward_mean=0.150, reward_bound=0.349, batch=216 
1692: loss=0.663, reward_mean=0.110, reward_bound=0.298, batch=221 
1693: loss=0.665, reward_mean=0.120, reward_bound=0.349, batch=224 
1694: loss=0.669, reward_mean=0.070, reward_bound=0.206, batch=226 
1695: loss=0.670, reward_mean=0.170, reward_bound=0.387, batch=191 
1696: loss=0.666, reward_mean=0.180, reward_bound=0.185, batch=201 
1697: loss=0.662, reward_mean=0.090, reward_bound=0.000, batch=210 
1698: loss=0.667, reward_mean=0.120, reward_bound=0.109, batch=217 
1699: loss=0.668, reward_mean=0.140, reward_bound=0.178, batch=222 
1700: loss=0.673, reward_mean=0.120, reward_bound=0.206, batch=228 
1701: loss=0.672, reward_mean=0.060, reward_bound=0.206, batch=227 
1702: loss=0.670, reward_mean=0.140, reward_bound=0.254, batch=227 
1703: loss=0.667, reward_mean=0.180, reward_bound=0.314, batch=223 
1704: loss=0.670, reward_mean=0.140, reward_bound=0.349, batch=215 
1705: loss=0.674, reward_mean=0.150, reward_bound=0.175, batch=220 
1706: loss=0.673, reward_mean=0.140, reward_bound=0.314, batch=223 
1707: loss=0.673, reward_mean=0.100, reward_bound=0.290, batch=226 
1708: loss=0.670, reward_mean=0.170, reward_bound=0.349, batch=226 
1709: loss=0.668, reward_mean=0.130, reward_bound=0.387, batch=216 
1710: loss=0.664, reward_mean=0.080, reward_bound=0.107, batch=221 
1711: loss=0.668, reward_mean=0.130, reward_bound=0.150, batch=224 
1712: loss=0.663, reward_mean=0.120, reward_bound=0.226, batch=227 
1713: loss=0.660, reward_mean=0.060, reward_bound=0.308, batch=229 
1714: loss=0.663, reward_mean=0.070, reward_bound=0.314, batch=228 
1715: loss=0.663, reward_mean=0.090, reward_bound=0.314, batch=228 
1716: loss=0.662, reward_mean=0.110, reward_bound=0.353, batch=229 
1717: loss=0.663, reward_mean=0.160, reward_bound=0.387, batch=225 
1718: loss=0.666, reward_mean=0.150, reward_bound=0.430, batch=179 
1719: loss=0.649, reward_mean=0.090, reward_bound=0.000, batch=188 
1720: loss=0.659, reward_mean=0.160, reward_bound=0.081, batch=201 
1721: loss=0.649, reward_mean=0.060, reward_bound=0.000, batch=207 
1722: loss=0.663, reward_mean=0.170, reward_bound=0.126, batch=215 
1723: loss=0.662, reward_mean=0.120, reward_bound=0.150, batch=219 
1724: loss=0.661, reward_mean=0.130, reward_bound=0.185, batch=220 
1725: loss=0.663, reward_mean=0.060, reward_bound=0.200, batch=224 
1726: loss=0.666, reward_mean=0.130, reward_bound=0.229, batch=226 
1727: loss=0.663, reward_mean=0.090, reward_bound=0.254, batch=219 
1728: loss=0.658, reward_mean=0.090, reward_bound=0.250, batch=223 
1729: loss=0.655, reward_mean=0.130, reward_bound=0.271, batch=226 
1730: loss=0.660, reward_mean=0.150, reward_bound=0.282, batch=222 
1731: loss=0.661, reward_mean=0.150, reward_bound=0.314, batch=219 
1732: loss=0.661, reward_mean=0.140, reward_bound=0.309, batch=223 
1733: loss=0.661, reward_mean=0.110, reward_bound=0.271, batch=226 
1734: loss=0.660, reward_mean=0.120, reward_bound=0.331, batch=228 
1735: loss=0.661, reward_mean=0.150, reward_bound=0.349, batch=220 
1736: loss=0.662, reward_mean=0.150, reward_bound=0.338, batch=224 
1737: loss=0.660, reward_mean=0.160, reward_bound=0.349, batch=225 
1738: loss=0.662, reward_mean=0.110, reward_bound=0.329, batch=227 
1739: loss=0.648, reward_mean=0.160, reward_bound=0.387, batch=214 
1740: loss=0.644, reward_mean=0.100, reward_bound=0.224, batch=220 
1741: loss=0.646, reward_mean=0.080, reward_bound=0.201, batch=224 
1742: loss=0.646, reward_mean=0.060, reward_bound=0.224, batch=227 
1743: loss=0.647, reward_mean=0.100, reward_bound=0.249, batch=229 
1744: loss=0.648, reward_mean=0.150, reward_bound=0.282, batch=228 
1745: loss=0.647, reward_mean=0.140, reward_bound=0.317, batch=229 
1746: loss=0.647, reward_mean=0.110, reward_bound=0.364, batch=230 
1747: loss=0.646, reward_mean=0.100, reward_bound=0.387, batch=227 
1748: loss=0.647, reward_mean=0.140, reward_bound=0.277, batch=229 
1749: loss=0.646, reward_mean=0.150, reward_bound=0.387, batch=229 
1750: loss=0.647, reward_mean=0.140, reward_bound=0.360, batch=230 
1751: loss=0.658, reward_mean=0.150, reward_bound=0.430, batch=214 
1752: loss=0.657, reward_mean=0.180, reward_bound=0.342, batch=220 
1753: loss=0.657, reward_mean=0.140, reward_bound=0.304, batch=224 
1754: loss=0.656, reward_mean=0.180, reward_bound=0.349, batch=224 
1755: loss=0.657, reward_mean=0.130, reward_bound=0.380, batch=227 
1756: loss=0.656, reward_mean=0.150, reward_bound=0.387, batch=224 
1757: loss=0.655, reward_mean=0.160, reward_bound=0.422, batch=227 
1758: loss=0.655, reward_mean=0.140, reward_bound=0.422, batch=229 
1759: loss=0.653, reward_mean=0.060, reward_bound=0.292, batch=230 
1760: loss=0.654, reward_mean=0.120, reward_bound=0.418, batch=231 
1761: loss=0.653, reward_mean=0.100, reward_bound=0.430, batch=224 
1762: loss=0.649, reward_mean=0.100, reward_bound=0.311, batch=227 
1763: loss=0.654, reward_mean=0.130, reward_bound=0.342, batch=229 
1764: loss=0.646, reward_mean=0.140, reward_bound=0.364, batch=230 
1765: loss=0.646, reward_mean=0.030, reward_bound=0.246, batch=231 
1766: loss=0.648, reward_mean=0.160, reward_bound=0.430, batch=229 
1767: loss=0.647, reward_mean=0.100, reward_bound=0.381, batch=230 
1768: loss=0.646, reward_mean=0.140, reward_bound=0.464, batch=231 
1769: loss=0.688, reward_mean=0.160, reward_bound=0.478, batch=167 
1770: loss=0.680, reward_mean=0.080, reward_bound=0.000, batch=175 
1771: loss=0.672, reward_mean=0.180, reward_bound=0.030, batch=192 
1772: loss=0.670, reward_mean=0.080, reward_bound=0.000, batch=200 
1773: loss=0.672, reward_mean=0.090, reward_bound=0.000, batch=209 
1774: loss=0.671, reward_mean=0.160, reward_bound=0.058, batch=215 
1775: loss=0.674, reward_mean=0.110, reward_bound=0.103, batch=220 
1776: loss=0.677, reward_mean=0.090, reward_bound=0.142, batch=224 
1777: loss=0.668, reward_mean=0.160, reward_bound=0.183, batch=227 
1778: loss=0.671, reward_mean=0.070, reward_bound=0.185, batch=225 
1779: loss=0.675, reward_mean=0.140, reward_bound=0.234, batch=227 
1780: loss=0.670, reward_mean=0.110, reward_bound=0.254, batch=226 
1781: loss=0.669, reward_mean=0.120, reward_bound=0.254, batch=227 
1782: loss=0.676, reward_mean=0.140, reward_bound=0.282, batch=221 
1783: loss=0.688, reward_mean=0.150, reward_bound=0.314, batch=215 
1784: loss=0.685, reward_mean=0.110, reward_bound=0.177, batch=220 
1785: loss=0.682, reward_mean=0.160, reward_bound=0.314, batch=223 
1786: loss=0.684, reward_mean=0.120, reward_bound=0.349, batch=216 
1787: loss=0.677, reward_mean=0.080, reward_bound=0.176, batch=221 
1788: loss=0.677, reward_mean=0.130, reward_bound=0.282, batch=224 
1789: loss=0.683, reward_mean=0.110, reward_bound=0.314, batch=224 
1790: loss=0.684, reward_mean=0.100, reward_bound=0.311, batch=227 
1791: loss=0.680, reward_mean=0.150, reward_bound=0.349, batch=227 
1792: loss=0.685, reward_mean=0.070, reward_bound=0.387, batch=210 
1793: loss=0.682, reward_mean=0.130, reward_bound=0.229, batch=215 
1794: loss=0.683, reward_mean=0.190, reward_bound=0.282, batch=219 
1795: loss=0.685, reward_mean=0.140, reward_bound=0.314, batch=221 
1796: loss=0.681, reward_mean=0.110, reward_bound=0.167, batch=224 
1797: loss=0.685, reward_mean=0.130, reward_bound=0.280, batch=227 
1798: loss=0.680, reward_mean=0.130, reward_bound=0.349, batch=226 
1799: loss=0.678, reward_mean=0.160, reward_bound=0.387, batch=224 
1800: loss=0.677, reward_mean=0.070, reward_bound=0.339, batch=227 
1801: loss=0.674, reward_mean=0.150, reward_bound=0.349, batch=228 
1802: loss=0.676, reward_mean=0.100, reward_bound=0.353, batch=229 
1803: loss=0.679, reward_mean=0.140, reward_bound=0.364, batch=230 
1804: loss=0.678, reward_mean=0.160, reward_bound=0.387, batch=228 
1805: loss=0.677, reward_mean=0.190, reward_bound=0.430, batch=201 
1806: loss=0.676, reward_mean=0.190, reward_bound=0.254, batch=210 
1807: loss=0.678, reward_mean=0.160, reward_bound=0.229, batch=216 
1808: loss=0.672, reward_mean=0.110, reward_bound=0.254, batch=218 
1809: loss=0.675, reward_mean=0.100, reward_bound=0.208, batch=222 
1810: loss=0.670, reward_mean=0.080, reward_bound=0.263, batch=225 
1811: loss=0.672, reward_mean=0.150, reward_bound=0.314, batch=225 
1812: loss=0.671, reward_mean=0.130, reward_bound=0.289, batch=227 
1813: loss=0.669, reward_mean=0.080, reward_bound=0.314, batch=228 
1814: loss=0.677, reward_mean=0.160, reward_bound=0.349, batch=228 
1815: loss=0.674, reward_mean=0.160, reward_bound=0.387, batch=223 
1816: loss=0.682, reward_mean=0.140, reward_bound=0.430, batch=215 
1817: loss=0.669, reward_mean=0.050, reward_bound=0.014, batch=220 
1818: loss=0.681, reward_mean=0.120, reward_bound=0.180, batch=224 
1819: loss=0.679, reward_mean=0.080, reward_bound=0.167, batch=226 
1820: loss=0.673, reward_mean=0.150, reward_bound=0.229, batch=226 
1821: loss=0.674, reward_mean=0.090, reward_bound=0.349, batch=226 
1822: loss=0.672, reward_mean=0.120, reward_bound=0.368, batch=228 
1823: loss=0.675, reward_mean=0.180, reward_bound=0.387, batch=228 
1824: loss=0.676, reward_mean=0.170, reward_bound=0.430, batch=226 
1825: loss=0.675, reward_mean=0.180, reward_bound=0.387, batch=227 
1826: loss=0.673, reward_mean=0.120, reward_bound=0.422, batch=229 
1827: loss=0.676, reward_mean=0.080, reward_bound=0.450, batch=230 
1828: loss=0.678, reward_mean=0.130, reward_bound=0.451, batch=231 
1829: loss=0.682, reward_mean=0.160, reward_bound=0.478, batch=194 
1830: loss=0.687, reward_mean=0.130, reward_bound=0.093, batch=206 
1831: loss=0.675, reward_mean=0.190, reward_bound=0.128, batch=214 
1832: loss=0.669, reward_mean=0.110, reward_bound=0.149, batch=220 
1833: loss=0.677, reward_mean=0.160, reward_bound=0.185, batch=221 
1834: loss=0.675, reward_mean=0.100, reward_bound=0.229, batch=221 
1835: loss=0.670, reward_mean=0.100, reward_bound=0.254, batch=222 
1836: loss=0.681, reward_mean=0.130, reward_bound=0.314, batch=218 
1837: loss=0.676, reward_mean=0.060, reward_bound=0.257, batch=222 
1838: loss=0.678, reward_mean=0.110, reward_bound=0.282, batch=224 
1839: loss=0.677, reward_mean=0.130, reward_bound=0.314, batch=225 
1840: loss=0.686, reward_mean=0.120, reward_bound=0.349, batch=220 
1841: loss=0.682, reward_mean=0.120, reward_bound=0.274, batch=224 
1842: loss=0.681, reward_mean=0.190, reward_bound=0.380, batch=227 
1843: loss=0.685, reward_mean=0.160, reward_bound=0.387, batch=212 
1844: loss=0.678, reward_mean=0.080, reward_bound=0.155, batch=218 
1845: loss=0.678, reward_mean=0.120, reward_bound=0.208, batch=222 
1846: loss=0.681, reward_mean=0.180, reward_bound=0.282, batch=224 
1847: loss=0.680, reward_mean=0.110, reward_bound=0.314, batch=224 
1848: loss=0.681, reward_mean=0.130, reward_bound=0.345, batch=227 
1849: loss=0.681, reward_mean=0.130, reward_bound=0.349, batch=228 
1850: loss=0.681, reward_mean=0.130, reward_bound=0.349, batch=228 
1851: loss=0.684, reward_mean=0.120, reward_bound=0.387, batch=220 
1852: loss=0.685, reward_mean=0.110, reward_bound=0.338, batch=224 
1853: loss=0.685, reward_mean=0.120, reward_bound=0.349, batch=225 
1854: loss=0.682, reward_mean=0.190, reward_bound=0.387, batch=226 
1855: loss=0.681, reward_mean=0.090, reward_bound=0.349, batch=227 
1856: loss=0.688, reward_mean=0.160, reward_bound=0.430, batch=211 
1857: loss=0.684, reward_mean=0.100, reward_bound=0.206, batch=217 
1858: loss=0.683, reward_mean=0.140, reward_bound=0.254, batch=221 
1859: loss=0.686, reward_mean=0.140, reward_bound=0.314, batch=222 
1860: loss=0.684, reward_mean=0.140, reward_bound=0.292, batch=225 
1861: loss=0.679, reward_mean=0.140, reward_bound=0.349, batch=224 
1862: loss=0.679, reward_mean=0.120, reward_bound=0.252, batch=227 
1863: loss=0.677, reward_mean=0.090, reward_bound=0.335, batch=229 
1864: loss=0.683, reward_mean=0.120, reward_bound=0.387, batch=222 
1865: loss=0.680, reward_mean=0.140, reward_bound=0.272, batch=225 
1866: loss=0.678, reward_mean=0.110, reward_bound=0.289, batch=227 
1867: loss=0.677, reward_mean=0.130, reward_bound=0.342, batch=229 
1868: loss=0.678, reward_mean=0.130, reward_bound=0.349, batch=229 
1869: loss=0.678, reward_mean=0.100, reward_bound=0.364, batch=230 
1870: loss=0.683, reward_mean=0.130, reward_bound=0.387, batch=228 
1871: loss=0.683, reward_mean=0.110, reward_bound=0.430, batch=228 
1872: loss=0.680, reward_mean=0.170, reward_bound=0.478, batch=231 
1873: loss=0.680, reward_mean=0.080, reward_bound=0.430, batch=231 
1874: loss=0.684, reward_mean=0.090, reward_bound=0.478, batch=217 
1875: loss=0.684, reward_mean=0.110, reward_bound=0.422, batch=222 
1876: loss=0.688, reward_mean=0.160, reward_bound=0.282, batch=224 
1877: loss=0.688, reward_mean=0.080, reward_bound=0.282, batch=226 
1878: loss=0.686, reward_mean=0.110, reward_bound=0.372, batch=228 
1879: loss=0.686, reward_mean=0.100, reward_bound=0.387, batch=228 
1880: loss=0.686, reward_mean=0.150, reward_bound=0.392, batch=229 
1881: loss=0.686, reward_mean=0.100, reward_bound=0.381, batch=230 
1882: loss=0.685, reward_mean=0.090, reward_bound=0.430, batch=229 
1883: loss=0.685, reward_mean=0.120, reward_bound=0.380, batch=230 
1884: loss=0.687, reward_mean=0.120, reward_bound=0.464, batch=231 
1885: loss=0.687, reward_mean=0.120, reward_bound=0.478, batch=227 
1886: loss=0.688, reward_mean=0.130, reward_bound=0.469, batch=229 
1887: loss=0.687, reward_mean=0.110, reward_bound=0.405, batch=230 
1888: loss=0.686, reward_mean=0.120, reward_bound=0.464, batch=231 
1889: loss=0.687, reward_mean=0.120, reward_bound=0.478, batch=228 
1890: loss=0.690, reward_mean=0.110, reward_bound=0.441, batch=229 
1891: loss=0.690, reward_mean=0.100, reward_bound=0.328, batch=230 
1892: loss=0.689, reward_mean=0.120, reward_bound=0.349, batch=230 
1893: loss=0.689, reward_mean=0.100, reward_bound=0.418, batch=231 
1894: loss=0.690, reward_mean=0.120, reward_bound=0.478, batch=231 
1896: loss=0.682, reward_mean=0.100, reward_bound=0.000, batch=10 
1897: loss=0.663, reward_mean=0.200, reward_bound=0.000, batch=30 
1898: loss=0.660, reward_mean=0.150, reward_bound=0.000, batch=45 
1899: loss=0.660, reward_mean=0.100, reward_bound=0.000, batch=55 
1900: loss=0.657, reward_mean=0.080, reward_bound=0.000, batch=63 
1901: loss=0.644, reward_mean=0.150, reward_bound=0.000, batch=78 
1902: loss=0.637, reward_mean=0.110, reward_bound=0.000, batch=89 
1903: loss=0.627, reward_mean=0.200, reward_bound=0.000, batch=109 
1904: loss=0.636, reward_mean=0.170, reward_bound=0.000, batch=126 
1905: loss=0.636, reward_mean=0.160, reward_bound=0.000, batch=142 
1906: loss=0.638, reward_mean=0.140, reward_bound=0.000, batch=156 
1907: loss=0.635, reward_mean=0.210, reward_bound=0.000, batch=177 
1908: loss=0.636, reward_mean=0.200, reward_bound=0.011, batch=194 
1909: loss=0.631, reward_mean=0.130, reward_bound=0.012, batch=206 
1910: loss=0.631, reward_mean=0.130, reward_bound=0.018, batch=214 
1911: loss=0.641, reward_mean=0.150, reward_bound=0.034, batch=220 
1912: loss=0.631, reward_mean=0.220, reward_bound=0.072, batch=222 
1913: loss=0.634, reward_mean=0.160, reward_bound=0.098, batch=216 
1914: loss=0.631, reward_mean=0.140, reward_bound=0.109, batch=216 
1915: loss=0.635, reward_mean=0.150, reward_bound=0.122, batch=218 
1916: loss=0.632, reward_mean=0.150, reward_bound=0.135, batch=217 
1917: loss=0.636, reward_mean=0.130, reward_bound=0.150, batch=211 
1918: loss=0.628, reward_mean=0.170, reward_bound=0.167, batch=199 
1919: loss=0.632, reward_mean=0.160, reward_bound=0.093, batch=209 
1920: loss=0.632, reward_mean=0.150, reward_bound=0.127, batch=216 
1921: loss=0.643, reward_mean=0.240, reward_bound=0.185, batch=201 
1922: loss=0.644, reward_mean=0.140, reward_bound=0.058, batch=210 
1923: loss=0.644, reward_mean=0.100, reward_bound=0.138, batch=217 
1924: loss=0.644, reward_mean=0.230, reward_bound=0.206, batch=201 
1925: loss=0.645, reward_mean=0.220, reward_bound=0.185, batch=210 
1926: loss=0.644, reward_mean=0.230, reward_bound=0.229, batch=189 
1927: loss=0.645, reward_mean=0.170, reward_bound=0.083, batch=202 
1928: loss=0.642, reward_mean=0.150, reward_bound=0.092, batch=211 
1929: loss=0.636, reward_mean=0.150, reward_bound=0.135, batch=217 
1930: loss=0.635, reward_mean=0.140, reward_bound=0.167, batch=221 
1931: loss=0.639, reward_mean=0.190, reward_bound=0.206, batch=224 
1932: loss=0.636, reward_mean=0.160, reward_bound=0.254, batch=198 
1933: loss=0.635, reward_mean=0.120, reward_bound=0.085, batch=208 
1934: loss=0.633, reward_mean=0.150, reward_bound=0.169, batch=215 
1935: loss=0.642, reward_mean=0.240, reward_bound=0.282, batch=195 
1936: loss=0.639, reward_mean=0.240, reward_bound=0.167, batch=205 
1937: loss=0.639, reward_mean=0.160, reward_bound=0.131, batch=213 
1938: loss=0.635, reward_mean=0.190, reward_bound=0.206, batch=216 
1939: loss=0.632, reward_mean=0.230, reward_bound=0.282, batch=216 
1940: loss=0.632, reward_mean=0.100, reward_bound=0.244, batch=221 
1941: loss=0.632, reward_mean=0.220, reward_bound=0.314, batch=180 
1942: loss=0.632, reward_mean=0.240, reward_bound=0.131, batch=196 
1943: loss=0.625, reward_mean=0.190, reward_bound=0.135, batch=206 
1944: loss=0.623, reward_mean=0.150, reward_bound=0.089, batch=213 
1945: loss=0.628, reward_mean=0.110, reward_bound=0.125, batch=219 
1946: loss=0.626, reward_mean=0.160, reward_bound=0.167, batch=219 
1947: loss=0.631, reward_mean=0.130, reward_bound=0.185, batch=222 
1948: loss=0.631, reward_mean=0.160, reward_bound=0.206, batch=231 
1949: loss=0.627, reward_mean=0.200, reward_bound=0.254, batch=223 
1950: loss=0.629, reward_mean=0.210, reward_bound=0.282, batch=218 
1951: loss=0.630, reward_mean=0.180, reward_bound=0.314, batch=217 
1952: loss=0.616, reward_mean=0.130, reward_bound=0.349, batch=159 
1953: loss=0.609, reward_mean=0.150, reward_bound=0.000, batch=174 
1954: loss=0.611, reward_mean=0.160, reward_bound=0.000, batch=190 
1955: loss=0.609, reward_mean=0.170, reward_bound=0.023, batch=203 
1956: loss=0.617, reward_mean=0.180, reward_bound=0.056, batch=212 
1957: loss=0.613, reward_mean=0.170, reward_bound=0.098, batch=216 
1958: loss=0.618, reward_mean=0.260, reward_bound=0.122, batch=220 
1959: loss=0.617, reward_mean=0.160, reward_bound=0.127, batch=224 
1960: loss=0.617, reward_mean=0.180, reward_bound=0.150, batch=225 
1961: loss=0.616, reward_mean=0.190, reward_bound=0.167, batch=225 
1962: loss=0.617, reward_mean=0.200, reward_bound=0.189, batch=227 
1963: loss=0.612, reward_mean=0.100, reward_bound=0.206, batch=225 
1964: loss=0.611, reward_mean=0.150, reward_bound=0.234, batch=227 
1965: loss=0.614, reward_mean=0.160, reward_bound=0.254, batch=223 
1966: loss=0.608, reward_mean=0.170, reward_bound=0.282, batch=212 
1967: loss=0.608, reward_mean=0.180, reward_bound=0.220, batch=218 
1968: loss=0.607, reward_mean=0.150, reward_bound=0.208, batch=222 
1969: loss=0.606, reward_mean=0.210, reward_bound=0.263, batch=225 
1970: loss=0.608, reward_mean=0.200, reward_bound=0.282, batch=225 
1971: loss=0.614, reward_mean=0.170, reward_bound=0.314, batch=217 
1972: loss=0.612, reward_mean=0.240, reward_bound=0.308, batch=222 
1973: loss=0.611, reward_mean=0.230, reward_bound=0.314, batch=224 
1974: loss=0.607, reward_mean=0.170, reward_bound=0.349, batch=217 
1975: loss=0.608, reward_mean=0.130, reward_bound=0.155, batch=222 
1976: loss=0.606, reward_mean=0.160, reward_bound=0.206, batch=227 
1977: loss=0.608, reward_mean=0.110, reward_bound=0.224, batch=229 
1978: loss=0.608, reward_mean=0.240, reward_bound=0.328, batch=230 
1979: loss=0.604, reward_mean=0.200, reward_bound=0.376, batch=231 
1980: loss=0.605, reward_mean=0.170, reward_bound=0.387, batch=165 
1981: loss=0.584, reward_mean=0.210, reward_bound=0.025, batch=185 
1982: loss=0.589, reward_mean=0.210, reward_bound=0.058, batch=200 
1983: loss=0.572, reward_mean=0.210, reward_bound=0.072, batch=209 
1984: loss=0.576, reward_mean=0.180, reward_bound=0.103, batch=216 
1985: loss=0.596, reward_mean=0.200, reward_bound=0.150, batch=214 
1986: loss=0.593, reward_mean=0.180, reward_bound=0.165, batch=220 
1987: loss=0.578, reward_mean=0.200, reward_bound=0.185, batch=218 
1988: loss=0.580, reward_mean=0.160, reward_bound=0.206, batch=215 
1989: loss=0.582, reward_mean=0.190, reward_bound=0.229, batch=217 
1990: loss=0.585, reward_mean=0.170, reward_bound=0.254, batch=214 
1991: loss=0.585, reward_mean=0.200, reward_bound=0.204, batch=220 
1992: loss=0.580, reward_mean=0.150, reward_bound=0.229, batch=223 
1993: loss=0.579, reward_mean=0.180, reward_bound=0.282, batch=214 
1994: loss=0.579, reward_mean=0.140, reward_bound=0.176, batch=220 
1995: loss=0.583, reward_mean=0.250, reward_bound=0.254, batch=223 
1996: loss=0.583, reward_mean=0.150, reward_bound=0.271, batch=226 
1997: loss=0.591, reward_mean=0.220, reward_bound=0.314, batch=209 
1998: loss=0.589, reward_mean=0.130, reward_bound=0.127, batch=216 
1999: loss=0.587, reward_mean=0.170, reward_bound=0.206, batch=220 
2000: loss=0.585, reward_mean=0.150, reward_bound=0.254, batch=223 
2001: loss=0.592, reward_mean=0.180, reward_bound=0.282, batch=224 
2002: loss=0.583, reward_mean=0.200, reward_bound=0.314, batch=226 
2003: loss=0.593, reward_mean=0.160, reward_bound=0.349, batch=209 
2004: loss=0.586, reward_mean=0.160, reward_bound=0.194, batch=216 
2005: loss=0.590, reward_mean=0.160, reward_bound=0.229, batch=219 
2006: loss=0.590, reward_mean=0.190, reward_bound=0.282, batch=219 
2007: loss=0.587, reward_mean=0.190, reward_bound=0.314, batch=222 
2008: loss=0.594, reward_mean=0.170, reward_bound=0.349, batch=220 
2009: loss=0.595, reward_mean=0.190, reward_bound=0.376, batch=224 
2010: loss=0.608, reward_mean=0.170, reward_bound=0.387, batch=208 
2011: loss=0.605, reward_mean=0.190, reward_bound=0.206, batch=214 
2012: loss=0.606, reward_mean=0.150, reward_bound=0.277, batch=220 
2013: loss=0.607, reward_mean=0.170, reward_bound=0.282, batch=222 
2014: loss=0.605, reward_mean=0.180, reward_bound=0.360, batch=225 
2015: loss=0.605, reward_mean=0.100, reward_bound=0.281, batch=227 
2016: loss=0.603, reward_mean=0.170, reward_bound=0.387, batch=220 
2017: loss=0.603, reward_mean=0.220, reward_bound=0.304, batch=224 
2018: loss=0.603, reward_mean=0.150, reward_bound=0.349, batch=226 
2019: loss=0.603, reward_mean=0.160, reward_bound=0.387, batch=225 
2020: loss=0.602, reward_mean=0.180, reward_bound=0.289, batch=227 
2021: loss=0.603, reward_mean=0.170, reward_bound=0.380, batch=229 
2022: loss=0.602, reward_mean=0.170, reward_bound=0.324, batch=230 
2023: loss=0.602, reward_mean=0.200, reward_bound=0.387, batch=228 
2024: loss=0.603, reward_mean=0.190, reward_bound=0.321, batch=229 
2025: loss=0.602, reward_mean=0.150, reward_bound=0.328, batch=230 
2026: loss=0.600, reward_mean=0.180, reward_bound=0.418, batch=231 
2027: loss=0.606, reward_mean=0.190, reward_bound=0.430, batch=122 
2028: loss=0.601, reward_mean=0.160, reward_bound=0.000, batch=138 
2029: loss=0.591, reward_mean=0.160, reward_bound=0.000, batch=154 
2030: loss=0.577, reward_mean=0.170, reward_bound=0.000, batch=171 
2031: loss=0.573, reward_mean=0.130, reward_bound=0.000, batch=184 
2032: loss=0.574, reward_mean=0.200, reward_bound=0.018, batch=198 
2033: loss=0.573, reward_mean=0.190, reward_bound=0.039, batch=208 
2034: loss=0.571, reward_mean=0.170, reward_bound=0.065, batch=213 
2035: loss=0.566, reward_mean=0.200, reward_bound=0.080, batch=217 
2036: loss=0.568, reward_mean=0.180, reward_bound=0.109, batch=223 
2037: loss=0.572, reward_mean=0.170, reward_bound=0.122, batch=224 
2038: loss=0.583, reward_mean=0.150, reward_bound=0.135, batch=226 
2039: loss=0.579, reward_mean=0.220, reward_bound=0.158, batch=228 
2040: loss=0.583, reward_mean=0.230, reward_bound=0.185, batch=217 
2041: loss=0.586, reward_mean=0.190, reward_bound=0.206, batch=214 
2042: loss=0.587, reward_mean=0.190, reward_bound=0.185, batch=219 
2043: loss=0.592, reward_mean=0.230, reward_bound=0.229, batch=221 
2044: loss=0.592, reward_mean=0.210, reward_bound=0.254, batch=211 
2045: loss=0.588, reward_mean=0.190, reward_bound=0.206, batch=216 
2046: loss=0.587, reward_mean=0.180, reward_bound=0.198, batch=221 
2047: loss=0.592, reward_mean=0.180, reward_bound=0.282, batch=209 
2048: loss=0.595, reward_mean=0.180, reward_bound=0.206, batch=215 
2049: loss=0.600, reward_mean=0.210, reward_bound=0.282, batch=218 
2050: loss=0.596, reward_mean=0.110, reward_bound=0.187, batch=222 
2051: loss=0.598, reward_mean=0.100, reward_bound=0.191, batch=225 
2052: loss=0.600, reward_mean=0.160, reward_bound=0.234, batch=227 
2053: loss=0.607, reward_mean=0.220, reward_bound=0.314, batch=222 
2054: loss=0.607, reward_mean=0.180, reward_bound=0.229, batch=225 
2055: loss=0.598, reward_mean=0.190, reward_bound=0.349, batch=208 
2056: loss=0.594, reward_mean=0.230, reward_bound=0.187, batch=215 
2057: loss=0.593, reward_mean=0.180, reward_bound=0.254, batch=218 
2058: loss=0.594, reward_mean=0.230, reward_bound=0.282, batch=220 
2059: loss=0.593, reward_mean=0.230, reward_bound=0.314, batch=221 
2060: loss=0.589, reward_mean=0.200, reward_bound=0.349, batch=222 
2061: loss=0.593, reward_mean=0.170, reward_bound=0.387, batch=194 
2062: loss=0.580, reward_mean=0.190, reward_bound=0.134, batch=206 
2063: loss=0.576, reward_mean=0.150, reward_bound=0.143, batch=214 
2064: loss=0.574, reward_mean=0.120, reward_bound=0.165, batch=220 
2065: loss=0.580, reward_mean=0.290, reward_bound=0.206, batch=227 
2066: loss=0.580, reward_mean=0.160, reward_bound=0.206, batch=228 
2067: loss=0.591, reward_mean=0.190, reward_bound=0.254, batch=221 
2068: loss=0.590, reward_mean=0.180, reward_bound=0.282, batch=223 
2069: loss=0.586, reward_mean=0.200, reward_bound=0.314, batch=221 
2070: loss=0.585, reward_mean=0.150, reward_bound=0.282, batch=224 
2071: loss=0.587, reward_mean=0.230, reward_bound=0.311, batch=227 
2072: loss=0.587, reward_mean=0.150, reward_bound=0.308, batch=229 
2073: loss=0.584, reward_mean=0.160, reward_bound=0.349, batch=223 
2074: loss=0.585, reward_mean=0.170, reward_bound=0.372, batch=226 
2075: loss=0.584, reward_mean=0.120, reward_bound=0.254, batch=227 
2076: loss=0.582, reward_mean=0.150, reward_bound=0.335, batch=229 
2077: loss=0.584, reward_mean=0.170, reward_bound=0.364, batch=230 
2078: loss=0.590, reward_mean=0.140, reward_bound=0.387, batch=222 
2079: loss=0.584, reward_mean=0.160, reward_bound=0.206, batch=227 
2080: loss=0.588, reward_mean=0.230, reward_bound=0.282, batch=228 
2081: loss=0.590, reward_mean=0.180, reward_bound=0.314, batch=228 
2082: loss=0.590, reward_mean=0.200, reward_bound=0.387, batch=228 
2083: loss=0.589, reward_mean=0.130, reward_bound=0.353, batch=229 
2084: loss=0.590, reward_mean=0.210, reward_bound=0.405, batch=230 
2085: loss=0.590, reward_mean=0.140, reward_bound=0.406, batch=231 
2086: loss=0.604, reward_mean=0.200, reward_bound=0.430, batch=192 
2087: loss=0.600, reward_mean=0.190, reward_bound=0.140, batch=204 
2088: loss=0.599, reward_mean=0.130, reward_bound=0.096, batch=213 
2089: loss=0.593, reward_mean=0.150, reward_bound=0.144, batch=219 
2090: loss=0.596, reward_mean=0.190, reward_bound=0.206, batch=217 
2091: loss=0.595, reward_mean=0.160, reward_bound=0.229, batch=220 
2092: loss=0.599, reward_mean=0.130, reward_bound=0.254, batch=220 
2093: loss=0.596, reward_mean=0.190, reward_bound=0.254, batch=223 
2094: loss=0.596, reward_mean=0.120, reward_bound=0.227, batch=226 
2095: loss=0.592, reward_mean=0.170, reward_bound=0.282, batch=223 
2096: loss=0.602, reward_mean=0.200, reward_bound=0.314, batch=219 
2097: loss=0.607, reward_mean=0.140, reward_bound=0.349, batch=216 
2098: loss=0.614, reward_mean=0.210, reward_bound=0.349, batch=220 
2099: loss=0.613, reward_mean=0.170, reward_bound=0.296, batch=224 
2100: loss=0.610, reward_mean=0.200, reward_bound=0.387, batch=219 
2101: loss=0.611, reward_mean=0.180, reward_bound=0.328, batch=223 
2102: loss=0.608, reward_mean=0.190, reward_bound=0.335, batch=226 
2103: loss=0.610, reward_mean=0.080, reward_bound=0.217, batch=228 
2104: loss=0.607, reward_mean=0.170, reward_bound=0.317, batch=229 
2105: loss=0.610, reward_mean=0.110, reward_bound=0.349, batch=227 
2106: loss=0.611, reward_mean=0.150, reward_bound=0.422, batch=229 
2107: loss=0.610, reward_mean=0.180, reward_bound=0.405, batch=230 
2108: loss=0.609, reward_mean=0.070, reward_bound=0.430, batch=215 
2109: loss=0.610, reward_mean=0.160, reward_bound=0.289, batch=220 
2110: loss=0.609, reward_mean=0.130, reward_bound=0.266, batch=224 
2111: loss=0.617, reward_mean=0.160, reward_bound=0.314, batch=226 
2112: loss=0.615, reward_mean=0.240, reward_bound=0.387, batch=226 
2113: loss=0.615, reward_mean=0.220, reward_bound=0.387, batch=226 
2114: loss=0.615, reward_mean=0.140, reward_bound=0.349, batch=227 
2115: loss=0.615, reward_mean=0.120, reward_bound=0.387, batch=228 
2116: loss=0.614, reward_mean=0.210, reward_bound=0.430, batch=226 
2117: loss=0.613, reward_mean=0.220, reward_bound=0.387, batch=227 
2118: loss=0.612, reward_mean=0.150, reward_bound=0.430, batch=227 
2119: loss=0.612, reward_mean=0.170, reward_bound=0.380, batch=229 
2120: loss=0.612, reward_mean=0.180, reward_bound=0.349, batch=229 
2121: loss=0.615, reward_mean=0.180, reward_bound=0.450, batch=230 
2122: loss=0.615, reward_mean=0.170, reward_bound=0.430, batch=230 
2123: loss=0.616, reward_mean=0.150, reward_bound=0.464, batch=231 
2124: loss=0.618, reward_mean=0.140, reward_bound=0.478, batch=93 
2125: loss=0.587, reward_mean=0.160, reward_bound=0.000, batch=109 
2126: loss=0.588, reward_mean=0.190, reward_bound=0.000, batch=128 
2127: loss=0.579, reward_mean=0.140, reward_bound=0.000, batch=142 
2128: loss=0.578, reward_mean=0.160, reward_bound=0.000, batch=158 
2129: loss=0.571, reward_mean=0.200, reward_bound=0.000, batch=178 
2130: loss=0.578, reward_mean=0.150, reward_bound=0.000, batch=193 
2131: loss=0.581, reward_mean=0.130, reward_bound=0.008, batch=205 
2132: loss=0.583, reward_mean=0.140, reward_bound=0.025, batch=212 
2133: loss=0.588, reward_mean=0.170, reward_bound=0.058, batch=217 
2134: loss=0.588, reward_mean=0.170, reward_bound=0.080, batch=221 
2135: loss=0.589, reward_mean=0.170, reward_bound=0.109, batch=221 
2136: loss=0.588, reward_mean=0.200, reward_bound=0.135, batch=222 
2137: loss=0.577, reward_mean=0.160, reward_bound=0.150, batch=223 
2138: loss=0.584, reward_mean=0.140, reward_bound=0.167, batch=220 
2139: loss=0.583, reward_mean=0.180, reward_bound=0.185, batch=216 
2140: loss=0.585, reward_mean=0.180, reward_bound=0.206, batch=212 
2141: loss=0.589, reward_mean=0.150, reward_bound=0.140, batch=218 
2142: loss=0.586, reward_mean=0.170, reward_bound=0.185, batch=220 
2143: loss=0.589, reward_mean=0.230, reward_bound=0.229, batch=212 
2144: loss=0.589, reward_mean=0.140, reward_bound=0.206, batch=218 
2145: loss=0.593, reward_mean=0.150, reward_bound=0.254, batch=208 
2146: loss=0.593, reward_mean=0.170, reward_bound=0.257, batch=215 
2147: loss=0.591, reward_mean=0.130, reward_bound=0.122, batch=219 
2148: loss=0.606, reward_mean=0.180, reward_bound=0.282, batch=199 
2149: loss=0.598, reward_mean=0.130, reward_bound=0.046, batch=209 
2150: loss=0.601, reward_mean=0.230, reward_bound=0.174, batch=216 
2151: loss=0.599, reward_mean=0.170, reward_bound=0.217, batch=221 
2152: loss=0.598, reward_mean=0.170, reward_bound=0.229, batch=223 
2153: loss=0.599, reward_mean=0.190, reward_bound=0.282, batch=221 
2154: loss=0.596, reward_mean=0.150, reward_bound=0.314, batch=198 
2155: loss=0.585, reward_mean=0.150, reward_bound=0.074, batch=208 
2156: loss=0.594, reward_mean=0.200, reward_bound=0.185, batch=213 
2157: loss=0.592, reward_mean=0.100, reward_bound=0.117, batch=219 
2158: loss=0.587, reward_mean=0.220, reward_bound=0.239, batch=223 
2159: loss=0.599, reward_mean=0.250, reward_bound=0.282, batch=224 
2160: loss=0.596, reward_mean=0.190, reward_bound=0.314, batch=222 
2161: loss=0.594, reward_mean=0.110, reward_bound=0.349, batch=194 
2162: loss=0.581, reward_mean=0.220, reward_bound=0.164, batch=206 
2163: loss=0.586, reward_mean=0.190, reward_bound=0.167, batch=212 
2164: loss=0.582, reward_mean=0.160, reward_bound=0.161, batch=218 
2165: loss=0.586, reward_mean=0.210, reward_bound=0.206, batch=221 
2166: loss=0.587, reward_mean=0.190, reward_bound=0.254, batch=224 
2167: loss=0.587, reward_mean=0.100, reward_bound=0.282, batch=222 
2168: loss=0.594, reward_mean=0.190, reward_bound=0.314, batch=218 
2169: loss=0.592, reward_mean=0.190, reward_bound=0.349, batch=215 
2170: loss=0.586, reward_mean=0.160, reward_bound=0.210, batch=220 
2171: loss=0.587, reward_mean=0.130, reward_bound=0.222, batch=224 
2172: loss=0.589, reward_mean=0.190, reward_bound=0.282, batch=222 
2173: loss=0.586, reward_mean=0.220, reward_bound=0.324, batch=225 
2174: loss=0.588, reward_mean=0.130, reward_bound=0.349, batch=225 
2175: loss=0.586, reward_mean=0.190, reward_bound=0.321, batch=227 
2176: loss=0.584, reward_mean=0.100, reward_bound=0.308, batch=229 
2177: loss=0.585, reward_mean=0.130, reward_bound=0.314, batch=228 
2178: loss=0.595, reward_mean=0.180, reward_bound=0.387, batch=177 
2179: loss=0.591, reward_mean=0.150, reward_bound=0.000, batch=192 
2180: loss=0.585, reward_mean=0.160, reward_bound=0.072, batch=204 
2181: loss=0.585, reward_mean=0.150, reward_bound=0.097, batch=213 
2182: loss=0.593, reward_mean=0.170, reward_bound=0.122, batch=218 
2183: loss=0.595, reward_mean=0.170, reward_bound=0.185, batch=219 
2184: loss=0.595, reward_mean=0.170, reward_bound=0.229, batch=213 
2185: loss=0.595, reward_mean=0.170, reward_bound=0.254, batch=218 
2186: loss=0.596, reward_mean=0.130, reward_bound=0.138, batch=222 
2187: loss=0.594, reward_mean=0.140, reward_bound=0.172, batch=225 
2188: loss=0.602, reward_mean=0.220, reward_bound=0.282, batch=219 
2189: loss=0.598, reward_mean=0.150, reward_bound=0.295, batch=223 
2190: loss=0.597, reward_mean=0.170, reward_bound=0.254, batch=225 
2191: loss=0.591, reward_mean=0.170, reward_bound=0.314, batch=221 
2192: loss=0.589, reward_mean=0.170, reward_bound=0.254, batch=224 
2193: loss=0.592, reward_mean=0.110, reward_bound=0.314, batch=226 
2194: loss=0.593, reward_mean=0.140, reward_bound=0.349, batch=214 
2195: loss=0.596, reward_mean=0.180, reward_bound=0.280, batch=220 
2196: loss=0.593, reward_mean=0.170, reward_bound=0.282, batch=220 
2197: loss=0.597, reward_mean=0.150, reward_bound=0.304, batch=224 
2198: loss=0.591, reward_mean=0.140, reward_bound=0.314, batch=224 
2199: loss=0.594, reward_mean=0.200, reward_bound=0.345, batch=227 
2200: loss=0.599, reward_mean=0.080, reward_bound=0.349, batch=225 
2201: loss=0.598, reward_mean=0.180, reward_bound=0.387, batch=211 
2202: loss=0.601, reward_mean=0.180, reward_bound=0.229, batch=216 
2203: loss=0.599, reward_mean=0.190, reward_bound=0.268, batch=221 
2204: loss=0.595, reward_mean=0.130, reward_bound=0.282, batch=224 
2205: loss=0.595, reward_mean=0.230, reward_bound=0.314, batch=225 
2206: loss=0.595, reward_mean=0.170, reward_bound=0.349, batch=225 
2207: loss=0.596, reward_mean=0.160, reward_bound=0.349, batch=226 
2208: loss=0.596, reward_mean=0.200, reward_bound=0.349, batch=227 
2209: loss=0.597, reward_mean=0.140, reward_bound=0.387, batch=223 
2210: loss=0.596, reward_mean=0.210, reward_bound=0.358, batch=226 
2211: loss=0.595, reward_mean=0.180, reward_bound=0.368, batch=228 
2212: loss=0.595, reward_mean=0.210, reward_bound=0.353, batch=229 
2213: loss=0.597, reward_mean=0.110, reward_bound=0.387, batch=227 
2214: loss=0.595, reward_mean=0.170, reward_bound=0.308, batch=229 
2215: loss=0.596, reward_mean=0.150, reward_bound=0.405, batch=230 
2216: loss=0.597, reward_mean=0.140, reward_bound=0.376, batch=231 
2217: loss=0.603, reward_mean=0.130, reward_bound=0.430, batch=159 
2218: loss=0.589, reward_mean=0.200, reward_bound=0.000, batch=179 
2219: loss=0.576, reward_mean=0.150, reward_bound=0.000, batch=194 
2220: loss=0.577, reward_mean=0.170, reward_bound=0.057, batch=206 
2221: loss=0.569, reward_mean=0.200, reward_bound=0.076, batch=214 
2222: loss=0.570, reward_mean=0.160, reward_bound=0.109, batch=218 
2223: loss=0.576, reward_mean=0.170, reward_bound=0.150, batch=215 
2224: loss=0.585, reward_mean=0.150, reward_bound=0.167, batch=218 
2225: loss=0.577, reward_mean=0.250, reward_bound=0.206, batch=221 
2226: loss=0.575, reward_mean=0.140, reward_bound=0.229, batch=220 
2227: loss=0.579, reward_mean=0.160, reward_bound=0.254, batch=217 
2228: loss=0.579, reward_mean=0.140, reward_bound=0.224, batch=222 
2229: loss=0.578, reward_mean=0.150, reward_bound=0.245, batch=225 
2230: loss=0.585, reward_mean=0.210, reward_bound=0.282, batch=216 
2231: loss=0.588, reward_mean=0.190, reward_bound=0.314, batch=204 
2232: loss=0.584, reward_mean=0.160, reward_bound=0.196, batch=213 
2233: loss=0.586, reward_mean=0.160, reward_bound=0.229, batch=218 
2234: loss=0.586, reward_mean=0.100, reward_bound=0.257, batch=222 
2235: loss=0.584, reward_mean=0.160, reward_bound=0.292, batch=225 
2236: loss=0.583, reward_mean=0.200, reward_bound=0.314, batch=222 
2237: loss=0.583, reward_mean=0.170, reward_bound=0.349, batch=212 
2238: loss=0.579, reward_mean=0.210, reward_bound=0.263, batch=218 
2239: loss=0.575, reward_mean=0.150, reward_bound=0.229, batch=221 
2240: loss=0.582, reward_mean=0.170, reward_bound=0.254, batch=224 
2241: loss=0.577, reward_mean=0.140, reward_bound=0.282, batch=226 
2242: loss=0.577, reward_mean=0.210, reward_bound=0.331, batch=228 
2243: loss=0.579, reward_mean=0.220, reward_bound=0.387, batch=207 
2244: loss=0.577, reward_mean=0.190, reward_bound=0.282, batch=214 
2245: loss=0.572, reward_mean=0.270, reward_bound=0.305, batch=220 
2246: loss=0.571, reward_mean=0.160, reward_bound=0.314, batch=222 
2247: loss=0.581, reward_mean=0.180, reward_bound=0.349, batch=221 
2248: loss=0.580, reward_mean=0.180, reward_bound=0.254, batch=224 
2249: loss=0.579, reward_mean=0.140, reward_bound=0.280, batch=227 
2250: loss=0.577, reward_mean=0.150, reward_bound=0.387, batch=217 
2251: loss=0.577, reward_mean=0.170, reward_bound=0.229, batch=221 
2252: loss=0.575, reward_mean=0.160, reward_bound=0.229, batch=224 
2253: loss=0.574, reward_mean=0.150, reward_bound=0.280, batch=227 
2254: loss=0.580, reward_mean=0.170, reward_bound=0.342, batch=229 
2255: loss=0.579, reward_mean=0.150, reward_bound=0.349, batch=229 
2256: loss=0.578, reward_mean=0.160, reward_bound=0.364, batch=230 
2257: loss=0.577, reward_mean=0.230, reward_bound=0.365, batch=231 
2258: loss=0.574, reward_mean=0.190, reward_bound=0.387, batch=230 
2259: loss=0.574, reward_mean=0.110, reward_bound=0.296, batch=231 
2260: loss=0.573, reward_mean=0.130, reward_bound=0.314, batch=231 
2261: loss=0.589, reward_mean=0.220, reward_bound=0.430, batch=191 
2262: loss=0.577, reward_mean=0.160, reward_bound=0.109, batch=203 
2263: loss=0.576, reward_mean=0.190, reward_bound=0.144, batch=212 
2264: loss=0.587, reward_mean=0.170, reward_bound=0.185, batch=217 
2265: loss=0.583, reward_mean=0.200, reward_bound=0.206, batch=219 
2266: loss=0.583, reward_mean=0.160, reward_bound=0.229, batch=221 
2267: loss=0.590, reward_mean=0.120, reward_bound=0.254, batch=220 
2268: loss=0.587, reward_mean=0.170, reward_bound=0.274, batch=224 
2269: loss=0.588, reward_mean=0.180, reward_bound=0.282, batch=225 
2270: loss=0.587, reward_mean=0.240, reward_bound=0.314, batch=226 
2271: loss=0.587, reward_mean=0.200, reward_bound=0.349, batch=223 
2272: loss=0.589, reward_mean=0.190, reward_bound=0.334, batch=226 
2273: loss=0.590, reward_mean=0.150, reward_bound=0.387, batch=219 
2274: loss=0.589, reward_mean=0.130, reward_bound=0.314, batch=222 
2275: loss=0.587, reward_mean=0.150, reward_bound=0.324, batch=225 
2276: loss=0.590, reward_mean=0.230, reward_bound=0.349, batch=225 
2277: loss=0.591, reward_mean=0.190, reward_bound=0.387, batch=226 
2278: loss=0.589, reward_mean=0.180, reward_bound=0.368, batch=228 
2279: loss=0.591, reward_mean=0.110, reward_bound=0.392, batch=229 
2280: loss=0.585, reward_mean=0.180, reward_bound=0.430, batch=210 
2281: loss=0.585, reward_mean=0.170, reward_bound=0.200, batch=217 
2282: loss=0.577, reward_mean=0.160, reward_bound=0.224, batch=222 
2283: loss=0.578, reward_mean=0.210, reward_bound=0.254, batch=224 
2284: loss=0.583, reward_mean=0.140, reward_bound=0.282, batch=223 
2285: loss=0.585, reward_mean=0.180, reward_bound=0.335, batch=226 
2286: loss=0.584, reward_mean=0.190, reward_bound=0.349, batch=224 
2287: loss=0.584, reward_mean=0.150, reward_bound=0.345, batch=227 
2288: loss=0.585, reward_mean=0.140, reward_bound=0.267, batch=229 
2289: loss=0.580, reward_mean=0.140, reward_bound=0.387, batch=226 
2290: loss=0.583, reward_mean=0.180, reward_bound=0.430, batch=217 
2291: loss=0.586, reward_mean=0.150, reward_bound=0.224, batch=222 
2292: loss=0.584, reward_mean=0.140, reward_bound=0.282, batch=223 
2293: loss=0.584, reward_mean=0.170, reward_bound=0.254, batch=223 
2294: loss=0.578, reward_mean=0.210, reward_bound=0.349, batch=225 
2295: loss=0.577, reward_mean=0.160, reward_bound=0.329, batch=227 
2296: loss=0.579, reward_mean=0.150, reward_bound=0.387, batch=227 
2297: loss=0.579, reward_mean=0.210, reward_bound=0.430, batch=227 
2298: loss=0.579, reward_mean=0.160, reward_bound=0.422, batch=229 
2299: loss=0.578, reward_mean=0.200, reward_bound=0.430, batch=229 
2300: loss=0.582, reward_mean=0.150, reward_bound=0.478, batch=232 
2301: loss=0.582, reward_mean=0.110, reward_bound=0.415, batch=232 
2302: loss=0.607, reward_mean=0.170, reward_bound=0.478, batch=138 
2303: loss=0.590, reward_mean=0.230, reward_bound=0.000, batch=161 
2304: loss=0.578, reward_mean=0.190, reward_bound=0.000, batch=180 
2305: loss=0.568, reward_mean=0.170, reward_bound=0.046, batch=196 
2306: loss=0.572, reward_mean=0.230, reward_bound=0.109, batch=206 
2307: loss=0.565, reward_mean=0.090, reward_bound=0.063, batch=214 
2308: loss=0.563, reward_mean=0.110, reward_bound=0.120, batch=220 
2309: loss=0.561, reward_mean=0.140, reward_bound=0.131, batch=224 
2310: loss=0.570, reward_mean=0.230, reward_bound=0.167, batch=224 
2311: loss=0.569, reward_mean=0.170, reward_bound=0.185, batch=226 
2312: loss=0.575, reward_mean=0.210, reward_bound=0.206, batch=221 
2313: loss=0.575, reward_mean=0.120, reward_bound=0.229, batch=221 
2314: loss=0.583, reward_mean=0.270, reward_bound=0.254, batch=213 
2315: loss=0.584, reward_mean=0.140, reward_bound=0.150, batch=218 
2316: loss=0.583, reward_mean=0.150, reward_bound=0.257, batch=222 
2317: loss=0.595, reward_mean=0.150, reward_bound=0.282, batch=213 
2318: loss=0.593, reward_mean=0.170, reward_bound=0.244, batch=219 
2319: loss=0.594, reward_mean=0.150, reward_bound=0.239, batch=223 
2320: loss=0.596, reward_mean=0.160, reward_bound=0.282, batch=225 
2321: loss=0.599, reward_mean=0.220, reward_bound=0.314, batch=206 
2322: loss=0.598, reward_mean=0.200, reward_bound=0.349, batch=188 
2323: loss=0.596, reward_mean=0.210, reward_bound=0.101, batch=201 
2324: loss=0.583, reward_mean=0.180, reward_bound=0.122, batch=210 
2325: loss=0.585, reward_mean=0.160, reward_bound=0.180, batch=217 
2326: loss=0.583, reward_mean=0.150, reward_bound=0.206, batch=220 
2327: loss=0.578, reward_mean=0.160, reward_bound=0.200, batch=224 
2328: loss=0.584, reward_mean=0.150, reward_bound=0.229, batch=223 
2329: loss=0.583, reward_mean=0.150, reward_bound=0.254, batch=224 
2330: loss=0.586, reward_mean=0.120, reward_bound=0.282, batch=222 
2331: loss=0.586, reward_mean=0.120, reward_bound=0.292, batch=225 
2332: loss=0.586, reward_mean=0.150, reward_bound=0.314, batch=223 
2333: loss=0.588, reward_mean=0.140, reward_bound=0.349, batch=220 
2334: loss=0.586, reward_mean=0.210, reward_bound=0.338, batch=224 
2335: loss=0.585, reward_mean=0.110, reward_bound=0.282, batch=226 
2336: loss=0.585, reward_mean=0.190, reward_bound=0.349, batch=226 
2337: loss=0.583, reward_mean=0.220, reward_bound=0.298, batch=228 
2338: loss=0.584, reward_mean=0.150, reward_bound=0.353, batch=229 
2339: loss=0.584, reward_mean=0.130, reward_bound=0.307, batch=230 
2340: loss=0.591, reward_mean=0.190, reward_bound=0.387, batch=202 
2341: loss=0.592, reward_mean=0.130, reward_bound=0.109, batch=211 
2342: loss=0.585, reward_mean=0.180, reward_bound=0.185, batch=217 
2343: loss=0.581, reward_mean=0.140, reward_bound=0.277, batch=222 
2344: loss=0.578, reward_mean=0.210, reward_bound=0.292, batch=225 
2345: loss=0.579, reward_mean=0.170, reward_bound=0.314, batch=224 
2346: loss=0.580, reward_mean=0.180, reward_bound=0.349, batch=217 
2347: loss=0.575, reward_mean=0.240, reward_bound=0.202, batch=222 
2348: loss=0.575, reward_mean=0.210, reward_bound=0.213, batch=225 
2349: loss=0.575, reward_mean=0.220, reward_bound=0.321, batch=227 
2350: loss=0.575, reward_mean=0.150, reward_bound=0.380, batch=229 
2351: loss=0.573, reward_mean=0.110, reward_bound=0.387, batch=224 
2352: loss=0.576, reward_mean=0.130, reward_bound=0.384, batch=227 
2353: loss=0.574, reward_mean=0.220, reward_bound=0.422, batch=229 
2354: loss=0.574, reward_mean=0.130, reward_bound=0.349, batch=229 
2355: loss=0.574, reward_mean=0.160, reward_bound=0.405, batch=230 
2356: loss=0.574, reward_mean=0.190, reward_bound=0.314, batch=230 
2357: loss=0.575, reward_mean=0.220, reward_bound=0.418, batch=231 
2358: loss=0.580, reward_mean=0.200, reward_bound=0.430, batch=191 
2359: loss=0.579, reward_mean=0.060, reward_bound=0.000, batch=197 
2360: loss=0.585, reward_mean=0.200, reward_bound=0.103, batch=208 
2361: loss=0.577, reward_mean=0.170, reward_bound=0.137, batch=215 
2362: loss=0.579, reward_mean=0.230, reward_bound=0.170, batch=220 
2363: loss=0.580, reward_mean=0.170, reward_bound=0.206, batch=225 
2364: loss=0.571, reward_mean=0.180, reward_bound=0.229, batch=225 
2365: loss=0.567, reward_mean=0.160, reward_bound=0.254, batch=225 
2366: loss=0.565, reward_mean=0.230, reward_bound=0.282, batch=226 
2367: loss=0.568, reward_mean=0.210, reward_bound=0.314, batch=224 
2368: loss=0.567, reward_mean=0.160, reward_bound=0.311, batch=227 
2369: loss=0.563, reward_mean=0.170, reward_bound=0.342, batch=229 
2370: loss=0.570, reward_mean=0.200, reward_bound=0.349, batch=223 
2371: loss=0.568, reward_mean=0.090, reward_bound=0.311, batch=226 
2372: loss=0.567, reward_mean=0.180, reward_bound=0.368, batch=228 
2373: loss=0.572, reward_mean=0.140, reward_bound=0.387, batch=219 
2374: loss=0.569, reward_mean=0.100, reward_bound=0.229, batch=222 
2375: loss=0.573, reward_mean=0.120, reward_bound=0.387, batch=224 
2376: loss=0.572, reward_mean=0.270, reward_bound=0.384, batch=227 
2377: loss=0.572, reward_mean=0.120, reward_bound=0.373, batch=229 
2378: loss=0.574, reward_mean=0.140, reward_bound=0.364, batch=230 
2379: loss=0.569, reward_mean=0.170, reward_bound=0.387, batch=228 
2380: loss=0.571, reward_mean=0.220, reward_bound=0.430, batch=214 
2381: loss=0.562, reward_mean=0.120, reward_bound=0.204, batch=220 
2382: loss=0.563, reward_mean=0.190, reward_bound=0.229, batch=223 
2383: loss=0.570, reward_mean=0.120, reward_bound=0.254, batch=223 
2384: loss=0.570, reward_mean=0.220, reward_bound=0.314, batch=224 
2385: loss=0.572, reward_mean=0.160, reward_bound=0.349, batch=226 
2386: loss=0.571, reward_mean=0.160, reward_bound=0.368, batch=228 
2387: loss=0.571, reward_mean=0.110, reward_bound=0.321, batch=229 
2388: loss=0.565, reward_mean=0.160, reward_bound=0.387, batch=224 
2389: loss=0.564, reward_mean=0.140, reward_bound=0.349, batch=226 
2390: loss=0.566, reward_mean=0.190, reward_bound=0.321, batch=228 
2391: loss=0.565, reward_mean=0.160, reward_bound=0.392, batch=229 
2392: loss=0.566, reward_mean=0.160, reward_bound=0.405, batch=230 
2393: loss=0.565, reward_mean=0.150, reward_bound=0.418, batch=231 
2394: loss=0.564, reward_mean=0.160, reward_bound=0.430, batch=226 
2395: loss=0.562, reward_mean=0.240, reward_bound=0.454, batch=228 
2396: loss=0.563, reward_mean=0.200, reward_bound=0.392, batch=229 
2397: loss=0.564, reward_mean=0.180, reward_bound=0.405, batch=230 
2398: loss=0.562, reward_mean=0.200, reward_bound=0.430, batch=229 
2399: loss=0.562, reward_mean=0.190, reward_bound=0.478, batch=231 
2400: loss=0.562, reward_mean=0.160, reward_bound=0.430, batch=231 
2401: loss=0.582, reward_mean=0.170, reward_bound=0.478, batch=178 
2402: loss=0.561, reward_mean=0.200, reward_bound=0.038, batch=193 
2403: loss=0.552, reward_mean=0.150, reward_bound=0.038, batch=205 
2404: loss=0.549, reward_mean=0.160, reward_bound=0.124, batch=213 
2405: loss=0.546, reward_mean=0.160, reward_bound=0.135, batch=217 
2406: loss=0.562, reward_mean=0.150, reward_bound=0.185, batch=217 
2407: loss=0.563, reward_mean=0.200, reward_bound=0.229, batch=221 
2408: loss=0.574, reward_mean=0.190, reward_bound=0.254, batch=221 
2409: loss=0.573, reward_mean=0.160, reward_bound=0.282, batch=222 
2410: loss=0.572, reward_mean=0.140, reward_bound=0.272, batch=225 
2411: loss=0.571, reward_mean=0.180, reward_bound=0.314, batch=219 
2412: loss=0.569, reward_mean=0.120, reward_bound=0.314, batch=222 
2413: loss=0.570, reward_mean=0.140, reward_bound=0.292, batch=225 
2414: loss=0.569, reward_mean=0.100, reward_bound=0.234, batch=227 
2415: loss=0.573, reward_mean=0.230, reward_bound=0.349, batch=217 
2416: loss=0.571, reward_mean=0.220, reward_bound=0.314, batch=221 
2417: loss=0.568, reward_mean=0.220, reward_bound=0.349, batch=224 
2418: loss=0.571, reward_mean=0.180, reward_bound=0.282, batch=226 
2419: loss=0.571, reward_mean=0.190, reward_bound=0.387, batch=216 
2420: loss=0.572, reward_mean=0.160, reward_bound=0.349, batch=220 
2421: loss=0.569, reward_mean=0.190, reward_bound=0.304, batch=224 
2422: loss=0.568, reward_mean=0.160, reward_bound=0.314, batch=225 
2423: loss=0.569, reward_mean=0.110, reward_bound=0.282, batch=226 
2424: loss=0.567, reward_mean=0.210, reward_bound=0.368, batch=228 
2425: loss=0.568, reward_mean=0.120, reward_bound=0.387, batch=228 
2426: loss=0.568, reward_mean=0.180, reward_bound=0.392, batch=229 
2427: loss=0.568, reward_mean=0.160, reward_bound=0.405, batch=230 
2428: loss=0.573, reward_mean=0.150, reward_bound=0.430, batch=205 
2429: loss=0.564, reward_mean=0.290, reward_bound=0.314, batch=212 
2430: loss=0.558, reward_mean=0.150, reward_bound=0.172, batch=218 
2431: loss=0.556, reward_mean=0.240, reward_bound=0.187, batch=222 
2432: loss=0.555, reward_mean=0.220, reward_bound=0.292, batch=225 
2433: loss=0.559, reward_mean=0.140, reward_bound=0.314, batch=225 
2434: loss=0.567, reward_mean=0.150, reward_bound=0.349, batch=218 
2435: loss=0.565, reward_mean=0.150, reward_bound=0.257, batch=222 
2436: loss=0.572, reward_mean=0.140, reward_bound=0.263, batch=225 
2437: loss=0.570, reward_mean=0.210, reward_bound=0.289, batch=227 
2438: loss=0.570, reward_mean=0.200, reward_bound=0.342, batch=229 
2439: loss=0.570, reward_mean=0.240, reward_bound=0.387, batch=221 
2440: loss=0.569, reward_mean=0.200, reward_bound=0.349, batch=223 
2441: loss=0.566, reward_mean=0.180, reward_bound=0.254, batch=225 
2442: loss=0.564, reward_mean=0.130, reward_bound=0.356, batch=227 
2443: loss=0.562, reward_mean=0.190, reward_bound=0.349, batch=228 
2444: loss=0.561, reward_mean=0.140, reward_bound=0.353, batch=229 
2445: loss=0.569, reward_mean=0.200, reward_bound=0.387, batch=226 
2446: loss=0.566, reward_mean=0.110, reward_bound=0.368, batch=228 
2447: loss=0.567, reward_mean=0.190, reward_bound=0.353, batch=229 
2448: loss=0.565, reward_mean=0.150, reward_bound=0.430, batch=220 
2449: loss=0.558, reward_mean=0.120, reward_bound=0.205, batch=224 
2450: loss=0.561, reward_mean=0.110, reward_bound=0.229, batch=225 
2451: loss=0.567, reward_mean=0.200, reward_bound=0.314, batch=225 
2452: loss=0.564, reward_mean=0.130, reward_bound=0.349, batch=225 
2453: loss=0.564, reward_mean=0.170, reward_bound=0.337, batch=227 
2454: loss=0.565, reward_mean=0.250, reward_bound=0.430, batch=224 
2455: loss=0.565, reward_mean=0.190, reward_bound=0.380, batch=227 
2456: loss=0.564, reward_mean=0.190, reward_bound=0.430, batch=228 
2457: loss=0.564, reward_mean=0.140, reward_bound=0.435, batch=229 
2458: loss=0.564, reward_mean=0.150, reward_bound=0.387, batch=229 
2459: loss=0.563, reward_mean=0.190, reward_bound=0.478, batch=231 
2460: loss=0.563, reward_mean=0.140, reward_bound=0.314, batch=231 
2461: loss=0.578, reward_mean=0.170, reward_bound=0.478, batch=197 
2462: loss=0.575, reward_mean=0.170, reward_bound=0.163, batch=208 
2463: loss=0.577, reward_mean=0.160, reward_bound=0.229, batch=213 
2464: loss=0.574, reward_mean=0.180, reward_bound=0.167, batch=218 
2465: loss=0.572, reward_mean=0.230, reward_bound=0.282, batch=216 
2466: loss=0.579, reward_mean=0.180, reward_bound=0.282, batch=220 
2467: loss=0.578, reward_mean=0.120, reward_bound=0.304, batch=224 
2468: loss=0.576, reward_mean=0.190, reward_bound=0.349, batch=219 
2469: loss=0.576, reward_mean=0.170, reward_bound=0.254, batch=221 
2470: loss=0.577, reward_mean=0.170, reward_bound=0.387, batch=216 
2471: loss=0.574, reward_mean=0.120, reward_bound=0.314, batch=220 
2472: loss=0.573, reward_mean=0.200, reward_bound=0.314, batch=221 
2473: loss=0.575, reward_mean=0.210, reward_bound=0.349, batch=222 
2474: loss=0.575, reward_mean=0.230, reward_bound=0.387, batch=221 
2475: loss=0.573, reward_mean=0.160, reward_bound=0.387, batch=224 
2476: loss=0.570, reward_mean=0.230, reward_bound=0.426, batch=227 
2477: loss=0.571, reward_mean=0.160, reward_bound=0.401, batch=229 
2478: loss=0.571, reward_mean=0.130, reward_bound=0.381, batch=230 
2479: loss=0.572, reward_mean=0.190, reward_bound=0.406, batch=231 
2480: loss=0.574, reward_mean=0.230, reward_bound=0.430, batch=223 
2481: loss=0.573, reward_mean=0.170, reward_bound=0.261, batch=226 
2482: loss=0.575, reward_mean=0.220, reward_bound=0.454, batch=228 
2483: loss=0.574, reward_mean=0.180, reward_bound=0.392, batch=229 
2484: loss=0.575, reward_mean=0.220, reward_bound=0.450, batch=230 
2485: loss=0.574, reward_mean=0.190, reward_bound=0.406, batch=231 
2486: loss=0.575, reward_mean=0.190, reward_bound=0.430, batch=230 
2487: loss=0.574, reward_mean=0.200, reward_bound=0.464, batch=231 
2488: loss=0.574, reward_mean=0.230, reward_bound=0.430, batch=231 
2489: loss=0.572, reward_mean=0.140, reward_bound=0.478, batch=212 
2490: loss=0.574, reward_mean=0.140, reward_bound=0.135, batch=216 
2491: loss=0.571, reward_mean=0.160, reward_bound=0.217, batch=221 
2492: loss=0.572, reward_mean=0.120, reward_bound=0.229, batch=223 
2493: loss=0.570, reward_mean=0.220, reward_bound=0.314, batch=225 
2494: loss=0.564, reward_mean=0.160, reward_bound=0.349, batch=224 
2495: loss=0.562, reward_mean=0.210, reward_bound=0.280, batch=227 
2496: loss=0.565, reward_mean=0.200, reward_bound=0.349, batch=227 
2497: loss=0.568, reward_mean=0.210, reward_bound=0.387, batch=224 
2498: loss=0.570, reward_mean=0.150, reward_bound=0.430, batch=220 
2499: loss=0.568, reward_mean=0.190, reward_bound=0.254, batch=223 
2500: loss=0.569, reward_mean=0.170, reward_bound=0.314, batch=225 
2501: loss=0.565, reward_mean=0.200, reward_bound=0.356, batch=227 
2502: loss=0.564, reward_mean=0.150, reward_bound=0.380, batch=229 
2503: loss=0.566, reward_mean=0.150, reward_bound=0.387, batch=227 
2504: loss=0.567, reward_mean=0.220, reward_bound=0.430, batch=227 
2505: loss=0.565, reward_mean=0.140, reward_bound=0.335, batch=229 
2506: loss=0.565, reward_mean=0.180, reward_bound=0.450, batch=230 
2507: loss=0.565, reward_mean=0.230, reward_bound=0.387, batch=230 
2508: loss=0.565, reward_mean=0.170, reward_bound=0.349, batch=230 
2509: loss=0.565, reward_mean=0.170, reward_bound=0.430, batch=230 
2510: loss=0.564, reward_mean=0.120, reward_bound=0.464, batch=231 
2511: loss=0.567, reward_mean=0.160, reward_bound=0.478, batch=221 
2512: loss=0.569, reward_mean=0.230, reward_bound=0.387, batch=224 
2513: loss=0.567, reward_mean=0.120, reward_bound=0.271, batch=227 
2514: loss=0.571, reward_mean=0.240, reward_bound=0.349, batch=228 
2515: loss=0.569, reward_mean=0.140, reward_bound=0.286, batch=229 
2516: loss=0.572, reward_mean=0.170, reward_bound=0.364, batch=230 
2517: loss=0.571, reward_mean=0.130, reward_bound=0.365, batch=231 
2518: loss=0.569, reward_mean=0.180, reward_bound=0.387, batch=228 
2519: loss=0.570, reward_mean=0.090, reward_bound=0.430, batch=227 
2520: loss=0.570, reward_mean=0.130, reward_bound=0.297, batch=229 
2521: loss=0.570, reward_mean=0.170, reward_bound=0.349, batch=228 
2522: loss=0.570, reward_mean=0.130, reward_bound=0.397, batch=229 
2523: loss=0.568, reward_mean=0.160, reward_bound=0.450, batch=230 
2524: loss=0.568, reward_mean=0.220, reward_bound=0.464, batch=231 
2525: loss=0.568, reward_mean=0.200, reward_bound=0.478, batch=228 
2527: loss=0.506, reward_mean=0.160, reward_bound=0.000, batch=16 
2528: loss=0.469, reward_mean=0.190, reward_bound=0.000, batch=35 
2529: loss=0.483, reward_mean=0.180, reward_bound=0.000, batch=53 
2530: loss=0.477, reward_mean=0.160, reward_bound=0.000, batch=69 
2531: loss=0.492, reward_mean=0.180, reward_bound=0.000, batch=87 
2532: loss=0.498, reward_mean=0.150, reward_bound=0.000, batch=102 
2533: loss=0.506, reward_mean=0.170, reward_bound=0.000, batch=119 
2534: loss=0.496, reward_mean=0.230, reward_bound=0.000, batch=142 
2535: loss=0.487, reward_mean=0.200, reward_bound=0.000, batch=162 
2536: loss=0.488, reward_mean=0.240, reward_bound=0.005, batch=183 
2537: loss=0.487, reward_mean=0.210, reward_bound=0.012, batch=198 
2538: loss=0.492, reward_mean=0.250, reward_bound=0.034, batch=207 
2539: loss=0.492, reward_mean=0.220, reward_bound=0.052, batch=213 
2540: loss=0.490, reward_mean=0.190, reward_bound=0.058, batch=218 
2541: loss=0.487, reward_mean=0.250, reward_bound=0.080, batch=221 
2542: loss=0.493, reward_mean=0.220, reward_bound=0.089, batch=224 
2543: loss=0.498, reward_mean=0.240, reward_bound=0.098, batch=223 
2544: loss=0.504, reward_mean=0.210, reward_bound=0.109, batch=224 
2545: loss=0.504, reward_mean=0.190, reward_bound=0.122, batch=223 
2546: loss=0.506, reward_mean=0.160, reward_bound=0.135, batch=213 
2547: loss=0.507, reward_mean=0.190, reward_bound=0.150, batch=208 
2548: loss=0.506, reward_mean=0.190, reward_bound=0.152, batch=215 
2549: loss=0.514, reward_mean=0.280, reward_bound=0.167, batch=210 
2550: loss=0.522, reward_mean=0.230, reward_bound=0.185, batch=201 
2551: loss=0.525, reward_mean=0.250, reward_bound=0.206, batch=189 
2552: loss=0.525, reward_mean=0.250, reward_bound=0.114, batch=202 
2553: loss=0.518, reward_mean=0.300, reward_bound=0.229, batch=187 
2554: loss=0.511, reward_mean=0.240, reward_bound=0.041, batch=201 
2555: loss=0.519, reward_mean=0.170, reward_bound=0.122, batch=210 
2556: loss=0.515, reward_mean=0.240, reward_bound=0.167, batch=214 
2557: loss=0.511, reward_mean=0.090, reward_bound=0.185, batch=217 
2558: loss=0.515, reward_mean=0.190, reward_bound=0.229, batch=220 
2559: loss=0.527, reward_mean=0.230, reward_bound=0.254, batch=194 
2560: loss=0.523, reward_mean=0.240, reward_bound=0.183, batch=206 
2561: loss=0.519, reward_mean=0.280, reward_bound=0.229, batch=212 
2562: loss=0.519, reward_mean=0.180, reward_bound=0.236, batch=218 
2563: loss=0.519, reward_mean=0.180, reward_bound=0.229, batch=221 
2564: loss=0.521, reward_mean=0.260, reward_bound=0.254, batch=222 
2565: loss=0.536, reward_mean=0.210, reward_bound=0.282, batch=188 
2566: loss=0.531, reward_mean=0.180, reward_bound=0.112, batch=201 
2567: loss=0.532, reward_mean=0.140, reward_bound=0.089, batch=210 
2568: loss=0.536, reward_mean=0.240, reward_bound=0.162, batch=217 
2569: loss=0.532, reward_mean=0.210, reward_bound=0.206, batch=219 
2570: loss=0.534, reward_mean=0.170, reward_bound=0.229, batch=220 
2571: loss=0.527, reward_mean=0.240, reward_bound=0.274, batch=224 
2572: loss=0.527, reward_mean=0.230, reward_bound=0.282, batch=225 
2573: loss=0.541, reward_mean=0.300, reward_bound=0.314, batch=190 
2574: loss=0.532, reward_mean=0.160, reward_bound=0.033, batch=203 
2575: loss=0.534, reward_mean=0.220, reward_bound=0.117, batch=212 
2576: loss=0.532, reward_mean=0.180, reward_bound=0.185, batch=217 
2577: loss=0.533, reward_mean=0.180, reward_bound=0.206, batch=219 
2578: loss=0.532, reward_mean=0.260, reward_bound=0.229, batch=222 
2579: loss=0.530, reward_mean=0.240, reward_bound=0.254, batch=222 
2580: loss=0.530, reward_mean=0.250, reward_bound=0.282, batch=222 
2581: loss=0.531, reward_mean=0.140, reward_bound=0.263, batch=225 
2582: loss=0.532, reward_mean=0.180, reward_bound=0.314, batch=218 
2583: loss=0.533, reward_mean=0.230, reward_bound=0.234, batch=222 
2584: loss=0.531, reward_mean=0.230, reward_bound=0.324, batch=225 
2585: loss=0.527, reward_mean=0.220, reward_bound=0.349, batch=175 
2586: loss=0.524, reward_mean=0.240, reward_bound=0.082, batch=192 
2587: loss=0.520, reward_mean=0.180, reward_bound=0.122, batch=203 
2588: loss=0.531, reward_mean=0.240, reward_bound=0.167, batch=209 
2589: loss=0.521, reward_mean=0.270, reward_bound=0.185, batch=215 
2590: loss=0.523, reward_mean=0.200, reward_bound=0.206, batch=219 
2591: loss=0.525, reward_mean=0.140, reward_bound=0.229, batch=222 
2592: loss=0.521, reward_mean=0.230, reward_bound=0.254, batch=220 
2593: loss=0.518, reward_mean=0.120, reward_bound=0.240, batch=224 
2594: loss=0.518, reward_mean=0.250, reward_bound=0.282, batch=221 
2595: loss=0.522, reward_mean=0.190, reward_bound=0.314, batch=220 
2596: loss=0.521, reward_mean=0.130, reward_bound=0.296, batch=224 
2597: loss=0.519, reward_mean=0.130, reward_bound=0.308, batch=227 
2598: loss=0.518, reward_mean=0.210, reward_bound=0.342, batch=229 
2599: loss=0.516, reward_mean=0.270, reward_bound=0.349, batch=226 
2600: loss=0.511, reward_mean=0.210, reward_bound=0.387, batch=145 
2601: loss=0.514, reward_mean=0.150, reward_bound=0.000, batch=160 
2602: loss=0.489, reward_mean=0.210, reward_bound=0.000, batch=181 
2603: loss=0.497, reward_mean=0.240, reward_bound=0.020, batch=195 
2604: loss=0.507, reward_mean=0.240, reward_bound=0.080, batch=205 
2605: loss=0.503, reward_mean=0.250, reward_bound=0.122, batch=211 
2606: loss=0.503, reward_mean=0.240, reward_bound=0.150, batch=217 
2607: loss=0.507, reward_mean=0.210, reward_bound=0.167, batch=217 
2608: loss=0.503, reward_mean=0.240, reward_bound=0.206, batch=216 
2609: loss=0.504, reward_mean=0.180, reward_bound=0.206, batch=220 
2610: loss=0.504, reward_mean=0.160, reward_bound=0.216, batch=224 
2611: loss=0.506, reward_mean=0.200, reward_bound=0.229, batch=221 
2612: loss=0.514, reward_mean=0.240, reward_bound=0.254, batch=219 
2613: loss=0.514, reward_mean=0.210, reward_bound=0.265, batch=223 
2614: loss=0.516, reward_mean=0.160, reward_bound=0.261, batch=226 
2615: loss=0.509, reward_mean=0.250, reward_bound=0.282, batch=224 
2616: loss=0.511, reward_mean=0.150, reward_bound=0.252, batch=227 
2617: loss=0.513, reward_mean=0.210, reward_bound=0.314, batch=209 
2618: loss=0.511, reward_mean=0.230, reward_bound=0.229, batch=215 
2619: loss=0.509, reward_mean=0.200, reward_bound=0.260, batch=220 
2620: loss=0.507, reward_mean=0.150, reward_bound=0.167, batch=223 
2621: loss=0.506, reward_mean=0.170, reward_bound=0.206, batch=225 
2622: loss=0.510, reward_mean=0.150, reward_bound=0.282, batch=221 
2623: loss=0.507, reward_mean=0.230, reward_bound=0.314, batch=223 
2624: loss=0.505, reward_mean=0.190, reward_bound=0.335, batch=226 
2625: loss=0.504, reward_mean=0.150, reward_bound=0.349, batch=211 
2626: loss=0.502, reward_mean=0.120, reward_bound=0.167, batch=217 
2627: loss=0.504, reward_mean=0.140, reward_bound=0.220, batch=222 
2628: loss=0.505, reward_mean=0.180, reward_bound=0.314, batch=224 
2629: loss=0.509, reward_mean=0.200, reward_bound=0.345, batch=227 
2630: loss=0.509, reward_mean=0.190, reward_bound=0.349, batch=223 
2631: loss=0.517, reward_mean=0.190, reward_bound=0.387, batch=197 
2632: loss=0.503, reward_mean=0.200, reward_bound=0.150, batch=207 
2633: loss=0.508, reward_mean=0.230, reward_bound=0.167, batch=213 
2634: loss=0.512, reward_mean=0.200, reward_bound=0.178, batch=219 
2635: loss=0.511, reward_mean=0.200, reward_bound=0.254, batch=221 
2636: loss=0.510, reward_mean=0.180, reward_bound=0.282, batch=222 
2637: loss=0.514, reward_mean=0.170, reward_bound=0.314, batch=219 
2638: loss=0.513, reward_mean=0.210, reward_bound=0.349, batch=222 
2639: loss=0.514, reward_mean=0.160, reward_bound=0.336, batch=225 
2640: loss=0.514, reward_mean=0.210, reward_bound=0.356, batch=227 
2641: loss=0.519, reward_mean=0.230, reward_bound=0.387, batch=218 
2642: loss=0.518, reward_mean=0.200, reward_bound=0.314, batch=221 
2643: loss=0.522, reward_mean=0.220, reward_bound=0.387, batch=222 
2644: loss=0.523, reward_mean=0.140, reward_bound=0.349, batch=224 
2645: loss=0.520, reward_mean=0.110, reward_bound=0.118, batch=227 
2646: loss=0.523, reward_mean=0.170, reward_bound=0.249, batch=229 
2647: loss=0.524, reward_mean=0.190, reward_bound=0.295, batch=230 
2648: loss=0.524, reward_mean=0.200, reward_bound=0.418, batch=231 
2649: loss=0.524, reward_mean=0.220, reward_bound=0.349, batch=231 
2650: loss=0.534, reward_mean=0.250, reward_bound=0.430, batch=124 
2651: loss=0.521, reward_mean=0.180, reward_bound=0.000, batch=142 
2652: loss=0.500, reward_mean=0.210, reward_bound=0.000, batch=163 
2653: loss=0.484, reward_mean=0.200, reward_bound=0.000, batch=183 
2654: loss=0.482, reward_mean=0.200, reward_bound=0.031, batch=197 
2655: loss=0.478, reward_mean=0.130, reward_bound=0.034, batch=208 
2656: loss=0.478, reward_mean=0.210, reward_bound=0.053, batch=215 
2657: loss=0.485, reward_mean=0.200, reward_bound=0.080, batch=219 
2658: loss=0.491, reward_mean=0.140, reward_bound=0.109, batch=222 
2659: loss=0.507, reward_mean=0.210, reward_bound=0.150, batch=219 
2660: loss=0.508, reward_mean=0.170, reward_bound=0.167, batch=222 
2661: loss=0.509, reward_mean=0.250, reward_bound=0.191, batch=225 
2662: loss=0.514, reward_mean=0.230, reward_bound=0.206, batch=222 
2663: loss=0.518, reward_mean=0.250, reward_bound=0.229, batch=216 
2664: loss=0.527, reward_mean=0.250, reward_bound=0.254, batch=211 
2665: loss=0.524, reward_mean=0.260, reward_bound=0.229, batch=216 
2666: loss=0.519, reward_mean=0.220, reward_bound=0.282, batch=205 
2667: loss=0.513, reward_mean=0.130, reward_bound=0.118, batch=213 
2668: loss=0.512, reward_mean=0.200, reward_bound=0.206, batch=215 
2669: loss=0.515, reward_mean=0.190, reward_bound=0.234, batch=220 
2670: loss=0.512, reward_mean=0.160, reward_bound=0.282, batch=223 
2671: loss=0.513, reward_mean=0.350, reward_bound=0.314, batch=211 
2672: loss=0.510, reward_mean=0.160, reward_bound=0.135, batch=217 
2673: loss=0.510, reward_mean=0.220, reward_bound=0.229, batch=221 
2674: loss=0.505, reward_mean=0.190, reward_bound=0.282, batch=224 
2675: loss=0.508, reward_mean=0.240, reward_bound=0.314, batch=225 
2676: loss=0.506, reward_mean=0.120, reward_bound=0.199, batch=227 
2677: loss=0.504, reward_mean=0.240, reward_bound=0.282, batch=228 
2678: loss=0.504, reward_mean=0.180, reward_bound=0.286, batch=229 
2679: loss=0.507, reward_mean=0.240, reward_bound=0.314, batch=228 
2680: loss=0.517, reward_mean=0.220, reward_bound=0.349, batch=215 
2681: loss=0.515, reward_mean=0.210, reward_bound=0.282, batch=219 
2682: loss=0.516, reward_mean=0.270, reward_bound=0.314, batch=219 
2683: loss=0.518, reward_mean=0.150, reward_bound=0.229, batch=221 
2684: loss=0.518, reward_mean=0.210, reward_bound=0.349, batch=224 
2685: loss=0.517, reward_mean=0.280, reward_bound=0.384, batch=227 
2686: loss=0.516, reward_mean=0.200, reward_bound=0.373, batch=229 
2687: loss=0.523, reward_mean=0.270, reward_bound=0.387, batch=191 
2688: loss=0.524, reward_mean=0.210, reward_bound=0.098, batch=203 
2689: loss=0.524, reward_mean=0.190, reward_bound=0.144, batch=212 
2690: loss=0.525, reward_mean=0.150, reward_bound=0.172, batch=218 
2691: loss=0.531, reward_mean=0.260, reward_bound=0.229, batch=219 
2692: loss=0.531, reward_mean=0.160, reward_bound=0.282, batch=217 
2693: loss=0.520, reward_mean=0.250, reward_bound=0.314, batch=216 
2694: loss=0.520, reward_mean=0.210, reward_bound=0.254, batch=220 
2695: loss=0.513, reward_mean=0.210, reward_bound=0.282, batch=223 
2696: loss=0.514, reward_mean=0.190, reward_bound=0.335, batch=226 
2697: loss=0.523, reward_mean=0.200, reward_bound=0.349, batch=219 
2698: loss=0.522, reward_mean=0.240, reward_bound=0.314, batch=221 
2699: loss=0.522, reward_mean=0.190, reward_bound=0.314, batch=224 
2700: loss=0.522, reward_mean=0.280, reward_bound=0.345, batch=227 
2701: loss=0.523, reward_mean=0.250, reward_bound=0.349, batch=228 
2702: loss=0.523, reward_mean=0.180, reward_bound=0.353, batch=229 
2703: loss=0.522, reward_mean=0.230, reward_bound=0.364, batch=230 
2704: loss=0.524, reward_mean=0.270, reward_bound=0.387, batch=221 
2705: loss=0.527, reward_mean=0.200, reward_bound=0.254, batch=224 
2706: loss=0.523, reward_mean=0.240, reward_bound=0.349, batch=225 
2707: loss=0.541, reward_mean=0.210, reward_bound=0.430, batch=180 
2708: loss=0.545, reward_mean=0.250, reward_bound=0.167, batch=195 
2709: loss=0.542, reward_mean=0.240, reward_bound=0.153, batch=206 
2710: loss=0.536, reward_mean=0.220, reward_bound=0.185, batch=213 
2711: loss=0.535, reward_mean=0.140, reward_bound=0.198, batch=219 
2712: loss=0.538, reward_mean=0.200, reward_bound=0.206, batch=221 
2713: loss=0.535, reward_mean=0.210, reward_bound=0.229, batch=224 
2714: loss=0.530, reward_mean=0.200, reward_bound=0.254, batch=218 
2715: loss=0.533, reward_mean=0.190, reward_bound=0.282, batch=217 
2716: loss=0.530, reward_mean=0.220, reward_bound=0.314, batch=220 
2717: loss=0.533, reward_mean=0.260, reward_bound=0.349, batch=214 
2718: loss=0.529, reward_mean=0.190, reward_bound=0.345, batch=220 
2719: loss=0.533, reward_mean=0.260, reward_bound=0.349, batch=221 
2720: loss=0.531, reward_mean=0.250, reward_bound=0.314, batch=224 
2721: loss=0.532, reward_mean=0.240, reward_bound=0.345, batch=227 
2722: loss=0.533, reward_mean=0.210, reward_bound=0.380, batch=229 
2723: loss=0.540, reward_mean=0.240, reward_bound=0.387, batch=216 
2724: loss=0.540, reward_mean=0.170, reward_bound=0.298, batch=221 
2725: loss=0.537, reward_mean=0.190, reward_bound=0.314, batch=224 
2726: loss=0.537, reward_mean=0.200, reward_bound=0.349, batch=226 
2727: loss=0.539, reward_mean=0.200, reward_bound=0.387, batch=223 
2728: loss=0.539, reward_mean=0.150, reward_bound=0.314, batch=225 
2729: loss=0.539, reward_mean=0.220, reward_bound=0.387, batch=226 
2730: loss=0.537, reward_mean=0.170, reward_bound=0.409, batch=228 
2731: loss=0.536, reward_mean=0.250, reward_bound=0.430, batch=207 
2732: loss=0.534, reward_mean=0.250, reward_bound=0.277, batch=215 
2733: loss=0.534, reward_mean=0.170, reward_bound=0.254, batch=219 
2734: loss=0.531, reward_mean=0.270, reward_bound=0.282, batch=222 
2735: loss=0.531, reward_mean=0.220, reward_bound=0.314, batch=223 
2736: loss=0.531, reward_mean=0.200, reward_bound=0.314, batch=225 
2737: loss=0.533, reward_mean=0.190, reward_bound=0.349, batch=220 
2738: loss=0.534, reward_mean=0.210, reward_bound=0.356, batch=224 
2739: loss=0.531, reward_mean=0.200, reward_bound=0.374, batch=227 
2740: loss=0.531, reward_mean=0.260, reward_bound=0.387, batch=224 
2741: loss=0.529, reward_mean=0.190, reward_bound=0.314, batch=226 
2742: loss=0.531, reward_mean=0.210, reward_bound=0.387, batch=227 
2743: loss=0.531, reward_mean=0.200, reward_bound=0.430, batch=219 
2744: loss=0.535, reward_mean=0.290, reward_bound=0.381, batch=223 
2745: loss=0.534, reward_mean=0.200, reward_bound=0.282, batch=225 
2746: loss=0.536, reward_mean=0.220, reward_bound=0.387, batch=225 
2747: loss=0.536, reward_mean=0.260, reward_bound=0.396, batch=227 
2748: loss=0.536, reward_mean=0.260, reward_bound=0.387, batch=228 
2749: loss=0.534, reward_mean=0.190, reward_bound=0.430, batch=226 
2750: loss=0.570, reward_mean=0.250, reward_bound=0.478, batch=81 
2751: loss=0.537, reward_mean=0.160, reward_bound=0.000, batch=97 
2752: loss=0.507, reward_mean=0.170, reward_bound=0.000, batch=114 
2753: loss=0.496, reward_mean=0.130, reward_bound=0.000, batch=127 
2754: loss=0.468, reward_mean=0.240, reward_bound=0.000, batch=151 
2755: loss=0.458, reward_mean=0.140, reward_bound=0.000, batch=165 
2756: loss=0.456, reward_mean=0.200, reward_bound=0.000, batch=185 
2757: loss=0.466, reward_mean=0.250, reward_bound=0.032, batch=199 
2758: loss=0.461, reward_mean=0.170, reward_bound=0.044, batch=209 
2759: loss=0.470, reward_mean=0.210, reward_bound=0.075, batch=216 
2760: loss=0.476, reward_mean=0.220, reward_bound=0.094, batch=221 
2761: loss=0.486, reward_mean=0.170, reward_bound=0.122, batch=222 
2762: loss=0.486, reward_mean=0.200, reward_bound=0.150, batch=217 
2763: loss=0.487, reward_mean=0.220, reward_bound=0.182, batch=222 
2764: loss=0.493, reward_mean=0.190, reward_bound=0.185, batch=210 
2765: loss=0.489, reward_mean=0.290, reward_bound=0.206, batch=222 
2766: loss=0.488, reward_mean=0.130, reward_bound=0.206, batch=227 
2767: loss=0.495, reward_mean=0.200, reward_bound=0.206, batch=215 
2768: loss=0.504, reward_mean=0.210, reward_bound=0.229, batch=207 
2769: loss=0.506, reward_mean=0.240, reward_bound=0.224, batch=215 
2770: loss=0.509, reward_mean=0.230, reward_bound=0.229, batch=219 
2771: loss=0.510, reward_mean=0.240, reward_bound=0.254, batch=205 
2772: loss=0.509, reward_mean=0.190, reward_bound=0.112, batch=213 
2773: loss=0.506, reward_mean=0.220, reward_bound=0.206, batch=218 
2774: loss=0.505, reward_mean=0.210, reward_bound=0.229, batch=220 
2775: loss=0.521, reward_mean=0.240, reward_bound=0.282, batch=201 
2776: loss=0.518, reward_mean=0.250, reward_bound=0.167, batch=210 
2777: loss=0.513, reward_mean=0.180, reward_bound=0.254, batch=215 
2778: loss=0.514, reward_mean=0.170, reward_bound=0.240, batch=220 
2779: loss=0.516, reward_mean=0.190, reward_bound=0.282, batch=223 
2780: loss=0.514, reward_mean=0.150, reward_bound=0.254, batch=225 
2781: loss=0.526, reward_mean=0.210, reward_bound=0.314, batch=194 
2782: loss=0.521, reward_mean=0.240, reward_bound=0.167, batch=205 
2783: loss=0.517, reward_mean=0.200, reward_bound=0.189, batch=213 
2784: loss=0.513, reward_mean=0.220, reward_bound=0.206, batch=218 
2785: loss=0.519, reward_mean=0.240, reward_bound=0.231, batch=222 
2786: loss=0.517, reward_mean=0.160, reward_bound=0.254, batch=224 
2787: loss=0.520, reward_mean=0.270, reward_bound=0.282, batch=226 
2788: loss=0.519, reward_mean=0.280, reward_bound=0.314, batch=227 
2789: loss=0.535, reward_mean=0.160, reward_bound=0.349, batch=185 
2790: loss=0.527, reward_mean=0.190, reward_bound=0.095, batch=199 
2791: loss=0.528, reward_mean=0.220, reward_bound=0.122, batch=207 
2792: loss=0.524, reward_mean=0.190, reward_bound=0.147, batch=215 
2793: loss=0.524, reward_mean=0.200, reward_bound=0.185, batch=218 
2794: loss=0.527, reward_mean=0.260, reward_bound=0.229, batch=217 
2795: loss=0.525, reward_mean=0.160, reward_bound=0.163, batch=222 
2796: loss=0.526, reward_mean=0.210, reward_bound=0.254, batch=222 
2797: loss=0.528, reward_mean=0.210, reward_bound=0.282, batch=221 
2798: loss=0.534, reward_mean=0.200, reward_bound=0.314, batch=221 
2799: loss=0.534, reward_mean=0.270, reward_bound=0.349, batch=215 
2800: loss=0.532, reward_mean=0.250, reward_bound=0.254, batch=219 
2801: loss=0.533, reward_mean=0.270, reward_bound=0.282, batch=219 
2802: loss=0.532, reward_mean=0.240, reward_bound=0.314, batch=221 
2803: loss=0.537, reward_mean=0.240, reward_bound=0.349, batch=224 
2804: loss=0.537, reward_mean=0.210, reward_bound=0.342, batch=227 
2805: loss=0.537, reward_mean=0.240, reward_bound=0.342, batch=229 
2806: loss=0.536, reward_mean=0.200, reward_bound=0.328, batch=230 
2807: loss=0.534, reward_mean=0.190, reward_bound=0.349, batch=230 
2808: loss=0.538, reward_mean=0.200, reward_bound=0.387, batch=179 
2809: loss=0.522, reward_mean=0.250, reward_bound=0.119, batch=195 
2810: loss=0.518, reward_mean=0.240, reward_bound=0.153, batch=206 
2811: loss=0.511, reward_mean=0.210, reward_bound=0.158, batch=214 
2812: loss=0.514, reward_mean=0.250, reward_bound=0.167, batch=217 
2813: loss=0.524, reward_mean=0.200, reward_bound=0.202, batch=222 
2814: loss=0.522, reward_mean=0.190, reward_bound=0.229, batch=220 
2815: loss=0.522, reward_mean=0.220, reward_bound=0.254, batch=219 
2816: loss=0.520, reward_mean=0.200, reward_bound=0.282, batch=218 
2817: loss=0.516, reward_mean=0.230, reward_bound=0.286, batch=222 
2818: loss=0.525, reward_mean=0.170, reward_bound=0.314, batch=216 
2819: loss=0.531, reward_mean=0.260, reward_bound=0.331, batch=221 
2820: loss=0.542, reward_mean=0.280, reward_bound=0.349, batch=215 
2821: loss=0.537, reward_mean=0.240, reward_bound=0.260, batch=220 
2822: loss=0.540, reward_mean=0.190, reward_bound=0.314, batch=223 
2823: loss=0.545, reward_mean=0.160, reward_bound=0.349, batch=224 
2824: loss=0.542, reward_mean=0.190, reward_bound=0.342, batch=227 
2825: loss=0.541, reward_mean=0.220, reward_bound=0.387, batch=207 
2826: loss=0.538, reward_mean=0.190, reward_bound=0.282, batch=214 
2827: loss=0.534, reward_mean=0.270, reward_bound=0.311, batch=220 
2828: loss=0.531, reward_mean=0.200, reward_bound=0.304, batch=224 
2829: loss=0.537, reward_mean=0.210, reward_bound=0.314, batch=225 
2830: loss=0.537, reward_mean=0.170, reward_bound=0.282, batch=225 
2831: loss=0.537, reward_mean=0.240, reward_bound=0.349, batch=219 
2832: loss=0.537, reward_mean=0.170, reward_bound=0.314, batch=222 
2833: loss=0.537, reward_mean=0.210, reward_bound=0.387, batch=217 
2834: loss=0.536, reward_mean=0.220, reward_bound=0.308, batch=222 
2835: loss=0.538, reward_mean=0.160, reward_bound=0.324, batch=225 
2836: loss=0.539, reward_mean=0.280, reward_bound=0.387, batch=223 
2837: loss=0.548, reward_mean=0.200, reward_bound=0.430, batch=155 
2838: loss=0.531, reward_mean=0.190, reward_bound=0.000, batch=174 
2839: loss=0.528, reward_mean=0.200, reward_bound=0.015, batch=191 
2840: loss=0.511, reward_mean=0.250, reward_bound=0.089, batch=203 
2841: loss=0.516, reward_mean=0.290, reward_bound=0.122, batch=210 
2842: loss=0.509, reward_mean=0.240, reward_bound=0.167, batch=214 
2843: loss=0.511, reward_mean=0.220, reward_bound=0.206, batch=216 
2844: loss=0.505, reward_mean=0.210, reward_bound=0.217, batch=221 
2845: loss=0.512, reward_mean=0.170, reward_bound=0.229, batch=214 
2846: loss=0.518, reward_mean=0.170, reward_bound=0.254, batch=212 
2847: loss=0.513, reward_mean=0.230, reward_bound=0.282, batch=209 
2848: loss=0.513, reward_mean=0.210, reward_bound=0.194, batch=216 
2849: loss=0.518, reward_mean=0.260, reward_bound=0.282, batch=218 
2850: loss=0.526, reward_mean=0.230, reward_bound=0.314, batch=207 
2851: loss=0.526, reward_mean=0.220, reward_bound=0.202, batch=215 
2852: loss=0.525, reward_mean=0.210, reward_bound=0.260, batch=220 
2853: loss=0.522, reward_mean=0.270, reward_bound=0.304, batch=224 
2854: loss=0.517, reward_mean=0.250, reward_bound=0.311, batch=227 
2855: loss=0.519, reward_mean=0.190, reward_bound=0.308, batch=229 
2856: loss=0.525, reward_mean=0.230, reward_bound=0.349, batch=205 
2857: loss=0.522, reward_mean=0.170, reward_bound=0.153, batch=213 
2858: loss=0.530, reward_mean=0.190, reward_bound=0.190, batch=219 
2859: loss=0.534, reward_mean=0.230, reward_bound=0.254, batch=221 
2860: loss=0.528, reward_mean=0.180, reward_bound=0.282, batch=223 
2861: loss=0.533, reward_mean=0.230, reward_bound=0.349, batch=224 
2862: loss=0.532, reward_mean=0.160, reward_bound=0.277, batch=227 
2863: loss=0.531, reward_mean=0.280, reward_bound=0.314, batch=226 
2864: loss=0.530, reward_mean=0.230, reward_bound=0.349, batch=226 
2865: loss=0.532, reward_mean=0.190, reward_bound=0.368, batch=228 
2866: loss=0.535, reward_mean=0.230, reward_bound=0.387, batch=207 
2867: loss=0.534, reward_mean=0.210, reward_bound=0.206, batch=214 
2868: loss=0.532, reward_mean=0.230, reward_bound=0.277, batch=220 
2869: loss=0.530, reward_mean=0.210, reward_bound=0.282, batch=219 
2870: loss=0.528, reward_mean=0.280, reward_bound=0.314, batch=220 
2871: loss=0.528, reward_mean=0.250, reward_bound=0.338, batch=224 
2872: loss=0.532, reward_mean=0.240, reward_bound=0.349, batch=224 
2873: loss=0.532, reward_mean=0.170, reward_bound=0.249, batch=227 
2874: loss=0.536, reward_mean=0.190, reward_bound=0.349, batch=228 
2875: loss=0.536, reward_mean=0.170, reward_bound=0.349, batch=228 
2876: loss=0.535, reward_mean=0.200, reward_bound=0.387, batch=220 
2877: loss=0.534, reward_mean=0.300, reward_bound=0.304, batch=224 
2878: loss=0.536, reward_mean=0.220, reward_bound=0.314, batch=225 
2879: loss=0.531, reward_mean=0.120, reward_bound=0.349, batch=225 
2880: loss=0.531, reward_mean=0.250, reward_bound=0.396, batch=227 
2881: loss=0.529, reward_mean=0.220, reward_bound=0.422, batch=229 
2882: loss=0.530, reward_mean=0.210, reward_bound=0.381, batch=230 
2883: loss=0.529, reward_mean=0.200, reward_bound=0.376, batch=231 
2884: loss=0.530, reward_mean=0.220, reward_bound=0.387, batch=231 
2885: loss=0.529, reward_mean=0.240, reward_bound=0.430, batch=205 
2886: loss=0.531, reward_mean=0.160, reward_bound=0.073, batch=213 
2887: loss=0.530, reward_mean=0.280, reward_bound=0.261, batch=219 
2888: loss=0.523, reward_mean=0.180, reward_bound=0.194, batch=223 
2889: loss=0.529, reward_mean=0.210, reward_bound=0.301, batch=226 
2890: loss=0.532, reward_mean=0.230, reward_bound=0.331, batch=228 
2891: loss=0.528, reward_mean=0.260, reward_bound=0.349, batch=223 
2892: loss=0.530, reward_mean=0.340, reward_bound=0.349, batch=224 
2893: loss=0.534, reward_mean=0.250, reward_bound=0.380, batch=227 
2894: loss=0.527, reward_mean=0.190, reward_bound=0.387, batch=225 
2895: loss=0.528, reward_mean=0.290, reward_bound=0.430, batch=220 
2896: loss=0.529, reward_mean=0.200, reward_bound=0.288, batch=224 
2897: loss=0.527, reward_mean=0.180, reward_bound=0.275, batch=227 
2898: loss=0.526, reward_mean=0.300, reward_bound=0.349, batch=225 
2899: loss=0.525, reward_mean=0.210, reward_bound=0.365, batch=227 
2900: loss=0.525, reward_mean=0.200, reward_bound=0.422, batch=229 
2901: loss=0.523, reward_mean=0.200, reward_bound=0.405, batch=230 
2902: loss=0.526, reward_mean=0.250, reward_bound=0.430, batch=225 
2903: loss=0.529, reward_mean=0.300, reward_bound=0.356, batch=227 
2904: loss=0.525, reward_mean=0.230, reward_bound=0.387, batch=227 
2905: loss=0.525, reward_mean=0.210, reward_bound=0.460, batch=229 
2906: loss=0.525, reward_mean=0.240, reward_bound=0.430, batch=229 
2907: loss=0.525, reward_mean=0.260, reward_bound=0.450, batch=230 
2908: loss=0.526, reward_mean=0.290, reward_bound=0.464, batch=231 
2909: loss=0.546, reward_mean=0.170, reward_bound=0.478, batch=157 
2910: loss=0.509, reward_mean=0.210, reward_bound=0.000, batch=178 
2911: loss=0.511, reward_mean=0.260, reward_bound=0.076, batch=194 
2912: loss=0.522, reward_mean=0.250, reward_bound=0.122, batch=202 
2913: loss=0.526, reward_mean=0.230, reward_bound=0.135, batch=208 
2914: loss=0.528, reward_mean=0.190, reward_bound=0.150, batch=212 
2915: loss=0.533, reward_mean=0.200, reward_bound=0.167, batch=216 
2916: loss=0.537, reward_mean=0.250, reward_bound=0.185, batch=216 
2917: loss=0.537, reward_mean=0.160, reward_bound=0.206, batch=216 
2918: loss=0.533, reward_mean=0.250, reward_bound=0.229, batch=217 
2919: loss=0.532, reward_mean=0.240, reward_bound=0.254, batch=209 
2920: loss=0.536, reward_mean=0.290, reward_bound=0.250, batch=216 
2921: loss=0.533, reward_mean=0.150, reward_bound=0.185, batch=220 
2922: loss=0.531, reward_mean=0.240, reward_bound=0.282, batch=209 
2923: loss=0.531, reward_mean=0.140, reward_bound=0.150, batch=215 
2924: loss=0.532, reward_mean=0.180, reward_bound=0.234, batch=220 
2925: loss=0.532, reward_mean=0.130, reward_bound=0.222, batch=224 
2926: loss=0.532, reward_mean=0.220, reward_bound=0.280, batch=227 
2927: loss=0.528, reward_mean=0.150, reward_bound=0.282, batch=227 
2928: loss=0.528, reward_mean=0.290, reward_bound=0.314, batch=217 
2929: loss=0.535, reward_mean=0.230, reward_bound=0.349, batch=202 
2930: loss=0.530, reward_mean=0.140, reward_bound=0.060, batch=211 
2931: loss=0.539, reward_mean=0.240, reward_bound=0.206, batch=215 
2932: loss=0.537, reward_mean=0.270, reward_bound=0.229, batch=217 
2933: loss=0.536, reward_mean=0.160, reward_bound=0.220, batch=222 
2934: loss=0.534, reward_mean=0.180, reward_bound=0.254, batch=222 
2935: loss=0.544, reward_mean=0.240, reward_bound=0.282, batch=224 
2936: loss=0.535, reward_mean=0.220, reward_bound=0.314, batch=219 
2937: loss=0.537, reward_mean=0.260, reward_bound=0.314, batch=222 
2938: loss=0.540, reward_mean=0.230, reward_bound=0.387, batch=201 
2939: loss=0.530, reward_mean=0.150, reward_bound=0.080, batch=210 
2940: loss=0.536, reward_mean=0.200, reward_bound=0.247, batch=217 
2941: loss=0.538, reward_mean=0.170, reward_bound=0.254, batch=219 
2942: loss=0.539, reward_mean=0.170, reward_bound=0.229, batch=222 
2943: loss=0.542, reward_mean=0.170, reward_bound=0.282, batch=219 
2944: loss=0.540, reward_mean=0.200, reward_bound=0.278, batch=223 
2945: loss=0.536, reward_mean=0.200, reward_bound=0.349, batch=217 
2946: loss=0.532, reward_mean=0.160, reward_bound=0.254, batch=221 
2947: loss=0.529, reward_mean=0.240, reward_bound=0.314, batch=224 
2948: loss=0.533, reward_mean=0.250, reward_bound=0.387, batch=216 
2949: loss=0.531, reward_mean=0.160, reward_bound=0.167, batch=220 
2950: loss=0.529, reward_mean=0.250, reward_bound=0.274, batch=224 
2951: loss=0.524, reward_mean=0.210, reward_bound=0.252, batch=227 
2952: loss=0.528, reward_mean=0.220, reward_bound=0.314, batch=227 
2953: loss=0.532, reward_mean=0.200, reward_bound=0.349, batch=226 
2954: loss=0.533, reward_mean=0.270, reward_bound=0.387, batch=224 
2955: loss=0.536, reward_mean=0.180, reward_bound=0.384, batch=227 
2956: loss=0.541, reward_mean=0.220, reward_bound=0.430, batch=191 
2957: loss=0.538, reward_mean=0.290, reward_bound=0.167, batch=202 
2958: loss=0.538, reward_mean=0.250, reward_bound=0.229, batch=208 
2959: loss=0.538, reward_mean=0.200, reward_bound=0.254, batch=210 
2960: loss=0.534, reward_mean=0.170, reward_bound=0.185, batch=216 
2961: loss=0.536, reward_mean=0.200, reward_bound=0.254, batch=215 
2962: loss=0.537, reward_mean=0.210, reward_bound=0.254, batch=219 
2963: loss=0.535, reward_mean=0.200, reward_bound=0.282, batch=220 
2964: loss=0.537, reward_mean=0.170, reward_bound=0.247, batch=224 
2965: loss=0.540, reward_mean=0.260, reward_bound=0.314, batch=219 
2966: loss=0.539, reward_mean=0.240, reward_bound=0.328, batch=223 
2967: loss=0.537, reward_mean=0.190, reward_bound=0.314, batch=225 
2968: loss=0.535, reward_mean=0.260, reward_bound=0.321, batch=227 
2969: loss=0.537, reward_mean=0.170, reward_bound=0.314, batch=228 
2970: loss=0.540, reward_mean=0.180, reward_bound=0.349, batch=220 
2971: loss=0.536, reward_mean=0.200, reward_bound=0.206, batch=226 
2972: loss=0.534, reward_mean=0.180, reward_bound=0.256, batch=228 
2973: loss=0.538, reward_mean=0.220, reward_bound=0.317, batch=229 
2974: loss=0.540, reward_mean=0.220, reward_bound=0.364, batch=230 
2975: loss=0.536, reward_mean=0.180, reward_bound=0.387, batch=228 
2976: loss=0.537, reward_mean=0.260, reward_bound=0.430, batch=213 
2977: loss=0.537, reward_mean=0.250, reward_bound=0.335, batch=219 
2978: loss=0.541, reward_mean=0.150, reward_bound=0.172, batch=223 
2979: loss=0.537, reward_mean=0.220, reward_bound=0.372, batch=226 
2980: loss=0.535, reward_mean=0.220, reward_bound=0.368, batch=228 
2981: loss=0.535, reward_mean=0.240, reward_bound=0.387, batch=226 
2982: loss=0.534, reward_mean=0.200, reward_bound=0.430, batch=222 
2983: loss=0.534, reward_mean=0.270, reward_bound=0.445, batch=225 
2984: loss=0.535, reward_mean=0.210, reward_bound=0.314, batch=226 
2985: loss=0.534, reward_mean=0.150, reward_bound=0.454, batch=228 
2986: loss=0.534, reward_mean=0.220, reward_bound=0.397, batch=229 
2987: loss=0.539, reward_mean=0.280, reward_bound=0.478, batch=231 
2988: loss=0.550, reward_mean=0.250, reward_bound=0.478, batch=181 
2989: loss=0.533, reward_mean=0.190, reward_bound=0.016, batch=196 
2990: loss=0.525, reward_mean=0.240, reward_bound=0.089, batch=207 
2991: loss=0.534, reward_mean=0.280, reward_bound=0.150, batch=214 
2992: loss=0.531, reward_mean=0.280, reward_bound=0.229, batch=217 
2993: loss=0.534, reward_mean=0.180, reward_bound=0.254, batch=220 
2994: loss=0.531, reward_mean=0.230, reward_bound=0.314, batch=212 
2995: loss=0.533, reward_mean=0.130, reward_bound=0.135, batch=217 
2996: loss=0.532, reward_mean=0.180, reward_bound=0.249, batch=222 
2997: loss=0.532, reward_mean=0.160, reward_bound=0.282, batch=224 
2998: loss=0.542, reward_mean=0.240, reward_bound=0.349, batch=215 
2999: loss=0.538, reward_mean=0.180, reward_bound=0.321, batch=220 
3000: loss=0.541, reward_mean=0.280, reward_bound=0.349, batch=223 
3001: loss=0.538, reward_mean=0.260, reward_bound=0.387, batch=211 
3002: loss=0.537, reward_mean=0.260, reward_bound=0.229, batch=216 
3003: loss=0.535, reward_mean=0.240, reward_bound=0.206, batch=220 
3004: loss=0.534, reward_mean=0.240, reward_bound=0.314, batch=221 
3005: loss=0.534, reward_mean=0.260, reward_bound=0.349, batch=224 
3006: loss=0.533, reward_mean=0.220, reward_bound=0.282, batch=226 
3007: loss=0.532, reward_mean=0.210, reward_bound=0.387, batch=221 
3008: loss=0.530, reward_mean=0.300, reward_bound=0.387, batch=223 
3009: loss=0.532, reward_mean=0.180, reward_bound=0.398, batch=226 
3010: loss=0.535, reward_mean=0.280, reward_bound=0.331, batch=228 
3011: loss=0.533, reward_mean=0.180, reward_bound=0.289, batch=229 
3012: loss=0.532, reward_mean=0.190, reward_bound=0.349, batch=228 
3013: loss=0.529, reward_mean=0.230, reward_bound=0.392, batch=229 
3014: loss=0.531, reward_mean=0.210, reward_bound=0.430, batch=213 
3015: loss=0.531, reward_mean=0.190, reward_bound=0.167, batch=216 
3016: loss=0.527, reward_mean=0.220, reward_bound=0.331, batch=221 
3017: loss=0.531, reward_mean=0.170, reward_bound=0.349, batch=224 
3018: loss=0.532, reward_mean=0.220, reward_bound=0.387, batch=221 
3019: loss=0.530, reward_mean=0.220, reward_bound=0.349, batch=224 
3020: loss=0.530, reward_mean=0.100, reward_bound=0.280, batch=227 
3021: loss=0.528, reward_mean=0.170, reward_bound=0.349, batch=228 
3022: loss=0.527, reward_mean=0.150, reward_bound=0.357, batch=229 
3023: loss=0.525, reward_mean=0.260, reward_bound=0.405, batch=230 
3024: loss=0.525, reward_mean=0.210, reward_bound=0.349, batch=230 
3025: loss=0.525, reward_mean=0.250, reward_bound=0.430, batch=224 
3026: loss=0.525, reward_mean=0.190, reward_bound=0.349, batch=226 
3027: loss=0.524, reward_mean=0.300, reward_bound=0.454, batch=228 
3028: loss=0.526, reward_mean=0.210, reward_bound=0.478, batch=230 
3029: loss=0.547, reward_mean=0.290, reward_bound=0.478, batch=207 
3030: loss=0.554, reward_mean=0.210, reward_bound=0.272, batch=215 
3031: loss=0.547, reward_mean=0.230, reward_bound=0.282, batch=219 
3032: loss=0.547, reward_mean=0.190, reward_bound=0.282, batch=222 
3033: loss=0.549, reward_mean=0.240, reward_bound=0.314, batch=224 
3034: loss=0.551, reward_mean=0.190, reward_bound=0.349, batch=225 
3035: loss=0.553, reward_mean=0.160, reward_bound=0.266, batch=227 
3036: loss=0.552, reward_mean=0.160, reward_bound=0.314, batch=228 
3037: loss=0.552, reward_mean=0.190, reward_bound=0.387, batch=225 
3038: loss=0.552, reward_mean=0.200, reward_bound=0.430, batch=222 
3039: loss=0.548, reward_mean=0.190, reward_bound=0.302, batch=225 
3040: loss=0.553, reward_mean=0.180, reward_bound=0.349, batch=226 
3041: loss=0.551, reward_mean=0.210, reward_bound=0.368, batch=228 
3042: loss=0.550, reward_mean=0.180, reward_bound=0.353, batch=229 
3043: loss=0.552, reward_mean=0.280, reward_bound=0.405, batch=230 
3044: loss=0.552, reward_mean=0.160, reward_bound=0.430, batch=229 
3045: loss=0.552, reward_mean=0.200, reward_bound=0.450, batch=230 
3046: loss=0.551, reward_mean=0.240, reward_bound=0.478, batch=218 
3047: loss=0.553, reward_mean=0.200, reward_bound=0.192, batch=222 
3048: loss=0.547, reward_mean=0.180, reward_bound=0.263, batch=225 
3049: loss=0.543, reward_mean=0.280, reward_bound=0.349, batch=225 
3050: loss=0.542, reward_mean=0.210, reward_bound=0.349, batch=226 
3051: loss=0.544, reward_mean=0.180, reward_bound=0.387, batch=227 
3052: loss=0.543, reward_mean=0.190, reward_bound=0.366, batch=229 
3053: loss=0.543, reward_mean=0.270, reward_bound=0.405, batch=230 
3054: loss=0.542, reward_mean=0.160, reward_bound=0.418, batch=231 
3055: loss=0.548, reward_mean=0.210, reward_bound=0.430, batch=226 
3056: loss=0.545, reward_mean=0.180, reward_bound=0.316, batch=228 
3057: loss=0.545, reward_mean=0.250, reward_bound=0.353, batch=229 
3058: loss=0.546, reward_mean=0.220, reward_bound=0.387, batch=229 
3059: loss=0.546, reward_mean=0.210, reward_bound=0.430, batch=228 
3060: loss=0.545, reward_mean=0.210, reward_bound=0.353, batch=229 
3061: loss=0.545, reward_mean=0.260, reward_bound=0.349, batch=229 
3062: loss=0.544, reward_mean=0.180, reward_bound=0.405, batch=230 
3063: loss=0.545, reward_mean=0.230, reward_bound=0.430, batch=229 
3064: loss=0.547, reward_mean=0.250, reward_bound=0.450, batch=230 
3065: loss=0.547, reward_mean=0.130, reward_bound=0.418, batch=231 
3066: loss=0.549, reward_mean=0.250, reward_bound=0.430, batch=231 
3067: loss=0.551, reward_mean=0.230, reward_bound=0.478, batch=224 
3068: loss=0.548, reward_mean=0.180, reward_bound=0.384, batch=227 
3069: loss=0.550, reward_mean=0.240, reward_bound=0.387, batch=227 
3070: loss=0.550, reward_mean=0.240, reward_bound=0.342, batch=229 
3071: loss=0.551, reward_mean=0.130, reward_bound=0.349, batch=229 
3072: loss=0.551, reward_mean=0.200, reward_bound=0.381, batch=230 
3073: loss=0.550, reward_mean=0.320, reward_bound=0.430, batch=230 
3074: loss=0.550, reward_mean=0.160, reward_bound=0.430, batch=230 
3075: loss=0.550, reward_mean=0.180, reward_bound=0.451, batch=231 
3076: loss=0.550, reward_mean=0.240, reward_bound=0.430, batch=231 
3077: loss=0.550, reward_mean=0.270, reward_bound=0.478, batch=227 
3078: loss=0.548, reward_mean=0.240, reward_bound=0.460, batch=229 
3079: loss=0.549, reward_mean=0.180, reward_bound=0.401, batch=230 
3080: loss=0.549, reward_mean=0.140, reward_bound=0.478, batch=229 
3081: loss=0.549, reward_mean=0.200, reward_bound=0.450, batch=230 
3082: loss=0.548, reward_mean=0.240, reward_bound=0.406, batch=231 
3083: loss=0.548, reward_mean=0.200, reward_bound=0.430, batch=231 
3084: loss=0.548, reward_mean=0.180, reward_bound=0.478, batch=231 
3086: loss=0.449, reward_mean=0.180, reward_bound=0.000, batch=18 
3087: loss=0.462, reward_mean=0.180, reward_bound=0.000, batch=36 
3088: loss=0.459, reward_mean=0.230, reward_bound=0.000, batch=59 
3089: loss=0.455, reward_mean=0.210, reward_bound=0.000, batch=80 
3090: loss=0.453, reward_mean=0.180, reward_bound=0.000, batch=98 
3091: loss=0.447, reward_mean=0.210, reward_bound=0.000, batch=119 
3092: loss=0.433, reward_mean=0.210, reward_bound=0.000, batch=140 
3093: loss=0.430, reward_mean=0.160, reward_bound=0.000, batch=156 
3094: loss=0.427, reward_mean=0.240, reward_bound=0.000, batch=179 
3095: loss=0.430, reward_mean=0.240, reward_bound=0.009, batch=195 
3096: loss=0.432, reward_mean=0.280, reward_bound=0.018, batch=205 
3097: loss=0.431, reward_mean=0.280, reward_bound=0.034, batch=211 
3098: loss=0.443, reward_mean=0.270, reward_bound=0.052, batch=215 
3099: loss=0.443, reward_mean=0.250, reward_bound=0.065, batch=217 
3100: loss=0.446, reward_mean=0.330, reward_bound=0.089, batch=225 
3101: loss=0.448, reward_mean=0.330, reward_bound=0.098, batch=216 
3102: loss=0.442, reward_mean=0.350, reward_bound=0.122, batch=213 
3103: loss=0.457, reward_mean=0.320, reward_bound=0.135, batch=217 
3104: loss=0.476, reward_mean=0.330, reward_bound=0.167, batch=201 
3105: loss=0.470, reward_mean=0.240, reward_bound=0.167, batch=210 
3106: loss=0.487, reward_mean=0.230, reward_bound=0.185, batch=204 
3107: loss=0.486, reward_mean=0.280, reward_bound=0.206, batch=193 
3108: loss=0.486, reward_mean=0.320, reward_bound=0.211, batch=205 
3109: loss=0.490, reward_mean=0.250, reward_bound=0.229, batch=180 
3110: loss=0.478, reward_mean=0.290, reward_bound=0.086, batch=196 
3111: loss=0.477, reward_mean=0.250, reward_bound=0.104, batch=207 
3112: loss=0.472, reward_mean=0.240, reward_bound=0.122, batch=214 
3113: loss=0.473, reward_mean=0.210, reward_bound=0.150, batch=218 
3114: loss=0.483, reward_mean=0.190, reward_bound=0.206, batch=220 
3115: loss=0.485, reward_mean=0.240, reward_bound=0.229, batch=222 
3116: loss=0.483, reward_mean=0.340, reward_bound=0.254, batch=185 
3117: loss=0.484, reward_mean=0.250, reward_bound=0.112, batch=199 
3118: loss=0.475, reward_mean=0.260, reward_bound=0.122, batch=207 
3119: loss=0.478, reward_mean=0.350, reward_bound=0.182, batch=215 
3120: loss=0.479, reward_mean=0.320, reward_bound=0.210, batch=220 
3121: loss=0.482, reward_mean=0.180, reward_bound=0.229, batch=218 
3122: loss=0.484, reward_mean=0.250, reward_bound=0.254, batch=219 
3123: loss=0.487, reward_mean=0.200, reward_bound=0.282, batch=183 
3124: loss=0.472, reward_mean=0.180, reward_bound=0.045, batch=198 
3125: loss=0.478, reward_mean=0.250, reward_bound=0.169, batch=208 
3126: loss=0.475, reward_mean=0.200, reward_bound=0.169, batch=215 
3127: loss=0.477, reward_mean=0.230, reward_bound=0.189, batch=220 
3128: loss=0.473, reward_mean=0.280, reward_bound=0.222, batch=224 
3129: loss=0.479, reward_mean=0.270, reward_bound=0.254, batch=226 
3130: loss=0.481, reward_mean=0.340, reward_bound=0.282, batch=226 
3131: loss=0.487, reward_mean=0.220, reward_bound=0.314, batch=173 
3132: loss=0.476, reward_mean=0.250, reward_bound=0.085, batch=191 
3133: loss=0.475, reward_mean=0.310, reward_bound=0.122, batch=203 
3134: loss=0.478, reward_mean=0.180, reward_bound=0.150, batch=209 
3135: loss=0.471, reward_mean=0.290, reward_bound=0.185, batch=214 
3136: loss=0.473, reward_mean=0.240, reward_bound=0.206, batch=217 
3137: loss=0.476, reward_mean=0.300, reward_bound=0.249, batch=222 
3138: loss=0.482, reward_mean=0.280, reward_bound=0.254, batch=220 
3139: loss=0.485, reward_mean=0.230, reward_bound=0.282, batch=216 
3140: loss=0.486, reward_mean=0.250, reward_bound=0.314, batch=215 
3141: loss=0.487, reward_mean=0.280, reward_bound=0.314, batch=218 
3142: loss=0.485, reward_mean=0.260, reward_bound=0.286, batch=222 
3143: loss=0.484, reward_mean=0.280, reward_bound=0.324, batch=225 
3144: loss=0.483, reward_mean=0.270, reward_bound=0.289, batch=227 
3145: loss=0.482, reward_mean=0.160, reward_bound=0.308, batch=229 
3146: loss=0.483, reward_mean=0.220, reward_bound=0.314, batch=228 
3147: loss=0.498, reward_mean=0.350, reward_bound=0.349, batch=163 
3148: loss=0.490, reward_mean=0.280, reward_bound=0.031, batch=183 
3149: loss=0.487, reward_mean=0.260, reward_bound=0.112, batch=198 
3150: loss=0.485, reward_mean=0.180, reward_bound=0.101, batch=208 
3151: loss=0.481, reward_mean=0.230, reward_bound=0.122, batch=214 
3152: loss=0.483, reward_mean=0.330, reward_bound=0.135, batch=219 
3153: loss=0.489, reward_mean=0.220, reward_bound=0.167, batch=218 
3154: loss=0.484, reward_mean=0.280, reward_bound=0.206, batch=217 
3155: loss=0.475, reward_mean=0.240, reward_bound=0.229, batch=217 
3156: loss=0.478, reward_mean=0.220, reward_bound=0.245, batch=222 
3157: loss=0.482, reward_mean=0.220, reward_bound=0.254, batch=215 
3158: loss=0.493, reward_mean=0.300, reward_bound=0.282, batch=213 
3159: loss=0.493, reward_mean=0.250, reward_bound=0.282, batch=218 
3160: loss=0.489, reward_mean=0.320, reward_bound=0.208, batch=222 
3161: loss=0.495, reward_mean=0.290, reward_bound=0.282, batch=223 
3162: loss=0.494, reward_mean=0.340, reward_bound=0.282, batch=225 
3163: loss=0.495, reward_mean=0.180, reward_bound=0.289, batch=227 
3164: loss=0.488, reward_mean=0.370, reward_bound=0.314, batch=211 
3165: loss=0.490, reward_mean=0.290, reward_bound=0.314, batch=215 
3166: loss=0.492, reward_mean=0.280, reward_bound=0.289, batch=220 
3167: loss=0.493, reward_mean=0.260, reward_bound=0.314, batch=221 
3168: loss=0.487, reward_mean=0.390, reward_bound=0.349, batch=204 
3169: loss=0.481, reward_mean=0.290, reward_bound=0.182, batch=213 
3170: loss=0.484, reward_mean=0.280, reward_bound=0.254, batch=218 
3171: loss=0.489, reward_mean=0.270, reward_bound=0.314, batch=219 
3172: loss=0.488, reward_mean=0.280, reward_bound=0.265, batch=223 
3173: loss=0.487, reward_mean=0.230, reward_bound=0.349, batch=218 
3174: loss=0.486, reward_mean=0.260, reward_bound=0.206, batch=221 
3175: loss=0.487, reward_mean=0.340, reward_bound=0.314, batch=223 
3176: loss=0.475, reward_mean=0.340, reward_bound=0.387, batch=150 
3177: loss=0.462, reward_mean=0.300, reward_bound=0.037, batch=175 
3178: loss=0.447, reward_mean=0.220, reward_bound=0.040, batch=192 
3179: loss=0.445, reward_mean=0.220, reward_bound=0.060, batch=204 
3180: loss=0.445, reward_mean=0.290, reward_bound=0.089, batch=211 
3181: loss=0.454, reward_mean=0.320, reward_bound=0.135, batch=212 
3182: loss=0.445, reward_mean=0.330, reward_bound=0.167, batch=217 
3183: loss=0.445, reward_mean=0.300, reward_bound=0.206, batch=217 
3184: loss=0.456, reward_mean=0.360, reward_bound=0.229, batch=215 
3185: loss=0.454, reward_mean=0.300, reward_bound=0.254, batch=208 
3186: loss=0.452, reward_mean=0.220, reward_bound=0.135, batch=214 
3187: loss=0.452, reward_mean=0.270, reward_bound=0.280, batch=220 
3188: loss=0.452, reward_mean=0.280, reward_bound=0.282, batch=211 
3189: loss=0.454, reward_mean=0.260, reward_bound=0.282, batch=216 
3190: loss=0.453, reward_mean=0.270, reward_bound=0.282, batch=220 
3191: loss=0.463, reward_mean=0.280, reward_bound=0.314, batch=209 
3192: loss=0.462, reward_mean=0.330, reward_bound=0.295, batch=216 
3193: loss=0.456, reward_mean=0.330, reward_bound=0.268, batch=221 
3194: loss=0.452, reward_mean=0.270, reward_bound=0.314, batch=222 
3195: loss=0.447, reward_mean=0.310, reward_bound=0.349, batch=200 
3196: loss=0.438, reward_mean=0.260, reward_bound=0.115, batch=210 
3197: loss=0.438, reward_mean=0.220, reward_bound=0.142, batch=217 
3198: loss=0.442, reward_mean=0.360, reward_bound=0.206, batch=220 
3199: loss=0.449, reward_mean=0.340, reward_bound=0.229, batch=222 
3200: loss=0.449, reward_mean=0.290, reward_bound=0.263, batch=225 
3201: loss=0.447, reward_mean=0.230, reward_bound=0.282, batch=219 
3202: loss=0.453, reward_mean=0.230, reward_bound=0.295, batch=223 
3203: loss=0.452, reward_mean=0.240, reward_bound=0.314, batch=224 
3204: loss=0.453, reward_mean=0.340, reward_bound=0.349, batch=222 
3205: loss=0.454, reward_mean=0.280, reward_bound=0.314, batch=224 
3206: loss=0.455, reward_mean=0.390, reward_bound=0.384, batch=227 
3207: loss=0.456, reward_mean=0.260, reward_bound=0.349, batch=228 
3208: loss=0.467, reward_mean=0.290, reward_bound=0.387, batch=206 
3209: loss=0.458, reward_mean=0.280, reward_bound=0.167, batch=213 
3210: loss=0.457, reward_mean=0.230, reward_bound=0.254, batch=217 
3211: loss=0.457, reward_mean=0.280, reward_bound=0.277, batch=222 
3212: loss=0.458, reward_mean=0.310, reward_bound=0.292, batch=225 
3213: loss=0.462, reward_mean=0.240, reward_bound=0.349, batch=222 
3214: loss=0.468, reward_mean=0.210, reward_bound=0.387, batch=221 
3215: loss=0.469, reward_mean=0.220, reward_bound=0.349, batch=224 
3216: loss=0.467, reward_mean=0.330, reward_bound=0.387, batch=223 
3217: loss=0.467, reward_mean=0.290, reward_bound=0.398, batch=226 
3218: loss=0.473, reward_mean=0.280, reward_bound=0.430, batch=120 
3219: loss=0.430, reward_mean=0.280, reward_bound=0.000, batch=148 
3220: loss=0.410, reward_mean=0.250, reward_bound=0.001, batch=173 
3221: loss=0.406, reward_mean=0.330, reward_bound=0.035, batch=191 
3222: loss=0.411, reward_mean=0.290, reward_bound=0.072, batch=203 
3223: loss=0.410, reward_mean=0.290, reward_bound=0.098, batch=209 
3224: loss=0.416, reward_mean=0.320, reward_bound=0.135, batch=213 
3225: loss=0.416, reward_mean=0.270, reward_bound=0.160, batch=219 
3226: loss=0.411, reward_mean=0.320, reward_bound=0.167, batch=220 
3227: loss=0.414, reward_mean=0.280, reward_bound=0.185, batch=218 
3228: loss=0.417, reward_mean=0.350, reward_bound=0.206, batch=220 
3229: loss=0.421, reward_mean=0.310, reward_bound=0.229, batch=211 
3230: loss=0.419, reward_mean=0.260, reward_bound=0.206, batch=216 
3231: loss=0.419, reward_mean=0.210, reward_bound=0.229, batch=220 
3232: loss=0.422, reward_mean=0.320, reward_bound=0.200, batch=224 
3233: loss=0.432, reward_mean=0.270, reward_bound=0.254, batch=213 
3234: loss=0.430, reward_mean=0.290, reward_bound=0.282, batch=209 
3235: loss=0.426, reward_mean=0.320, reward_bound=0.239, batch=216 
3236: loss=0.425, reward_mean=0.300, reward_bound=0.268, batch=221 
3237: loss=0.429, reward_mean=0.320, reward_bound=0.282, batch=222 
3238: loss=0.447, reward_mean=0.280, reward_bound=0.314, batch=198 
3239: loss=0.435, reward_mean=0.280, reward_bound=0.187, batch=208 
3240: loss=0.440, reward_mean=0.250, reward_bound=0.206, batch=213 
3241: loss=0.442, reward_mean=0.320, reward_bound=0.254, batch=215 
3242: loss=0.439, reward_mean=0.280, reward_bound=0.282, batch=216 
3243: loss=0.436, reward_mean=0.270, reward_bound=0.298, batch=221 
3244: loss=0.437, reward_mean=0.340, reward_bound=0.314, batch=220 
3245: loss=0.443, reward_mean=0.370, reward_bound=0.349, batch=200 
3246: loss=0.439, reward_mean=0.270, reward_bound=0.180, batch=210 
3247: loss=0.440, reward_mean=0.280, reward_bound=0.247, batch=217 
3248: loss=0.440, reward_mean=0.280, reward_bound=0.245, batch=222 
3249: loss=0.439, reward_mean=0.300, reward_bound=0.314, batch=222 
3250: loss=0.446, reward_mean=0.330, reward_bound=0.349, batch=222 
3251: loss=0.446, reward_mean=0.210, reward_bound=0.272, batch=225 
3252: loss=0.446, reward_mean=0.350, reward_bound=0.387, batch=185 
3253: loss=0.442, reward_mean=0.290, reward_bound=0.103, batch=199 
3254: loss=0.440, reward_mean=0.270, reward_bound=0.141, batch=209 
3255: loss=0.438, reward_mean=0.230, reward_bound=0.174, batch=216 
3256: loss=0.444, reward_mean=0.280, reward_bound=0.206, batch=219 
3257: loss=0.435, reward_mean=0.320, reward_bound=0.254, batch=217 
3258: loss=0.433, reward_mean=0.270, reward_bound=0.249, batch=222 
3259: loss=0.431, reward_mean=0.280, reward_bound=0.282, batch=219 
3260: loss=0.432, reward_mean=0.190, reward_bound=0.295, batch=223 
3261: loss=0.430, reward_mean=0.180, reward_bound=0.290, batch=226 
3262: loss=0.438, reward_mean=0.310, reward_bound=0.314, batch=224 
3263: loss=0.433, reward_mean=0.300, reward_bound=0.349, batch=214 
3264: loss=0.430, reward_mean=0.220, reward_bound=0.345, batch=220 
3265: loss=0.430, reward_mean=0.230, reward_bound=0.266, batch=224 
3266: loss=0.432, reward_mean=0.230, reward_bound=0.311, batch=227 
3267: loss=0.432, reward_mean=0.310, reward_bound=0.314, batch=226 
3268: loss=0.435, reward_mean=0.340, reward_bound=0.349, batch=227 
3269: loss=0.434, reward_mean=0.280, reward_bound=0.373, batch=229 
3270: loss=0.436, reward_mean=0.220, reward_bound=0.364, batch=230 
3271: loss=0.437, reward_mean=0.270, reward_bound=0.376, batch=231 
3272: loss=0.443, reward_mean=0.270, reward_bound=0.387, batch=211 
3273: loss=0.439, reward_mean=0.310, reward_bound=0.282, batch=216 
3274: loss=0.438, reward_mean=0.340, reward_bound=0.314, batch=218 
3275: loss=0.442, reward_mean=0.240, reward_bound=0.254, batch=221 
3276: loss=0.440, reward_mean=0.220, reward_bound=0.282, batch=223 
3277: loss=0.442, reward_mean=0.270, reward_bound=0.229, batch=225 
3278: loss=0.440, reward_mean=0.330, reward_bound=0.349, batch=221 
3279: loss=0.442, reward_mean=0.310, reward_bound=0.387, batch=223 
3280: loss=0.442, reward_mean=0.280, reward_bound=0.387, batch=225 
3281: loss=0.445, reward_mean=0.300, reward_bound=0.430, batch=183 
3282: loss=0.439, reward_mean=0.290, reward_bound=0.244, batch=198 
3283: loss=0.442, reward_mean=0.310, reward_bound=0.208, batch=208 
3284: loss=0.440, reward_mean=0.310, reward_bound=0.231, batch=215 
3285: loss=0.447, reward_mean=0.290, reward_bound=0.254, batch=216 
3286: loss=0.447, reward_mean=0.260, reward_bound=0.241, batch=221 
3287: loss=0.450, reward_mean=0.340, reward_bound=0.282, batch=220 
3288: loss=0.457, reward_mean=0.310, reward_bound=0.314, batch=213 
3289: loss=0.459, reward_mean=0.340, reward_bound=0.349, batch=210 
3290: loss=0.456, reward_mean=0.280, reward_bound=0.229, batch=216 
3291: loss=0.456, reward_mean=0.320, reward_bound=0.268, batch=221 
3292: loss=0.456, reward_mean=0.210, reward_bound=0.282, batch=221 
3293: loss=0.455, reward_mean=0.370, reward_bound=0.314, batch=224 
3294: loss=0.455, reward_mean=0.160, reward_bound=0.314, batch=226 
3295: loss=0.457, reward_mean=0.280, reward_bound=0.349, batch=221 
3296: loss=0.455, reward_mean=0.250, reward_bound=0.349, batch=223 
3297: loss=0.454, reward_mean=0.300, reward_bound=0.387, batch=214 
3298: loss=0.454, reward_mean=0.290, reward_bound=0.308, batch=220 
3299: loss=0.452, reward_mean=0.340, reward_bound=0.349, batch=223 
3300: loss=0.450, reward_mean=0.350, reward_bound=0.372, batch=226 
3301: loss=0.449, reward_mean=0.280, reward_bound=0.368, batch=228 
3302: loss=0.454, reward_mean=0.220, reward_bound=0.387, batch=227 
3303: loss=0.447, reward_mean=0.260, reward_bound=0.430, batch=208 
3304: loss=0.447, reward_mean=0.320, reward_bound=0.254, batch=214 
3305: loss=0.442, reward_mean=0.230, reward_bound=0.282, batch=218 
3306: loss=0.444, reward_mean=0.260, reward_bound=0.206, batch=220 
3307: loss=0.444, reward_mean=0.270, reward_bound=0.304, batch=224 
3308: loss=0.445, reward_mean=0.300, reward_bound=0.314, batch=226 
3309: loss=0.448, reward_mean=0.260, reward_bound=0.349, batch=220 
3310: loss=0.451, reward_mean=0.310, reward_bound=0.274, batch=224 
3311: loss=0.453, reward_mean=0.210, reward_bound=0.311, batch=227 
3312: loss=0.449, reward_mean=0.280, reward_bound=0.342, batch=229 
3313: loss=0.451, reward_mean=0.360, reward_bound=0.387, batch=223 
3314: loss=0.448, reward_mean=0.330, reward_bound=0.430, batch=218 
3315: loss=0.445, reward_mean=0.300, reward_bound=0.314, batch=221 
3316: loss=0.445, reward_mean=0.250, reward_bound=0.314, batch=224 
3317: loss=0.449, reward_mean=0.290, reward_bound=0.349, batch=224 
3318: loss=0.450, reward_mean=0.320, reward_bound=0.282, batch=226 
3319: loss=0.449, reward_mean=0.300, reward_bound=0.368, batch=228 
3320: loss=0.444, reward_mean=0.250, reward_bound=0.387, batch=226 
3321: loss=0.443, reward_mean=0.260, reward_bound=0.316, batch=228 
3322: loss=0.442, reward_mean=0.220, reward_bound=0.357, batch=229 
3323: loss=0.445, reward_mean=0.390, reward_bound=0.430, batch=228 
3324: loss=0.445, reward_mean=0.240, reward_bound=0.430, batch=228 
3325: loss=0.445, reward_mean=0.240, reward_bound=0.430, batch=228 
3326: loss=0.444, reward_mean=0.280, reward_bound=0.397, batch=229 
3327: loss=0.444, reward_mean=0.210, reward_bound=0.282, batch=229 
3328: loss=0.444, reward_mean=0.240, reward_bound=0.424, batch=230 
3329: loss=0.443, reward_mean=0.290, reward_bound=0.406, batch=231 
3330: loss=0.444, reward_mean=0.270, reward_bound=0.430, batch=231 
3331: loss=0.509, reward_mean=0.350, reward_bound=0.478, batch=105 
3332: loss=0.432, reward_mean=0.250, reward_bound=0.000, batch=130 
3333: loss=0.404, reward_mean=0.280, reward_bound=0.000, batch=158 
3334: loss=0.395, reward_mean=0.310, reward_bound=0.010, batch=180 
3335: loss=0.402, reward_mean=0.310, reward_bound=0.031, batch=195 
3336: loss=0.403, reward_mean=0.150, reward_bound=0.020, batch=206 
3337: loss=0.417, reward_mean=0.290, reward_bound=0.065, batch=209 
3338: loss=0.427, reward_mean=0.270, reward_bound=0.089, batch=212 
3339: loss=0.435, reward_mean=0.210, reward_bound=0.109, batch=209 
3340: loss=0.448, reward_mean=0.380, reward_bound=0.135, batch=209 
3341: loss=0.443, reward_mean=0.340, reward_bound=0.167, batch=204 
3342: loss=0.445, reward_mean=0.240, reward_bound=0.165, batch=213 
3343: loss=0.444, reward_mean=0.370, reward_bound=0.185, batch=217 
3344: loss=0.446, reward_mean=0.290, reward_bound=0.198, batch=222 
3345: loss=0.445, reward_mean=0.290, reward_bound=0.206, batch=233 
3346: loss=0.451, reward_mean=0.260, reward_bound=0.206, batch=226 
3347: loss=0.449, reward_mean=0.310, reward_bound=0.229, batch=215 
3348: loss=0.458, reward_mean=0.280, reward_bound=0.254, batch=206 
3349: loss=0.472, reward_mean=0.350, reward_bound=0.282, batch=199 
3350: loss=0.465, reward_mean=0.230, reward_bound=0.148, batch=209 
3351: loss=0.468, reward_mean=0.340, reward_bound=0.265, batch=216 
3352: loss=0.466, reward_mean=0.230, reward_bound=0.244, batch=221 
3353: loss=0.483, reward_mean=0.230, reward_bound=0.314, batch=190 
3354: loss=0.476, reward_mean=0.240, reward_bound=0.109, batch=202 
3355: loss=0.471, reward_mean=0.260, reward_bound=0.126, batch=211 
3356: loss=0.475, reward_mean=0.230, reward_bound=0.150, batch=217 
3357: loss=0.477, reward_mean=0.300, reward_bound=0.206, batch=218 
3358: loss=0.480, reward_mean=0.340, reward_bound=0.282, batch=216 
3359: loss=0.478, reward_mean=0.210, reward_bound=0.256, batch=221 
3360: loss=0.479, reward_mean=0.250, reward_bound=0.282, batch=223 
3361: loss=0.478, reward_mean=0.280, reward_bound=0.282, batch=224 
3362: loss=0.477, reward_mean=0.240, reward_bound=0.314, batch=223 
3363: loss=0.483, reward_mean=0.230, reward_bound=0.349, batch=197 
3364: loss=0.479, reward_mean=0.250, reward_bound=0.206, batch=207 
3365: loss=0.478, reward_mean=0.230, reward_bound=0.178, batch=215 
3366: loss=0.491, reward_mean=0.270, reward_bound=0.229, batch=218 
3367: loss=0.492, reward_mean=0.300, reward_bound=0.254, batch=221 
3368: loss=0.482, reward_mean=0.280, reward_bound=0.282, batch=221 
3369: loss=0.484, reward_mean=0.200, reward_bound=0.349, batch=217 
3370: loss=0.485, reward_mean=0.270, reward_bound=0.282, batch=221 
3371: loss=0.484, reward_mean=0.260, reward_bound=0.229, batch=224 
3372: loss=0.486, reward_mean=0.300, reward_bound=0.345, batch=227 
3373: loss=0.485, reward_mean=0.260, reward_bound=0.349, batch=227 
3374: loss=0.492, reward_mean=0.300, reward_bound=0.387, batch=189 
3375: loss=0.477, reward_mean=0.290, reward_bound=0.185, batch=201 
3376: loss=0.474, reward_mean=0.280, reward_bound=0.167, batch=209 
3377: loss=0.477, reward_mean=0.280, reward_bound=0.239, batch=216 
3378: loss=0.477, reward_mean=0.280, reward_bound=0.206, batch=220 
3379: loss=0.480, reward_mean=0.230, reward_bound=0.254, batch=216 
3380: loss=0.474, reward_mean=0.240, reward_bound=0.202, batch=221 
3381: loss=0.475, reward_mean=0.150, reward_bound=0.254, batch=224 
3382: loss=0.471, reward_mean=0.180, reward_bound=0.229, batch=226 
3383: loss=0.478, reward_mean=0.230, reward_bound=0.282, batch=225 
3384: loss=0.485, reward_mean=0.240, reward_bound=0.314, batch=217 
3385: loss=0.484, reward_mean=0.270, reward_bound=0.282, batch=221 
3386: loss=0.490, reward_mean=0.190, reward_bound=0.349, batch=220 
3387: loss=0.488, reward_mean=0.230, reward_bound=0.282, batch=223 
3388: loss=0.487, reward_mean=0.250, reward_bound=0.335, batch=226 
3389: loss=0.486, reward_mean=0.230, reward_bound=0.368, batch=228 
3390: loss=0.488, reward_mean=0.230, reward_bound=0.387, batch=217 
3391: loss=0.489, reward_mean=0.300, reward_bound=0.387, batch=219 
3392: loss=0.501, reward_mean=0.270, reward_bound=0.430, batch=170 
3393: loss=0.473, reward_mean=0.210, reward_bound=0.036, batch=189 
3394: loss=0.482, reward_mean=0.280, reward_bound=0.071, batch=202 
3395: loss=0.483, reward_mean=0.220, reward_bound=0.102, batch=211 
3396: loss=0.491, reward_mean=0.290, reward_bound=0.135, batch=215 
3397: loss=0.486, reward_mean=0.210, reward_bound=0.153, batch=220 
3398: loss=0.488, reward_mean=0.210, reward_bound=0.180, batch=224 
3399: loss=0.485, reward_mean=0.250, reward_bound=0.206, batch=224 
3400: loss=0.488, reward_mean=0.230, reward_bound=0.229, batch=222 
3401: loss=0.483, reward_mean=0.260, reward_bound=0.254, batch=223 
3402: loss=0.489, reward_mean=0.340, reward_bound=0.282, batch=219 
3403: loss=0.487, reward_mean=0.230, reward_bound=0.250, batch=223 
3404: loss=0.498, reward_mean=0.260, reward_bound=0.314, batch=222 
3405: loss=0.496, reward_mean=0.220, reward_bound=0.272, batch=225 
3406: loss=0.498, reward_mean=0.300, reward_bound=0.349, batch=213 
3407: loss=0.497, reward_mean=0.220, reward_bound=0.322, batch=219 
3408: loss=0.496, reward_mean=0.320, reward_bound=0.349, batch=221 
3409: loss=0.493, reward_mean=0.230, reward_bound=0.314, batch=223 
3410: loss=0.496, reward_mean=0.330, reward_bound=0.349, batch=225 
3411: loss=0.499, reward_mean=0.250, reward_bound=0.387, batch=215 
3412: loss=0.494, reward_mean=0.220, reward_bound=0.314, batch=219 
3413: loss=0.497, reward_mean=0.330, reward_bound=0.364, batch=223 
3414: loss=0.499, reward_mean=0.200, reward_bound=0.387, batch=225 
3415: loss=0.498, reward_mean=0.210, reward_bound=0.396, batch=227 
3416: loss=0.500, reward_mean=0.160, reward_bound=0.395, batch=229 
3417: loss=0.503, reward_mean=0.300, reward_bound=0.430, batch=204 
3418: loss=0.501, reward_mean=0.270, reward_bound=0.185, batch=212 
3419: loss=0.499, reward_mean=0.280, reward_bound=0.282, batch=213 
3420: loss=0.499, reward_mean=0.260, reward_bound=0.220, batch=219 
3421: loss=0.496, reward_mean=0.220, reward_bound=0.265, batch=223 
3422: loss=0.492, reward_mean=0.260, reward_bound=0.301, batch=226 
3423: loss=0.492, reward_mean=0.290, reward_bound=0.298, batch=228 
3424: loss=0.493, reward_mean=0.250, reward_bound=0.314, batch=228 
3425: loss=0.498, reward_mean=0.240, reward_bound=0.349, batch=222 
3426: loss=0.501, reward_mean=0.250, reward_bound=0.282, batch=224 
3427: loss=0.500, reward_mean=0.290, reward_bound=0.384, batch=227 
3428: loss=0.499, reward_mean=0.240, reward_bound=0.387, batch=222 
3429: loss=0.495, reward_mean=0.290, reward_bound=0.430, batch=216 
3430: loss=0.493, reward_mean=0.180, reward_bound=0.210, batch=221 
3431: loss=0.492, reward_mean=0.230, reward_bound=0.254, batch=224 
3432: loss=0.490, reward_mean=0.270, reward_bound=0.314, batch=226 
3433: loss=0.491, reward_mean=0.290, reward_bound=0.349, batch=226 
3434: loss=0.493, reward_mean=0.260, reward_bound=0.387, batch=226 
3435: loss=0.492, reward_mean=0.200, reward_bound=0.298, batch=228 
3436: loss=0.493, reward_mean=0.230, reward_bound=0.349, batch=228 
3437: loss=0.493, reward_mean=0.250, reward_bound=0.430, batch=224 
3438: loss=0.494, reward_mean=0.240, reward_bound=0.384, batch=227 
3439: loss=0.493, reward_mean=0.310, reward_bound=0.272, batch=229 
3440: loss=0.492, reward_mean=0.280, reward_bound=0.309, batch=230 
3441: loss=0.490, reward_mean=0.280, reward_bound=0.387, batch=228 
3442: loss=0.490, reward_mean=0.230, reward_bound=0.349, batch=228 
3443: loss=0.490, reward_mean=0.260, reward_bound=0.430, batch=227 
3444: loss=0.488, reward_mean=0.260, reward_bound=0.469, batch=229 
3445: loss=0.487, reward_mean=0.200, reward_bound=0.424, batch=230 
3446: loss=0.487, reward_mean=0.250, reward_bound=0.387, batch=230 
3447: loss=0.489, reward_mean=0.270, reward_bound=0.418, batch=231 
3448: loss=0.498, reward_mean=0.270, reward_bound=0.478, batch=151 
3449: loss=0.459, reward_mean=0.270, reward_bound=0.015, batch=175 
3450: loss=0.440, reward_mean=0.160, reward_bound=0.000, batch=191 
3451: loss=0.434, reward_mean=0.330, reward_bound=0.047, batch=202 
3452: loss=0.440, reward_mean=0.330, reward_bound=0.098, batch=208 
3453: loss=0.450, reward_mean=0.360, reward_bound=0.109, batch=214 
3454: loss=0.454, reward_mean=0.310, reward_bound=0.150, batch=215 
3455: loss=0.456, reward_mean=0.220, reward_bound=0.167, batch=219 
3456: loss=0.449, reward_mean=0.260, reward_bound=0.185, batch=220 
3457: loss=0.442, reward_mean=0.260, reward_bound=0.206, batch=227 
3458: loss=0.455, reward_mean=0.230, reward_bound=0.229, batch=221 
3459: loss=0.458, reward_mean=0.290, reward_bound=0.254, batch=219 
3460: loss=0.467, reward_mean=0.290, reward_bound=0.282, batch=214 
3461: loss=0.463, reward_mean=0.290, reward_bound=0.226, batch=220 
3462: loss=0.466, reward_mean=0.300, reward_bound=0.282, batch=221 
3463: loss=0.468, reward_mean=0.260, reward_bound=0.314, batch=210 
3464: loss=0.462, reward_mean=0.300, reward_bound=0.304, batch=217 
3465: loss=0.469, reward_mean=0.250, reward_bound=0.314, batch=218 
3466: loss=0.470, reward_mean=0.240, reward_bound=0.231, batch=222 
3467: loss=0.469, reward_mean=0.240, reward_bound=0.263, batch=225 
3468: loss=0.474, reward_mean=0.280, reward_bound=0.349, batch=209 
3469: loss=0.473, reward_mean=0.280, reward_bound=0.309, batch=216 
3470: loss=0.475, reward_mean=0.300, reward_bound=0.331, batch=221 
3471: loss=0.476, reward_mean=0.260, reward_bound=0.282, batch=224 
3472: loss=0.475, reward_mean=0.280, reward_bound=0.345, batch=227 
3473: loss=0.477, reward_mean=0.270, reward_bound=0.349, batch=221 
3474: loss=0.476, reward_mean=0.300, reward_bound=0.349, batch=224 
3475: loss=0.476, reward_mean=0.270, reward_bound=0.311, batch=227 
3476: loss=0.478, reward_mean=0.270, reward_bound=0.349, batch=228 
3477: loss=0.483, reward_mean=0.340, reward_bound=0.387, batch=201 
3478: loss=0.481, reward_mean=0.240, reward_bound=0.135, batch=209 
3479: loss=0.479, reward_mean=0.200, reward_bound=0.174, batch=216 
3480: loss=0.482, reward_mean=0.250, reward_bound=0.331, batch=221 
3481: loss=0.483, reward_mean=0.270, reward_bound=0.349, batch=221 
3482: loss=0.489, reward_mean=0.300, reward_bound=0.387, batch=223 
3483: loss=0.489, reward_mean=0.250, reward_bound=0.384, batch=226 
3484: loss=0.489, reward_mean=0.340, reward_bound=0.316, batch=228 
3485: loss=0.487, reward_mean=0.280, reward_bound=0.387, batch=228 
3486: loss=0.487, reward_mean=0.250, reward_bound=0.392, batch=229 
3487: loss=0.501, reward_mean=0.220, reward_bound=0.430, batch=190 
3488: loss=0.496, reward_mean=0.290, reward_bound=0.185, batch=201 
3489: loss=0.494, reward_mean=0.260, reward_bound=0.229, batch=206 
3490: loss=0.493, reward_mean=0.220, reward_bound=0.185, batch=213 
3491: loss=0.495, reward_mean=0.230, reward_bound=0.198, batch=219 
3492: loss=0.493, reward_mean=0.270, reward_bound=0.194, batch=223 
3493: loss=0.498, reward_mean=0.320, reward_bound=0.254, batch=225 
3494: loss=0.500, reward_mean=0.300, reward_bound=0.282, batch=224 
3495: loss=0.495, reward_mean=0.250, reward_bound=0.314, batch=222 
3496: loss=0.493, reward_mean=0.240, reward_bound=0.302, batch=225 
3497: loss=0.494, reward_mean=0.170, reward_bound=0.203, batch=227 
3498: loss=0.500, reward_mean=0.300, reward_bound=0.349, batch=219 
3499: loss=0.497, reward_mean=0.260, reward_bound=0.278, batch=223 
3500: loss=0.497, reward_mean=0.330, reward_bound=0.301, batch=226 
3501: loss=0.496, reward_mean=0.250, reward_bound=0.298, batch=228 
3502: loss=0.500, reward_mean=0.280, reward_bound=0.349, batch=227 
3503: loss=0.497, reward_mean=0.260, reward_bound=0.330, batch=229 
3504: loss=0.500, reward_mean=0.260, reward_bound=0.364, batch=230 
3505: loss=0.506, reward_mean=0.220, reward_bound=0.387, batch=219 
3506: loss=0.504, reward_mean=0.200, reward_bound=0.265, batch=223 
3507: loss=0.503, reward_mean=0.270, reward_bound=0.335, batch=226 
3508: loss=0.500, reward_mean=0.320, reward_bound=0.316, batch=228 
3509: loss=0.508, reward_mean=0.220, reward_bound=0.349, batch=226 
3510: loss=0.508, reward_mean=0.150, reward_bound=0.331, batch=228 
3511: loss=0.501, reward_mean=0.230, reward_bound=0.392, batch=229 
3512: loss=0.507, reward_mean=0.250, reward_bound=0.430, batch=209 
3513: loss=0.502, reward_mean=0.160, reward_bound=0.150, batch=215 
3514: loss=0.501, reward_mean=0.280, reward_bound=0.229, batch=219 
3515: loss=0.501, reward_mean=0.270, reward_bound=0.282, batch=222 
3516: loss=0.500, reward_mean=0.300, reward_bound=0.324, batch=225 
3517: loss=0.504, reward_mean=0.250, reward_bound=0.349, batch=223 
3518: loss=0.502, reward_mean=0.230, reward_bound=0.349, batch=225 
3519: loss=0.505, reward_mean=0.270, reward_bound=0.387, batch=222 
3520: loss=0.502, reward_mean=0.280, reward_bound=0.324, batch=225 
3521: loss=0.501, reward_mean=0.240, reward_bound=0.356, batch=227 
3522: loss=0.501, reward_mean=0.200, reward_bound=0.380, batch=229 
3523: loss=0.501, reward_mean=0.200, reward_bound=0.387, batch=229 
3524: loss=0.499, reward_mean=0.220, reward_bound=0.295, batch=230 
3525: loss=0.503, reward_mean=0.280, reward_bound=0.418, batch=231 
3526: loss=0.501, reward_mean=0.290, reward_bound=0.430, batch=222 
3527: loss=0.500, reward_mean=0.250, reward_bound=0.324, batch=225 
3528: loss=0.501, reward_mean=0.240, reward_bound=0.349, batch=225 
3529: loss=0.501, reward_mean=0.280, reward_bound=0.356, batch=227 
3530: loss=0.502, reward_mean=0.220, reward_bound=0.361, batch=229 
3531: loss=0.503, reward_mean=0.260, reward_bound=0.364, batch=230 
3532: loss=0.502, reward_mean=0.220, reward_bound=0.387, batch=230 
3533: loss=0.502, reward_mean=0.210, reward_bound=0.304, batch=231 
3534: loss=0.501, reward_mean=0.240, reward_bound=0.430, batch=227 
3535: loss=0.501, reward_mean=0.180, reward_bound=0.277, batch=229 
3536: loss=0.501, reward_mean=0.220, reward_bound=0.282, batch=229 
3537: loss=0.501, reward_mean=0.300, reward_bound=0.401, batch=230 
3538: loss=0.501, reward_mean=0.250, reward_bound=0.349, batch=230 
3539: loss=0.501, reward_mean=0.260, reward_bound=0.338, batch=231 
3540: loss=0.502, reward_mean=0.180, reward_bound=0.478, batch=188 
3541: loss=0.499, reward_mean=0.320, reward_bound=0.167, batch=199 
3542: loss=0.495, reward_mean=0.210, reward_bound=0.148, batch=209 
3543: loss=0.493, reward_mean=0.230, reward_bound=0.206, batch=215 
3544: loss=0.487, reward_mean=0.230, reward_bound=0.254, batch=212 
3545: loss=0.486, reward_mean=0.290, reward_bound=0.198, batch=218 
3546: loss=0.486, reward_mean=0.350, reward_bound=0.282, batch=218 
3547: loss=0.489, reward_mean=0.310, reward_bound=0.314, batch=218 
3548: loss=0.490, reward_mean=0.220, reward_bound=0.208, batch=222 
3549: loss=0.486, reward_mean=0.260, reward_bound=0.292, batch=225 
3550: loss=0.483, reward_mean=0.240, reward_bound=0.314, batch=226 
3551: loss=0.484, reward_mean=0.320, reward_bound=0.349, batch=222 
3552: loss=0.485, reward_mean=0.250, reward_bound=0.349, batch=224 
3553: loss=0.495, reward_mean=0.280, reward_bound=0.387, batch=208 
3554: loss=0.486, reward_mean=0.210, reward_bound=0.192, batch=215 
3555: loss=0.486, reward_mean=0.360, reward_bound=0.314, batch=217 
3556: loss=0.485, reward_mean=0.200, reward_bound=0.254, batch=221 
3557: loss=0.486, reward_mean=0.250, reward_bound=0.314, batch=222 
3558: loss=0.486, reward_mean=0.260, reward_bound=0.324, batch=225 
3559: loss=0.485, reward_mean=0.260, reward_bound=0.349, batch=224 
3560: loss=0.481, reward_mean=0.190, reward_bound=0.380, batch=227 
3561: loss=0.483, reward_mean=0.310, reward_bound=0.349, batch=228 
3562: loss=0.487, reward_mean=0.280, reward_bound=0.387, batch=219 
3563: loss=0.486, reward_mean=0.180, reward_bound=0.314, batch=222 
3564: loss=0.488, reward_mean=0.270, reward_bound=0.360, batch=225 
3565: loss=0.487, reward_mean=0.250, reward_bound=0.314, batch=226 
3566: loss=0.487, reward_mean=0.230, reward_bound=0.349, batch=226 
3567: loss=0.486, reward_mean=0.230, reward_bound=0.368, batch=228 
3568: loss=0.485, reward_mean=0.260, reward_bound=0.392, batch=229 
3569: loss=0.497, reward_mean=0.210, reward_bound=0.430, batch=213 
3570: loss=0.499, reward_mean=0.240, reward_bound=0.314, batch=216 
3571: loss=0.496, reward_mean=0.220, reward_bound=0.298, batch=221 
3572: loss=0.497, reward_mean=0.260, reward_bound=0.349, batch=221 
3573: loss=0.496, reward_mean=0.250, reward_bound=0.387, batch=224 
3574: loss=0.499, reward_mean=0.280, reward_bound=0.339, batch=227 
3575: loss=0.494, reward_mean=0.270, reward_bound=0.380, batch=229 
3576: loss=0.497, reward_mean=0.240, reward_bound=0.387, batch=228 
3577: loss=0.501, reward_mean=0.290, reward_bound=0.430, batch=226 
3578: loss=0.499, reward_mean=0.280, reward_bound=0.368, batch=228 
3579: loss=0.501, reward_mean=0.230, reward_bound=0.387, batch=227 
3580: loss=0.499, reward_mean=0.330, reward_bound=0.422, batch=229 
3581: loss=0.500, reward_mean=0.290, reward_bound=0.430, batch=227 
3582: loss=0.501, reward_mean=0.270, reward_bound=0.366, batch=229 
3583: loss=0.502, reward_mean=0.290, reward_bound=0.424, batch=230 
3584: loss=0.499, reward_mean=0.240, reward_bound=0.478, batch=203 
3585: loss=0.499, reward_mean=0.310, reward_bound=0.254, batch=211 
3586: loss=0.494, reward_mean=0.230, reward_bound=0.206, batch=217 
3587: loss=0.496, reward_mean=0.280, reward_bound=0.308, batch=222 
3588: loss=0.498, reward_mean=0.320, reward_bound=0.292, batch=225 
3589: loss=0.497, reward_mean=0.210, reward_bound=0.266, batch=227 
3590: loss=0.495, reward_mean=0.190, reward_bound=0.314, batch=226 
3591: loss=0.493, reward_mean=0.330, reward_bound=0.349, batch=224 
3592: loss=0.492, reward_mean=0.250, reward_bound=0.349, batch=226 
3593: loss=0.497, reward_mean=0.220, reward_bound=0.387, batch=218 
3594: loss=0.492, reward_mean=0.210, reward_bound=0.208, batch=222 
3595: loss=0.493, reward_mean=0.260, reward_bound=0.314, batch=223 
3596: loss=0.491, reward_mean=0.250, reward_bound=0.301, batch=226 
3597: loss=0.493, reward_mean=0.290, reward_bound=0.368, batch=228 
3598: loss=0.493, reward_mean=0.290, reward_bound=0.387, batch=226 
3599: loss=0.493, reward_mean=0.260, reward_bound=0.387, batch=227 
3600: loss=0.493, reward_mean=0.260, reward_bound=0.342, batch=229 
3601: loss=0.493, reward_mean=0.280, reward_bound=0.387, batch=229 
3602: loss=0.493, reward_mean=0.270, reward_bound=0.381, batch=230 
3603: loss=0.491, reward_mean=0.270, reward_bound=0.430, batch=223 
3604: loss=0.486, reward_mean=0.160, reward_bound=0.271, batch=226 
3605: loss=0.485, reward_mean=0.260, reward_bound=0.331, batch=228 
3606: loss=0.495, reward_mean=0.210, reward_bound=0.387, batch=227 
3607: loss=0.494, reward_mean=0.320, reward_bound=0.469, batch=229 
3608: loss=0.495, reward_mean=0.230, reward_bound=0.360, batch=230 
3609: loss=0.493, reward_mean=0.270, reward_bound=0.478, batch=215 
3610: loss=0.497, reward_mean=0.260, reward_bound=0.240, batch=220 
3611: loss=0.498, reward_mean=0.340, reward_bound=0.387, batch=223 
3612: loss=0.495, reward_mean=0.210, reward_bound=0.349, batch=225 
3613: loss=0.498, reward_mean=0.260, reward_bound=0.387, batch=225 
3614: loss=0.496, reward_mean=0.270, reward_bound=0.396, batch=227 
3615: loss=0.495, reward_mean=0.250, reward_bound=0.407, batch=229 
3616: loss=0.495, reward_mean=0.210, reward_bound=0.387, batch=229 
3617: loss=0.495, reward_mean=0.270, reward_bound=0.405, batch=230 
3618: loss=0.496, reward_mean=0.210, reward_bound=0.406, batch=231 
3619: loss=0.496, reward_mean=0.260, reward_bound=0.349, batch=231 
3620: loss=0.496, reward_mean=0.230, reward_bound=0.387, batch=231 
3621: loss=0.497, reward_mean=0.240, reward_bound=0.430, batch=225 
3622: loss=0.496, reward_mean=0.300, reward_bound=0.365, batch=227 
3623: loss=0.496, reward_mean=0.250, reward_bound=0.407, batch=229 
3624: loss=0.496, reward_mean=0.240, reward_bound=0.349, batch=229 
3625: loss=0.497, reward_mean=0.300, reward_bound=0.430, batch=229 
3626: loss=0.496, reward_mean=0.200, reward_bound=0.360, batch=230 
3627: loss=0.493, reward_mean=0.280, reward_bound=0.478, batch=220 
3628: loss=0.491, reward_mean=0.230, reward_bound=0.296, batch=224 
3629: loss=0.492, reward_mean=0.280, reward_bound=0.349, batch=225 
3630: loss=0.494, reward_mean=0.270, reward_bound=0.387, batch=226 
3631: loss=0.496, reward_mean=0.310, reward_bound=0.409, batch=228 
3632: loss=0.495, reward_mean=0.210, reward_bound=0.392, batch=229 
3633: loss=0.493, reward_mean=0.200, reward_bound=0.430, batch=227 
3634: loss=0.492, reward_mean=0.220, reward_bound=0.380, batch=229 
3635: loss=0.496, reward_mean=0.250, reward_bound=0.450, batch=230 
3636: loss=0.499, reward_mean=0.300, reward_bound=0.464, batch=231 
3637: loss=0.494, reward_mean=0.230, reward_bound=0.478, batch=225 
3638: loss=0.494, reward_mean=0.220, reward_bound=0.365, batch=227 
3639: loss=0.494, reward_mean=0.310, reward_bound=0.380, batch=229 
3640: loss=0.495, reward_mean=0.250, reward_bound=0.450, batch=230 
3641: loss=0.492, reward_mean=0.340, reward_bound=0.478, batch=229 
3642: loss=0.492, reward_mean=0.260, reward_bound=0.450, batch=230 
3643: loss=0.492, reward_mean=0.210, reward_bound=0.464, batch=231 
3644: loss=0.492, reward_mean=0.290, reward_bound=0.282, batch=231 
3645: loss=0.492, reward_mean=0.280, reward_bound=0.387, batch=231 
3646: loss=0.492, reward_mean=0.250, reward_bound=0.387, batch=231 
3647: loss=0.492, reward_mean=0.360, reward_bound=0.387, batch=231 
3648: loss=0.492, reward_mean=0.250, reward_bound=0.478, batch=230 
3649: loss=0.492, reward_mean=0.290, reward_bound=0.430, batch=230 
3650: loss=0.490, reward_mean=0.290, reward_bound=0.515, batch=231 
3651: loss=0.490, reward_mean=0.330, reward_bound=0.430, batch=231 
3653: loss=0.370, reward_mean=0.290, reward_bound=0.000, batch=29 
3654: loss=0.363, reward_mean=0.230, reward_bound=0.000, batch=52 
3655: loss=0.347, reward_mean=0.320, reward_bound=0.000, batch=84 
3656: loss=0.354, reward_mean=0.190, reward_bound=0.000, batch=103 
3657: loss=0.344, reward_mean=0.210, reward_bound=0.000, batch=124 
3658: loss=0.346, reward_mean=0.280, reward_bound=0.000, batch=152 
3659: loss=0.358, reward_mean=0.290, reward_bound=0.003, batch=175 
3660: loss=0.359, reward_mean=0.340, reward_bound=0.023, batch=186 
3661: loss=0.367, reward_mean=0.280, reward_bound=0.031, batch=197 
3662: loss=0.366, reward_mean=0.260, reward_bound=0.047, batch=205 
3663: loss=0.360, reward_mean=0.340, reward_bound=0.065, batch=204 
3664: loss=0.354, reward_mean=0.280, reward_bound=0.079, batch=213 
3665: loss=0.358, reward_mean=0.300, reward_bound=0.085, batch=219 
3666: loss=0.350, reward_mean=0.320, reward_bound=0.089, batch=219 
3667: loss=0.349, reward_mean=0.340, reward_bound=0.109, batch=215 
3668: loss=0.360, reward_mean=0.240, reward_bound=0.122, batch=204 
3669: loss=0.354, reward_mean=0.340, reward_bound=0.135, batch=199 
3670: loss=0.355, reward_mean=0.380, reward_bound=0.150, batch=197 
3671: loss=0.362, reward_mean=0.350, reward_bound=0.167, batch=195 
3672: loss=0.361, reward_mean=0.250, reward_bound=0.145, batch=206 
3673: loss=0.360, reward_mean=0.290, reward_bound=0.167, batch=212 
3674: loss=0.358, reward_mean=0.370, reward_bound=0.185, batch=203 
3675: loss=0.357, reward_mean=0.330, reward_bound=0.206, batch=195 
3676: loss=0.356, reward_mean=0.260, reward_bound=0.127, batch=206 
3677: loss=0.362, reward_mean=0.390, reward_bound=0.229, batch=182 
3678: loss=0.352, reward_mean=0.320, reward_bound=0.102, batch=197 
3679: loss=0.355, reward_mean=0.350, reward_bound=0.122, batch=207 
3680: loss=0.360, reward_mean=0.430, reward_bound=0.202, batch=215 
3681: loss=0.368, reward_mean=0.320, reward_bound=0.206, batch=218 
3682: loss=0.379, reward_mean=0.360, reward_bound=0.254, batch=200 
3683: loss=0.381, reward_mean=0.390, reward_bound=0.185, batch=209 
3684: loss=0.381, reward_mean=0.320, reward_bound=0.185, batch=215 
3685: loss=0.387, reward_mean=0.310, reward_bound=0.282, batch=182 
3686: loss=0.388, reward_mean=0.330, reward_bound=0.080, batch=196 
3687: loss=0.385, reward_mean=0.350, reward_bound=0.158, batch=207 
3688: loss=0.380, reward_mean=0.290, reward_bound=0.185, batch=213 
3689: loss=0.382, reward_mean=0.230, reward_bound=0.229, batch=215 
3690: loss=0.381, reward_mean=0.430, reward_bound=0.254, batch=217 
3691: loss=0.379, reward_mean=0.400, reward_bound=0.308, batch=222 
3692: loss=0.383, reward_mean=0.350, reward_bound=0.314, batch=175 
3693: loss=0.366, reward_mean=0.320, reward_bound=0.047, batch=192 
3694: loss=0.362, reward_mean=0.300, reward_bound=0.082, batch=204 
3695: loss=0.361, reward_mean=0.280, reward_bound=0.109, batch=212 
3696: loss=0.360, reward_mean=0.280, reward_bound=0.135, batch=213 
3697: loss=0.369, reward_mean=0.310, reward_bound=0.185, batch=215 
3698: loss=0.365, reward_mean=0.320, reward_bound=0.206, batch=213 
3699: loss=0.365, reward_mean=0.330, reward_bound=0.244, batch=219 
3700: loss=0.374, reward_mean=0.400, reward_bound=0.282, batch=214 
3701: loss=0.380, reward_mean=0.370, reward_bound=0.282, batch=219 
3702: loss=0.378, reward_mean=0.320, reward_bound=0.278, batch=223 
3703: loss=0.375, reward_mean=0.340, reward_bound=0.314, batch=215 
3704: loss=0.376, reward_mean=0.260, reward_bound=0.273, batch=220 
3705: loss=0.375, reward_mean=0.390, reward_bound=0.314, batch=223 
3706: loss=0.375, reward_mean=0.310, reward_bound=0.335, batch=226 
3707: loss=0.380, reward_mean=0.270, reward_bound=0.349, batch=155 
3708: loss=0.369, reward_mean=0.300, reward_bound=0.035, batch=178 
3709: loss=0.367, reward_mean=0.310, reward_bound=0.058, batch=192 
3710: loss=0.373, reward_mean=0.290, reward_bound=0.098, batch=200 
3711: loss=0.373, reward_mean=0.290, reward_bound=0.109, batch=209 
3712: loss=0.370, reward_mean=0.340, reward_bound=0.157, batch=216 
3713: loss=0.374, reward_mean=0.270, reward_bound=0.167, batch=216 
3714: loss=0.374, reward_mean=0.320, reward_bound=0.185, batch=219 
3715: loss=0.376, reward_mean=0.340, reward_bound=0.206, batch=222 
3716: loss=0.379, reward_mean=0.280, reward_bound=0.229, batch=220 
3717: loss=0.373, reward_mean=0.320, reward_bound=0.254, batch=213 
3718: loss=0.375, reward_mean=0.350, reward_bound=0.282, batch=211 
3719: loss=0.374, reward_mean=0.320, reward_bound=0.282, batch=217 
3720: loss=0.374, reward_mean=0.320, reward_bound=0.314, batch=213 
3721: loss=0.372, reward_mean=0.310, reward_bound=0.322, batch=219 
3722: loss=0.377, reward_mean=0.380, reward_bound=0.349, batch=205 
3723: loss=0.380, reward_mean=0.280, reward_bound=0.282, batch=211 
3724: loss=0.382, reward_mean=0.310, reward_bound=0.229, batch=217 
3725: loss=0.379, reward_mean=0.310, reward_bound=0.277, batch=222 
3726: loss=0.378, reward_mean=0.270, reward_bound=0.292, batch=225 
3727: loss=0.380, reward_mean=0.280, reward_bound=0.314, batch=226 
3728: loss=0.383, reward_mean=0.250, reward_bound=0.349, batch=220 
3729: loss=0.383, reward_mean=0.300, reward_bound=0.320, batch=224 
3730: loss=0.380, reward_mean=0.320, reward_bound=0.280, batch=227 
3731: loss=0.385, reward_mean=0.320, reward_bound=0.380, batch=229 
3732: loss=0.382, reward_mean=0.350, reward_bound=0.387, batch=157 
3733: loss=0.370, reward_mean=0.350, reward_bound=0.072, batch=179 
3734: loss=0.354, reward_mean=0.300, reward_bound=0.089, batch=194 
3735: loss=0.364, reward_mean=0.290, reward_bound=0.135, batch=203 
3736: loss=0.366, reward_mean=0.300, reward_bound=0.167, batch=206 
3737: loss=0.360, reward_mean=0.370, reward_bound=0.185, batch=212 
3738: loss=0.357, reward_mean=0.270, reward_bound=0.206, batch=223 
3739: loss=0.362, reward_mean=0.240, reward_bound=0.220, batch=226 
3740: loss=0.366, reward_mean=0.340, reward_bound=0.254, batch=223 
3741: loss=0.370, reward_mean=0.380, reward_bound=0.282, batch=213 
3742: loss=0.371, reward_mean=0.430, reward_bound=0.301, batch=219 
3743: loss=0.374, reward_mean=0.340, reward_bound=0.265, batch=223 
3744: loss=0.374, reward_mean=0.330, reward_bound=0.301, batch=226 
3745: loss=0.375, reward_mean=0.210, reward_bound=0.229, batch=227 
3746: loss=0.381, reward_mean=0.320, reward_bound=0.314, batch=209 
3747: loss=0.382, reward_mean=0.300, reward_bound=0.163, batch=216 
3748: loss=0.374, reward_mean=0.400, reward_bound=0.254, batch=219 
3749: loss=0.372, reward_mean=0.370, reward_bound=0.254, batch=222 
3750: loss=0.373, reward_mean=0.410, reward_bound=0.282, batch=224 
3751: loss=0.373, reward_mean=0.380, reward_bound=0.314, batch=225 
3752: loss=0.372, reward_mean=0.340, reward_bound=0.296, batch=227 
3753: loss=0.377, reward_mean=0.340, reward_bound=0.349, batch=212 
3754: loss=0.372, reward_mean=0.290, reward_bound=0.213, batch=218 
3755: loss=0.372, reward_mean=0.250, reward_bound=0.231, batch=222 
3756: loss=0.374, reward_mean=0.230, reward_bound=0.272, batch=225 
3757: loss=0.372, reward_mean=0.320, reward_bound=0.314, batch=224 
3758: loss=0.375, reward_mean=0.310, reward_bound=0.349, batch=222 
3759: loss=0.375, reward_mean=0.280, reward_bound=0.263, batch=225 
3760: loss=0.374, reward_mean=0.190, reward_bound=0.206, batch=226 
3761: loss=0.380, reward_mean=0.370, reward_bound=0.331, batch=228 
3762: loss=0.379, reward_mean=0.320, reward_bound=0.349, batch=228 
3763: loss=0.385, reward_mean=0.280, reward_bound=0.387, batch=204 
3764: loss=0.381, reward_mean=0.320, reward_bound=0.226, batch=213 
3765: loss=0.380, reward_mean=0.280, reward_bound=0.244, batch=219 
3766: loss=0.386, reward_mean=0.350, reward_bound=0.265, batch=223 
3767: loss=0.384, reward_mean=0.300, reward_bound=0.252, batch=226 
3768: loss=0.380, reward_mean=0.350, reward_bound=0.298, batch=228 
3769: loss=0.381, reward_mean=0.210, reward_bound=0.314, batch=224 
3770: loss=0.382, reward_mean=0.260, reward_bound=0.314, batch=226 
3771: loss=0.387, reward_mean=0.240, reward_bound=0.349, batch=222 
3772: loss=0.385, reward_mean=0.340, reward_bound=0.387, batch=223 
3773: loss=0.383, reward_mean=0.300, reward_bound=0.335, batch=226 
3774: loss=0.384, reward_mean=0.320, reward_bound=0.387, batch=225 
3775: loss=0.385, reward_mean=0.380, reward_bound=0.365, batch=227 
3776: loss=0.384, reward_mean=0.350, reward_bound=0.387, batch=228 
3777: loss=0.384, reward_mean=0.320, reward_bound=0.387, batch=228 
3778: loss=0.397, reward_mean=0.280, reward_bound=0.430, batch=116 
3779: loss=0.340, reward_mean=0.310, reward_bound=0.000, batch=147 
3780: loss=0.335, reward_mean=0.230, reward_bound=0.000, batch=170 
3781: loss=0.358, reward_mean=0.330, reward_bound=0.020, batch=188 
3782: loss=0.344, reward_mean=0.230, reward_bound=0.048, batch=201 
3783: loss=0.336, reward_mean=0.340, reward_bound=0.072, batch=210 
3784: loss=0.350, reward_mean=0.390, reward_bound=0.098, batch=215 
3785: loss=0.352, reward_mean=0.400, reward_bound=0.109, batch=231 
3786: loss=0.353, reward_mean=0.390, reward_bound=0.122, batch=226 
3787: loss=0.353, reward_mean=0.320, reward_bound=0.150, batch=224 
3788: loss=0.360, reward_mean=0.280, reward_bound=0.167, batch=225 
3789: loss=0.356, reward_mean=0.290, reward_bound=0.185, batch=222 
3790: loss=0.356, reward_mean=0.350, reward_bound=0.206, batch=232 
3791: loss=0.355, reward_mean=0.400, reward_bound=0.206, batch=244 
3792: loss=0.353, reward_mean=0.410, reward_bound=0.206, batch=234 
3793: loss=0.361, reward_mean=0.220, reward_bound=0.229, batch=225 
3794: loss=0.371, reward_mean=0.300, reward_bound=0.254, batch=210 
3795: loss=0.369, reward_mean=0.340, reward_bound=0.282, batch=200 
3796: loss=0.364, reward_mean=0.280, reward_bound=0.180, batch=210 
3797: loss=0.363, reward_mean=0.390, reward_bound=0.185, batch=216 
3798: loss=0.364, reward_mean=0.340, reward_bound=0.185, batch=220 
3799: loss=0.363, reward_mean=0.300, reward_bound=0.247, batch=224 
3800: loss=0.366, reward_mean=0.420, reward_bound=0.254, batch=222 
3801: loss=0.367, reward_mean=0.380, reward_bound=0.314, batch=204 
3802: loss=0.367, reward_mean=0.420, reward_bound=0.254, batch=212 
3803: loss=0.366, reward_mean=0.330, reward_bound=0.314, batch=215 
3804: loss=0.360, reward_mean=0.360, reward_bound=0.314, batch=219 
3805: loss=0.360, reward_mean=0.380, reward_bound=0.314, batch=220 
3806: loss=0.365, reward_mean=0.340, reward_bound=0.329, batch=224 
3807: loss=0.369, reward_mean=0.340, reward_bound=0.349, batch=199 
3808: loss=0.366, reward_mean=0.330, reward_bound=0.185, batch=207 
3809: loss=0.367, reward_mean=0.340, reward_bound=0.206, batch=214 
3810: loss=0.364, reward_mean=0.400, reward_bound=0.254, batch=219 
3811: loss=0.374, reward_mean=0.370, reward_bound=0.282, batch=217 
3812: loss=0.368, reward_mean=0.380, reward_bound=0.314, batch=217 
3813: loss=0.367, reward_mean=0.280, reward_bound=0.254, batch=221 
3814: loss=0.365, reward_mean=0.370, reward_bound=0.282, batch=223 
3815: loss=0.368, reward_mean=0.300, reward_bound=0.271, batch=226 
3816: loss=0.369, reward_mean=0.360, reward_bound=0.298, batch=228 
3817: loss=0.365, reward_mean=0.380, reward_bound=0.349, batch=224 
3818: loss=0.378, reward_mean=0.370, reward_bound=0.387, batch=188 
3819: loss=0.372, reward_mean=0.330, reward_bound=0.138, batch=201 
3820: loss=0.367, reward_mean=0.290, reward_bound=0.167, batch=209 
3821: loss=0.371, reward_mean=0.250, reward_bound=0.206, batch=213 
3822: loss=0.376, reward_mean=0.320, reward_bound=0.244, batch=219 
3823: loss=0.375, reward_mean=0.370, reward_bound=0.254, batch=219 
3824: loss=0.379, reward_mean=0.330, reward_bound=0.282, batch=221 
3825: loss=0.382, reward_mean=0.290, reward_bound=0.314, batch=217 
3826: loss=0.380, reward_mean=0.290, reward_bound=0.342, batch=222 
3827: loss=0.379, reward_mean=0.350, reward_bound=0.263, batch=225 
3828: loss=0.378, reward_mean=0.370, reward_bound=0.349, batch=217 
3829: loss=0.378, reward_mean=0.370, reward_bound=0.282, batch=220 
3830: loss=0.376, reward_mean=0.310, reward_bound=0.296, batch=224 
3831: loss=0.373, reward_mean=0.360, reward_bound=0.314, batch=226 
3832: loss=0.373, reward_mean=0.380, reward_bound=0.349, batch=227 
3833: loss=0.374, reward_mean=0.390, reward_bound=0.349, batch=228 
3834: loss=0.374, reward_mean=0.320, reward_bound=0.353, batch=229 
3835: loss=0.379, reward_mean=0.310, reward_bound=0.387, batch=222 
3836: loss=0.378, reward_mean=0.280, reward_bound=0.387, batch=224 
3837: loss=0.378, reward_mean=0.250, reward_bound=0.426, batch=227 
3838: loss=0.378, reward_mean=0.290, reward_bound=0.314, batch=227 
3839: loss=0.386, reward_mean=0.340, reward_bound=0.430, batch=174 
3840: loss=0.380, reward_mean=0.290, reward_bound=0.097, batch=192 
3841: loss=0.383, reward_mean=0.440, reward_bound=0.150, batch=201 
3842: loss=0.379, reward_mean=0.360, reward_bound=0.206, batch=209 
3843: loss=0.377, reward_mean=0.290, reward_bound=0.229, batch=212 
3844: loss=0.374, reward_mean=0.320, reward_bound=0.254, batch=217 
3845: loss=0.381, reward_mean=0.370, reward_bound=0.282, batch=209 
3846: loss=0.383, reward_mean=0.350, reward_bound=0.314, batch=204 
3847: loss=0.380, reward_mean=0.420, reward_bound=0.183, batch=213 
3848: loss=0.377, reward_mean=0.420, reward_bound=0.254, batch=215 
3849: loss=0.379, reward_mean=0.340, reward_bound=0.282, batch=219 
3850: loss=0.380, reward_mean=0.210, reward_bound=0.278, batch=223 
3851: loss=0.377, reward_mean=0.210, reward_bound=0.314, batch=223 
3852: loss=0.390, reward_mean=0.300, reward_bound=0.349, batch=208 
3853: loss=0.389, reward_mean=0.280, reward_bound=0.173, batch=215 
3854: loss=0.388, reward_mean=0.380, reward_bound=0.387, batch=203 
3855: loss=0.398, reward_mean=0.400, reward_bound=0.282, batch=210 
3856: loss=0.392, reward_mean=0.400, reward_bound=0.338, batch=217 
3857: loss=0.393, reward_mean=0.280, reward_bound=0.342, batch=222 
3858: loss=0.392, reward_mean=0.370, reward_bound=0.272, batch=225 
3859: loss=0.395, reward_mean=0.330, reward_bound=0.356, batch=227 
3860: loss=0.394, reward_mean=0.330, reward_bound=0.387, batch=222 
3861: loss=0.392, reward_mean=0.400, reward_bound=0.282, batch=224 
3862: loss=0.393, reward_mean=0.290, reward_bound=0.345, batch=227 
3863: loss=0.394, reward_mean=0.210, reward_bound=0.380, batch=229 
3864: loss=0.388, reward_mean=0.340, reward_bound=0.430, batch=197 
3865: loss=0.382, reward_mean=0.320, reward_bound=0.224, batch=208 
3866: loss=0.384, reward_mean=0.400, reward_bound=0.282, batch=209 
3867: loss=0.381, reward_mean=0.280, reward_bound=0.174, batch=216 
3868: loss=0.380, reward_mean=0.340, reward_bound=0.229, batch=220 
3869: loss=0.388, reward_mean=0.340, reward_bound=0.304, batch=224 
3870: loss=0.383, reward_mean=0.310, reward_bound=0.314, batch=222 
3871: loss=0.385, reward_mean=0.260, reward_bound=0.349, batch=214 
3872: loss=0.383, reward_mean=0.350, reward_bound=0.252, batch=220 
3873: loss=0.388, reward_mean=0.370, reward_bound=0.274, batch=224 
3874: loss=0.387, reward_mean=0.270, reward_bound=0.314, batch=226 
3875: loss=0.381, reward_mean=0.340, reward_bound=0.349, batch=225 
3876: loss=0.383, reward_mean=0.320, reward_bound=0.387, batch=222 
3877: loss=0.387, reward_mean=0.400, reward_bound=0.387, batch=224 
3878: loss=0.384, reward_mean=0.320, reward_bound=0.384, batch=227 
3879: loss=0.384, reward_mean=0.340, reward_bound=0.314, batch=228 
3880: loss=0.386, reward_mean=0.480, reward_bound=0.387, batch=228 
3881: loss=0.391, reward_mean=0.260, reward_bound=0.430, batch=214 
3882: loss=0.391, reward_mean=0.370, reward_bound=0.384, batch=220 
3883: loss=0.392, reward_mean=0.310, reward_bound=0.387, batch=222 
3884: loss=0.389, reward_mean=0.270, reward_bound=0.360, batch=225 
3885: loss=0.389, reward_mean=0.280, reward_bound=0.396, batch=227 
3886: loss=0.395, reward_mean=0.470, reward_bound=0.430, batch=227 
3887: loss=0.395, reward_mean=0.250, reward_bound=0.469, batch=229 
3888: loss=0.394, reward_mean=0.270, reward_bound=0.401, batch=230 
3889: loss=0.394, reward_mean=0.330, reward_bound=0.430, batch=230 
3890: loss=0.393, reward_mean=0.340, reward_bound=0.378, batch=231 
3891: loss=0.347, reward_mean=0.400, reward_bound=0.478, batch=101 
3892: loss=0.315, reward_mean=0.240, reward_bound=0.000, batch=125 
3893: loss=0.295, reward_mean=0.300, reward_bound=0.000, batch=155 
3894: loss=0.287, reward_mean=0.290, reward_bound=0.003, batch=178 
3895: loss=0.300, reward_mean=0.310, reward_bound=0.021, batch=194 
3896: loss=0.287, reward_mean=0.390, reward_bound=0.052, batch=204 
3897: loss=0.285, reward_mean=0.340, reward_bound=0.080, batch=208 
3898: loss=0.307, reward_mean=0.370, reward_bound=0.109, batch=209 
3899: loss=0.307, reward_mean=0.330, reward_bound=0.135, batch=210 
3900: loss=0.307, reward_mean=0.340, reward_bound=0.150, batch=212 
3901: loss=0.315, reward_mean=0.340, reward_bound=0.167, batch=209 
3902: loss=0.318, reward_mean=0.330, reward_bound=0.185, batch=205 
3903: loss=0.313, reward_mean=0.380, reward_bound=0.206, batch=204 
3904: loss=0.308, reward_mean=0.240, reward_bound=0.182, batch=213 
3905: loss=0.315, reward_mean=0.380, reward_bound=0.229, batch=202 
3906: loss=0.310, reward_mean=0.300, reward_bound=0.229, batch=210 
3907: loss=0.308, reward_mean=0.390, reward_bound=0.254, batch=198 
3908: loss=0.309, reward_mean=0.370, reward_bound=0.257, batch=208 
3909: loss=0.310, reward_mean=0.340, reward_bound=0.282, batch=196 
3910: loss=0.308, reward_mean=0.330, reward_bound=0.158, batch=207 
3911: loss=0.305, reward_mean=0.360, reward_bound=0.249, batch=215 
3912: loss=0.312, reward_mean=0.420, reward_bound=0.282, batch=218 
3913: loss=0.327, reward_mean=0.400, reward_bound=0.314, batch=199 
3914: loss=0.320, reward_mean=0.380, reward_bound=0.182, batch=209 
3915: loss=0.323, reward_mean=0.380, reward_bound=0.229, batch=215 
3916: loss=0.322, reward_mean=0.290, reward_bound=0.254, batch=216 
3917: loss=0.325, reward_mean=0.400, reward_bound=0.314, batch=219 
3918: loss=0.324, reward_mean=0.310, reward_bound=0.265, batch=223 
3919: loss=0.324, reward_mean=0.340, reward_bound=0.301, batch=226 
3920: loss=0.326, reward_mean=0.390, reward_bound=0.349, batch=187 
3921: loss=0.312, reward_mean=0.330, reward_bound=0.097, batch=201 
3922: loss=0.315, reward_mean=0.320, reward_bound=0.122, batch=209 
3923: loss=0.308, reward_mean=0.360, reward_bound=0.157, batch=216 
3924: loss=0.312, reward_mean=0.510, reward_bound=0.241, batch=221 
3925: loss=0.309, reward_mean=0.250, reward_bound=0.206, batch=224 
3926: loss=0.307, reward_mean=0.400, reward_bound=0.254, batch=224 
3927: loss=0.310, reward_mean=0.340, reward_bound=0.282, batch=225 
3928: loss=0.311, reward_mean=0.380, reward_bound=0.314, batch=216 
3929: loss=0.308, reward_mean=0.300, reward_bound=0.254, batch=220 
3930: loss=0.309, reward_mean=0.270, reward_bound=0.222, batch=224 
3931: loss=0.309, reward_mean=0.440, reward_bound=0.314, batch=226 
3932: loss=0.313, reward_mean=0.350, reward_bound=0.349, batch=217 
3933: loss=0.314, reward_mean=0.350, reward_bound=0.224, batch=222 
3934: loss=0.316, reward_mean=0.400, reward_bound=0.282, batch=224 
3935: loss=0.317, reward_mean=0.240, reward_bound=0.345, batch=227 
3936: loss=0.315, reward_mean=0.280, reward_bound=0.330, batch=229 
3937: loss=0.315, reward_mean=0.310, reward_bound=0.254, batch=229 
3938: loss=0.314, reward_mean=0.340, reward_bound=0.349, batch=229 
3939: loss=0.342, reward_mean=0.330, reward_bound=0.387, batch=186 
3940: loss=0.332, reward_mean=0.350, reward_bound=0.150, batch=199 
3941: loss=0.334, reward_mean=0.330, reward_bound=0.185, batch=208 
3942: loss=0.332, reward_mean=0.330, reward_bound=0.156, batch=215 
3943: loss=0.336, reward_mean=0.370, reward_bound=0.229, batch=216 
3944: loss=0.334, reward_mean=0.210, reward_bound=0.254, batch=220 
3945: loss=0.327, reward_mean=0.340, reward_bound=0.282, batch=221 
3946: loss=0.331, reward_mean=0.340, reward_bound=0.314, batch=214 
3947: loss=0.335, reward_mean=0.360, reward_bound=0.349, batch=213 
3948: loss=0.333, reward_mean=0.390, reward_bound=0.254, batch=218 
3949: loss=0.335, reward_mean=0.320, reward_bound=0.282, batch=220 
3950: loss=0.344, reward_mean=0.280, reward_bound=0.282, batch=223 
3951: loss=0.345, reward_mean=0.350, reward_bound=0.335, batch=226 
3952: loss=0.340, reward_mean=0.300, reward_bound=0.349, batch=225 
3953: loss=0.343, reward_mean=0.400, reward_bound=0.387, batch=217 
3954: loss=0.343, reward_mean=0.340, reward_bound=0.277, batch=222 
3955: loss=0.340, reward_mean=0.270, reward_bound=0.292, batch=225 
3956: loss=0.342, reward_mean=0.290, reward_bound=0.387, batch=226 
3957: loss=0.339, reward_mean=0.330, reward_bound=0.368, batch=228 
3958: loss=0.342, reward_mean=0.340, reward_bound=0.387, batch=226 
3959: loss=0.341, reward_mean=0.250, reward_bound=0.368, batch=228 
3960: loss=0.342, reward_mean=0.340, reward_bound=0.387, batch=228 
3961: loss=0.342, reward_mean=0.250, reward_bound=0.387, batch=228 
3962: loss=0.337, reward_mean=0.350, reward_bound=0.430, batch=176 
3963: loss=0.322, reward_mean=0.290, reward_bound=0.061, batch=193 
3964: loss=0.336, reward_mean=0.280, reward_bound=0.105, batch=205 
3965: loss=0.326, reward_mean=0.280, reward_bound=0.112, batch=213 
3966: loss=0.334, reward_mean=0.270, reward_bound=0.130, batch=219 
3967: loss=0.329, reward_mean=0.390, reward_bound=0.185, batch=217 
3968: loss=0.323, reward_mean=0.300, reward_bound=0.195, batch=222 
3969: loss=0.319, reward_mean=0.330, reward_bound=0.206, batch=229 
3970: loss=0.316, reward_mean=0.380, reward_bound=0.206, batch=229 
3971: loss=0.314, reward_mean=0.410, reward_bound=0.229, batch=223 
3972: loss=0.316, reward_mean=0.430, reward_bound=0.254, batch=223 
3973: loss=0.317, reward_mean=0.350, reward_bound=0.282, batch=218 
3974: loss=0.325, reward_mean=0.430, reward_bound=0.314, batch=208 
3975: loss=0.319, reward_mean=0.280, reward_bound=0.314, batch=213 
3976: loss=0.327, reward_mean=0.440, reward_bound=0.349, batch=208 
3977: loss=0.322, reward_mean=0.290, reward_bound=0.257, batch=215 
3978: loss=0.318, reward_mean=0.310, reward_bound=0.216, batch=220 
3979: loss=0.321, reward_mean=0.320, reward_bound=0.314, batch=219 
3980: loss=0.322, reward_mean=0.410, reward_bound=0.254, batch=222 
3981: loss=0.319, reward_mean=0.420, reward_bound=0.314, batch=222 
3982: loss=0.317, reward_mean=0.320, reward_bound=0.314, batch=224 
3983: loss=0.317, reward_mean=0.350, reward_bound=0.349, batch=224 
3984: loss=0.318, reward_mean=0.380, reward_bound=0.345, batch=227 
3985: loss=0.321, reward_mean=0.380, reward_bound=0.387, batch=215 
3986: loss=0.322, reward_mean=0.420, reward_bound=0.396, batch=220 
3987: loss=0.321, reward_mean=0.390, reward_bound=0.282, batch=223 
3988: loss=0.319, reward_mean=0.320, reward_bound=0.372, batch=226 
3989: loss=0.320, reward_mean=0.320, reward_bound=0.331, batch=228 
3990: loss=0.317, reward_mean=0.360, reward_bound=0.353, batch=229 
3991: loss=0.318, reward_mean=0.290, reward_bound=0.387, batch=228 
3992: loss=0.318, reward_mean=0.370, reward_bound=0.392, batch=229 
3993: loss=0.317, reward_mean=0.350, reward_bound=0.309, batch=230 
3994: loss=0.317, reward_mean=0.380, reward_bound=0.418, batch=231 
3995: loss=0.332, reward_mean=0.270, reward_bound=0.430, batch=202 
3996: loss=0.329, reward_mean=0.390, reward_bound=0.213, batch=211 
3997: loss=0.329, reward_mean=0.400, reward_bound=0.229, batch=216 
3998: loss=0.329, reward_mean=0.310, reward_bound=0.282, batch=215 
3999: loss=0.326, reward_mean=0.310, reward_bound=0.260, batch=220 
4000: loss=0.333, reward_mean=0.390, reward_bound=0.314, batch=223 
4001: loss=0.335, reward_mean=0.330, reward_bound=0.335, batch=226 
4002: loss=0.335, reward_mean=0.360, reward_bound=0.349, batch=218 
4003: loss=0.331, reward_mean=0.310, reward_bound=0.257, batch=222 
4004: loss=0.337, reward_mean=0.320, reward_bound=0.314, batch=223 
4005: loss=0.337, reward_mean=0.290, reward_bound=0.349, batch=225 
4006: loss=0.333, reward_mean=0.400, reward_bound=0.387, batch=218 
4007: loss=0.333, reward_mean=0.410, reward_bound=0.349, batch=221 
4008: loss=0.332, reward_mean=0.340, reward_bound=0.349, batch=223 
4009: loss=0.332, reward_mean=0.340, reward_bound=0.349, batch=225 
4010: loss=0.333, reward_mean=0.320, reward_bound=0.356, batch=227 
4011: loss=0.331, reward_mean=0.400, reward_bound=0.387, batch=227 
4012: loss=0.330, reward_mean=0.330, reward_bound=0.308, batch=229 
4013: loss=0.333, reward_mean=0.350, reward_bound=0.364, batch=230 
4014: loss=0.329, reward_mean=0.320, reward_bound=0.430, batch=218 
4015: loss=0.326, reward_mean=0.370, reward_bound=0.392, batch=222 
4016: loss=0.328, reward_mean=0.390, reward_bound=0.400, batch=225 
4017: loss=0.328, reward_mean=0.310, reward_bound=0.396, batch=227 
4018: loss=0.328, reward_mean=0.350, reward_bound=0.422, batch=229 
4019: loss=0.328, reward_mean=0.290, reward_bound=0.430, batch=229 
4020: loss=0.327, reward_mean=0.380, reward_bound=0.478, batch=231 
4021: loss=0.349, reward_mean=0.330, reward_bound=0.478, batch=155 
4022: loss=0.306, reward_mean=0.380, reward_bound=0.041, batch=178 
4023: loss=0.313, reward_mean=0.360, reward_bound=0.066, batch=194 
4024: loss=0.322, reward_mean=0.380, reward_bound=0.097, batch=206 
4025: loss=0.326, reward_mean=0.310, reward_bound=0.098, batch=212 
4026: loss=0.325, reward_mean=0.290, reward_bound=0.135, batch=217 
4027: loss=0.322, reward_mean=0.380, reward_bound=0.185, batch=216 
4028: loss=0.334, reward_mean=0.410, reward_bound=0.229, batch=215 
4029: loss=0.332, reward_mean=0.320, reward_bound=0.254, batch=216 
4030: loss=0.329, reward_mean=0.370, reward_bound=0.282, batch=211 
4031: loss=0.327, reward_mean=0.270, reward_bound=0.282, batch=216 
4032: loss=0.327, reward_mean=0.320, reward_bound=0.314, batch=200 
4033: loss=0.314, reward_mean=0.310, reward_bound=0.206, batch=211 
4034: loss=0.313, reward_mean=0.370, reward_bound=0.206, batch=217 
4035: loss=0.313, reward_mean=0.380, reward_bound=0.229, batch=220 
4036: loss=0.319, reward_mean=0.300, reward_bound=0.254, batch=221 
4037: loss=0.320, reward_mean=0.290, reward_bound=0.282, batch=219 
4038: loss=0.316, reward_mean=0.400, reward_bound=0.295, batch=223 
4039: loss=0.332, reward_mean=0.360, reward_bound=0.349, batch=202 
4040: loss=0.329, reward_mean=0.280, reward_bound=0.254, batch=207 
4041: loss=0.332, reward_mean=0.370, reward_bound=0.282, batch=212 
4042: loss=0.330, reward_mean=0.410, reward_bound=0.236, batch=218 
4043: loss=0.329, reward_mean=0.410, reward_bound=0.254, batch=220 
4044: loss=0.322, reward_mean=0.350, reward_bound=0.304, batch=224 
4045: loss=0.323, reward_mean=0.360, reward_bound=0.314, batch=220 
4046: loss=0.322, reward_mean=0.290, reward_bound=0.282, batch=223 
4047: loss=0.321, reward_mean=0.340, reward_bound=0.314, batch=224 
4048: loss=0.319, reward_mean=0.340, reward_bound=0.349, batch=223 
4049: loss=0.325, reward_mean=0.400, reward_bound=0.387, batch=199 
4050: loss=0.323, reward_mean=0.280, reward_bound=0.215, batch=209 
4051: loss=0.315, reward_mean=0.360, reward_bound=0.215, batch=216 
4052: loss=0.319, reward_mean=0.390, reward_bound=0.282, batch=218 
4053: loss=0.318, reward_mean=0.270, reward_bound=0.282, batch=221 
4054: loss=0.317, reward_mean=0.370, reward_bound=0.282, batch=224 
4055: loss=0.315, reward_mean=0.340, reward_bound=0.314, batch=225 
4056: loss=0.313, reward_mean=0.430, reward_bound=0.349, batch=216 
4057: loss=0.311, reward_mean=0.350, reward_bound=0.351, batch=221 
4058: loss=0.309, reward_mean=0.320, reward_bound=0.282, batch=224 
4059: loss=0.314, reward_mean=0.330, reward_bound=0.384, batch=227 
4060: loss=0.314, reward_mean=0.410, reward_bound=0.342, batch=229 
4061: loss=0.317, reward_mean=0.380, reward_bound=0.387, batch=217 
4062: loss=0.318, reward_mean=0.370, reward_bound=0.380, batch=222 
4063: loss=0.318, reward_mean=0.320, reward_bound=0.387, batch=223 
4064: loss=0.316, reward_mean=0.330, reward_bound=0.349, batch=225 
4065: loss=0.315, reward_mean=0.300, reward_bound=0.321, batch=227 
4066: loss=0.319, reward_mean=0.390, reward_bound=0.380, batch=229 
4067: loss=0.318, reward_mean=0.360, reward_bound=0.387, batch=228 
4068: loss=0.318, reward_mean=0.360, reward_bound=0.357, batch=229 
4069: loss=0.333, reward_mean=0.320, reward_bound=0.430, batch=200 
4070: loss=0.323, reward_mean=0.420, reward_bound=0.206, batch=211 
4071: loss=0.326, reward_mean=0.370, reward_bound=0.206, batch=216 
4072: loss=0.315, reward_mean=0.430, reward_bound=0.229, batch=220 
4073: loss=0.317, reward_mean=0.380, reward_bound=0.282, batch=220 
4074: loss=0.318, reward_mean=0.390, reward_bound=0.314, batch=218 
4075: loss=0.315, reward_mean=0.350, reward_bound=0.257, batch=222 
4076: loss=0.314, reward_mean=0.380, reward_bound=0.292, batch=225 
4077: loss=0.320, reward_mean=0.360, reward_bound=0.349, batch=221 
4078: loss=0.331, reward_mean=0.380, reward_bound=0.387, batch=212 
4079: loss=0.326, reward_mean=0.370, reward_bound=0.283, batch=218 
4080: loss=0.321, reward_mean=0.310, reward_bound=0.286, batch=222 
4081: loss=0.326, reward_mean=0.400, reward_bound=0.314, batch=224 
4082: loss=0.325, reward_mean=0.400, reward_bound=0.349, batch=225 
4083: loss=0.328, reward_mean=0.330, reward_bound=0.387, batch=221 
4084: loss=0.328, reward_mean=0.420, reward_bound=0.254, batch=224 
4085: loss=0.329, reward_mean=0.300, reward_bound=0.314, batch=226 
4086: loss=0.328, reward_mean=0.340, reward_bound=0.349, batch=226 
4087: loss=0.329, reward_mean=0.320, reward_bound=0.331, batch=228 
4088: loss=0.327, reward_mean=0.410, reward_bound=0.387, batch=228 
4089: loss=0.328, reward_mean=0.390, reward_bound=0.430, batch=217 
4090: loss=0.323, reward_mean=0.330, reward_bound=0.206, batch=221 
4091: loss=0.326, reward_mean=0.310, reward_bound=0.282, batch=223 
4092: loss=0.326, reward_mean=0.330, reward_bound=0.322, batch=226 
4093: loss=0.326, reward_mean=0.320, reward_bound=0.349, batch=227 
4094: loss=0.325, reward_mean=0.330, reward_bound=0.380, batch=229 
4095: loss=0.324, reward_mean=0.340, reward_bound=0.364, batch=230 
4096: loss=0.329, reward_mean=0.390, reward_bound=0.387, batch=228 
4097: loss=0.327, reward_mean=0.400, reward_bound=0.430, batch=223 
4098: loss=0.323, reward_mean=0.340, reward_bound=0.301, batch=226 
4099: loss=0.327, reward_mean=0.350, reward_bound=0.331, batch=228 
4100: loss=0.328, reward_mean=0.370, reward_bound=0.349, batch=228 
4101: loss=0.326, reward_mean=0.350, reward_bound=0.387, batch=226 
4102: loss=0.326, reward_mean=0.390, reward_bound=0.349, batch=227 
4103: loss=0.327, reward_mean=0.310, reward_bound=0.430, batch=227 
4104: loss=0.328, reward_mean=0.410, reward_bound=0.430, batch=228 
4105: loss=0.327, reward_mean=0.290, reward_bound=0.397, batch=229 
4106: loss=0.327, reward_mean=0.370, reward_bound=0.430, batch=229 
4107: loss=0.327, reward_mean=0.310, reward_bound=0.424, batch=230 
4108: loss=0.340, reward_mean=0.250, reward_bound=0.478, batch=189 
4109: loss=0.332, reward_mean=0.350, reward_bound=0.122, batch=201 
4110: loss=0.322, reward_mean=0.410, reward_bound=0.167, batch=210 
4111: loss=0.325, reward_mean=0.370, reward_bound=0.247, batch=217 
4112: loss=0.326, reward_mean=0.350, reward_bound=0.254, batch=218 
4113: loss=0.325, reward_mean=0.330, reward_bound=0.254, batch=221 
4114: loss=0.329, reward_mean=0.240, reward_bound=0.282, batch=217 
4115: loss=0.327, reward_mean=0.220, reward_bound=0.277, batch=222 
4116: loss=0.324, reward_mean=0.340, reward_bound=0.314, batch=222 
4117: loss=0.328, reward_mean=0.280, reward_bound=0.349, batch=217 
4118: loss=0.330, reward_mean=0.390, reward_bound=0.380, batch=222 
4119: loss=0.328, reward_mean=0.320, reward_bound=0.360, batch=225 
4120: loss=0.335, reward_mean=0.340, reward_bound=0.387, batch=216 
4121: loss=0.334, reward_mean=0.330, reward_bound=0.298, batch=221 
4122: loss=0.334, reward_mean=0.400, reward_bound=0.314, batch=222 
4123: loss=0.334, reward_mean=0.340, reward_bound=0.292, batch=225 
4124: loss=0.334, reward_mean=0.410, reward_bound=0.314, batch=226 
4125: loss=0.333, reward_mean=0.320, reward_bound=0.387, batch=227 
4126: loss=0.333, reward_mean=0.320, reward_bound=0.387, batch=228 
4127: loss=0.335, reward_mean=0.330, reward_bound=0.430, batch=215 
4128: loss=0.334, reward_mean=0.310, reward_bound=0.314, batch=219 
4129: loss=0.332, reward_mean=0.340, reward_bound=0.295, batch=223 
4130: loss=0.333, reward_mean=0.340, reward_bound=0.314, batch=225 
4131: loss=0.334, reward_mean=0.370, reward_bound=0.349, batch=226 
4132: loss=0.334, reward_mean=0.330, reward_bound=0.368, batch=228 
4133: loss=0.333, reward_mean=0.340, reward_bound=0.353, batch=229 
4134: loss=0.335, reward_mean=0.380, reward_bound=0.387, batch=226 
4135: loss=0.336, reward_mean=0.410, reward_bound=0.368, batch=228 
4136: loss=0.336, reward_mean=0.360, reward_bound=0.392, batch=229 
4137: loss=0.335, reward_mean=0.410, reward_bound=0.430, batch=223 
4138: loss=0.334, reward_mean=0.380, reward_bound=0.335, batch=226 
4139: loss=0.340, reward_mean=0.350, reward_bound=0.430, batch=227 
4140: loss=0.340, reward_mean=0.350, reward_bound=0.430, batch=228 
4141: loss=0.339, reward_mean=0.370, reward_bound=0.478, batch=231 
4142: loss=0.339, reward_mean=0.400, reward_bound=0.478, batch=213 
4143: loss=0.339, reward_mean=0.360, reward_bound=0.220, batch=219 
4144: loss=0.336, reward_mean=0.360, reward_bound=0.328, batch=223 
4145: loss=0.334, reward_mean=0.370, reward_bound=0.349, batch=222 
4146: loss=0.332, reward_mean=0.300, reward_bound=0.314, batch=224 
4147: loss=0.336, reward_mean=0.420, reward_bound=0.387, batch=225 
4148: loss=0.340, reward_mean=0.300, reward_bound=0.430, batch=220 
4149: loss=0.338, reward_mean=0.310, reward_bound=0.274, batch=224 
4150: loss=0.340, reward_mean=0.300, reward_bound=0.282, batch=225 
4151: loss=0.342, reward_mean=0.330, reward_bound=0.349, batch=224 
4152: loss=0.341, reward_mean=0.270, reward_bound=0.345, batch=227 
4153: loss=0.342, reward_mean=0.380, reward_bound=0.387, batch=227 
4154: loss=0.341, reward_mean=0.290, reward_bound=0.414, batch=229 
4155: loss=0.341, reward_mean=0.370, reward_bound=0.430, batch=228 
4156: loss=0.341, reward_mean=0.270, reward_bound=0.430, batch=228 
4157: loss=0.343, reward_mean=0.240, reward_bound=0.353, batch=229 
4158: loss=0.341, reward_mean=0.330, reward_bound=0.450, batch=230 
4159: loss=0.341, reward_mean=0.400, reward_bound=0.418, batch=231 
4160: loss=0.343, reward_mean=0.360, reward_bound=0.478, batch=220 
4161: loss=0.345, reward_mean=0.300, reward_bound=0.338, batch=224 
4162: loss=0.346, reward_mean=0.300, reward_bound=0.345, batch=227 
4163: loss=0.344, reward_mean=0.420, reward_bound=0.349, batch=228 
4164: loss=0.343, reward_mean=0.360, reward_bound=0.353, batch=229 
4165: loss=0.343, reward_mean=0.270, reward_bound=0.387, batch=228 
4166: loss=0.344, reward_mean=0.240, reward_bound=0.430, batch=222 
4167: loss=0.341, reward_mean=0.360, reward_bound=0.236, batch=225 
4168: loss=0.343, reward_mean=0.330, reward_bound=0.349, batch=226 
4169: loss=0.343, reward_mean=0.380, reward_bound=0.387, batch=224 
4170: loss=0.343, reward_mean=0.280, reward_bound=0.387, batch=226 
4171: loss=0.342, reward_mean=0.390, reward_bound=0.387, batch=227 
4172: loss=0.340, reward_mean=0.430, reward_bound=0.469, batch=229 
4173: loss=0.339, reward_mean=0.270, reward_bound=0.324, batch=230 
4174: loss=0.340, reward_mean=0.300, reward_bound=0.387, batch=230 
4175: loss=0.339, reward_mean=0.400, reward_bound=0.418, batch=231 
4176: loss=0.340, reward_mean=0.350, reward_bound=0.478, batch=224 
4177: loss=0.340, reward_mean=0.340, reward_bound=0.282, batch=226 
4178: loss=0.341, reward_mean=0.350, reward_bound=0.349, batch=227 
4179: loss=0.339, reward_mean=0.370, reward_bound=0.422, batch=229 
4180: loss=0.340, reward_mean=0.360, reward_bound=0.430, batch=229 
4181: loss=0.340, reward_mean=0.410, reward_bound=0.381, batch=230 
4182: loss=0.339, reward_mean=0.340, reward_bound=0.418, batch=231 
4183: loss=0.340, reward_mean=0.380, reward_bound=0.430, batch=229 
4184: loss=0.338, reward_mean=0.350, reward_bound=0.424, batch=230 
4185: loss=0.341, reward_mean=0.360, reward_bound=0.478, batch=227 
4186: loss=0.342, reward_mean=0.390, reward_bound=0.511, batch=229 
4187: loss=0.342, reward_mean=0.320, reward_bound=0.445, batch=230 
4188: loss=0.342, reward_mean=0.350, reward_bound=0.430, batch=230 
4190: loss=0.232, reward_mean=0.320, reward_bound=0.000, batch=32 
4191: loss=0.227, reward_mean=0.320, reward_bound=0.000, batch=64 
4192: loss=0.227, reward_mean=0.360, reward_bound=0.000, batch=100 
4193: loss=0.223, reward_mean=0.320, reward_bound=0.000, batch=132 
4194: loss=0.220, reward_mean=0.310, reward_bound=0.000, batch=162 
4195: loss=0.221, reward_mean=0.280, reward_bound=0.001, batch=182 
4196: loss=0.234, reward_mean=0.330, reward_bound=0.008, batch=196 
4197: loss=0.234, reward_mean=0.380, reward_bound=0.026, batch=207 
4198: loss=0.237, reward_mean=0.320, reward_bound=0.038, batch=208 
4199: loss=0.245, reward_mean=0.340, reward_bound=0.047, batch=217 
4200: loss=0.248, reward_mean=0.370, reward_bound=0.058, batch=224 
4201: loss=0.240, reward_mean=0.480, reward_bound=0.080, batch=219 
4202: loss=0.239, reward_mean=0.420, reward_bound=0.098, batch=221 
4203: loss=0.238, reward_mean=0.390, reward_bound=0.122, batch=213 
4204: loss=0.243, reward_mean=0.320, reward_bound=0.135, batch=203 
4205: loss=0.244, reward_mean=0.370, reward_bound=0.150, batch=200 
4206: loss=0.247, reward_mean=0.440, reward_bound=0.167, batch=189 
4207: loss=0.249, reward_mean=0.380, reward_bound=0.109, batch=201 
4208: loss=0.246, reward_mean=0.470, reward_bound=0.150, batch=208 
4209: loss=0.254, reward_mean=0.330, reward_bound=0.185, batch=190 
4210: loss=0.252, reward_mean=0.350, reward_bound=0.180, batch=203 
4211: loss=0.253, reward_mean=0.350, reward_bound=0.206, batch=188 
4212: loss=0.256, reward_mean=0.360, reward_bound=0.154, batch=201 
4213: loss=0.252, reward_mean=0.420, reward_bound=0.206, batch=209 
4214: loss=0.261, reward_mean=0.420, reward_bound=0.229, batch=179 
4215: loss=0.253, reward_mean=0.430, reward_bound=0.109, batch=194 
4216: loss=0.255, reward_mean=0.500, reward_bound=0.150, batch=202 
4217: loss=0.261, reward_mean=0.450, reward_bound=0.213, batch=211 
4218: loss=0.265, reward_mean=0.300, reward_bound=0.206, batch=217 
4219: loss=0.265, reward_mean=0.390, reward_bound=0.229, batch=221 
4220: loss=0.267, reward_mean=0.360, reward_bound=0.254, batch=190 
4221: loss=0.260, reward_mean=0.380, reward_bound=0.135, batch=202 
4222: loss=0.260, reward_mean=0.380, reward_bound=0.185, batch=210 
4223: loss=0.260, reward_mean=0.320, reward_bound=0.206, batch=218 
4224: loss=0.262, reward_mean=0.400, reward_bound=0.206, batch=221 
4225: loss=0.257, reward_mean=0.340, reward_bound=0.282, batch=184 
4226: loss=0.255, reward_mean=0.510, reward_bound=0.223, batch=199 
4227: loss=0.255, reward_mean=0.330, reward_bound=0.229, batch=206 
4228: loss=0.261, reward_mean=0.360, reward_bound=0.254, batch=208 
4229: loss=0.260, reward_mean=0.380, reward_bound=0.257, batch=215 
4230: loss=0.260, reward_mean=0.430, reward_bound=0.282, batch=217 
4231: loss=0.259, reward_mean=0.460, reward_bound=0.224, batch=222 
4232: loss=0.259, reward_mean=0.450, reward_bound=0.282, batch=224 
4233: loss=0.273, reward_mean=0.410, reward_bound=0.314, batch=172 
4234: loss=0.261, reward_mean=0.350, reward_bound=0.074, batch=190 
4235: loss=0.255, reward_mean=0.380, reward_bound=0.089, batch=202 
4236: loss=0.260, reward_mean=0.300, reward_bound=0.150, batch=209 
4237: loss=0.264, reward_mean=0.470, reward_bound=0.185, batch=215 
4238: loss=0.272, reward_mean=0.430, reward_bound=0.206, batch=219 
4239: loss=0.274, reward_mean=0.360, reward_bound=0.229, batch=218 
4240: loss=0.267, reward_mean=0.440, reward_bound=0.254, batch=215 
4241: loss=0.269, reward_mean=0.380, reward_bound=0.282, batch=218 
4242: loss=0.260, reward_mean=0.420, reward_bound=0.314, batch=208 
4243: loss=0.260, reward_mean=0.340, reward_bound=0.254, batch=214 
4244: loss=0.264, reward_mean=0.430, reward_bound=0.314, batch=219 
4245: loss=0.262, reward_mean=0.310, reward_bound=0.265, batch=223 
4246: loss=0.266, reward_mean=0.410, reward_bound=0.314, batch=224 
4247: loss=0.264, reward_mean=0.360, reward_bound=0.311, batch=227 
4248: loss=0.266, reward_mean=0.340, reward_bound=0.342, batch=229 
4249: loss=0.277, reward_mean=0.300, reward_bound=0.349, batch=170 
4250: loss=0.269, reward_mean=0.320, reward_bound=0.046, batch=189 
4251: loss=0.260, reward_mean=0.390, reward_bound=0.080, batch=201 
4252: loss=0.258, reward_mean=0.340, reward_bound=0.098, batch=207 
4253: loss=0.257, reward_mean=0.420, reward_bound=0.135, batch=213 
4254: loss=0.265, reward_mean=0.380, reward_bound=0.167, batch=218 
4255: loss=0.263, reward_mean=0.390, reward_bound=0.185, batch=216 
4256: loss=0.263, reward_mean=0.360, reward_bound=0.206, batch=217 
4257: loss=0.268, reward_mean=0.400, reward_bound=0.229, batch=217 
4258: loss=0.271, reward_mean=0.390, reward_bound=0.254, batch=218 
4259: loss=0.277, reward_mean=0.370, reward_bound=0.282, batch=209 
4260: loss=0.276, reward_mean=0.470, reward_bound=0.314, batch=211 
4261: loss=0.276, reward_mean=0.310, reward_bound=0.167, batch=217 
4262: loss=0.282, reward_mean=0.380, reward_bound=0.302, batch=222 
4263: loss=0.277, reward_mean=0.460, reward_bound=0.324, batch=225 
4264: loss=0.274, reward_mean=0.420, reward_bound=0.349, batch=213 
4265: loss=0.274, reward_mean=0.360, reward_bound=0.282, batch=218 
4266: loss=0.273, reward_mean=0.340, reward_bound=0.229, batch=219 
4267: loss=0.273, reward_mean=0.450, reward_bound=0.349, batch=221 
4268: loss=0.274, reward_mean=0.390, reward_bound=0.349, batch=223 
4269: loss=0.274, reward_mean=0.320, reward_bound=0.358, batch=226 
4270: loss=0.264, reward_mean=0.390, reward_bound=0.387, batch=156 
4271: loss=0.250, reward_mean=0.370, reward_bound=0.040, batch=179 
4272: loss=0.244, reward_mean=0.390, reward_bound=0.061, batch=195 
4273: loss=0.247, reward_mean=0.370, reward_bound=0.122, batch=205 
4274: loss=0.249, reward_mean=0.320, reward_bound=0.135, batch=212 
4275: loss=0.248, reward_mean=0.510, reward_bound=0.185, batch=213 
4276: loss=0.249, reward_mean=0.380, reward_bound=0.229, batch=208 
4277: loss=0.250, reward_mean=0.390, reward_bound=0.254, batch=204 
4278: loss=0.249, reward_mean=0.380, reward_bound=0.252, batch=213 
4279: loss=0.255, reward_mean=0.460, reward_bound=0.282, batch=210 
4280: loss=0.255, reward_mean=0.360, reward_bound=0.274, batch=217 
4281: loss=0.265, reward_mean=0.370, reward_bound=0.314, batch=205 
4282: loss=0.265, reward_mean=0.370, reward_bound=0.167, batch=212 
4283: loss=0.261, reward_mean=0.360, reward_bound=0.236, batch=218 
4284: loss=0.257, reward_mean=0.400, reward_bound=0.286, batch=222 
4285: loss=0.262, reward_mean=0.420, reward_bound=0.314, batch=219 
4286: loss=0.268, reward_mean=0.440, reward_bound=0.349, batch=206 
4287: loss=0.270, reward_mean=0.470, reward_bound=0.298, batch=214 
4288: loss=0.269, reward_mean=0.400, reward_bound=0.282, batch=219 
4289: loss=0.268, reward_mean=0.380, reward_bound=0.314, batch=221 
4290: loss=0.273, reward_mean=0.460, reward_bound=0.349, batch=218 
4291: loss=0.275, reward_mean=0.360, reward_bound=0.321, batch=222 
4292: loss=0.275, reward_mean=0.370, reward_bound=0.360, batch=225 
4293: loss=0.271, reward_mean=0.440, reward_bound=0.387, batch=203 
4294: loss=0.264, reward_mean=0.450, reward_bound=0.229, batch=211 
4295: loss=0.259, reward_mean=0.330, reward_bound=0.229, batch=217 
4296: loss=0.259, reward_mean=0.410, reward_bound=0.254, batch=221 
4297: loss=0.260, reward_mean=0.330, reward_bound=0.282, batch=222 
4298: loss=0.258, reward_mean=0.280, reward_bound=0.314, batch=223 
4299: loss=0.264, reward_mean=0.440, reward_bound=0.349, batch=217 
4300: loss=0.270, reward_mean=0.420, reward_bound=0.387, batch=212 
4301: loss=0.265, reward_mean=0.350, reward_bound=0.236, batch=218 
4302: loss=0.269, reward_mean=0.370, reward_bound=0.314, batch=217 
4303: loss=0.267, reward_mean=0.400, reward_bound=0.349, batch=220 
4304: loss=0.267, reward_mean=0.410, reward_bound=0.376, batch=224 
4305: loss=0.264, reward_mean=0.370, reward_bound=0.345, batch=227 
4306: loss=0.268, reward_mean=0.330, reward_bound=0.387, batch=223 
4307: loss=0.270, reward_mean=0.360, reward_bound=0.387, batch=225 
4308: loss=0.278, reward_mean=0.330, reward_bound=0.430, batch=123 
4309: loss=0.239, reward_mean=0.390, reward_bound=0.008, batch=156 
4310: loss=0.234, reward_mean=0.480, reward_bound=0.052, batch=178 
4311: loss=0.236, reward_mean=0.440, reward_bound=0.080, batch=192 
4312: loss=0.243, reward_mean=0.460, reward_bound=0.098, batch=198 
4313: loss=0.237, reward_mean=0.410, reward_bound=0.109, batch=207 
4314: loss=0.239, reward_mean=0.450, reward_bound=0.135, batch=212 
4315: loss=0.240, reward_mean=0.360, reward_bound=0.150, batch=217 
4316: loss=0.252, reward_mean=0.290, reward_bound=0.167, batch=219 
4317: loss=0.253, reward_mean=0.380, reward_bound=0.185, batch=215 
4318: loss=0.250, reward_mean=0.350, reward_bound=0.206, batch=214 
4319: loss=0.249, reward_mean=0.400, reward_bound=0.229, batch=216 
4320: loss=0.259, reward_mean=0.350, reward_bound=0.254, batch=207 
4321: loss=0.253, reward_mean=0.330, reward_bound=0.185, batch=214 
4322: loss=0.254, reward_mean=0.360, reward_bound=0.252, batch=220 
4323: loss=0.256, reward_mean=0.350, reward_bound=0.282, batch=198 
4324: loss=0.249, reward_mean=0.330, reward_bound=0.206, batch=207 
4325: loss=0.248, reward_mean=0.450, reward_bound=0.229, batch=214 
4326: loss=0.253, reward_mean=0.430, reward_bound=0.280, batch=220 
4327: loss=0.251, reward_mean=0.380, reward_bound=0.282, batch=223 
4328: loss=0.261, reward_mean=0.350, reward_bound=0.314, batch=208 
4329: loss=0.260, reward_mean=0.350, reward_bound=0.257, batch=215 
4330: loss=0.265, reward_mean=0.450, reward_bound=0.282, batch=219 
4331: loss=0.257, reward_mean=0.470, reward_bound=0.349, batch=206 
4332: loss=0.249, reward_mean=0.260, reward_bound=0.168, batch=214 
4333: loss=0.245, reward_mean=0.300, reward_bound=0.204, batch=220 
4334: loss=0.247, reward_mean=0.360, reward_bound=0.247, batch=224 
4335: loss=0.249, reward_mean=0.330, reward_bound=0.254, batch=221 
4336: loss=0.252, reward_mean=0.440, reward_bound=0.254, batch=224 
4337: loss=0.253, reward_mean=0.390, reward_bound=0.282, batch=223 
4338: loss=0.251, reward_mean=0.350, reward_bound=0.314, batch=223 
4339: loss=0.253, reward_mean=0.480, reward_bound=0.349, batch=217 
4340: loss=0.250, reward_mean=0.340, reward_bound=0.267, batch=222 
4341: loss=0.254, reward_mean=0.340, reward_bound=0.282, batch=224 
4342: loss=0.256, reward_mean=0.390, reward_bound=0.349, batch=226 
4343: loss=0.263, reward_mean=0.400, reward_bound=0.387, batch=201 
4344: loss=0.262, reward_mean=0.450, reward_bound=0.282, batch=210 
4345: loss=0.260, reward_mean=0.400, reward_bound=0.338, batch=217 
4346: loss=0.258, reward_mean=0.290, reward_bound=0.342, batch=222 
4347: loss=0.261, reward_mean=0.390, reward_bound=0.349, batch=222 
4348: loss=0.259, reward_mean=0.360, reward_bound=0.360, batch=225 
4349: loss=0.258, reward_mean=0.400, reward_bound=0.356, batch=227 
4350: loss=0.265, reward_mean=0.320, reward_bound=0.387, batch=222 
4351: loss=0.267, reward_mean=0.450, reward_bound=0.314, batch=225 
4352: loss=0.266, reward_mean=0.350, reward_bound=0.387, batch=225 
4353: loss=0.266, reward_mean=0.460, reward_bound=0.356, batch=227 
4354: loss=0.270, reward_mean=0.340, reward_bound=0.380, batch=229 
4355: loss=0.271, reward_mean=0.320, reward_bound=0.387, batch=228 
4356: loss=0.271, reward_mean=0.360, reward_bound=0.325, batch=229 
4357: loss=0.287, reward_mean=0.390, reward_bound=0.430, batch=173 
4358: loss=0.287, reward_mean=0.320, reward_bound=0.085, batch=191 
4359: loss=0.289, reward_mean=0.380, reward_bound=0.109, batch=203 
4360: loss=0.287, reward_mean=0.430, reward_bound=0.150, batch=211 
4361: loss=0.283, reward_mean=0.380, reward_bound=0.206, batch=214 
4362: loss=0.284, reward_mean=0.340, reward_bound=0.229, batch=214 
4363: loss=0.285, reward_mean=0.330, reward_bound=0.252, batch=220 
4364: loss=0.280, reward_mean=0.510, reward_bound=0.254, batch=220 
4365: loss=0.279, reward_mean=0.340, reward_bound=0.240, batch=224 
4366: loss=0.274, reward_mean=0.340, reward_bound=0.282, batch=220 
4367: loss=0.272, reward_mean=0.370, reward_bound=0.222, batch=224 
4368: loss=0.275, reward_mean=0.390, reward_bound=0.311, batch=227 
4369: loss=0.277, reward_mean=0.430, reward_bound=0.314, batch=213 
4370: loss=0.282, reward_mean=0.460, reward_bound=0.349, batch=204 
4371: loss=0.279, reward_mean=0.380, reward_bound=0.314, batch=210 
4372: loss=0.277, reward_mean=0.310, reward_bound=0.254, batch=216 
4373: loss=0.276, reward_mean=0.360, reward_bound=0.314, batch=218 
4374: loss=0.275, reward_mean=0.340, reward_bound=0.349, batch=221 
4375: loss=0.274, reward_mean=0.400, reward_bound=0.349, batch=223 
4376: loss=0.273, reward_mean=0.380, reward_bound=0.358, batch=226 
4377: loss=0.279, reward_mean=0.350, reward_bound=0.387, batch=214 
4378: loss=0.281, reward_mean=0.360, reward_bound=0.254, batch=219 
4379: loss=0.283, reward_mean=0.450, reward_bound=0.328, batch=223 
4380: loss=0.280, reward_mean=0.440, reward_bound=0.335, batch=226 
4381: loss=0.279, reward_mean=0.300, reward_bound=0.349, batch=225 
4382: loss=0.277, reward_mean=0.410, reward_bound=0.387, batch=225 
4383: loss=0.275, reward_mean=0.340, reward_bound=0.321, batch=227 
4384: loss=0.275, reward_mean=0.330, reward_bound=0.349, batch=227 
4385: loss=0.276, reward_mean=0.380, reward_bound=0.387, batch=228 
4386: loss=0.289, reward_mean=0.370, reward_bound=0.430, batch=198 
4387: loss=0.293, reward_mean=0.410, reward_bound=0.150, batch=207 
4388: loss=0.285, reward_mean=0.410, reward_bound=0.206, batch=213 
4389: loss=0.286, reward_mean=0.390, reward_bound=0.206, batch=218 
4390: loss=0.284, reward_mean=0.420, reward_bound=0.231, batch=222 
4391: loss=0.283, reward_mean=0.370, reward_bound=0.254, batch=223 
4392: loss=0.285, reward_mean=0.300, reward_bound=0.282, batch=222 
4393: loss=0.286, reward_mean=0.340, reward_bound=0.314, batch=218 
4394: loss=0.289, reward_mean=0.420, reward_bound=0.349, batch=218 
4395: loss=0.289, reward_mean=0.360, reward_bound=0.317, batch=222 
4396: loss=0.288, reward_mean=0.300, reward_bound=0.349, batch=224 
4397: loss=0.289, reward_mean=0.410, reward_bound=0.387, batch=220 
4398: loss=0.286, reward_mean=0.370, reward_bound=0.296, batch=224 
4399: loss=0.288, reward_mean=0.480, reward_bound=0.349, batch=225 
4400: loss=0.288, reward_mean=0.400, reward_bound=0.396, batch=227 
4401: loss=0.290, reward_mean=0.360, reward_bound=0.308, batch=229 
4402: loss=0.287, reward_mean=0.380, reward_bound=0.405, batch=230 
4403: loss=0.289, reward_mean=0.360, reward_bound=0.430, batch=219 
4404: loss=0.290, reward_mean=0.320, reward_bound=0.295, batch=223 
4405: loss=0.287, reward_mean=0.330, reward_bound=0.314, batch=225 
4406: loss=0.285, reward_mean=0.320, reward_bound=0.349, batch=226 
4407: loss=0.284, reward_mean=0.440, reward_bound=0.387, batch=226 
4408: loss=0.283, reward_mean=0.360, reward_bound=0.372, batch=228 
4409: loss=0.286, reward_mean=0.340, reward_bound=0.430, batch=228 
4410: loss=0.285, reward_mean=0.420, reward_bound=0.397, batch=229 
4411: loss=0.284, reward_mean=0.420, reward_bound=0.424, batch=230 
4412: loss=0.283, reward_mean=0.350, reward_bound=0.439, batch=231 
4413: loss=0.311, reward_mean=0.390, reward_bound=0.478, batch=98 
4414: loss=0.225, reward_mean=0.330, reward_bound=0.000, batch=131 
4415: loss=0.223, reward_mean=0.540, reward_bound=0.012, batch=160 
4416: loss=0.217, reward_mean=0.350, reward_bound=0.026, batch=182 
4417: loss=0.230, reward_mean=0.420, reward_bound=0.047, batch=192 
4418: loss=0.231, reward_mean=0.340, reward_bound=0.058, batch=202 
4419: loss=0.238, reward_mean=0.450, reward_bound=0.080, batch=210 
4420: loss=0.249, reward_mean=0.400, reward_bound=0.109, batch=205 
4421: loss=0.254, reward_mean=0.390, reward_bound=0.135, batch=206 
4422: loss=0.245, reward_mean=0.430, reward_bound=0.150, batch=212 
4423: loss=0.249, reward_mean=0.380, reward_bound=0.167, batch=209 
4424: loss=0.251, reward_mean=0.410, reward_bound=0.167, batch=215 
4425: loss=0.240, reward_mean=0.400, reward_bound=0.185, batch=214 
4426: loss=0.247, reward_mean=0.290, reward_bound=0.206, batch=206 
4427: loss=0.251, reward_mean=0.450, reward_bound=0.229, batch=204 
4428: loss=0.253, reward_mean=0.380, reward_bound=0.254, batch=189 
4429: loss=0.253, reward_mean=0.350, reward_bound=0.150, batch=199 
4430: loss=0.248, reward_mean=0.320, reward_bound=0.109, batch=208 
4431: loss=0.255, reward_mean=0.420, reward_bound=0.169, batch=215 
4432: loss=0.258, reward_mean=0.340, reward_bound=0.185, batch=219 
4433: loss=0.261, reward_mean=0.350, reward_bound=0.215, batch=223 
4434: loss=0.258, reward_mean=0.330, reward_bound=0.254, batch=222 
4435: loss=0.269, reward_mean=0.310, reward_bound=0.282, batch=203 
4436: loss=0.267, reward_mean=0.320, reward_bound=0.211, batch=212 
4437: loss=0.267, reward_mean=0.420, reward_bound=0.236, batch=218 
4438: loss=0.267, reward_mean=0.450, reward_bound=0.254, batch=220 
4439: loss=0.263, reward_mean=0.290, reward_bound=0.222, batch=224 
4440: loss=0.263, reward_mean=0.370, reward_bound=0.282, batch=226 
4441: loss=0.276, reward_mean=0.360, reward_bound=0.314, batch=198 
4442: loss=0.273, reward_mean=0.360, reward_bound=0.169, batch=208 
4443: loss=0.271, reward_mean=0.430, reward_bound=0.185, batch=214 
4444: loss=0.273, reward_mean=0.360, reward_bound=0.254, batch=219 
4445: loss=0.272, reward_mean=0.440, reward_bound=0.282, batch=217 
4446: loss=0.274, reward_mean=0.410, reward_bound=0.277, batch=222 
4447: loss=0.275, reward_mean=0.390, reward_bound=0.236, batch=225 
4448: loss=0.277, reward_mean=0.360, reward_bound=0.314, batch=223 
4449: loss=0.274, reward_mean=0.340, reward_bound=0.349, batch=198 
4450: loss=0.268, reward_mean=0.350, reward_bound=0.208, batch=208 
4451: loss=0.276, reward_mean=0.390, reward_bound=0.229, batch=214 
4452: loss=0.279, reward_mean=0.450, reward_bound=0.229, batch=218 
4453: loss=0.277, reward_mean=0.350, reward_bound=0.282, batch=216 
4454: loss=0.276, reward_mean=0.410, reward_bound=0.314, batch=219 
4455: loss=0.275, reward_mean=0.400, reward_bound=0.295, batch=223 
4456: loss=0.273, reward_mean=0.330, reward_bound=0.314, batch=224 
4457: loss=0.272, reward_mean=0.400, reward_bound=0.342, batch=227 
4458: loss=0.274, reward_mean=0.420, reward_bound=0.349, batch=225 
4459: loss=0.273, reward_mean=0.370, reward_bound=0.321, batch=227 
4460: loss=0.273, reward_mean=0.430, reward_bound=0.349, batch=228 
4461: loss=0.286, reward_mean=0.360, reward_bound=0.387, batch=171 
4462: loss=0.268, reward_mean=0.460, reward_bound=0.150, batch=188 
4463: loss=0.266, reward_mean=0.360, reward_bound=0.135, batch=200 
4464: loss=0.267, reward_mean=0.400, reward_bound=0.185, batch=202 
4465: loss=0.258, reward_mean=0.400, reward_bound=0.206, batch=216 
4466: loss=0.266, reward_mean=0.370, reward_bound=0.206, batch=217 
4467: loss=0.271, reward_mean=0.460, reward_bound=0.229, batch=218 
4468: loss=0.282, reward_mean=0.450, reward_bound=0.254, batch=211 
4469: loss=0.286, reward_mean=0.390, reward_bound=0.282, batch=202 
4470: loss=0.283, reward_mean=0.420, reward_bound=0.263, batch=211 
4471: loss=0.285, reward_mean=0.350, reward_bound=0.282, batch=214 
4472: loss=0.282, reward_mean=0.350, reward_bound=0.254, batch=218 
4473: loss=0.287, reward_mean=0.340, reward_bound=0.282, batch=220 
4474: loss=0.287, reward_mean=0.340, reward_bound=0.282, batch=223 
4475: loss=0.287, reward_mean=0.390, reward_bound=0.314, batch=218 
4476: loss=0.285, reward_mean=0.380, reward_bound=0.257, batch=222 
4477: loss=0.283, reward_mean=0.310, reward_bound=0.324, batch=225 
4478: loss=0.286, reward_mean=0.330, reward_bound=0.349, batch=210 
4479: loss=0.288, reward_mean=0.380, reward_bound=0.376, batch=217 
4480: loss=0.285, reward_mean=0.360, reward_bound=0.249, batch=222 
4481: loss=0.286, reward_mean=0.450, reward_bound=0.282, batch=223 
4482: loss=0.287, reward_mean=0.400, reward_bound=0.301, batch=226 
4483: loss=0.290, reward_mean=0.440, reward_bound=0.349, batch=227 
4484: loss=0.289, reward_mean=0.340, reward_bound=0.387, batch=206 
4485: loss=0.287, reward_mean=0.350, reward_bound=0.241, batch=214 
4486: loss=0.290, reward_mean=0.450, reward_bound=0.345, batch=220 
4487: loss=0.286, reward_mean=0.360, reward_bound=0.296, batch=224 
4488: loss=0.286, reward_mean=0.340, reward_bound=0.254, batch=226 
4489: loss=0.284, reward_mean=0.330, reward_bound=0.298, batch=228 
4490: loss=0.284, reward_mean=0.400, reward_bound=0.349, batch=227 
4491: loss=0.284, reward_mean=0.460, reward_bound=0.349, batch=228 
4492: loss=0.282, reward_mean=0.370, reward_bound=0.387, batch=221 
4493: loss=0.281, reward_mean=0.390, reward_bound=0.387, batch=224 
4494: loss=0.281, reward_mean=0.350, reward_bound=0.349, batch=226 
4495: loss=0.295, reward_mean=0.430, reward_bound=0.430, batch=179 
4496: loss=0.296, reward_mean=0.410, reward_bound=0.150, batch=194 
4497: loss=0.293, reward_mean=0.350, reward_bound=0.167, batch=204 
4498: loss=0.288, reward_mean=0.400, reward_bound=0.204, batch=213 
4499: loss=0.292, reward_mean=0.380, reward_bound=0.206, batch=213 
4500: loss=0.288, reward_mean=0.380, reward_bound=0.167, batch=218 
4501: loss=0.286, reward_mean=0.360, reward_bound=0.229, batch=219 
4502: loss=0.289, reward_mean=0.360, reward_bound=0.254, batch=219 
4503: loss=0.287, reward_mean=0.360, reward_bound=0.254, batch=222 
4504: loss=0.287, reward_mean=0.370, reward_bound=0.236, batch=225 
4505: loss=0.292, reward_mean=0.370, reward_bound=0.282, batch=224 
4506: loss=0.296, reward_mean=0.320, reward_bound=0.314, batch=214 
4507: loss=0.295, reward_mean=0.330, reward_bound=0.314, batch=219 
4508: loss=0.295, reward_mean=0.310, reward_bound=0.349, batch=211 
4509: loss=0.292, reward_mean=0.340, reward_bound=0.282, batch=217 
4510: loss=0.293, reward_mean=0.350, reward_bound=0.314, batch=219 
4511: loss=0.291, reward_mean=0.390, reward_bound=0.215, batch=223 
4512: loss=0.293, reward_mean=0.450, reward_bound=0.282, batch=225 
4513: loss=0.292, reward_mean=0.320, reward_bound=0.314, batch=226 
4514: loss=0.294, reward_mean=0.400, reward_bound=0.349, batch=224 
4515: loss=0.292, reward_mean=0.370, reward_bound=0.384, batch=227 
4516: loss=0.292, reward_mean=0.370, reward_bound=0.349, batch=228 
4517: loss=0.296, reward_mean=0.310, reward_bound=0.387, batch=212 
4518: loss=0.295, reward_mean=0.380, reward_bound=0.360, batch=218 
4519: loss=0.292, reward_mean=0.440, reward_bound=0.286, batch=222 
4520: loss=0.289, reward_mean=0.260, reward_bound=0.220, batch=225 
4521: loss=0.291, reward_mean=0.340, reward_bound=0.254, batch=226 
4522: loss=0.290, reward_mean=0.430, reward_bound=0.368, batch=228 
4523: loss=0.291, reward_mean=0.440, reward_bound=0.387, batch=227 
4524: loss=0.294, reward_mean=0.300, reward_bound=0.422, batch=229 
4525: loss=0.293, reward_mean=0.400, reward_bound=0.405, batch=230 
4526: loss=0.291, reward_mean=0.410, reward_bound=0.430, batch=208 
4527: loss=0.289, reward_mean=0.370, reward_bound=0.314, batch=214 
4528: loss=0.289, reward_mean=0.410, reward_bound=0.349, batch=216 
4529: loss=0.291, reward_mean=0.350, reward_bound=0.349, batch=220 
4530: loss=0.291, reward_mean=0.390, reward_bound=0.314, batch=223 
4531: loss=0.289, reward_mean=0.270, reward_bound=0.282, batch=225 
4532: loss=0.291, reward_mean=0.340, reward_bound=0.356, batch=227 
4533: loss=0.287, reward_mean=0.390, reward_bound=0.387, batch=221 
4534: loss=0.288, reward_mean=0.430, reward_bound=0.430, batch=221 
4535: loss=0.286, reward_mean=0.390, reward_bound=0.349, batch=224 
4536: loss=0.287, reward_mean=0.320, reward_bound=0.384, batch=227 
4537: loss=0.287, reward_mean=0.370, reward_bound=0.430, batch=225 
4538: loss=0.285, reward_mean=0.360, reward_bound=0.440, batch=227 
4539: loss=0.285, reward_mean=0.460, reward_bound=0.380, batch=229 
4540: loss=0.286, reward_mean=0.280, reward_bound=0.387, batch=229 
4541: loss=0.285, reward_mean=0.440, reward_bound=0.478, batch=231 
4542: loss=0.287, reward_mean=0.360, reward_bound=0.478, batch=147 
4543: loss=0.273, reward_mean=0.440, reward_bound=0.087, batch=173 
4544: loss=0.263, reward_mean=0.470, reward_bound=0.117, batch=191 
4545: loss=0.255, reward_mean=0.360, reward_bound=0.135, batch=203 
4546: loss=0.248, reward_mean=0.380, reward_bound=0.167, batch=210 
4547: loss=0.252, reward_mean=0.410, reward_bound=0.206, batch=218 
4548: loss=0.259, reward_mean=0.350, reward_bound=0.206, batch=214 
4549: loss=0.261, reward_mean=0.330, reward_bound=0.226, batch=220 
4550: loss=0.259, reward_mean=0.420, reward_bound=0.229, batch=214 
4551: loss=0.267, reward_mean=0.390, reward_bound=0.254, batch=212 
4552: loss=0.272, reward_mean=0.370, reward_bound=0.282, batch=205 
4553: loss=0.274, reward_mean=0.460, reward_bound=0.260, batch=213 
4554: loss=0.275, reward_mean=0.380, reward_bound=0.244, batch=219 
4555: loss=0.272, reward_mean=0.400, reward_bound=0.265, batch=223 
4556: loss=0.266, reward_mean=0.390, reward_bound=0.282, batch=221 
4557: loss=0.271, reward_mean=0.330, reward_bound=0.314, batch=198 
4558: loss=0.270, reward_mean=0.430, reward_bound=0.254, batch=207 
4559: loss=0.270, reward_mean=0.330, reward_bound=0.202, batch=215 
4560: loss=0.262, reward_mean=0.410, reward_bound=0.206, batch=219 
4561: loss=0.266, reward_mean=0.360, reward_bound=0.295, batch=223 
4562: loss=0.264, reward_mean=0.390, reward_bound=0.314, batch=221 
4563: loss=0.264, reward_mean=0.330, reward_bound=0.314, batch=222 
4564: loss=0.266, reward_mean=0.350, reward_bound=0.324, batch=225 
4565: loss=0.270, reward_mean=0.310, reward_bound=0.349, batch=208 
4566: loss=0.269, reward_mean=0.370, reward_bound=0.286, batch=215 
4567: loss=0.264, reward_mean=0.410, reward_bound=0.314, batch=219 
4568: loss=0.273, reward_mean=0.370, reward_bound=0.387, batch=192 
4569: loss=0.263, reward_mean=0.370, reward_bound=0.119, batch=204 
4570: loss=0.271, reward_mean=0.360, reward_bound=0.185, batch=211 
4571: loss=0.274, reward_mean=0.410, reward_bound=0.229, batch=217 
4572: loss=0.267, reward_mean=0.390, reward_bound=0.254, batch=220 
4573: loss=0.269, reward_mean=0.480, reward_bound=0.282, batch=221 
4574: loss=0.275, reward_mean=0.350, reward_bound=0.314, batch=215 
4575: loss=0.277, reward_mean=0.360, reward_bound=0.349, batch=211 
4576: loss=0.275, reward_mean=0.350, reward_bound=0.167, batch=217 
4577: loss=0.273, reward_mean=0.410, reward_bound=0.277, batch=222 
4578: loss=0.272, reward_mean=0.390, reward_bound=0.314, batch=223 
4579: loss=0.274, reward_mean=0.360, reward_bound=0.322, batch=226 
4580: loss=0.276, reward_mean=0.450, reward_bound=0.349, batch=226 
4581: loss=0.276, reward_mean=0.320, reward_bound=0.368, batch=228 
4582: loss=0.275, reward_mean=0.410, reward_bound=0.353, batch=229 
4583: loss=0.274, reward_mean=0.450, reward_bound=0.387, batch=217 
4584: loss=0.272, reward_mean=0.350, reward_bound=0.282, batch=220 
4585: loss=0.270, reward_mean=0.460, reward_bound=0.288, batch=224 
4586: loss=0.268, reward_mean=0.320, reward_bound=0.280, batch=227 
4587: loss=0.271, reward_mean=0.350, reward_bound=0.342, batch=229 
4588: loss=0.273, reward_mean=0.340, reward_bound=0.387, batch=224 
4589: loss=0.273, reward_mean=0.400, reward_bound=0.380, batch=227 
4590: loss=0.273, reward_mean=0.400, reward_bound=0.387, batch=227 
4591: loss=0.281, reward_mean=0.420, reward_bound=0.430, batch=194 
4592: loss=0.270, reward_mean=0.380, reward_bound=0.204, batch=206 
4593: loss=0.261, reward_mean=0.370, reward_bound=0.206, batch=213 
4594: loss=0.263, reward_mean=0.430, reward_bound=0.229, batch=218 
4595: loss=0.267, reward_mean=0.340, reward_bound=0.282, batch=219 
4596: loss=0.274, reward_mean=0.400, reward_bound=0.314, batch=215 
4597: loss=0.272, reward_mean=0.410, reward_bound=0.229, batch=219 
4598: loss=0.269, reward_mean=0.380, reward_bound=0.282, batch=222 
4599: loss=0.271, reward_mean=0.370, reward_bound=0.349, batch=218 
4600: loss=0.272, reward_mean=0.340, reward_bound=0.353, batch=222 
4601: loss=0.270, reward_mean=0.350, reward_bound=0.282, batch=224 
4602: loss=0.270, reward_mean=0.400, reward_bound=0.223, batch=227 
4603: loss=0.274, reward_mean=0.530, reward_bound=0.349, batch=226 
4604: loss=0.278, reward_mean=0.330, reward_bound=0.387, batch=223 
4605: loss=0.277, reward_mean=0.430, reward_bound=0.335, batch=226 
4606: loss=0.274, reward_mean=0.350, reward_bound=0.387, batch=227 
4607: loss=0.281, reward_mean=0.290, reward_bound=0.430, batch=210 
4608: loss=0.275, reward_mean=0.290, reward_bound=0.254, batch=216 
4609: loss=0.276, reward_mean=0.370, reward_bound=0.282, batch=220 
4610: loss=0.277, reward_mean=0.340, reward_bound=0.314, batch=223 
4611: loss=0.275, reward_mean=0.280, reward_bound=0.282, batch=225 
4612: loss=0.275, reward_mean=0.410, reward_bound=0.356, batch=227 
4613: loss=0.277, reward_mean=0.410, reward_bound=0.387, batch=226 
4614: loss=0.275, reward_mean=0.380, reward_bound=0.390, batch=228 
4615: loss=0.275, reward_mean=0.280, reward_bound=0.321, batch=229 
4616: loss=0.279, reward_mean=0.420, reward_bound=0.430, batch=222 
4617: loss=0.279, reward_mean=0.370, reward_bound=0.302, batch=225 
4618: loss=0.278, reward_mean=0.340, reward_bound=0.349, batch=224 
4619: loss=0.276, reward_mean=0.430, reward_bound=0.380, batch=227 
4620: loss=0.277, reward_mean=0.440, reward_bound=0.387, batch=226 
4621: loss=0.275, reward_mean=0.420, reward_bound=0.351, batch=228 
4622: loss=0.275, reward_mean=0.330, reward_bound=0.392, batch=229 
4623: loss=0.277, reward_mean=0.430, reward_bound=0.381, batch=230 
4624: loss=0.277, reward_mean=0.440, reward_bound=0.406, batch=231 
4625: loss=0.281, reward_mean=0.410, reward_bound=0.430, batch=227 
4626: loss=0.280, reward_mean=0.380, reward_bound=0.469, batch=229 
4627: loss=0.283, reward_mean=0.340, reward_bound=0.401, batch=230 
4628: loss=0.283, reward_mean=0.390, reward_bound=0.349, batch=230 
4629: loss=0.283, reward_mean=0.330, reward_bound=0.387, batch=230 
4630: loss=0.282, reward_mean=0.520, reward_bound=0.439, batch=231 
4631: loss=0.282, reward_mean=0.360, reward_bound=0.430, batch=231 
4632: loss=0.287, reward_mean=0.380, reward_bound=0.478, batch=187 
4633: loss=0.283, reward_mean=0.460, reward_bound=0.167, batch=200 
4634: loss=0.280, reward_mean=0.400, reward_bound=0.162, batch=210 
4635: loss=0.273, reward_mean=0.450, reward_bound=0.185, batch=214 
4636: loss=0.274, reward_mean=0.400, reward_bound=0.206, batch=217 
4637: loss=0.274, reward_mean=0.300, reward_bound=0.229, batch=219 
4638: loss=0.282, reward_mean=0.360, reward_bound=0.282, batch=217 
4639: loss=0.281, reward_mean=0.360, reward_bound=0.308, batch=222 
4640: loss=0.279, reward_mean=0.380, reward_bound=0.272, batch=225 
4641: loss=0.274, reward_mean=0.360, reward_bound=0.314, batch=218 
4642: loss=0.271, reward_mean=0.360, reward_bound=0.286, batch=222 
4643: loss=0.272, reward_mean=0.350, reward_bound=0.314, batch=223 
4644: loss=0.274, reward_mean=0.340, reward_bound=0.301, batch=226 
4645: loss=0.285, reward_mean=0.350, reward_bound=0.349, batch=214 
4646: loss=0.284, reward_mean=0.400, reward_bound=0.252, batch=220 
4647: loss=0.280, reward_mean=0.400, reward_bound=0.314, batch=222 
4648: loss=0.283, reward_mean=0.370, reward_bound=0.360, batch=225 
4649: loss=0.285, reward_mean=0.470, reward_bound=0.356, batch=227 
4650: loss=0.290, reward_mean=0.370, reward_bound=0.387, batch=214 
4651: loss=0.289, reward_mean=0.300, reward_bound=0.254, batch=218 
4652: loss=0.290, reward_mean=0.350, reward_bound=0.286, batch=222 
4653: loss=0.288, reward_mean=0.360, reward_bound=0.263, batch=225 
4654: loss=0.289, reward_mean=0.330, reward_bound=0.314, batch=224 
4655: loss=0.286, reward_mean=0.340, reward_bound=0.349, batch=225 
4656: loss=0.285, reward_mean=0.380, reward_bound=0.356, batch=227 
4657: loss=0.284, reward_mean=0.360, reward_bound=0.380, batch=229 
4658: loss=0.285, reward_mean=0.400, reward_bound=0.387, batch=224 
4659: loss=0.285, reward_mean=0.370, reward_bound=0.384, batch=227 
4660: loss=0.285, reward_mean=0.320, reward_bound=0.349, batch=227 
4661: loss=0.279, reward_mean=0.370, reward_bound=0.430, batch=210 
4662: loss=0.280, reward_mean=0.420, reward_bound=0.296, batch=217 
4663: loss=0.277, reward_mean=0.340, reward_bound=0.314, batch=221 
4664: loss=0.274, reward_mean=0.400, reward_bound=0.349, batch=224 
4665: loss=0.277, reward_mean=0.460, reward_bound=0.387, batch=223 
4666: loss=0.277, reward_mean=0.400, reward_bound=0.358, batch=226 
4667: loss=0.276, reward_mean=0.390, reward_bound=0.351, batch=228 
4668: loss=0.277, reward_mean=0.360, reward_bound=0.387, batch=228 
4669: loss=0.278, reward_mean=0.430, reward_bound=0.430, batch=223 
4670: loss=0.277, reward_mean=0.340, reward_bound=0.314, batch=225 
4671: loss=0.280, reward_mean=0.390, reward_bound=0.478, batch=206 
4672: loss=0.272, reward_mean=0.410, reward_bound=0.268, batch=214 
4673: loss=0.268, reward_mean=0.370, reward_bound=0.254, batch=219 
4674: loss=0.267, reward_mean=0.410, reward_bound=0.282, batch=222 
4675: loss=0.278, reward_mean=0.320, reward_bound=0.314, batch=221 
4676: loss=0.279, reward_mean=0.450, reward_bound=0.349, batch=222 
4677: loss=0.279, reward_mean=0.400, reward_bound=0.349, batch=224 
4678: loss=0.283, reward_mean=0.300, reward_bound=0.345, batch=227 
4679: loss=0.281, reward_mean=0.320, reward_bound=0.349, batch=228 
4680: loss=0.280, reward_mean=0.440, reward_bound=0.353, batch=229 
4681: loss=0.282, reward_mean=0.480, reward_bound=0.387, batch=226 
4682: loss=0.280, reward_mean=0.370, reward_bound=0.390, batch=228 
4683: loss=0.278, reward_mean=0.350, reward_bound=0.430, batch=219 
4684: loss=0.280, reward_mean=0.410, reward_bound=0.349, batch=222 
4685: loss=0.279, reward_mean=0.440, reward_bound=0.314, batch=223 
4686: loss=0.281, reward_mean=0.380, reward_bound=0.335, batch=226 
4687: loss=0.283, reward_mean=0.340, reward_bound=0.331, batch=228 
4688: loss=0.281, reward_mean=0.380, reward_bound=0.387, batch=225 
4689: loss=0.281, reward_mean=0.370, reward_bound=0.396, batch=227 
4690: loss=0.280, reward_mean=0.370, reward_bound=0.430, batch=227 
4691: loss=0.280, reward_mean=0.460, reward_bound=0.430, batch=227 
4692: loss=0.279, reward_mean=0.370, reward_bound=0.469, batch=229 
4693: loss=0.279, reward_mean=0.410, reward_bound=0.405, batch=230 
4694: loss=0.279, reward_mean=0.320, reward_bound=0.430, batch=229 
4695: loss=0.281, reward_mean=0.430, reward_bound=0.450, batch=230 
4696: loss=0.278, reward_mean=0.350, reward_bound=0.478, batch=216 
4697: loss=0.278, reward_mean=0.460, reward_bound=0.314, batch=220 
4698: loss=0.276, reward_mean=0.470, reward_bound=0.349, batch=222 
4699: loss=0.274, reward_mean=0.350, reward_bound=0.314, batch=224 
4700: loss=0.273, reward_mean=0.430, reward_bound=0.345, batch=227 
4701: loss=0.275, reward_mean=0.340, reward_bound=0.349, batch=228 
4702: loss=0.275, reward_mean=0.410, reward_bound=0.387, batch=226 
4703: loss=0.273, reward_mean=0.360, reward_bound=0.372, batch=228 
4704: loss=0.273, reward_mean=0.350, reward_bound=0.357, batch=229 
4705: loss=0.271, reward_mean=0.420, reward_bound=0.364, batch=230 
4706: loss=0.270, reward_mean=0.510, reward_bound=0.365, batch=231 
4707: loss=0.274, reward_mean=0.320, reward_bound=0.387, batch=231 
4708: loss=0.276, reward_mean=0.360, reward_bound=0.430, batch=227 
4709: loss=0.279, reward_mean=0.330, reward_bound=0.414, batch=229 
4710: loss=0.279, reward_mean=0.310, reward_bound=0.405, batch=230 
4711: loss=0.276, reward_mean=0.390, reward_bound=0.430, batch=229 
4712: loss=0.275, reward_mean=0.390, reward_bound=0.424, batch=230 
4713: loss=0.275, reward_mean=0.400, reward_bound=0.464, batch=231 
4714: loss=0.275, reward_mean=0.330, reward_bound=0.430, batch=231 
4715: loss=0.274, reward_mean=0.440, reward_bound=0.478, batch=226 
4716: loss=0.274, reward_mean=0.340, reward_bound=0.351, batch=228 
4717: loss=0.274, reward_mean=0.430, reward_bound=0.353, batch=229 
4718: loss=0.275, reward_mean=0.330, reward_bound=0.343, batch=230 
4719: loss=0.275, reward_mean=0.370, reward_bound=0.376, batch=231 
4720: loss=0.273, reward_mean=0.370, reward_bound=0.387, batch=230 
4721: loss=0.272, reward_mean=0.390, reward_bound=0.464, batch=231 
4722: loss=0.274, reward_mean=0.360, reward_bound=0.478, batch=228 
4723: loss=0.274, reward_mean=0.290, reward_bound=0.349, batch=228 
4724: loss=0.274, reward_mean=0.430, reward_bound=0.435, batch=229 
4725: loss=0.272, reward_mean=0.370, reward_bound=0.328, batch=230 
4726: loss=0.274, reward_mean=0.440, reward_bound=0.515, batch=231 
4727: loss=0.274, reward_mean=0.380, reward_bound=0.478, batch=231 
4728: loss=0.274, reward_mean=0.390, reward_bound=0.478, batch=231 
4729: loss=0.274, reward_mean=0.370, reward_bound=0.430, batch=231 
4730: loss=0.274, reward_mean=0.410, reward_bound=0.478, batch=231 
4731: loss=0.274, reward_mean=0.370, reward_bound=0.478, batch=231 
4733: loss=0.192, reward_mean=0.370, reward_bound=0.000, batch=37 
4734: loss=0.187, reward_mean=0.460, reward_bound=0.000, batch=83 
4735: loss=0.176, reward_mean=0.450, reward_bound=0.000, batch=128 
4736: loss=0.178, reward_mean=0.370, reward_bound=0.001, batch=159 
4737: loss=0.183, reward_mean=0.420, reward_bound=0.004, batch=180 
4738: loss=0.185, reward_mean=0.390, reward_bound=0.014, batch=196 
4739: loss=0.205, reward_mean=0.410, reward_bound=0.025, batch=202 
4740: loss=0.203, reward_mean=0.480, reward_bound=0.038, batch=207 
4741: loss=0.208, reward_mean=0.390, reward_bound=0.052, batch=211 
4742: loss=0.216, reward_mean=0.450, reward_bound=0.065, batch=215 
4743: loss=0.211, reward_mean=0.390, reward_bound=0.082, batch=220 
4744: loss=0.221, reward_mean=0.430, reward_bound=0.098, batch=203 
4745: loss=0.217, reward_mean=0.440, reward_bound=0.109, batch=210 
4746: loss=0.216, reward_mean=0.410, reward_bound=0.122, batch=214 
4747: loss=0.213, reward_mean=0.470, reward_bound=0.149, batch=220 
4748: loss=0.212, reward_mean=0.470, reward_bound=0.150, batch=208 
4749: loss=0.216, reward_mean=0.400, reward_bound=0.167, batch=205 
4750: loss=0.211, reward_mean=0.350, reward_bound=0.185, batch=184 
4751: loss=0.212, reward_mean=0.400, reward_bound=0.109, batch=197 
4752: loss=0.215, reward_mean=0.370, reward_bound=0.163, batch=208 
4753: loss=0.213, reward_mean=0.420, reward_bound=0.185, batch=210 
4754: loss=0.213, reward_mean=0.380, reward_bound=0.206, batch=222 
4755: loss=0.213, reward_mean=0.380, reward_bound=0.206, batch=234 
4756: loss=0.220, reward_mean=0.430, reward_bound=0.206, batch=218 
4757: loss=0.217, reward_mean=0.460, reward_bound=0.229, batch=194 
4758: loss=0.213, reward_mean=0.440, reward_bound=0.183, batch=206 
4759: loss=0.212, reward_mean=0.380, reward_bound=0.150, batch=213 
4760: loss=0.215, reward_mean=0.450, reward_bound=0.206, batch=216 
4761: loss=0.213, reward_mean=0.450, reward_bound=0.241, batch=221 
4762: loss=0.220, reward_mean=0.390, reward_bound=0.254, batch=182 
4763: loss=0.217, reward_mean=0.390, reward_bound=0.206, batch=198 
4764: loss=0.213, reward_mean=0.370, reward_bound=0.206, batch=206 
4765: loss=0.212, reward_mean=0.470, reward_bound=0.229, batch=210 
4766: loss=0.216, reward_mean=0.360, reward_bound=0.254, batch=214 
4767: loss=0.215, reward_mean=0.450, reward_bound=0.280, batch=220 
4768: loss=0.210, reward_mean=0.440, reward_bound=0.282, batch=188 
4769: loss=0.208, reward_mean=0.440, reward_bound=0.208, batch=201 
4770: loss=0.207, reward_mean=0.390, reward_bound=0.185, batch=209 
4771: loss=0.205, reward_mean=0.320, reward_bound=0.164, batch=216 
4772: loss=0.209, reward_mean=0.480, reward_bound=0.229, batch=219 
4773: loss=0.207, reward_mean=0.440, reward_bound=0.254, batch=220 
4774: loss=0.208, reward_mean=0.410, reward_bound=0.282, batch=220 
4775: loss=0.207, reward_mean=0.460, reward_bound=0.314, batch=173 
4776: loss=0.201, reward_mean=0.500, reward_bound=0.144, batch=191 
4777: loss=0.202, reward_mean=0.420, reward_bound=0.150, batch=202 
4778: loss=0.202, reward_mean=0.440, reward_bound=0.185, batch=208 
4779: loss=0.199, reward_mean=0.490, reward_bound=0.229, batch=209 
4780: loss=0.193, reward_mean=0.480, reward_bound=0.254, batch=212 
4781: loss=0.199, reward_mean=0.450, reward_bound=0.282, batch=210 
4782: loss=0.200, reward_mean=0.390, reward_bound=0.247, batch=217 
4783: loss=0.202, reward_mean=0.380, reward_bound=0.314, batch=213 
4784: loss=0.200, reward_mean=0.340, reward_bound=0.229, batch=218 
4785: loss=0.205, reward_mean=0.490, reward_bound=0.349, batch=163 
4786: loss=0.190, reward_mean=0.310, reward_bound=0.044, batch=184 
4787: loss=0.186, reward_mean=0.330, reward_bound=0.071, batch=199 
4788: loss=0.187, reward_mean=0.460, reward_bound=0.098, batch=207 
4789: loss=0.194, reward_mean=0.350, reward_bound=0.135, batch=211 
4790: loss=0.193, reward_mean=0.440, reward_bound=0.150, batch=211 
4791: loss=0.205, reward_mean=0.360, reward_bound=0.185, batch=211 
4792: loss=0.196, reward_mean=0.370, reward_bound=0.206, batch=210 
4793: loss=0.197, reward_mean=0.460, reward_bound=0.229, batch=208 
4794: loss=0.197, reward_mean=0.420, reward_bound=0.190, batch=215 
4795: loss=0.196, reward_mean=0.420, reward_bound=0.254, batch=210 
4796: loss=0.196, reward_mean=0.450, reward_bound=0.222, batch=217 
4797: loss=0.193, reward_mean=0.410, reward_bound=0.254, batch=220 
4798: loss=0.196, reward_mean=0.440, reward_bound=0.229, batch=223 
4799: loss=0.195, reward_mean=0.460, reward_bound=0.282, batch=225 
4800: loss=0.193, reward_mean=0.440, reward_bound=0.314, batch=212 
4801: loss=0.192, reward_mean=0.450, reward_bound=0.282, batch=217 
4802: loss=0.194, reward_mean=0.470, reward_bound=0.342, batch=222 
4803: loss=0.194, reward_mean=0.440, reward_bound=0.302, batch=225 
4804: loss=0.198, reward_mean=0.470, reward_bound=0.349, batch=217 
4805: loss=0.197, reward_mean=0.370, reward_bound=0.202, batch=222 
4806: loss=0.197, reward_mean=0.480, reward_bound=0.324, batch=225 
4807: loss=0.195, reward_mean=0.430, reward_bound=0.387, batch=150 
4808: loss=0.178, reward_mean=0.380, reward_bound=0.025, batch=174 
4809: loss=0.167, reward_mean=0.460, reward_bound=0.079, batch=192 
4810: loss=0.173, reward_mean=0.540, reward_bound=0.135, batch=199 
4811: loss=0.178, reward_mean=0.470, reward_bound=0.167, batch=203 
4812: loss=0.179, reward_mean=0.490, reward_bound=0.185, batch=206 
4813: loss=0.188, reward_mean=0.340, reward_bound=0.206, batch=208 
4814: loss=0.184, reward_mean=0.470, reward_bound=0.208, batch=215 
4815: loss=0.191, reward_mean=0.460, reward_bound=0.229, batch=212 
4816: loss=0.186, reward_mean=0.550, reward_bound=0.254, batch=207 
4817: loss=0.186, reward_mean=0.450, reward_bound=0.282, batch=205 
4818: loss=0.186, reward_mean=0.420, reward_bound=0.175, batch=213 
4819: loss=0.191, reward_mean=0.310, reward_bound=0.229, batch=217 
4820: loss=0.192, reward_mean=0.440, reward_bound=0.277, batch=222 
4821: loss=0.192, reward_mean=0.410, reward_bound=0.292, batch=225 
4822: loss=0.199, reward_mean=0.410, reward_bound=0.314, batch=210 
4823: loss=0.201, reward_mean=0.460, reward_bound=0.314, batch=215 
4824: loss=0.199, reward_mean=0.480, reward_bound=0.314, batch=219 
4825: loss=0.197, reward_mean=0.280, reward_bound=0.206, batch=222 
4826: loss=0.197, reward_mean=0.430, reward_bound=0.282, batch=224 
4827: loss=0.197, reward_mean=0.410, reward_bound=0.342, batch=227 
4828: loss=0.196, reward_mean=0.430, reward_bound=0.349, batch=212 
4829: loss=0.194, reward_mean=0.510, reward_bound=0.324, batch=218 
4830: loss=0.195, reward_mean=0.470, reward_bound=0.349, batch=217 
4831: loss=0.194, reward_mean=0.430, reward_bound=0.342, batch=222 
4832: loss=0.193, reward_mean=0.430, reward_bound=0.349, batch=223 
4833: loss=0.199, reward_mean=0.340, reward_bound=0.387, batch=198 
4834: loss=0.195, reward_mean=0.510, reward_bound=0.208, batch=208 
4835: loss=0.195, reward_mean=0.530, reward_bound=0.206, batch=214 
4836: loss=0.195, reward_mean=0.380, reward_bound=0.229, batch=218 
4837: loss=0.199, reward_mean=0.410, reward_bound=0.254, batch=218 
4838: loss=0.199, reward_mean=0.350, reward_bound=0.257, batch=222 
4839: loss=0.202, reward_mean=0.400, reward_bound=0.245, batch=225 
4840: loss=0.197, reward_mean=0.470, reward_bound=0.289, batch=227 
4841: loss=0.200, reward_mean=0.410, reward_bound=0.314, batch=227 
4842: loss=0.199, reward_mean=0.430, reward_bound=0.335, batch=229 
4843: loss=0.201, reward_mean=0.430, reward_bound=0.349, batch=221 
4844: loss=0.201, reward_mean=0.360, reward_bound=0.282, batch=224 
4845: loss=0.202, reward_mean=0.390, reward_bound=0.308, batch=227 
4846: loss=0.203, reward_mean=0.470, reward_bound=0.314, batch=228 
4847: loss=0.200, reward_mean=0.380, reward_bound=0.387, batch=219 
4848: loss=0.199, reward_mean=0.400, reward_bound=0.324, batch=223 
4849: loss=0.212, reward_mean=0.450, reward_bound=0.430, batch=102 
4850: loss=0.166, reward_mean=0.460, reward_bound=0.013, batch=141 
4851: loss=0.147, reward_mean=0.400, reward_bound=0.008, batch=168 
4852: loss=0.159, reward_mean=0.370, reward_bound=0.018, batch=186 
4853: loss=0.160, reward_mean=0.520, reward_bound=0.047, batch=198 
4854: loss=0.162, reward_mean=0.390, reward_bound=0.080, batch=206 
4855: loss=0.170, reward_mean=0.430, reward_bound=0.098, batch=210 
4856: loss=0.175, reward_mean=0.460, reward_bound=0.118, batch=217 
4857: loss=0.181, reward_mean=0.450, reward_bound=0.135, batch=214 
4858: loss=0.184, reward_mean=0.420, reward_bound=0.150, batch=210 
4859: loss=0.185, reward_mean=0.470, reward_bound=0.167, batch=205 
4860: loss=0.188, reward_mean=0.450, reward_bound=0.185, batch=202 
4861: loss=0.192, reward_mean=0.460, reward_bound=0.206, batch=214 
4862: loss=0.195, reward_mean=0.480, reward_bound=0.206, batch=212 
4863: loss=0.201, reward_mean=0.450, reward_bound=0.229, batch=204 
4864: loss=0.206, reward_mean=0.460, reward_bound=0.254, batch=199 
4865: loss=0.204, reward_mean=0.420, reward_bound=0.174, batch=209 
4866: loss=0.207, reward_mean=0.320, reward_bound=0.127, batch=216 
4867: loss=0.208, reward_mean=0.400, reward_bound=0.229, batch=217 
4868: loss=0.206, reward_mean=0.440, reward_bound=0.249, batch=222 
4869: loss=0.207, reward_mean=0.420, reward_bound=0.282, batch=209 
4870: loss=0.220, reward_mean=0.390, reward_bound=0.314, batch=194 
4871: loss=0.218, reward_mean=0.470, reward_bound=0.229, batch=204 
4872: loss=0.217, reward_mean=0.460, reward_bound=0.254, batch=212 
4873: loss=0.215, reward_mean=0.350, reward_bound=0.191, batch=218 
4874: loss=0.216, reward_mean=0.510, reward_bound=0.229, batch=221 
4875: loss=0.215, reward_mean=0.430, reward_bound=0.282, batch=223 
4876: loss=0.214, reward_mean=0.390, reward_bound=0.314, batch=221 
4877: loss=0.213, reward_mean=0.410, reward_bound=0.282, batch=223 
4878: loss=0.213, reward_mean=0.350, reward_bound=0.349, batch=199 
4879: loss=0.213, reward_mean=0.370, reward_bound=0.109, batch=206 
4880: loss=0.212, reward_mean=0.370, reward_bound=0.185, batch=213 
4881: loss=0.213, reward_mean=0.470, reward_bound=0.229, batch=218 
4882: loss=0.212, reward_mean=0.410, reward_bound=0.257, batch=222 
4883: loss=0.210, reward_mean=0.370, reward_bound=0.282, batch=223 
4884: loss=0.208, reward_mean=0.400, reward_bound=0.335, batch=226 
4885: loss=0.207, reward_mean=0.420, reward_bound=0.314, batch=227 
4886: loss=0.210, reward_mean=0.430, reward_bound=0.349, batch=217 
4887: loss=0.209, reward_mean=0.300, reward_bound=0.263, batch=222 
4888: loss=0.209, reward_mean=0.330, reward_bound=0.302, batch=225 
4889: loss=0.209, reward_mean=0.440, reward_bound=0.296, batch=227 
4890: loss=0.212, reward_mean=0.370, reward_bound=0.349, batch=227 
4891: loss=0.212, reward_mean=0.470, reward_bound=0.380, batch=229 
4892: loss=0.219, reward_mean=0.330, reward_bound=0.387, batch=190 
4893: loss=0.220, reward_mean=0.420, reward_bound=0.288, batch=203 
4894: loss=0.214, reward_mean=0.460, reward_bound=0.160, batch=212 
4895: loss=0.210, reward_mean=0.430, reward_bound=0.206, batch=220 
4896: loss=0.221, reward_mean=0.410, reward_bound=0.254, batch=219 
4897: loss=0.221, reward_mean=0.500, reward_bound=0.282, batch=222 
4898: loss=0.221, reward_mean=0.450, reward_bound=0.314, batch=218 
4899: loss=0.221, reward_mean=0.370, reward_bound=0.282, batch=221 
4900: loss=0.222, reward_mean=0.440, reward_bound=0.349, batch=216 
4901: loss=0.219, reward_mean=0.390, reward_bound=0.387, batch=209 
4902: loss=0.215, reward_mean=0.440, reward_bound=0.314, batch=215 
4903: loss=0.216, reward_mean=0.440, reward_bound=0.167, batch=219 
4904: loss=0.213, reward_mean=0.390, reward_bound=0.295, batch=223 
4905: loss=0.214, reward_mean=0.420, reward_bound=0.335, batch=226 
4906: loss=0.215, reward_mean=0.440, reward_bound=0.349, batch=223 
4907: loss=0.215, reward_mean=0.360, reward_bound=0.301, batch=226 
4908: loss=0.216, reward_mean=0.420, reward_bound=0.349, batch=227 
4909: loss=0.216, reward_mean=0.340, reward_bound=0.380, batch=229 
4910: loss=0.218, reward_mean=0.390, reward_bound=0.387, batch=222 
4911: loss=0.218, reward_mean=0.410, reward_bound=0.349, batch=224 
4912: loss=0.217, reward_mean=0.400, reward_bound=0.384, batch=227 
4913: loss=0.218, reward_mean=0.360, reward_bound=0.342, batch=229 
4914: loss=0.223, reward_mean=0.400, reward_bound=0.405, batch=230 
4915: loss=0.214, reward_mean=0.420, reward_bound=0.430, batch=163 
4916: loss=0.202, reward_mean=0.380, reward_bound=0.082, batch=184 
4917: loss=0.197, reward_mean=0.360, reward_bound=0.098, batch=198 
4918: loss=0.198, reward_mean=0.370, reward_bound=0.111, batch=208 
4919: loss=0.202, reward_mean=0.420, reward_bound=0.167, batch=213 
4920: loss=0.209, reward_mean=0.440, reward_bound=0.206, batch=218 
4921: loss=0.205, reward_mean=0.490, reward_bound=0.229, batch=215 
4922: loss=0.210, reward_mean=0.390, reward_bound=0.254, batch=208 
4923: loss=0.211, reward_mean=0.430, reward_bound=0.185, batch=212 
4924: loss=0.217, reward_mean=0.310, reward_bound=0.229, batch=216 
4925: loss=0.218, reward_mean=0.530, reward_bound=0.282, batch=209 
4926: loss=0.219, reward_mean=0.360, reward_bound=0.314, batch=206 
4927: loss=0.213, reward_mean=0.350, reward_bound=0.185, batch=212 
4928: loss=0.216, reward_mean=0.340, reward_bound=0.254, batch=216 
4929: loss=0.213, reward_mean=0.400, reward_bound=0.186, batch=221 
4930: loss=0.214, reward_mean=0.440, reward_bound=0.254, batch=224 
4931: loss=0.215, reward_mean=0.390, reward_bound=0.314, batch=225 
4932: loss=0.216, reward_mean=0.500, reward_bound=0.321, batch=227 
4933: loss=0.217, reward_mean=0.310, reward_bound=0.349, batch=209 
4934: loss=0.220, reward_mean=0.440, reward_bound=0.254, batch=215 
4935: loss=0.216, reward_mean=0.480, reward_bound=0.321, batch=220 
4936: loss=0.216, reward_mean=0.330, reward_bound=0.254, batch=223 
4937: loss=0.216, reward_mean=0.410, reward_bound=0.349, batch=225 
4938: loss=0.216, reward_mean=0.420, reward_bound=0.387, batch=206 
4939: loss=0.216, reward_mean=0.430, reward_bound=0.254, batch=211 
4940: loss=0.218, reward_mean=0.400, reward_bound=0.206, batch=216 
4941: loss=0.212, reward_mean=0.440, reward_bound=0.241, batch=221 
4942: loss=0.219, reward_mean=0.400, reward_bound=0.282, batch=221 
4943: loss=0.213, reward_mean=0.320, reward_bound=0.314, batch=219 
4944: loss=0.214, reward_mean=0.390, reward_bound=0.328, batch=223 
4945: loss=0.212, reward_mean=0.490, reward_bound=0.335, batch=226 
4946: loss=0.215, reward_mean=0.420, reward_bound=0.349, batch=224 
4947: loss=0.217, reward_mean=0.350, reward_bound=0.384, batch=227 
4948: loss=0.217, reward_mean=0.380, reward_bound=0.387, batch=219 
4949: loss=0.215, reward_mean=0.450, reward_bound=0.364, batch=223 
4950: loss=0.214, reward_mean=0.360, reward_bound=0.345, batch=226 
4951: loss=0.216, reward_mean=0.470, reward_bound=0.430, batch=205 
4952: loss=0.215, reward_mean=0.450, reward_bound=0.234, batch=213 
4953: loss=0.219, reward_mean=0.480, reward_bound=0.282, batch=218 
4954: loss=0.220, reward_mean=0.400, reward_bound=0.231, batch=222 
4955: loss=0.220, reward_mean=0.350, reward_bound=0.282, batch=224 
4956: loss=0.220, reward_mean=0.420, reward_bound=0.311, batch=227 
4957: loss=0.220, reward_mean=0.480, reward_bound=0.314, batch=224 
4958: loss=0.219, reward_mean=0.430, reward_bound=0.282, batch=226 
4959: loss=0.220, reward_mean=0.450, reward_bound=0.349, batch=225 
4960: loss=0.219, reward_mean=0.490, reward_bound=0.387, batch=223 
4961: loss=0.217, reward_mean=0.350, reward_bound=0.413, batch=226 
4962: loss=0.217, reward_mean=0.420, reward_bound=0.351, batch=228 
4963: loss=0.214, reward_mean=0.450, reward_bound=0.430, batch=217 
4964: loss=0.212, reward_mean=0.470, reward_bound=0.249, batch=222 
4965: loss=0.212, reward_mean=0.440, reward_bound=0.349, batch=224 
4966: loss=0.212, reward_mean=0.370, reward_bound=0.349, batch=226 
4967: loss=0.212, reward_mean=0.390, reward_bound=0.387, batch=226 
4968: loss=0.214, reward_mean=0.450, reward_bound=0.430, batch=225 
4969: loss=0.216, reward_mean=0.460, reward_bound=0.478, batch=87 
4970: loss=0.150, reward_mean=0.390, reward_bound=0.000, batch=126 
4971: loss=0.157, reward_mean=0.400, reward_bound=0.002, batch=158 
4972: loss=0.158, reward_mean=0.430, reward_bound=0.013, batch=179 
4973: loss=0.169, reward_mean=0.450, reward_bound=0.029, batch=195 
4974: loss=0.174, reward_mean=0.400, reward_bound=0.058, batch=208 
4975: loss=0.183, reward_mean=0.390, reward_bound=0.080, batch=211 
4976: loss=0.187, reward_mean=0.420, reward_bound=0.098, batch=214 
4977: loss=0.188, reward_mean=0.410, reward_bound=0.122, batch=214 
4978: loss=0.187, reward_mean=0.380, reward_bound=0.135, batch=211 
4979: loss=0.185, reward_mean=0.420, reward_bound=0.150, batch=213 
4980: loss=0.177, reward_mean=0.490, reward_bound=0.167, batch=218 
4981: loss=0.181, reward_mean=0.490, reward_bound=0.185, batch=215 
4982: loss=0.184, reward_mean=0.430, reward_bound=0.206, batch=205 
4983: loss=0.193, reward_mean=0.440, reward_bound=0.229, batch=199 
4984: loss=0.191, reward_mean=0.460, reward_bound=0.215, batch=209 
4985: loss=0.186, reward_mean=0.550, reward_bound=0.254, batch=201 
4986: loss=0.186, reward_mean=0.510, reward_bound=0.206, batch=210 
4987: loss=0.188, reward_mean=0.470, reward_bound=0.222, batch=217 
4988: loss=0.190, reward_mean=0.540, reward_bound=0.282, batch=196 
4989: loss=0.190, reward_mean=0.440, reward_bound=0.254, batch=206 
4990: loss=0.188, reward_mean=0.450, reward_bound=0.254, batch=213 
4991: loss=0.183, reward_mean=0.470, reward_bound=0.282, batch=215 
4992: loss=0.184, reward_mean=0.430, reward_bound=0.282, batch=219 
4993: loss=0.183, reward_mean=0.390, reward_bound=0.314, batch=195 
4994: loss=0.186, reward_mean=0.420, reward_bound=0.185, batch=204 
4995: loss=0.186, reward_mean=0.420, reward_bound=0.150, batch=212 
4996: loss=0.181, reward_mean=0.540, reward_bound=0.229, batch=217 
4997: loss=0.182, reward_mean=0.500, reward_bound=0.282, batch=217 
4998: loss=0.183, reward_mean=0.490, reward_bound=0.254, batch=221 
4999: loss=0.181, reward_mean=0.480, reward_bound=0.282, batch=223 
5000: loss=0.184, reward_mean=0.440, reward_bound=0.314, batch=220 
5001: loss=0.186, reward_mean=0.310, reward_bound=0.296, batch=224 
5002: loss=0.183, reward_mean=0.420, reward_bound=0.314, batch=226 
5003: loss=0.183, reward_mean=0.440, reward_bound=0.349, batch=185 
5004: loss=0.175, reward_mean=0.510, reward_bound=0.170, batch=199 
5005: loss=0.179, reward_mean=0.480, reward_bound=0.185, batch=207 
5006: loss=0.180, reward_mean=0.470, reward_bound=0.224, batch=215 
5007: loss=0.180, reward_mean=0.450, reward_bound=0.229, batch=217 
5008: loss=0.177, reward_mean=0.590, reward_bound=0.282, batch=220 
5009: loss=0.180, reward_mean=0.400, reward_bound=0.314, batch=222 
5010: loss=0.180, reward_mean=0.430, reward_bound=0.302, batch=225 
5011: loss=0.175, reward_mean=0.460, reward_bound=0.349, batch=215 
5012: loss=0.175, reward_mean=0.380, reward_bound=0.296, batch=220 
5013: loss=0.173, reward_mean=0.480, reward_bound=0.338, batch=224 
5014: loss=0.172, reward_mean=0.420, reward_bound=0.254, batch=226 
5015: loss=0.173, reward_mean=0.430, reward_bound=0.349, batch=224 
5016: loss=0.171, reward_mean=0.530, reward_bound=0.311, batch=227 
5017: loss=0.189, reward_mean=0.470, reward_bound=0.387, batch=177 
5018: loss=0.185, reward_mean=0.400, reward_bound=0.122, batch=191 
5019: loss=0.182, reward_mean=0.390, reward_bound=0.135, batch=202 
5020: loss=0.183, reward_mean=0.410, reward_bound=0.185, batch=206 
5021: loss=0.180, reward_mean=0.360, reward_bound=0.185, batch=213 
5022: loss=0.184, reward_mean=0.510, reward_bound=0.229, batch=216 
5023: loss=0.183, reward_mean=0.530, reward_bound=0.254, batch=217 
5024: loss=0.184, reward_mean=0.430, reward_bound=0.282, batch=221 
5025: loss=0.181, reward_mean=0.420, reward_bound=0.314, batch=215 
5026: loss=0.181, reward_mean=0.440, reward_bound=0.296, batch=220 
5027: loss=0.181, reward_mean=0.430, reward_bound=0.314, batch=222 
5028: loss=0.188, reward_mean=0.420, reward_bound=0.349, batch=211 
5029: loss=0.192, reward_mean=0.490, reward_bound=0.282, batch=217 
5030: loss=0.191, reward_mean=0.350, reward_bound=0.314, batch=219 
5031: loss=0.190, reward_mean=0.460, reward_bound=0.349, batch=221 
5032: loss=0.190, reward_mean=0.450, reward_bound=0.349, batch=224 
5033: loss=0.190, reward_mean=0.430, reward_bound=0.384, batch=227 
5034: loss=0.188, reward_mean=0.470, reward_bound=0.308, batch=229 
5035: loss=0.189, reward_mean=0.420, reward_bound=0.349, batch=229 
5036: loss=0.186, reward_mean=0.450, reward_bound=0.387, batch=213 
5037: loss=0.185, reward_mean=0.440, reward_bound=0.254, batch=218 
5038: loss=0.186, reward_mean=0.480, reward_bound=0.257, batch=222 
5039: loss=0.188, reward_mean=0.440, reward_bound=0.263, batch=225 
5040: loss=0.187, reward_mean=0.440, reward_bound=0.289, batch=227 
5041: loss=0.188, reward_mean=0.430, reward_bound=0.349, batch=224 
5042: loss=0.186, reward_mean=0.450, reward_bound=0.384, batch=227 
5043: loss=0.187, reward_mean=0.360, reward_bound=0.387, batch=222 
5044: loss=0.186, reward_mean=0.440, reward_bound=0.324, batch=225 
5045: loss=0.187, reward_mean=0.380, reward_bound=0.387, batch=226 
5046: loss=0.186, reward_mean=0.490, reward_bound=0.368, batch=228 
5047: loss=0.198, reward_mean=0.420, reward_bound=0.430, batch=169 
5048: loss=0.184, reward_mean=0.320, reward_bound=0.057, batch=188 
5049: loss=0.192, reward_mean=0.490, reward_bound=0.111, batch=201 
5050: loss=0.190, reward_mean=0.460, reward_bound=0.167, batch=201 
5051: loss=0.186, reward_mean=0.450, reward_bound=0.185, batch=207 
5052: loss=0.196, reward_mean=0.450, reward_bound=0.206, batch=209 
5053: loss=0.191, reward_mean=0.380, reward_bound=0.229, batch=213 
5054: loss=0.191, reward_mean=0.450, reward_bound=0.220, batch=219 
5055: loss=0.191, reward_mean=0.440, reward_bound=0.254, batch=219 
5056: loss=0.189, reward_mean=0.420, reward_bound=0.265, batch=223 
5057: loss=0.189, reward_mean=0.430, reward_bound=0.271, batch=226 
5058: loss=0.192, reward_mean=0.380, reward_bound=0.282, batch=213 
5059: loss=0.192, reward_mean=0.470, reward_bound=0.314, batch=210 
5060: loss=0.190, reward_mean=0.470, reward_bound=0.254, batch=216 
5061: loss=0.190, reward_mean=0.340, reward_bound=0.176, batch=221 
5062: loss=0.194, reward_mean=0.480, reward_bound=0.282, batch=222 
5063: loss=0.197, reward_mean=0.450, reward_bound=0.263, batch=225 
5064: loss=0.200, reward_mean=0.460, reward_bound=0.349, batch=217 
5065: loss=0.198, reward_mean=0.510, reward_bound=0.314, batch=221 
5066: loss=0.202, reward_mean=0.490, reward_bound=0.349, batch=223 
5067: loss=0.202, reward_mean=0.480, reward_bound=0.271, batch=226 
5068: loss=0.201, reward_mean=0.450, reward_bound=0.268, batch=228 
5069: loss=0.204, reward_mean=0.480, reward_bound=0.387, batch=206 
5070: loss=0.203, reward_mean=0.490, reward_bound=0.298, batch=214 
5071: loss=0.203, reward_mean=0.430, reward_bound=0.282, batch=219 
5072: loss=0.208, reward_mean=0.340, reward_bound=0.265, batch=223 
5073: loss=0.203, reward_mean=0.320, reward_bound=0.335, batch=226 
5074: loss=0.199, reward_mean=0.470, reward_bound=0.349, batch=220 
5075: loss=0.200, reward_mean=0.440, reward_bound=0.365, batch=224 
5076: loss=0.200, reward_mean=0.400, reward_bound=0.254, batch=226 
5077: loss=0.199, reward_mean=0.320, reward_bound=0.314, batch=227 
5078: loss=0.199, reward_mean=0.470, reward_bound=0.314, batch=227 
5079: loss=0.199, reward_mean=0.400, reward_bound=0.314, batch=228 
5080: loss=0.200, reward_mean=0.470, reward_bound=0.387, batch=228 
5081: loss=0.199, reward_mean=0.350, reward_bound=0.430, batch=206 
5082: loss=0.192, reward_mean=0.360, reward_bound=0.186, batch=214 
5083: loss=0.194, reward_mean=0.430, reward_bound=0.280, batch=220 
5084: loss=0.193, reward_mean=0.480, reward_bound=0.282, batch=221 
5085: loss=0.196, reward_mean=0.440, reward_bound=0.314, batch=216 
5086: loss=0.197, reward_mean=0.390, reward_bound=0.254, batch=220 
5087: loss=0.200, reward_mean=0.450, reward_bound=0.349, batch=222 
5088: loss=0.201, reward_mean=0.390, reward_bound=0.272, batch=225 
5089: loss=0.198, reward_mean=0.440, reward_bound=0.321, batch=227 
5090: loss=0.199, reward_mean=0.350, reward_bound=0.349, batch=225 
5091: loss=0.201, reward_mean=0.440, reward_bound=0.387, batch=222 
5092: loss=0.199, reward_mean=0.390, reward_bound=0.430, batch=212 
5093: loss=0.200, reward_mean=0.390, reward_bound=0.324, batch=218 
5094: loss=0.199, reward_mean=0.460, reward_bound=0.349, batch=221 
5095: loss=0.200, reward_mean=0.420, reward_bound=0.387, batch=223 
5096: loss=0.199, reward_mean=0.450, reward_bound=0.349, batch=225 
5097: loss=0.200, reward_mean=0.430, reward_bound=0.387, batch=225 
5098: loss=0.200, reward_mean=0.450, reward_bound=0.365, batch=227 
5099: loss=0.198, reward_mean=0.350, reward_bound=0.430, batch=224 
5100: loss=0.196, reward_mean=0.480, reward_bound=0.252, batch=227 
5101: loss=0.196, reward_mean=0.460, reward_bound=0.373, batch=229 
5102: loss=0.196, reward_mean=0.530, reward_bound=0.430, batch=227 
5103: loss=0.211, reward_mean=0.420, reward_bound=0.478, batch=145 
5104: loss=0.174, reward_mean=0.430, reward_bound=0.021, batch=171 
5105: loss=0.184, reward_mean=0.510, reward_bound=0.072, batch=188 
5106: loss=0.190, reward_mean=0.410, reward_bound=0.109, batch=197 
5107: loss=0.190, reward_mean=0.390, reward_bound=0.122, batch=205 
5108: loss=0.194, reward_mean=0.370, reward_bound=0.150, batch=212 
5109: loss=0.205, reward_mean=0.470, reward_bound=0.185, batch=211 
5110: loss=0.200, reward_mean=0.360, reward_bound=0.206, batch=209 
5111: loss=0.198, reward_mean=0.450, reward_bound=0.229, batch=215 
5112: loss=0.203, reward_mean=0.470, reward_bound=0.254, batch=216 
5113: loss=0.200, reward_mean=0.500, reward_bound=0.268, batch=221 
5114: loss=0.203, reward_mean=0.410, reward_bound=0.282, batch=210 
5115: loss=0.202, reward_mean=0.430, reward_bound=0.314, batch=202 
5116: loss=0.196, reward_mean=0.410, reward_bound=0.150, batch=210 
5117: loss=0.193, reward_mean=0.350, reward_bound=0.167, batch=216 
5118: loss=0.196, reward_mean=0.440, reward_bound=0.254, batch=219 
5119: loss=0.196, reward_mean=0.440, reward_bound=0.282, batch=222 
5120: loss=0.197, reward_mean=0.440, reward_bound=0.314, batch=220 
5121: loss=0.197, reward_mean=0.390, reward_bound=0.282, batch=223 
5122: loss=0.196, reward_mean=0.430, reward_bound=0.271, batch=226 
5123: loss=0.197, reward_mean=0.460, reward_bound=0.314, batch=226 
5124: loss=0.198, reward_mean=0.350, reward_bound=0.331, batch=228 
5125: loss=0.204, reward_mean=0.350, reward_bound=0.349, batch=201 
5126: loss=0.200, reward_mean=0.390, reward_bound=0.185, batch=209 
5127: loss=0.197, reward_mean=0.470, reward_bound=0.206, batch=215 
5128: loss=0.196, reward_mean=0.430, reward_bound=0.234, batch=220 
5129: loss=0.199, reward_mean=0.450, reward_bound=0.282, batch=220 
5130: loss=0.202, reward_mean=0.430, reward_bound=0.314, batch=223 
5131: loss=0.203, reward_mean=0.420, reward_bound=0.276, batch=226 
5132: loss=0.204, reward_mean=0.460, reward_bound=0.349, batch=219 
5133: loss=0.205, reward_mean=0.400, reward_bound=0.328, batch=223 
5134: loss=0.202, reward_mean=0.430, reward_bound=0.349, batch=225 
5135: loss=0.203, reward_mean=0.460, reward_bound=0.387, batch=198 
5136: loss=0.202, reward_mean=0.450, reward_bound=0.169, batch=208 
5137: loss=0.202, reward_mean=0.420, reward_bound=0.190, batch=215 
5138: loss=0.197, reward_mean=0.440, reward_bound=0.229, batch=219 
5139: loss=0.197, reward_mean=0.430, reward_bound=0.282, batch=216 
5140: loss=0.195, reward_mean=0.430, reward_bound=0.331, batch=221 
5141: loss=0.195, reward_mean=0.370, reward_bound=0.254, batch=224 
5142: loss=0.202, reward_mean=0.510, reward_bound=0.349, batch=216 
5143: loss=0.199, reward_mean=0.470, reward_bound=0.387, batch=216 
5144: loss=0.202, reward_mean=0.470, reward_bound=0.331, batch=221 
5145: loss=0.202, reward_mean=0.370, reward_bound=0.349, batch=224 
5146: loss=0.201, reward_mean=0.440, reward_bound=0.249, batch=227 
5147: loss=0.201, reward_mean=0.440, reward_bound=0.282, batch=228 
5148: loss=0.197, reward_mean=0.410, reward_bound=0.387, batch=222 
5149: loss=0.199, reward_mean=0.410, reward_bound=0.349, batch=224 
5150: loss=0.199, reward_mean=0.510, reward_bound=0.384, batch=227 
5151: loss=0.202, reward_mean=0.420, reward_bound=0.342, batch=229 
5152: loss=0.206, reward_mean=0.400, reward_bound=0.430, batch=192 
5153: loss=0.196, reward_mean=0.470, reward_bound=0.206, batch=206 
5154: loss=0.196, reward_mean=0.410, reward_bound=0.217, batch=214 
5155: loss=0.200, reward_mean=0.450, reward_bound=0.254, batch=216 
5156: loss=0.207, reward_mean=0.390, reward_bound=0.282, batch=218 
5157: loss=0.204, reward_mean=0.320, reward_bound=0.282, batch=221 
5158: loss=0.206, reward_mean=0.450, reward_bound=0.314, batch=220 
5159: loss=0.204, reward_mean=0.420, reward_bound=0.296, batch=224 
5160: loss=0.206, reward_mean=0.420, reward_bound=0.314, batch=225 
5161: loss=0.207, reward_mean=0.490, reward_bound=0.349, batch=220 
5162: loss=0.207, reward_mean=0.480, reward_bound=0.349, batch=222 
5163: loss=0.205, reward_mean=0.410, reward_bound=0.324, batch=225 
5164: loss=0.210, reward_mean=0.510, reward_bound=0.387, batch=213 
5165: loss=0.209, reward_mean=0.450, reward_bound=0.271, batch=219 
5166: loss=0.207, reward_mean=0.440, reward_bound=0.328, batch=223 
5167: loss=0.206, reward_mean=0.400, reward_bound=0.349, batch=224 
5168: loss=0.206, reward_mean=0.450, reward_bound=0.314, batch=226 
5169: loss=0.206, reward_mean=0.390, reward_bound=0.331, batch=228 
5170: loss=0.210, reward_mean=0.490, reward_bound=0.349, batch=227 
5171: loss=0.209, reward_mean=0.390, reward_bound=0.387, batch=225 
5172: loss=0.202, reward_mean=0.420, reward_bound=0.430, batch=218 
5173: loss=0.201, reward_mean=0.400, reward_bound=0.282, batch=221 
5174: loss=0.202, reward_mean=0.490, reward_bound=0.387, batch=222 
5175: loss=0.201, reward_mean=0.320, reward_bound=0.282, batch=223 
5176: loss=0.199, reward_mean=0.400, reward_bound=0.335, batch=226 
5177: loss=0.199, reward_mean=0.380, reward_bound=0.314, batch=227 
5178: loss=0.198, reward_mean=0.440, reward_bound=0.380, batch=229 
5179: loss=0.200, reward_mean=0.360, reward_bound=0.387, batch=225 
5180: loss=0.201, reward_mean=0.470, reward_bound=0.430, batch=225 
5181: loss=0.201, reward_mean=0.430, reward_bound=0.356, batch=227 
5182: loss=0.202, reward_mean=0.430, reward_bound=0.387, batch=228 
5183: loss=0.201, reward_mean=0.460, reward_bound=0.321, batch=229 
5184: loss=0.200, reward_mean=0.480, reward_bound=0.328, batch=230 
5185: loss=0.200, reward_mean=0.410, reward_bound=0.376, batch=231 
5186: loss=0.201, reward_mean=0.450, reward_bound=0.387, batch=230 
5187: loss=0.201, reward_mean=0.460, reward_bound=0.430, batch=230 
5188: loss=0.201, reward_mean=0.460, reward_bound=0.439, batch=231 
5189: loss=0.205, reward_mean=0.430, reward_bound=0.478, batch=186 
5190: loss=0.200, reward_mean=0.460, reward_bound=0.143, batch=200 
5191: loss=0.197, reward_mean=0.390, reward_bound=0.150, batch=208 
5192: loss=0.194, reward_mean=0.490, reward_bound=0.206, batch=212 
5193: loss=0.195, reward_mean=0.430, reward_bound=0.229, batch=217 
5194: loss=0.197, reward_mean=0.470, reward_bound=0.254, batch=217 
5195: loss=0.195, reward_mean=0.480, reward_bound=0.282, batch=218 
5196: loss=0.202, reward_mean=0.400, reward_bound=0.314, batch=215 
5197: loss=0.205, reward_mean=0.380, reward_bound=0.349, batch=219 
5198: loss=0.205, reward_mean=0.440, reward_bound=0.387, batch=212 
5199: loss=0.209, reward_mean=0.430, reward_bound=0.254, batch=217 
5200: loss=0.205, reward_mean=0.440, reward_bound=0.314, batch=217 
5201: loss=0.202, reward_mean=0.460, reward_bound=0.282, batch=221 
5202: loss=0.204, reward_mean=0.460, reward_bound=0.349, batch=222 
5203: loss=0.207, reward_mean=0.370, reward_bound=0.324, batch=225 
5204: loss=0.204, reward_mean=0.440, reward_bound=0.387, batch=226 
5205: loss=0.204, reward_mean=0.490, reward_bound=0.351, batch=228 
5206: loss=0.206, reward_mean=0.510, reward_bound=0.430, batch=211 
5207: loss=0.201, reward_mean=0.330, reward_bound=0.185, batch=216 
5208: loss=0.204, reward_mean=0.390, reward_bound=0.282, batch=218 
5209: loss=0.205, reward_mean=0.470, reward_bound=0.349, batch=217 
5210: loss=0.205, reward_mean=0.400, reward_bound=0.202, batch=222 
5211: loss=0.205, reward_mean=0.400, reward_bound=0.387, batch=223 
5212: loss=0.204, reward_mean=0.360, reward_bound=0.322, batch=226 
5213: loss=0.207, reward_mean=0.460, reward_bound=0.349, batch=226 
5214: loss=0.207, reward_mean=0.390, reward_bound=0.368, batch=228 
5215: loss=0.207, reward_mean=0.450, reward_bound=0.387, batch=227 
5216: loss=0.209, reward_mean=0.550, reward_bound=0.430, batch=218 
5217: loss=0.206, reward_mean=0.460, reward_bound=0.353, batch=222 
5218: loss=0.204, reward_mean=0.360, reward_bound=0.263, batch=225 
5219: loss=0.206, reward_mean=0.440, reward_bound=0.356, batch=227 
5220: loss=0.208, reward_mean=0.540, reward_bound=0.387, batch=225 
5221: loss=0.208, reward_mean=0.460, reward_bound=0.321, batch=227 
5222: loss=0.210, reward_mean=0.400, reward_bound=0.349, batch=228 
5223: loss=0.210, reward_mean=0.440, reward_bound=0.353, batch=229 
5224: loss=0.209, reward_mean=0.390, reward_bound=0.430, batch=222 
5225: loss=0.208, reward_mean=0.460, reward_bound=0.292, batch=225 
5226: loss=0.207, reward_mean=0.480, reward_bound=0.349, batch=226 
5227: loss=0.206, reward_mean=0.350, reward_bound=0.351, batch=228 
5228: loss=0.209, reward_mean=0.340, reward_bound=0.387, batch=228 
5229: loss=0.209, reward_mean=0.430, reward_bound=0.357, batch=229 
5230: loss=0.208, reward_mean=0.350, reward_bound=0.381, batch=230 
5231: loss=0.208, reward_mean=0.370, reward_bound=0.430, batch=225 
5232: loss=0.207, reward_mean=0.400, reward_bound=0.234, batch=227 
5233: loss=0.207, reward_mean=0.460, reward_bound=0.308, batch=229 
5234: loss=0.207, reward_mean=0.470, reward_bound=0.314, batch=228 
5235: loss=0.207, reward_mean=0.420, reward_bound=0.387, batch=227 
5236: loss=0.210, reward_mean=0.410, reward_bound=0.430, batch=227 
5237: loss=0.210, reward_mean=0.440, reward_bound=0.387, batch=228 
5238: loss=0.209, reward_mean=0.440, reward_bound=0.435, batch=229 
5239: loss=0.209, reward_mean=0.370, reward_bound=0.364, batch=230 
5240: loss=0.210, reward_mean=0.400, reward_bound=0.464, batch=231 
5241: loss=0.210, reward_mean=0.450, reward_bound=0.430, batch=231 
5242: loss=0.211, reward_mean=0.450, reward_bound=0.478, batch=207 
5243: loss=0.205, reward_mean=0.360, reward_bound=0.185, batch=214 
5244: loss=0.207, reward_mean=0.390, reward_bound=0.206, batch=217 
5245: loss=0.206, reward_mean=0.430, reward_bound=0.229, batch=221 
5246: loss=0.206, reward_mean=0.510, reward_bound=0.282, batch=223 
5247: loss=0.209, reward_mean=0.380, reward_bound=0.314, batch=223 
5248: loss=0.212, reward_mean=0.330, reward_bound=0.254, batch=225 
5249: loss=0.208, reward_mean=0.330, reward_bound=0.349, batch=224 
5250: loss=0.208, reward_mean=0.430, reward_bound=0.387, batch=225 
5251: loss=0.208, reward_mean=0.460, reward_bound=0.396, batch=227 
5252: loss=0.209, reward_mean=0.420, reward_bound=0.430, batch=218 
5253: loss=0.208, reward_mean=0.440, reward_bound=0.353, batch=222 
5254: loss=0.206, reward_mean=0.530, reward_bound=0.360, batch=225 
5255: loss=0.207, reward_mean=0.370, reward_bound=0.289, batch=227 
5256: loss=0.208, reward_mean=0.410, reward_bound=0.380, batch=229 
5257: loss=0.207, reward_mean=0.390, reward_bound=0.364, batch=230 
5258: loss=0.209, reward_mean=0.390, reward_bound=0.387, batch=228 
5259: loss=0.210, reward_mean=0.440, reward_bound=0.430, batch=226 
5260: loss=0.210, reward_mean=0.380, reward_bound=0.430, batch=226 
5261: loss=0.212, reward_mean=0.440, reward_bound=0.409, batch=228 
5262: loss=0.211, reward_mean=0.410, reward_bound=0.317, batch=229 
5263: loss=0.213, reward_mean=0.410, reward_bound=0.381, batch=230 
5264: loss=0.212, reward_mean=0.460, reward_bound=0.418, batch=231 
5265: loss=0.212, reward_mean=0.360, reward_bound=0.387, batch=231 
5266: loss=0.221, reward_mean=0.520, reward_bound=0.478, batch=219 
5267: loss=0.221, reward_mean=0.460, reward_bound=0.364, batch=223 
5268: loss=0.220, reward_mean=0.450, reward_bound=0.314, batch=225 
5269: loss=0.222, reward_mean=0.410, reward_bound=0.387, batch=226 
5270: loss=0.222, reward_mean=0.410, reward_bound=0.430, batch=224 
5271: loss=0.221, reward_mean=0.400, reward_bound=0.380, batch=227 
5272: loss=0.221, reward_mean=0.360, reward_bound=0.308, batch=229 
5273: loss=0.222, reward_mean=0.390, reward_bound=0.387, batch=224 
5274: loss=0.221, reward_mean=0.430, reward_bound=0.314, batch=225 
5275: loss=0.220, reward_mean=0.330, reward_bound=0.210, batch=227 
5276: loss=0.220, reward_mean=0.330, reward_bound=0.229, batch=228 
5277: loss=0.222, reward_mean=0.450, reward_bound=0.435, batch=229 
5278: loss=0.222, reward_mean=0.410, reward_bound=0.381, batch=230 
5279: loss=0.222, reward_mean=0.450, reward_bound=0.406, batch=231 
5280: loss=0.222, reward_mean=0.400, reward_bound=0.430, batch=229 
5281: loss=0.221, reward_mean=0.390, reward_bound=0.450, batch=230 
5282: loss=0.221, reward_mean=0.400, reward_bound=0.464, batch=231 
5283: loss=0.221, reward_mean=0.280, reward_bound=0.387, batch=231 
5284: loss=0.221, reward_mean=0.400, reward_bound=0.430, batch=231 
5285: loss=0.223, reward_mean=0.400, reward_bound=0.478, batch=226 
5286: loss=0.221, reward_mean=0.450, reward_bound=0.505, batch=228 
5287: loss=0.221, reward_mean=0.390, reward_bound=0.435, batch=229 
5288: loss=0.220, reward_mean=0.420, reward_bound=0.380, batch=230 
5289: loss=0.220, reward_mean=0.380, reward_bound=0.464, batch=231 
5290: loss=0.219, reward_mean=0.490, reward_bound=0.387, batch=231 
5291: loss=0.220, reward_mean=0.410, reward_bound=0.478, batch=231 
5292: loss=0.220, reward_mean=0.520, reward_bound=0.478, batch=231 
5293: loss=0.220, reward_mean=0.460, reward_bound=0.478, batch=231 
5295: loss=0.114, reward_mean=0.520, reward_bound=0.000, batch=52 
5296: loss=0.106, reward_mean=0.380, reward_bound=0.000, batch=90 
5297: loss=0.111, reward_mean=0.520, reward_bound=0.001, batch=132 
5298: loss=0.120, reward_mean=0.480, reward_bound=0.007, batch=161 
5299: loss=0.127, reward_mean=0.440, reward_bound=0.018, batch=178 
5300: loss=0.129, reward_mean=0.420, reward_bound=0.028, batch=194 
5301: loss=0.131, reward_mean=0.380, reward_bound=0.042, batch=206 
5302: loss=0.134, reward_mean=0.440, reward_bound=0.061, batch=214 
5303: loss=0.136, reward_mean=0.340, reward_bound=0.072, batch=213 
5304: loss=0.147, reward_mean=0.590, reward_bound=0.089, batch=210 
5305: loss=0.146, reward_mean=0.490, reward_bound=0.109, batch=206 
5306: loss=0.150, reward_mean=0.480, reward_bound=0.122, batch=210 
5307: loss=0.151, reward_mean=0.360, reward_bound=0.135, batch=209 
5308: loss=0.153, reward_mean=0.440, reward_bound=0.150, batch=215 
5309: loss=0.153, reward_mean=0.360, reward_bound=0.167, batch=197 
5310: loss=0.153, reward_mean=0.460, reward_bound=0.163, batch=208 
5311: loss=0.154, reward_mean=0.380, reward_bound=0.167, batch=213 
5312: loss=0.160, reward_mean=0.470, reward_bound=0.185, batch=194 
5313: loss=0.156, reward_mean=0.370, reward_bound=0.135, batch=205 
5314: loss=0.158, reward_mean=0.370, reward_bound=0.185, batch=212 
5315: loss=0.157, reward_mean=0.390, reward_bound=0.206, batch=222 
5316: loss=0.156, reward_mean=0.400, reward_bound=0.206, batch=234 
5317: loss=0.157, reward_mean=0.360, reward_bound=0.206, batch=209 
5318: loss=0.157, reward_mean=0.430, reward_bound=0.164, batch=216 
5319: loss=0.164, reward_mean=0.460, reward_bound=0.229, batch=193 
5320: loss=0.163, reward_mean=0.370, reward_bound=0.206, batch=203 
5321: loss=0.166, reward_mean=0.460, reward_bound=0.206, batch=210 
5322: loss=0.168, reward_mean=0.360, reward_bound=0.206, batch=218 
5323: loss=0.168, reward_mean=0.490, reward_bound=0.229, batch=219 
5324: loss=0.162, reward_mean=0.430, reward_bound=0.254, batch=188 
5325: loss=0.158, reward_mean=0.310, reward_bound=0.137, batch=201 
5326: loss=0.155, reward_mean=0.500, reward_bound=0.206, batch=209 
5327: loss=0.155, reward_mean=0.390, reward_bound=0.167, batch=215 
5328: loss=0.154, reward_mean=0.390, reward_bound=0.206, batch=218 
5329: loss=0.158, reward_mean=0.380, reward_bound=0.254, batch=215 
5330: loss=0.159, reward_mean=0.500, reward_bound=0.282, batch=185 
5331: loss=0.156, reward_mean=0.440, reward_bound=0.112, batch=199 
5332: loss=0.152, reward_mean=0.380, reward_bound=0.127, batch=209 
5333: loss=0.153, reward_mean=0.470, reward_bound=0.206, batch=214 
5334: loss=0.158, reward_mean=0.550, reward_bound=0.254, batch=215 
5335: loss=0.156, reward_mean=0.430, reward_bound=0.282, batch=219 
5336: loss=0.162, reward_mean=0.470, reward_bound=0.314, batch=174 
5337: loss=0.156, reward_mean=0.480, reward_bound=0.120, batch=192 
5338: loss=0.160, reward_mean=0.470, reward_bound=0.135, batch=203 
5339: loss=0.160, reward_mean=0.460, reward_bound=0.185, batch=211 
5340: loss=0.163, reward_mean=0.470, reward_bound=0.206, batch=213 
5341: loss=0.164, reward_mean=0.450, reward_bound=0.229, batch=216 
5342: loss=0.167, reward_mean=0.460, reward_bound=0.254, batch=212 
5343: loss=0.165, reward_mean=0.470, reward_bound=0.282, batch=210 
5344: loss=0.164, reward_mean=0.460, reward_bound=0.222, batch=217 
5345: loss=0.164, reward_mean=0.460, reward_bound=0.229, batch=221 
5346: loss=0.162, reward_mean=0.390, reward_bound=0.254, batch=224 
5347: loss=0.161, reward_mean=0.410, reward_bound=0.282, batch=225 
5348: loss=0.162, reward_mean=0.430, reward_bound=0.314, batch=220 
5349: loss=0.173, reward_mean=0.480, reward_bound=0.349, batch=158 
5350: loss=0.159, reward_mean=0.480, reward_bound=0.073, batch=180 
5351: loss=0.155, reward_mean=0.350, reward_bound=0.042, batch=195 
5352: loss=0.151, reward_mean=0.350, reward_bound=0.080, batch=205 
5353: loss=0.161, reward_mean=0.480, reward_bound=0.127, batch=213 
5354: loss=0.168, reward_mean=0.400, reward_bound=0.167, batch=216 
5355: loss=0.169, reward_mean=0.400, reward_bound=0.185, batch=218 
5356: loss=0.172, reward_mean=0.380, reward_bound=0.206, batch=214 
5357: loss=0.181, reward_mean=0.530, reward_bound=0.229, batch=216 
5358: loss=0.181, reward_mean=0.460, reward_bound=0.254, batch=218 
5359: loss=0.181, reward_mean=0.290, reward_bound=0.171, batch=222 
5360: loss=0.183, reward_mean=0.390, reward_bound=0.263, batch=225 
5361: loss=0.176, reward_mean=0.340, reward_bound=0.282, batch=213 
5362: loss=0.168, reward_mean=0.450, reward_bound=0.314, batch=202 
5363: loss=0.168, reward_mean=0.440, reward_bound=0.229, batch=210 
5364: loss=0.167, reward_mean=0.490, reward_bound=0.282, batch=214 
5365: loss=0.168, reward_mean=0.470, reward_bound=0.314, batch=219 
5366: loss=0.170, reward_mean=0.350, reward_bound=0.328, batch=223 
5367: loss=0.170, reward_mean=0.420, reward_bound=0.261, batch=226 
5368: loss=0.169, reward_mean=0.370, reward_bound=0.316, batch=228 
5369: loss=0.167, reward_mean=0.400, reward_bound=0.349, batch=209 
5370: loss=0.166, reward_mean=0.370, reward_bound=0.150, batch=213 
5371: loss=0.164, reward_mean=0.480, reward_bound=0.254, batch=216 
5372: loss=0.163, reward_mean=0.400, reward_bound=0.282, batch=219 
5373: loss=0.164, reward_mean=0.450, reward_bound=0.314, batch=220 
5374: loss=0.164, reward_mean=0.510, reward_bound=0.304, batch=224 
5375: loss=0.167, reward_mean=0.390, reward_bound=0.349, batch=225 
5376: loss=0.172, reward_mean=0.420, reward_bound=0.387, batch=155 
5377: loss=0.161, reward_mean=0.420, reward_bound=0.080, batch=177 
5378: loss=0.157, reward_mean=0.480, reward_bound=0.150, batch=192 
5379: loss=0.163, reward_mean=0.550, reward_bound=0.167, batch=201 
5380: loss=0.167, reward_mean=0.400, reward_bound=0.206, batch=206 
5381: loss=0.168, reward_mean=0.440, reward_bound=0.229, batch=205 
5382: loss=0.165, reward_mean=0.520, reward_bound=0.254, batch=206 
5383: loss=0.167, reward_mean=0.400, reward_bound=0.282, batch=204 
5384: loss=0.166, reward_mean=0.520, reward_bound=0.229, batch=210 
5385: loss=0.169, reward_mean=0.430, reward_bound=0.200, batch=217 
5386: loss=0.170, reward_mean=0.420, reward_bound=0.229, batch=221 
5387: loss=0.173, reward_mean=0.520, reward_bound=0.282, batch=219 
5388: loss=0.177, reward_mean=0.530, reward_bound=0.314, batch=210 
5389: loss=0.175, reward_mean=0.460, reward_bound=0.216, batch=217 
5390: loss=0.175, reward_mean=0.360, reward_bound=0.229, batch=220 
5391: loss=0.177, reward_mean=0.490, reward_bound=0.314, batch=222 
5392: loss=0.179, reward_mean=0.480, reward_bound=0.349, batch=205 
5393: loss=0.181, reward_mean=0.430, reward_bound=0.229, batch=211 
5394: loss=0.185, reward_mean=0.510, reward_bound=0.282, batch=217 
5395: loss=0.180, reward_mean=0.430, reward_bound=0.314, batch=219 
5396: loss=0.182, reward_mean=0.480, reward_bound=0.349, batch=219 
5397: loss=0.180, reward_mean=0.470, reward_bound=0.364, batch=223 
5398: loss=0.179, reward_mean=0.390, reward_bound=0.335, batch=226 
5399: loss=0.180, reward_mean=0.480, reward_bound=0.368, batch=228 
5400: loss=0.179, reward_mean=0.520, reward_bound=0.387, batch=201 
5401: loss=0.179, reward_mean=0.350, reward_bound=0.206, batch=210 
5402: loss=0.176, reward_mean=0.380, reward_bound=0.185, batch=216 
5403: loss=0.174, reward_mean=0.310, reward_bound=0.198, batch=221 
5404: loss=0.175, reward_mean=0.410, reward_bound=0.254, batch=224 
5405: loss=0.178, reward_mean=0.500, reward_bound=0.282, batch=221 
5406: loss=0.176, reward_mean=0.410, reward_bound=0.314, batch=221 
5407: loss=0.176, reward_mean=0.440, reward_bound=0.229, batch=224 
5408: loss=0.179, reward_mean=0.440, reward_bound=0.314, batch=225 
5409: loss=0.178, reward_mean=0.450, reward_bound=0.296, batch=227 
5410: loss=0.177, reward_mean=0.490, reward_bound=0.349, batch=226 
5411: loss=0.179, reward_mean=0.340, reward_bound=0.387, batch=221 
5412: loss=0.178, reward_mean=0.460, reward_bound=0.254, batch=224 
5413: loss=0.177, reward_mean=0.410, reward_bound=0.422, batch=227 
5414: loss=0.178, reward_mean=0.380, reward_bound=0.422, batch=229 
5415: loss=0.178, reward_mean=0.340, reward_bound=0.405, batch=230 
5416: loss=0.190, reward_mean=0.450, reward_bound=0.430, batch=135 
5417: loss=0.157, reward_mean=0.410, reward_bound=0.028, batch=164 
5418: loss=0.153, reward_mean=0.390, reward_bound=0.072, batch=183 
5419: loss=0.160, reward_mean=0.430, reward_bound=0.098, batch=191 
5420: loss=0.164, reward_mean=0.310, reward_bound=0.109, batch=203 
5421: loss=0.161, reward_mean=0.360, reward_bound=0.122, batch=206 
5422: loss=0.160, reward_mean=0.370, reward_bound=0.135, batch=213 
5423: loss=0.162, reward_mean=0.440, reward_bound=0.160, batch=219 
5424: loss=0.159, reward_mean=0.480, reward_bound=0.167, batch=220 
5425: loss=0.157, reward_mean=0.500, reward_bound=0.200, batch=224 
5426: loss=0.161, reward_mean=0.400, reward_bound=0.206, batch=218 
5427: loss=0.158, reward_mean=0.350, reward_bound=0.169, batch=222 
5428: loss=0.156, reward_mean=0.430, reward_bound=0.229, batch=222 
5429: loss=0.165, reward_mean=0.390, reward_bound=0.254, batch=208 
5430: loss=0.163, reward_mean=0.380, reward_bound=0.206, batch=214 
5431: loss=0.166, reward_mean=0.490, reward_bound=0.282, batch=209 
5432: loss=0.166, reward_mean=0.460, reward_bound=0.174, batch=216 
5433: loss=0.167, reward_mean=0.330, reward_bound=0.268, batch=221 
5434: loss=0.167, reward_mean=0.480, reward_bound=0.314, batch=204 
5435: loss=0.163, reward_mean=0.380, reward_bound=0.108, batch=213 
5436: loss=0.166, reward_mean=0.410, reward_bound=0.206, batch=218 
5437: loss=0.161, reward_mean=0.550, reward_bound=0.231, batch=222 
5438: loss=0.164, reward_mean=0.430, reward_bound=0.282, batch=222 
5439: loss=0.165, reward_mean=0.430, reward_bound=0.314, batch=218 
5440: loss=0.165, reward_mean=0.400, reward_bound=0.317, batch=222 
5441: loss=0.164, reward_mean=0.390, reward_bound=0.254, batch=224 
5442: loss=0.164, reward_mean=0.360, reward_bound=0.345, batch=227 
5443: loss=0.171, reward_mean=0.410, reward_bound=0.349, batch=202 
5444: loss=0.167, reward_mean=0.340, reward_bound=0.150, batch=210 
5445: loss=0.170, reward_mean=0.390, reward_bound=0.206, batch=218 
5446: loss=0.174, reward_mean=0.460, reward_bound=0.282, batch=216 
5447: loss=0.175, reward_mean=0.410, reward_bound=0.282, batch=220 
5448: loss=0.170, reward_mean=0.420, reward_bound=0.314, batch=219 
5449: loss=0.169, reward_mean=0.390, reward_bound=0.278, batch=223 
5450: loss=0.169, reward_mean=0.430, reward_bound=0.314, batch=223 
5451: loss=0.167, reward_mean=0.440, reward_bound=0.349, batch=220 
5452: loss=0.165, reward_mean=0.390, reward_bound=0.266, batch=224 
5453: loss=0.165, reward_mean=0.410, reward_bound=0.311, batch=227 
5454: loss=0.165, reward_mean=0.450, reward_bound=0.349, batch=226 
5455: loss=0.175, reward_mean=0.390, reward_bound=0.387, batch=195 
5456: loss=0.174, reward_mean=0.420, reward_bound=0.206, batch=205 
5457: loss=0.171, reward_mean=0.510, reward_bound=0.206, batch=211 
5458: loss=0.178, reward_mean=0.420, reward_bound=0.254, batch=215 
5459: loss=0.177, reward_mean=0.400, reward_bound=0.240, batch=220 
5460: loss=0.176, reward_mean=0.450, reward_bound=0.282, batch=216 
5461: loss=0.174, reward_mean=0.450, reward_bound=0.314, batch=217 
5462: loss=0.173, reward_mean=0.400, reward_bound=0.314, batch=221 
5463: loss=0.171, reward_mean=0.380, reward_bound=0.314, batch=224 
5464: loss=0.170, reward_mean=0.430, reward_bound=0.314, batch=226 
5465: loss=0.170, reward_mean=0.380, reward_bound=0.349, batch=219 
5466: loss=0.169, reward_mean=0.270, reward_bound=0.133, batch=223 
5467: loss=0.168, reward_mean=0.410, reward_bound=0.301, batch=226 
5468: loss=0.169, reward_mean=0.360, reward_bound=0.254, batch=227 
5469: loss=0.167, reward_mean=0.360, reward_bound=0.342, batch=229 
5470: loss=0.172, reward_mean=0.380, reward_bound=0.387, batch=219 
5471: loss=0.169, reward_mean=0.470, reward_bound=0.295, batch=223 
5472: loss=0.169, reward_mean=0.520, reward_bound=0.372, batch=226 
5473: loss=0.169, reward_mean=0.420, reward_bound=0.409, batch=228 
5474: loss=0.180, reward_mean=0.380, reward_bound=0.430, batch=183 
5475: loss=0.173, reward_mean=0.410, reward_bound=0.095, batch=198 
5476: loss=0.169, reward_mean=0.410, reward_bound=0.152, batch=208 
5477: loss=0.171, reward_mean=0.470, reward_bound=0.185, batch=211 
5478: loss=0.169, reward_mean=0.450, reward_bound=0.229, batch=216 
5479: loss=0.170, reward_mean=0.490, reward_bound=0.254, batch=220 
5480: loss=0.171, reward_mean=0.380, reward_bound=0.282, batch=217 
5481: loss=0.173, reward_mean=0.410, reward_bound=0.277, batch=222 
5482: loss=0.177, reward_mean=0.380, reward_bound=0.314, batch=217 
5483: loss=0.175, reward_mean=0.530, reward_bound=0.342, batch=222 
5484: loss=0.174, reward_mean=0.440, reward_bound=0.229, batch=224 
5485: loss=0.171, reward_mean=0.360, reward_bound=0.277, batch=227 
5486: loss=0.174, reward_mean=0.440, reward_bound=0.282, batch=226 
5487: loss=0.174, reward_mean=0.450, reward_bound=0.349, batch=215 
5488: loss=0.173, reward_mean=0.510, reward_bound=0.282, batch=219 
5489: loss=0.177, reward_mean=0.460, reward_bound=0.387, batch=210 
5490: loss=0.177, reward_mean=0.380, reward_bound=0.254, batch=216 
5491: loss=0.175, reward_mean=0.370, reward_bound=0.217, batch=221 
5492: loss=0.178, reward_mean=0.480, reward_bound=0.229, batch=222 
5493: loss=0.177, reward_mean=0.450, reward_bound=0.282, batch=222 
5494: loss=0.175, reward_mean=0.380, reward_bound=0.349, batch=217 
5495: loss=0.173, reward_mean=0.520, reward_bound=0.308, batch=222 
5496: loss=0.171, reward_mean=0.410, reward_bound=0.213, batch=225 
5497: loss=0.172, reward_mean=0.420, reward_bound=0.349, batch=226 
5498: loss=0.172, reward_mean=0.440, reward_bound=0.387, batch=225 
5499: loss=0.172, reward_mean=0.350, reward_bound=0.321, batch=227 
5500: loss=0.177, reward_mean=0.430, reward_bound=0.430, batch=210 
5501: loss=0.178, reward_mean=0.410, reward_bound=0.254, batch=216 
5502: loss=0.176, reward_mean=0.510, reward_bound=0.298, batch=221 
5503: loss=0.174, reward_mean=0.400, reward_bound=0.349, batch=223 
5504: loss=0.175, reward_mean=0.430, reward_bound=0.335, batch=226 
5505: loss=0.176, reward_mean=0.330, reward_bound=0.298, batch=228 
5506: loss=0.174, reward_mean=0.370, reward_bound=0.387, batch=227 
5507: loss=0.178, reward_mean=0.410, reward_bound=0.430, batch=218 
5508: loss=0.177, reward_mean=0.460, reward_bound=0.286, batch=222 
5509: loss=0.176, reward_mean=0.400, reward_bound=0.324, batch=225 
5510: loss=0.176, reward_mean=0.490, reward_bound=0.349, batch=223 
5511: loss=0.175, reward_mean=0.400, reward_bound=0.335, batch=226 
5512: loss=0.174, reward_mean=0.390, reward_bound=0.331, batch=228 
5513: loss=0.176, reward_mean=0.370, reward_bound=0.349, batch=227 
5514: loss=0.176, reward_mean=0.390, reward_bound=0.387, batch=226 
5515: loss=0.178, reward_mean=0.470, reward_bound=0.430, batch=224 
5516: loss=0.177, reward_mean=0.480, reward_bound=0.465, batch=227 
5517: loss=0.177, reward_mean=0.430, reward_bound=0.469, batch=229 
5518: loss=0.176, reward_mean=0.410, reward_bound=0.381, batch=230 
5519: loss=0.177, reward_mean=0.410, reward_bound=0.430, batch=229 
5520: loss=0.177, reward_mean=0.590, reward_bound=0.478, batch=232 
5521: loss=0.189, reward_mean=0.400, reward_bound=0.478, batch=91 
5522: loss=0.131, reward_mean=0.440, reward_bound=0.002, batch=133 
5523: loss=0.120, reward_mean=0.350, reward_bound=0.005, batch=163 
5524: loss=0.135, reward_mean=0.520, reward_bound=0.028, batch=183 
5525: loss=0.147, reward_mean=0.440, reward_bound=0.052, batch=194 
5526: loss=0.147, reward_mean=0.390, reward_bound=0.058, batch=201 
5527: loss=0.147, reward_mean=0.370, reward_bound=0.072, batch=209 
5528: loss=0.153, reward_mean=0.430, reward_bound=0.098, batch=211 
5529: loss=0.157, reward_mean=0.380, reward_bound=0.122, batch=216 
5530: loss=0.157, reward_mean=0.360, reward_bound=0.150, batch=214 
5531: loss=0.156, reward_mean=0.470, reward_bound=0.167, batch=216 
5532: loss=0.161, reward_mean=0.540, reward_bound=0.185, batch=218 
5533: loss=0.170, reward_mean=0.440, reward_bound=0.206, batch=211 
5534: loss=0.178, reward_mean=0.390, reward_bound=0.229, batch=210 
5535: loss=0.182, reward_mean=0.360, reward_bound=0.254, batch=199 
5536: loss=0.182, reward_mean=0.360, reward_bound=0.185, batch=208 
5537: loss=0.181, reward_mean=0.460, reward_bound=0.257, batch=215 
5538: loss=0.180, reward_mean=0.380, reward_bound=0.282, batch=193 
5539: loss=0.175, reward_mean=0.530, reward_bound=0.229, batch=204 
5540: loss=0.174, reward_mean=0.540, reward_bound=0.280, batch=213 
5541: loss=0.174, reward_mean=0.350, reward_bound=0.244, batch=219 
5542: loss=0.173, reward_mean=0.350, reward_bound=0.282, batch=219 
5543: loss=0.176, reward_mean=0.500, reward_bound=0.314, batch=199 
5544: loss=0.170, reward_mean=0.320, reward_bound=0.127, batch=209 
5545: loss=0.172, reward_mean=0.430, reward_bound=0.206, batch=214 
5546: loss=0.175, reward_mean=0.470, reward_bound=0.254, batch=217 
5547: loss=0.173, reward_mean=0.430, reward_bound=0.272, batch=222 
5548: loss=0.173, reward_mean=0.410, reward_bound=0.282, batch=220 
5549: loss=0.172, reward_mean=0.440, reward_bound=0.254, batch=223 
5550: loss=0.178, reward_mean=0.390, reward_bound=0.349, batch=193 
5551: loss=0.176, reward_mean=0.420, reward_bound=0.130, batch=205 
5552: loss=0.177, reward_mean=0.540, reward_bound=0.185, batch=212 
5553: loss=0.178, reward_mean=0.440, reward_bound=0.236, batch=218 
5554: loss=0.174, reward_mean=0.490, reward_bound=0.254, batch=217 
5555: loss=0.173, reward_mean=0.430, reward_bound=0.282, batch=218 
5556: loss=0.176, reward_mean=0.490, reward_bound=0.314, batch=212 
5557: loss=0.175, reward_mean=0.450, reward_bound=0.324, batch=218 
5558: loss=0.175, reward_mean=0.440, reward_bound=0.349, batch=216 
5559: loss=0.174, reward_mean=0.480, reward_bound=0.282, batch=220 
5560: loss=0.174, reward_mean=0.370, reward_bound=0.282, batch=223 
5561: loss=0.173, reward_mean=0.460, reward_bound=0.314, batch=224 
5562: loss=0.173, reward_mean=0.300, reward_bound=0.349, batch=223 
5563: loss=0.172, reward_mean=0.450, reward_bound=0.335, batch=226 
5564: loss=0.171, reward_mean=0.490, reward_bound=0.349, batch=227 
5565: loss=0.171, reward_mean=0.340, reward_bound=0.349, batch=228 
5566: loss=0.176, reward_mean=0.540, reward_bound=0.387, batch=182 
5567: loss=0.171, reward_mean=0.350, reward_bound=0.065, batch=196 
5568: loss=0.167, reward_mean=0.430, reward_bound=0.167, batch=206 
5569: loss=0.165, reward_mean=0.520, reward_bound=0.185, batch=213 
5570: loss=0.170, reward_mean=0.450, reward_bound=0.206, batch=218 
5571: loss=0.169, reward_mean=0.450, reward_bound=0.229, batch=221 
5572: loss=0.171, reward_mean=0.470, reward_bound=0.254, batch=214 
5573: loss=0.176, reward_mean=0.490, reward_bound=0.282, batch=214 
5574: loss=0.175, reward_mean=0.410, reward_bound=0.282, batch=218 
5575: loss=0.177, reward_mean=0.430, reward_bound=0.314, batch=213 
5576: loss=0.179, reward_mean=0.480, reward_bound=0.349, batch=209 
5577: loss=0.180, reward_mean=0.430, reward_bound=0.282, batch=213 
5578: loss=0.176, reward_mean=0.500, reward_bound=0.335, batch=219 
5579: loss=0.176, reward_mean=0.460, reward_bound=0.387, batch=209 
5580: loss=0.179, reward_mean=0.430, reward_bound=0.185, batch=215 
5581: loss=0.179, reward_mean=0.410, reward_bound=0.189, batch=220 
5582: loss=0.177, reward_mean=0.480, reward_bound=0.282, batch=222 
5583: loss=0.177, reward_mean=0.400, reward_bound=0.349, batch=222 
5584: loss=0.178, reward_mean=0.390, reward_bound=0.387, batch=222 
5585: loss=0.177, reward_mean=0.400, reward_bound=0.349, batch=224 
5586: loss=0.176, reward_mean=0.400, reward_bound=0.345, batch=227 
5587: loss=0.175, reward_mean=0.380, reward_bound=0.380, batch=229 
5588: loss=0.176, reward_mean=0.340, reward_bound=0.364, batch=230 
5589: loss=0.177, reward_mean=0.450, reward_bound=0.387, batch=229 
5590: loss=0.178, reward_mean=0.400, reward_bound=0.381, batch=230 
5591: loss=0.178, reward_mean=0.390, reward_bound=0.349, batch=230 
5592: loss=0.188, reward_mean=0.450, reward_bound=0.430, batch=161 
5593: loss=0.158, reward_mean=0.450, reward_bound=0.058, batch=182 
5594: loss=0.158, reward_mean=0.360, reward_bound=0.072, batch=196 
5595: loss=0.167, reward_mean=0.460, reward_bound=0.104, batch=207 
5596: loss=0.163, reward_mean=0.340, reward_bound=0.109, batch=218 
5597: loss=0.169, reward_mean=0.400, reward_bound=0.122, batch=220 
5598: loss=0.170, reward_mean=0.390, reward_bound=0.150, batch=221 
5599: loss=0.174, reward_mean=0.430, reward_bound=0.185, batch=213 
5600: loss=0.172, reward_mean=0.480, reward_bound=0.229, batch=216 
5601: loss=0.174, reward_mean=0.390, reward_bound=0.254, batch=216 
5602: loss=0.172, reward_mean=0.480, reward_bound=0.282, batch=216 
5603: loss=0.174, reward_mean=0.330, reward_bound=0.244, batch=221 
5604: loss=0.173, reward_mean=0.410, reward_bound=0.282, batch=224 
5605: loss=0.177, reward_mean=0.410, reward_bound=0.314, batch=209 
5606: loss=0.176, reward_mean=0.490, reward_bound=0.254, batch=215 
5607: loss=0.177, reward_mean=0.420, reward_bound=0.260, batch=220 
5608: loss=0.176, reward_mean=0.400, reward_bound=0.338, batch=224 
5609: loss=0.181, reward_mean=0.480, reward_bound=0.349, batch=211 
5610: loss=0.183, reward_mean=0.400, reward_bound=0.282, batch=216 
5611: loss=0.183, reward_mean=0.430, reward_bound=0.314, batch=219 
5612: loss=0.184, reward_mean=0.340, reward_bound=0.309, batch=223 
5613: loss=0.182, reward_mean=0.320, reward_bound=0.349, batch=225 
5614: loss=0.181, reward_mean=0.420, reward_bound=0.356, batch=227 
5615: loss=0.183, reward_mean=0.380, reward_bound=0.380, batch=229 
5616: loss=0.185, reward_mean=0.460, reward_bound=0.387, batch=207 
5617: loss=0.180, reward_mean=0.370, reward_bound=0.249, batch=215 
5618: loss=0.179, reward_mean=0.530, reward_bound=0.254, batch=219 
5619: loss=0.178, reward_mean=0.460, reward_bound=0.282, batch=221 
5620: loss=0.181, reward_mean=0.400, reward_bound=0.314, batch=219 
5621: loss=0.180, reward_mean=0.390, reward_bound=0.328, batch=223 
5622: loss=0.179, reward_mean=0.370, reward_bound=0.349, batch=221 
5623: loss=0.178, reward_mean=0.430, reward_bound=0.254, batch=223 
5624: loss=0.181, reward_mean=0.480, reward_bound=0.387, batch=220 
5625: loss=0.179, reward_mean=0.490, reward_bound=0.282, batch=223 
5626: loss=0.177, reward_mean=0.430, reward_bound=0.301, batch=226 
5627: loss=0.178, reward_mean=0.430, reward_bound=0.314, batch=226 
5628: loss=0.181, reward_mean=0.360, reward_bound=0.316, batch=228 
5629: loss=0.184, reward_mean=0.530, reward_bound=0.349, batch=228 
5630: loss=0.181, reward_mean=0.430, reward_bound=0.392, batch=229 
5631: loss=0.185, reward_mean=0.410, reward_bound=0.430, batch=202 
5632: loss=0.185, reward_mean=0.420, reward_bound=0.254, batch=210 
5633: loss=0.182, reward_mean=0.320, reward_bound=0.240, batch=217 
5634: loss=0.176, reward_mean=0.520, reward_bound=0.277, batch=222 
5635: loss=0.174, reward_mean=0.460, reward_bound=0.282, batch=224 
5636: loss=0.173, reward_mean=0.400, reward_bound=0.311, batch=227 
5637: loss=0.177, reward_mean=0.300, reward_bound=0.314, batch=221 
5638: loss=0.181, reward_mean=0.480, reward_bound=0.349, batch=220 
5639: loss=0.181, reward_mean=0.320, reward_bound=0.274, batch=224 
5640: loss=0.179, reward_mean=0.340, reward_bound=0.342, batch=227 
5641: loss=0.181, reward_mean=0.390, reward_bound=0.282, batch=228 
5642: loss=0.179, reward_mean=0.420, reward_bound=0.317, batch=229 
5643: loss=0.180, reward_mean=0.470, reward_bound=0.387, batch=221 
5644: loss=0.178, reward_mean=0.400, reward_bound=0.282, batch=223 
5645: loss=0.178, reward_mean=0.400, reward_bound=0.314, batch=224 
5646: loss=0.180, reward_mean=0.430, reward_bound=0.384, batch=227 
5647: loss=0.178, reward_mean=0.410, reward_bound=0.373, batch=229 
5648: loss=0.179, reward_mean=0.450, reward_bound=0.387, batch=229 
5649: loss=0.178, reward_mean=0.400, reward_bound=0.328, batch=230 
5650: loss=0.182, reward_mean=0.390, reward_bound=0.430, batch=217 
5651: loss=0.180, reward_mean=0.410, reward_bound=0.224, batch=222 
5652: loss=0.179, reward_mean=0.450, reward_bound=0.236, batch=225 
5653: loss=0.181, reward_mean=0.510, reward_bound=0.314, batch=226 
5654: loss=0.183, reward_mean=0.340, reward_bound=0.387, batch=226 
5655: loss=0.182, reward_mean=0.510, reward_bound=0.430, batch=225 
5656: loss=0.182, reward_mean=0.430, reward_bound=0.430, batch=226 
5657: loss=0.182, reward_mean=0.320, reward_bound=0.387, batch=227 
5658: loss=0.183, reward_mean=0.470, reward_bound=0.387, batch=228 
5659: loss=0.184, reward_mean=0.480, reward_bound=0.435, batch=229 
5660: loss=0.184, reward_mean=0.470, reward_bound=0.381, batch=230 
5661: loss=0.183, reward_mean=0.520, reward_bound=0.464, batch=231 
5662: loss=0.195, reward_mean=0.440, reward_bound=0.478, batch=155 
5663: loss=0.179, reward_mean=0.360, reward_bound=0.042, batch=177 
5664: loss=0.175, reward_mean=0.420, reward_bound=0.089, batch=196 
5665: loss=0.173, reward_mean=0.350, reward_bound=0.089, batch=206 
5666: loss=0.167, reward_mean=0.390, reward_bound=0.122, batch=213 
5667: loss=0.174, reward_mean=0.430, reward_bound=0.150, batch=218 
5668: loss=0.183, reward_mean=0.520, reward_bound=0.206, batch=215 
5669: loss=0.185, reward_mean=0.370, reward_bound=0.229, batch=211 
5670: loss=0.184, reward_mean=0.370, reward_bound=0.167, batch=217 
5671: loss=0.184, reward_mean=0.430, reward_bound=0.254, batch=215 
5672: loss=0.181, reward_mean=0.330, reward_bound=0.282, batch=212 
5673: loss=0.180, reward_mean=0.470, reward_bound=0.236, batch=218 
5674: loss=0.179, reward_mean=0.440, reward_bound=0.257, batch=222 
5675: loss=0.177, reward_mean=0.470, reward_bound=0.282, batch=224 
5676: loss=0.176, reward_mean=0.400, reward_bound=0.280, batch=227 
5677: loss=0.177, reward_mean=0.410, reward_bound=0.314, batch=211 
5678: loss=0.176, reward_mean=0.400, reward_bound=0.314, batch=217 
5679: loss=0.177, reward_mean=0.440, reward_bound=0.349, batch=204 
5680: loss=0.175, reward_mean=0.460, reward_bound=0.229, batch=212 
5681: loss=0.178, reward_mean=0.340, reward_bound=0.254, batch=215 
5682: loss=0.176, reward_mean=0.430, reward_bound=0.282, batch=218 
5683: loss=0.175, reward_mean=0.460, reward_bound=0.314, batch=221 
5684: loss=0.174, reward_mean=0.430, reward_bound=0.254, batch=224 
5685: loss=0.174, reward_mean=0.460, reward_bound=0.349, batch=221 
5686: loss=0.173, reward_mean=0.380, reward_bound=0.206, batch=223 
5687: loss=0.174, reward_mean=0.430, reward_bound=0.314, batch=225 
5688: loss=0.174, reward_mean=0.450, reward_bound=0.349, batch=225 
5689: loss=0.183, reward_mean=0.500, reward_bound=0.387, batch=196 
5690: loss=0.180, reward_mean=0.500, reward_bound=0.217, batch=207 
5691: loss=0.181, reward_mean=0.390, reward_bound=0.277, batch=215 
5692: loss=0.180, reward_mean=0.450, reward_bound=0.282, batch=217 
5693: loss=0.181, reward_mean=0.440, reward_bound=0.272, batch=222 
5694: loss=0.182, reward_mean=0.410, reward_bound=0.282, batch=224 
5695: loss=0.181, reward_mean=0.460, reward_bound=0.314, batch=222 
5696: loss=0.180, reward_mean=0.390, reward_bound=0.245, batch=225 
5697: loss=0.184, reward_mean=0.410, reward_bound=0.349, batch=218 
5698: loss=0.185, reward_mean=0.470, reward_bound=0.257, batch=222 
5699: loss=0.184, reward_mean=0.410, reward_bound=0.292, batch=225 
5700: loss=0.182, reward_mean=0.470, reward_bound=0.356, batch=227 
5701: loss=0.182, reward_mean=0.480, reward_bound=0.380, batch=229 
5702: loss=0.180, reward_mean=0.470, reward_bound=0.387, batch=219 
5703: loss=0.180, reward_mean=0.450, reward_bound=0.387, batch=222 
5704: loss=0.195, reward_mean=0.420, reward_bound=0.430, batch=195 
5705: loss=0.190, reward_mean=0.440, reward_bound=0.138, batch=206 
5706: loss=0.183, reward_mean=0.420, reward_bound=0.217, batch=214 
5707: loss=0.188, reward_mean=0.440, reward_bound=0.229, batch=214 
5708: loss=0.183, reward_mean=0.390, reward_bound=0.226, batch=220 
5709: loss=0.189, reward_mean=0.380, reward_bound=0.254, batch=221 
5710: loss=0.188, reward_mean=0.440, reward_bound=0.282, batch=221 
5711: loss=0.190, reward_mean=0.410, reward_bound=0.314, batch=218 
5712: loss=0.189, reward_mean=0.410, reward_bound=0.166, batch=222 
5713: loss=0.188, reward_mean=0.400, reward_bound=0.263, batch=225 
5714: loss=0.192, reward_mean=0.480, reward_bound=0.349, batch=217 
5715: loss=0.192, reward_mean=0.360, reward_bound=0.282, batch=221 
5716: loss=0.193, reward_mean=0.420, reward_bound=0.349, batch=223 
5717: loss=0.193, reward_mean=0.490, reward_bound=0.358, batch=226 
5718: loss=0.197, reward_mean=0.480, reward_bound=0.387, batch=221 
5719: loss=0.196, reward_mean=0.480, reward_bound=0.387, batch=223 
5720: loss=0.196, reward_mean=0.380, reward_bound=0.314, batch=225 
5721: loss=0.195, reward_mean=0.540, reward_bound=0.349, batch=226 
5722: loss=0.198, reward_mean=0.450, reward_bound=0.368, batch=228 
5723: loss=0.201, reward_mean=0.370, reward_bound=0.392, batch=229 
5724: loss=0.201, reward_mean=0.460, reward_bound=0.430, batch=216 
5725: loss=0.198, reward_mean=0.420, reward_bound=0.331, batch=221 
5726: loss=0.200, reward_mean=0.430, reward_bound=0.349, batch=223 
5727: loss=0.197, reward_mean=0.440, reward_bound=0.387, batch=224 
5728: loss=0.196, reward_mean=0.400, reward_bound=0.282, batch=226 
5729: loss=0.196, reward_mean=0.390, reward_bound=0.409, batch=228 
5730: loss=0.197, reward_mean=0.380, reward_bound=0.430, batch=224 
5731: loss=0.197, reward_mean=0.440, reward_bound=0.342, batch=227 
5732: loss=0.197, reward_mean=0.360, reward_bound=0.342, batch=229 
5733: loss=0.199, reward_mean=0.420, reward_bound=0.424, batch=230 
5734: loss=0.198, reward_mean=0.350, reward_bound=0.418, batch=231 
5735: loss=0.199, reward_mean=0.300, reward_bound=0.430, batch=230 
5736: loss=0.195, reward_mean=0.370, reward_bound=0.478, batch=181 
5737: loss=0.188, reward_mean=0.440, reward_bound=0.185, batch=196 
5738: loss=0.184, reward_mean=0.440, reward_bound=0.206, batch=203 
5739: loss=0.187, reward_mean=0.360, reward_bound=0.229, batch=207 
5740: loss=0.179, reward_mean=0.490, reward_bound=0.254, batch=211 
5741: loss=0.175, reward_mean=0.410, reward_bound=0.206, batch=217 
5742: loss=0.177, reward_mean=0.290, reward_bound=0.254, batch=221 
5743: loss=0.176, reward_mean=0.390, reward_bound=0.254, batch=224 
5744: loss=0.182, reward_mean=0.440, reward_bound=0.282, batch=213 
5745: loss=0.180, reward_mean=0.490, reward_bound=0.261, batch=219 
5746: loss=0.182, reward_mean=0.460, reward_bound=0.282, batch=222 
5747: loss=0.185, reward_mean=0.460, reward_bound=0.314, batch=217 
5748: loss=0.189, reward_mean=0.420, reward_bound=0.349, batch=210 
5749: loss=0.185, reward_mean=0.480, reward_bound=0.185, batch=216 
5750: loss=0.188, reward_mean=0.430, reward_bound=0.298, batch=221 
5751: loss=0.192, reward_mean=0.480, reward_bound=0.314, batch=223 
5752: loss=0.192, reward_mean=0.460, reward_bound=0.349, batch=221 
5753: loss=0.196, reward_mean=0.440, reward_bound=0.387, batch=206 
5754: loss=0.194, reward_mean=0.480, reward_bound=0.314, batch=210 
5755: loss=0.191, reward_mean=0.440, reward_bound=0.229, batch=216 
5756: loss=0.190, reward_mean=0.500, reward_bound=0.314, batch=219 
5757: loss=0.188, reward_mean=0.390, reward_bound=0.295, batch=223 
5758: loss=0.189, reward_mean=0.510, reward_bound=0.349, batch=223 
5759: loss=0.189, reward_mean=0.460, reward_bound=0.335, batch=226 
5760: loss=0.186, reward_mean=0.460, reward_bound=0.368, batch=228 
5761: loss=0.191, reward_mean=0.450, reward_bound=0.387, batch=218 
5762: loss=0.191, reward_mean=0.420, reward_bound=0.314, batch=221 
5763: loss=0.190, reward_mean=0.460, reward_bound=0.387, batch=223 
5764: loss=0.189, reward_mean=0.500, reward_bound=0.387, batch=224 
5765: loss=0.189, reward_mean=0.480, reward_bound=0.349, batch=225 
5766: loss=0.188, reward_mean=0.440, reward_bound=0.289, batch=227 
5767: loss=0.188, reward_mean=0.450, reward_bound=0.314, batch=228 
5768: loss=0.188, reward_mean=0.380, reward_bound=0.353, batch=229 
5769: loss=0.188, reward_mean=0.430, reward_bound=0.364, batch=230 
5770: loss=0.188, reward_mean=0.380, reward_bound=0.387, batch=230 
5771: loss=0.195, reward_mean=0.330, reward_bound=0.430, batch=205 
5772: loss=0.195, reward_mean=0.360, reward_bound=0.234, batch=213 
5773: loss=0.191, reward_mean=0.450, reward_bound=0.229, batch=218 
5774: loss=0.190, reward_mean=0.350, reward_bound=0.282, batch=220 
5775: loss=0.190, reward_mean=0.400, reward_bound=0.314, batch=220 
5776: loss=0.190, reward_mean=0.370, reward_bound=0.313, batch=224 
5777: loss=0.190, reward_mean=0.550, reward_bound=0.349, batch=220 
5778: loss=0.189, reward_mean=0.440, reward_bound=0.314, batch=223 
5779: loss=0.190, reward_mean=0.460, reward_bound=0.387, batch=220 
5780: loss=0.194, reward_mean=0.420, reward_bound=0.406, batch=224 
5781: loss=0.192, reward_mean=0.490, reward_bound=0.314, batch=226 
5782: loss=0.192, reward_mean=0.420, reward_bound=0.349, batch=227 
5783: loss=0.191, reward_mean=0.440, reward_bound=0.380, batch=229 
5784: loss=0.195, reward_mean=0.450, reward_bound=0.430, batch=217 
5785: loss=0.195, reward_mean=0.370, reward_bound=0.430, batch=217 
5786: loss=0.196, reward_mean=0.390, reward_bound=0.349, batch=221 
5787: loss=0.195, reward_mean=0.360, reward_bound=0.254, batch=224 
5788: loss=0.199, reward_mean=0.420, reward_bound=0.282, batch=226 
5789: loss=0.195, reward_mean=0.360, reward_bound=0.349, batch=224 
5790: loss=0.194, reward_mean=0.400, reward_bound=0.387, batch=225 
5791: loss=0.194, reward_mean=0.370, reward_bound=0.396, batch=227 
5792: loss=0.196, reward_mean=0.480, reward_bound=0.430, batch=227 
5793: loss=0.196, reward_mean=0.440, reward_bound=0.401, batch=229 
5794: loss=0.197, reward_mean=0.410, reward_bound=0.360, batch=230 
5795: loss=0.197, reward_mean=0.420, reward_bound=0.430, batch=230 
5796: loss=0.196, reward_mean=0.420, reward_bound=0.478, batch=201 
5797: loss=0.190, reward_mean=0.420, reward_bound=0.185, batch=210 
5798: loss=0.185, reward_mean=0.460, reward_bound=0.206, batch=221 
5799: loss=0.183, reward_mean=0.400, reward_bound=0.206, batch=224 
5800: loss=0.179, reward_mean=0.390, reward_bound=0.229, batch=225 
5801: loss=0.185, reward_mean=0.420, reward_bound=0.260, batch=227 
5802: loss=0.184, reward_mean=0.350, reward_bound=0.282, batch=227 
5803: loss=0.190, reward_mean=0.400, reward_bound=0.314, batch=220 
5804: loss=0.189, reward_mean=0.480, reward_bound=0.349, batch=219 
5805: loss=0.190, reward_mean=0.470, reward_bound=0.295, batch=223 
5806: loss=0.191, reward_mean=0.460, reward_bound=0.387, batch=218 
5807: loss=0.190, reward_mean=0.390, reward_bound=0.289, batch=222 
5808: loss=0.190, reward_mean=0.430, reward_bound=0.282, batch=224 
5809: loss=0.190, reward_mean=0.450, reward_bound=0.345, batch=227 
5810: loss=0.190, reward_mean=0.310, reward_bound=0.349, batch=228 
5811: loss=0.190, reward_mean=0.350, reward_bound=0.387, batch=228 
5812: loss=0.190, reward_mean=0.450, reward_bound=0.349, batch=228 
5813: loss=0.193, reward_mean=0.390, reward_bound=0.430, batch=217 
5814: loss=0.193, reward_mean=0.400, reward_bound=0.349, batch=221 
5815: loss=0.192, reward_mean=0.370, reward_bound=0.349, batch=224 
5816: loss=0.192, reward_mean=0.500, reward_bound=0.387, batch=224 
5817: loss=0.192, reward_mean=0.340, reward_bound=0.387, batch=224 
5818: loss=0.191, reward_mean=0.500, reward_bound=0.430, batch=223 
5819: loss=0.194, reward_mean=0.500, reward_bound=0.349, batch=225 
5820: loss=0.193, reward_mean=0.500, reward_bound=0.387, batch=226 
5821: loss=0.193, reward_mean=0.470, reward_bound=0.390, batch=228 
5822: loss=0.191, reward_mean=0.380, reward_bound=0.430, batch=225 
5823: loss=0.190, reward_mean=0.430, reward_bound=0.356, batch=227 
5824: loss=0.190, reward_mean=0.450, reward_bound=0.373, batch=229 
5825: loss=0.189, reward_mean=0.480, reward_bound=0.405, batch=230 
5826: loss=0.189, reward_mean=0.420, reward_bound=0.387, batch=230 
5827: loss=0.188, reward_mean=0.380, reward_bound=0.418, batch=231 
5828: loss=0.190, reward_mean=0.410, reward_bound=0.430, batch=229 
5829: loss=0.190, reward_mean=0.390, reward_bound=0.430, batch=229 
5830: loss=0.189, reward_mean=0.480, reward_bound=0.364, batch=230 
5831: loss=0.192, reward_mean=0.330, reward_bound=0.329, batch=231 
5832: loss=0.189, reward_mean=0.360, reward_bound=0.387, batch=231 
5833: loss=0.196, reward_mean=0.420, reward_bound=0.478, batch=216 
5834: loss=0.198, reward_mean=0.410, reward_bound=0.314, batch=220 
5835: loss=0.195, reward_mean=0.440, reward_bound=0.274, batch=224 
5836: loss=0.195, reward_mean=0.470, reward_bound=0.282, batch=226 
5837: loss=0.197, reward_mean=0.420, reward_bound=0.349, batch=224 
5838: loss=0.196, reward_mean=0.410, reward_bound=0.426, batch=227 
5839: loss=0.195, reward_mean=0.390, reward_bound=0.387, batch=228 
5840: loss=0.196, reward_mean=0.400, reward_bound=0.430, batch=223 
5841: loss=0.194, reward_mean=0.410, reward_bound=0.301, batch=226 
5842: loss=0.194, reward_mean=0.510, reward_bound=0.331, batch=228 
5843: loss=0.195, reward_mean=0.430, reward_bound=0.353, batch=229 
5844: loss=0.195, reward_mean=0.380, reward_bound=0.430, batch=229 
5845: loss=0.194, reward_mean=0.390, reward_bound=0.478, batch=231 
5846: loss=0.194, reward_mean=0.390, reward_bound=0.430, batch=231 
5847: loss=0.195, reward_mean=0.410, reward_bound=0.478, batch=225 
5848: loss=0.196, reward_mean=0.380, reward_bound=0.430, batch=226 
5849: loss=0.196, reward_mean=0.370, reward_bound=0.314, batch=227 
5850: loss=0.198, reward_mean=0.410, reward_bound=0.422, batch=229 
5851: loss=0.200, reward_mean=0.500, reward_bound=0.450, batch=230 
5852: loss=0.200, reward_mean=0.410, reward_bound=0.430, batch=230 
5853: loss=0.196, reward_mean=0.370, reward_bound=0.478, batch=228 
5854: loss=0.196, reward_mean=0.430, reward_bound=0.484, batch=229 
5855: loss=0.196, reward_mean=0.420, reward_bound=0.450, batch=230 
5856: loss=0.197, reward_mean=0.440, reward_bound=0.376, batch=231 
5857: loss=0.196, reward_mean=0.460, reward_bound=0.387, batch=231 
5859: loss=0.097, reward_mean=0.530, reward_bound=0.000, batch=53 
5860: loss=0.105, reward_mean=0.430, reward_bound=0.000, batch=96 
5861: loss=0.100, reward_mean=0.450, reward_bound=0.000, batch=137 
5862: loss=0.103, reward_mean=0.440, reward_bound=0.003, batch=166 
5863: loss=0.111, reward_mean=0.500, reward_bound=0.011, batch=184 
5864: loss=0.113, reward_mean=0.380, reward_bound=0.020, batch=196 
5865: loss=0.120, reward_mean=0.480, reward_bound=0.038, batch=205 
5866: loss=0.124, reward_mean=0.410, reward_bound=0.052, batch=211 
5867: loss=0.126, reward_mean=0.430, reward_bound=0.065, batch=212 
5868: loss=0.123, reward_mean=0.390, reward_bound=0.082, batch=218 
5869: loss=0.129, reward_mean=0.500, reward_bound=0.100, batch=222 
5870: loss=0.132, reward_mean=0.430, reward_bound=0.122, batch=207 
5871: loss=0.132, reward_mean=0.390, reward_bound=0.135, batch=213 
5872: loss=0.134, reward_mean=0.400, reward_bound=0.150, batch=198 
5873: loss=0.134, reward_mean=0.470, reward_bound=0.167, batch=185 
5874: loss=0.135, reward_mean=0.460, reward_bound=0.135, batch=198 
5875: loss=0.132, reward_mean=0.430, reward_bound=0.169, batch=208 
5876: loss=0.133, reward_mean=0.490, reward_bound=0.185, batch=197 
5877: loss=0.130, reward_mean=0.390, reward_bound=0.178, batch=208 
5878: loss=0.129, reward_mean=0.360, reward_bound=0.185, batch=213 
5879: loss=0.135, reward_mean=0.410, reward_bound=0.206, batch=194 
5880: loss=0.137, reward_mean=0.390, reward_bound=0.167, batch=205 
5881: loss=0.137, reward_mean=0.440, reward_bound=0.206, batch=212 
5882: loss=0.142, reward_mean=0.430, reward_bound=0.229, batch=185 
5883: loss=0.137, reward_mean=0.480, reward_bound=0.124, batch=199 
5884: loss=0.142, reward_mean=0.470, reward_bound=0.167, batch=208 
5885: loss=0.145, reward_mean=0.540, reward_bound=0.229, batch=212 
5886: loss=0.152, reward_mean=0.460, reward_bound=0.254, batch=188 
5887: loss=0.146, reward_mean=0.350, reward_bound=0.098, batch=199 
5888: loss=0.149, reward_mean=0.460, reward_bound=0.150, batch=208 
5889: loss=0.148, reward_mean=0.440, reward_bound=0.169, batch=215 
5890: loss=0.148, reward_mean=0.490, reward_bound=0.229, batch=217 
5891: loss=0.149, reward_mean=0.370, reward_bound=0.249, batch=222 
5892: loss=0.150, reward_mean=0.490, reward_bound=0.254, batch=223 
5893: loss=0.153, reward_mean=0.500, reward_bound=0.282, batch=182 
5894: loss=0.148, reward_mean=0.430, reward_bound=0.082, batch=197 
5895: loss=0.144, reward_mean=0.380, reward_bound=0.109, batch=209 
5896: loss=0.144, reward_mean=0.450, reward_bound=0.150, batch=215 
5897: loss=0.149, reward_mean=0.460, reward_bound=0.185, batch=216 
5898: loss=0.149, reward_mean=0.410, reward_bound=0.206, batch=218 
5899: loss=0.152, reward_mean=0.470, reward_bound=0.229, batch=217 
5900: loss=0.153, reward_mean=0.380, reward_bound=0.254, batch=214 
5901: loss=0.152, reward_mean=0.440, reward_bound=0.282, batch=215 
5902: loss=0.150, reward_mean=0.370, reward_bound=0.229, batch=219 
5903: loss=0.150, reward_mean=0.380, reward_bound=0.229, batch=222 
5904: loss=0.151, reward_mean=0.370, reward_bound=0.314, batch=180 
5905: loss=0.148, reward_mean=0.430, reward_bound=0.131, batch=196 
5906: loss=0.143, reward_mean=0.380, reward_bound=0.135, batch=205 
5907: loss=0.143, reward_mean=0.400, reward_bound=0.170, batch=213 
5908: loss=0.139, reward_mean=0.450, reward_bound=0.206, batch=218 
5909: loss=0.148, reward_mean=0.420, reward_bound=0.254, batch=217 
5910: loss=0.145, reward_mean=0.530, reward_bound=0.282, batch=217 
5911: loss=0.151, reward_mean=0.380, reward_bound=0.314, batch=213 
5912: loss=0.154, reward_mean=0.380, reward_bound=0.271, batch=219 
5913: loss=0.151, reward_mean=0.460, reward_bound=0.314, batch=222 
5914: loss=0.167, reward_mean=0.500, reward_bound=0.349, batch=164 
5915: loss=0.159, reward_mean=0.420, reward_bound=0.051, batch=185 
5916: loss=0.161, reward_mean=0.390, reward_bound=0.089, batch=200 
5917: loss=0.162, reward_mean=0.400, reward_bound=0.122, batch=209 
5918: loss=0.158, reward_mean=0.390, reward_bound=0.150, batch=214 
5919: loss=0.169, reward_mean=0.530, reward_bound=0.185, batch=217 
5920: loss=0.169, reward_mean=0.360, reward_bound=0.206, batch=221 
5921: loss=0.174, reward_mean=0.490, reward_bound=0.254, batch=216 
5922: loss=0.178, reward_mean=0.400, reward_bound=0.282, batch=211 
5923: loss=0.176, reward_mean=0.370, reward_bound=0.185, batch=217 
5924: loss=0.177, reward_mean=0.490, reward_bound=0.282, batch=221 
5925: loss=0.178, reward_mean=0.490, reward_bound=0.314, batch=215 
5926: loss=0.177, reward_mean=0.400, reward_bound=0.194, batch=220 
5927: loss=0.179, reward_mean=0.460, reward_bound=0.274, batch=224 
5928: loss=0.174, reward_mean=0.440, reward_bound=0.349, batch=214 
5929: loss=0.172, reward_mean=0.430, reward_bound=0.311, batch=220 
5930: loss=0.171, reward_mean=0.420, reward_bound=0.282, batch=223 
5931: loss=0.175, reward_mean=0.360, reward_bound=0.349, batch=220 
5932: loss=0.174, reward_mean=0.380, reward_bound=0.338, batch=224 
5933: loss=0.184, reward_mean=0.310, reward_bound=0.387, batch=150 
5934: loss=0.161, reward_mean=0.430, reward_bound=0.047, batch=174 
5935: loss=0.152, reward_mean=0.480, reward_bound=0.071, batch=192 
5936: loss=0.158, reward_mean=0.340, reward_bound=0.089, batch=203 
5937: loss=0.162, reward_mean=0.380, reward_bound=0.109, batch=207 
5938: loss=0.168, reward_mean=0.450, reward_bound=0.167, batch=205 
5939: loss=0.168, reward_mean=0.460, reward_bound=0.185, batch=209 
5940: loss=0.171, reward_mean=0.360, reward_bound=0.206, batch=211 
5941: loss=0.171, reward_mean=0.450, reward_bound=0.229, batch=208 
5942: loss=0.173, reward_mean=0.440, reward_bound=0.254, batch=206 
5943: loss=0.173, reward_mean=0.450, reward_bound=0.229, batch=213 
5944: loss=0.171, reward_mean=0.470, reward_bound=0.254, batch=216 
5945: loss=0.169, reward_mean=0.420, reward_bound=0.282, batch=215 
5946: loss=0.176, reward_mean=0.410, reward_bound=0.314, batch=202 
5947: loss=0.174, reward_mean=0.440, reward_bound=0.292, batch=211 
5948: loss=0.174, reward_mean=0.400, reward_bound=0.282, batch=217 
5949: loss=0.171, reward_mean=0.390, reward_bound=0.167, batch=221 
5950: loss=0.170, reward_mean=0.380, reward_bound=0.229, batch=224 
5951: loss=0.170, reward_mean=0.450, reward_bound=0.282, batch=225 
5952: loss=0.170, reward_mean=0.480, reward_bound=0.314, batch=221 
5953: loss=0.175, reward_mean=0.410, reward_bound=0.349, batch=208 
5954: loss=0.175, reward_mean=0.410, reward_bound=0.208, batch=215 
5955: loss=0.171, reward_mean=0.410, reward_bound=0.254, batch=219 
5956: loss=0.172, reward_mean=0.450, reward_bound=0.349, batch=217 
5957: loss=0.171, reward_mean=0.370, reward_bound=0.267, batch=222 
5958: loss=0.172, reward_mean=0.530, reward_bound=0.349, batch=222 
5959: loss=0.170, reward_mean=0.340, reward_bound=0.360, batch=225 
5960: loss=0.174, reward_mean=0.370, reward_bound=0.387, batch=208 
5961: loss=0.171, reward_mean=0.460, reward_bound=0.317, batch=215 
5962: loss=0.169, reward_mean=0.410, reward_bound=0.234, batch=220 
5963: loss=0.168, reward_mean=0.460, reward_bound=0.274, batch=224 
5964: loss=0.177, reward_mean=0.410, reward_bound=0.282, batch=224 
5965: loss=0.177, reward_mean=0.410, reward_bound=0.311, batch=227 
5966: loss=0.173, reward_mean=0.430, reward_bound=0.349, batch=224 
5967: loss=0.173, reward_mean=0.390, reward_bound=0.345, batch=227 
5968: loss=0.173, reward_mean=0.460, reward_bound=0.349, batch=226 
5969: loss=0.172, reward_mean=0.440, reward_bound=0.368, batch=228 
5970: loss=0.173, reward_mean=0.490, reward_bound=0.387, batch=224 
5971: loss=0.172, reward_mean=0.510, reward_bound=0.345, batch=227 
5972: loss=0.173, reward_mean=0.360, reward_bound=0.387, batch=227 
5973: loss=0.191, reward_mean=0.460, reward_bound=0.430, batch=128 
5974: loss=0.163, reward_mean=0.510, reward_bound=0.058, batch=158 
5975: loss=0.162, reward_mean=0.470, reward_bound=0.065, batch=176 
5976: loss=0.159, reward_mean=0.420, reward_bound=0.080, batch=191 
5977: loss=0.164, reward_mean=0.430, reward_bound=0.098, batch=202 
5978: loss=0.165, reward_mean=0.320, reward_bound=0.122, batch=206 
5979: loss=0.167, reward_mean=0.410, reward_bound=0.150, batch=203 
5980: loss=0.167, reward_mean=0.360, reward_bound=0.167, batch=205 
5981: loss=0.169, reward_mean=0.340, reward_bound=0.185, batch=200 
5982: loss=0.171, reward_mean=0.470, reward_bound=0.162, batch=210 
5983: loss=0.165, reward_mean=0.430, reward_bound=0.185, batch=216 
5984: loss=0.171, reward_mean=0.440, reward_bound=0.206, batch=214 
5985: loss=0.172, reward_mean=0.310, reward_bound=0.226, batch=220 
5986: loss=0.174, reward_mean=0.540, reward_bound=0.229, batch=219 
5987: loss=0.179, reward_mean=0.460, reward_bound=0.254, batch=214 
5988: loss=0.179, reward_mean=0.520, reward_bound=0.282, batch=199 
5989: loss=0.178, reward_mean=0.390, reward_bound=0.229, batch=207 
5990: loss=0.178, reward_mean=0.450, reward_bound=0.282, batch=213 
5991: loss=0.176, reward_mean=0.410, reward_bound=0.314, batch=199 
5992: loss=0.179, reward_mean=0.490, reward_bound=0.282, batch=206 
5993: loss=0.181, reward_mean=0.410, reward_bound=0.268, batch=214 
5994: loss=0.183, reward_mean=0.420, reward_bound=0.229, batch=219 
5995: loss=0.177, reward_mean=0.440, reward_bound=0.282, batch=219 
5996: loss=0.182, reward_mean=0.490, reward_bound=0.314, batch=221 
5997: loss=0.188, reward_mean=0.430, reward_bound=0.349, batch=199 
5998: loss=0.187, reward_mean=0.420, reward_bound=0.157, batch=209 
5999: loss=0.183, reward_mean=0.400, reward_bound=0.239, batch=216 
6000: loss=0.186, reward_mean=0.390, reward_bound=0.254, batch=219 
6001: loss=0.189, reward_mean=0.390, reward_bound=0.282, batch=216 
6002: loss=0.187, reward_mean=0.460, reward_bound=0.314, batch=219 
6003: loss=0.186, reward_mean=0.340, reward_bound=0.254, batch=222 
6004: loss=0.185, reward_mean=0.380, reward_bound=0.302, batch=225 
6005: loss=0.186, reward_mean=0.380, reward_bound=0.349, batch=215 
6006: loss=0.185, reward_mean=0.380, reward_bound=0.289, batch=220 
6007: loss=0.186, reward_mean=0.400, reward_bound=0.349, batch=219 
6008: loss=0.185, reward_mean=0.430, reward_bound=0.250, batch=223 
6009: loss=0.186, reward_mean=0.460, reward_bound=0.314, batch=225 
6010: loss=0.187, reward_mean=0.400, reward_bound=0.356, batch=227 
6011: loss=0.194, reward_mean=0.370, reward_bound=0.387, batch=196 
6012: loss=0.189, reward_mean=0.330, reward_bound=0.130, batch=207 
6013: loss=0.190, reward_mean=0.330, reward_bound=0.185, batch=214 
6014: loss=0.191, reward_mean=0.420, reward_bound=0.252, batch=220 
6015: loss=0.194, reward_mean=0.450, reward_bound=0.254, batch=222 
6016: loss=0.193, reward_mean=0.450, reward_bound=0.282, batch=222 
6017: loss=0.193, reward_mean=0.430, reward_bound=0.314, batch=224 
6018: loss=0.193, reward_mean=0.450, reward_bound=0.345, batch=227 
6019: loss=0.193, reward_mean=0.370, reward_bound=0.349, batch=219 
6020: loss=0.193, reward_mean=0.400, reward_bound=0.278, batch=223 
6021: loss=0.192, reward_mean=0.500, reward_bound=0.335, batch=226 
6022: loss=0.190, reward_mean=0.350, reward_bound=0.241, batch=228 
6023: loss=0.190, reward_mean=0.470, reward_bound=0.317, batch=229 
6024: loss=0.190, reward_mean=0.370, reward_bound=0.349, batch=229 
6025: loss=0.195, reward_mean=0.420, reward_bound=0.387, batch=223 
6026: loss=0.192, reward_mean=0.370, reward_bound=0.430, batch=178 
6027: loss=0.183, reward_mean=0.290, reward_bound=0.072, batch=193 
6028: loss=0.178, reward_mean=0.430, reward_bound=0.117, batch=205 
6029: loss=0.182, reward_mean=0.460, reward_bound=0.150, batch=209 
6030: loss=0.180, reward_mean=0.330, reward_bound=0.194, batch=216 
6031: loss=0.181, reward_mean=0.350, reward_bound=0.229, batch=219 
6032: loss=0.184, reward_mean=0.440, reward_bound=0.254, batch=216 
6033: loss=0.185, reward_mean=0.460, reward_bound=0.282, batch=220 
6034: loss=0.188, reward_mean=0.490, reward_bound=0.314, batch=219 
6035: loss=0.191, reward_mean=0.490, reward_bound=0.349, batch=212 
6036: loss=0.191, reward_mean=0.380, reward_bound=0.387, batch=203 
6037: loss=0.189, reward_mean=0.420, reward_bound=0.206, batch=211 
6038: loss=0.189, reward_mean=0.400, reward_bound=0.282, batch=216 
6039: loss=0.187, reward_mean=0.420, reward_bound=0.298, batch=221 
6040: loss=0.186, reward_mean=0.410, reward_bound=0.254, batch=224 
6041: loss=0.187, reward_mean=0.410, reward_bound=0.314, batch=224 
6042: loss=0.189, reward_mean=0.400, reward_bound=0.254, batch=226 
6043: loss=0.189, reward_mean=0.400, reward_bound=0.349, batch=223 
6044: loss=0.190, reward_mean=0.460, reward_bound=0.358, batch=226 
6045: loss=0.189, reward_mean=0.340, reward_bound=0.387, batch=219 
6046: loss=0.188, reward_mean=0.470, reward_bound=0.295, batch=223 
6047: loss=0.191, reward_mean=0.500, reward_bound=0.335, batch=226 
6048: loss=0.191, reward_mean=0.390, reward_bound=0.349, batch=226 
6049: loss=0.190, reward_mean=0.410, reward_bound=0.368, batch=228 
6050: loss=0.188, reward_mean=0.440, reward_bound=0.387, batch=227 
6051: loss=0.188, reward_mean=0.360, reward_bound=0.387, batch=227 
6052: loss=0.187, reward_mean=0.460, reward_bound=0.430, batch=206 
6053: loss=0.185, reward_mean=0.440, reward_bound=0.254, batch=212 
6054: loss=0.186, reward_mean=0.450, reward_bound=0.314, batch=217 
6055: loss=0.187, reward_mean=0.340, reward_bound=0.224, batch=222 
6056: loss=0.185, reward_mean=0.340, reward_bound=0.236, batch=225 
6057: loss=0.186, reward_mean=0.480, reward_bound=0.314, batch=225 
6058: loss=0.186, reward_mean=0.440, reward_bound=0.349, batch=224 
6059: loss=0.185, reward_mean=0.390, reward_bound=0.349, batch=226 
6060: loss=0.184, reward_mean=0.420, reward_bound=0.368, batch=228 
6061: loss=0.185, reward_mean=0.360, reward_bound=0.387, batch=225 
6062: loss=0.186, reward_mean=0.470, reward_bound=0.396, batch=227 
6063: loss=0.185, reward_mean=0.350, reward_bound=0.308, batch=229 
6064: loss=0.185, reward_mean=0.480, reward_bound=0.430, batch=213 
6065: loss=0.182, reward_mean=0.510, reward_bound=0.282, batch=218 
6066: loss=0.181, reward_mean=0.470, reward_bound=0.187, batch=222 
6067: loss=0.183, reward_mean=0.440, reward_bound=0.314, batch=224 
6068: loss=0.181, reward_mean=0.410, reward_bound=0.280, batch=227 
6069: loss=0.181, reward_mean=0.450, reward_bound=0.254, batch=228 
6070: loss=0.181, reward_mean=0.430, reward_bound=0.282, batch=228 
6071: loss=0.184, reward_mean=0.470, reward_bound=0.387, batch=224 
6072: loss=0.185, reward_mean=0.460, reward_bound=0.252, batch=227 
6073: loss=0.184, reward_mean=0.400, reward_bound=0.349, batch=228 
6074: loss=0.183, reward_mean=0.470, reward_bound=0.392, batch=229 
6075: loss=0.183, reward_mean=0.460, reward_bound=0.381, batch=230 
6076: loss=0.183, reward_mean=0.470, reward_bound=0.418, batch=231 
6077: loss=0.183, reward_mean=0.370, reward_bound=0.387, batch=231 
6078: loss=0.184, reward_mean=0.380, reward_bound=0.430, batch=223 
6079: loss=0.183, reward_mean=0.380, reward_bound=0.372, batch=226 
6080: loss=0.183, reward_mean=0.420, reward_bound=0.331, batch=228 
6081: loss=0.183, reward_mean=0.370, reward_bound=0.353, batch=229 
6082: loss=0.184, reward_mean=0.470, reward_bound=0.387, batch=226 
6083: loss=0.183, reward_mean=0.420, reward_bound=0.409, batch=228 
6084: loss=0.183, reward_mean=0.440, reward_bound=0.430, batch=228 
6085: loss=0.183, reward_mean=0.340, reward_bound=0.392, batch=229 
6086: loss=0.182, reward_mean=0.420, reward_bound=0.381, batch=230 
6087: loss=0.183, reward_mean=0.390, reward_bound=0.430, batch=229 
6088: loss=0.183, reward_mean=0.370, reward_bound=0.450, batch=230 
6089: loss=0.183, reward_mean=0.410, reward_bound=0.338, batch=231 
6090: loss=0.183, reward_mean=0.430, reward_bound=0.387, batch=231 
6091: loss=0.183, reward_mean=0.330, reward_bound=0.430, batch=230 
6092: loss=0.199, reward_mean=0.410, reward_bound=0.478, batch=98 
6093: loss=0.130, reward_mean=0.430, reward_bound=0.000, batch=138 
6094: loss=0.137, reward_mean=0.470, reward_bound=0.018, batch=164 
6095: loss=0.158, reward_mean=0.520, reward_bound=0.052, batch=185 
6096: loss=0.162, reward_mean=0.440, reward_bound=0.065, batch=194 
6097: loss=0.155, reward_mean=0.430, reward_bound=0.089, batch=204 
6098: loss=0.158, reward_mean=0.400, reward_bound=0.120, batch=213 
6099: loss=0.163, reward_mean=0.400, reward_bound=0.130, batch=219 
6100: loss=0.165, reward_mean=0.420, reward_bound=0.150, batch=218 
6101: loss=0.165, reward_mean=0.420, reward_bound=0.167, batch=215 
6102: loss=0.168, reward_mean=0.490, reward_bound=0.189, batch=220 
6103: loss=0.162, reward_mean=0.510, reward_bound=0.206, batch=233 
6104: loss=0.167, reward_mean=0.420, reward_bound=0.206, batch=230 
6105: loss=0.168, reward_mean=0.500, reward_bound=0.229, batch=230 
6106: loss=0.175, reward_mean=0.440, reward_bound=0.254, batch=222 
6107: loss=0.173, reward_mean=0.400, reward_bound=0.282, batch=204 
6108: loss=0.171, reward_mean=0.370, reward_bound=0.206, batch=210 
6109: loss=0.171, reward_mean=0.410, reward_bound=0.254, batch=214 
6110: loss=0.169, reward_mean=0.430, reward_bound=0.282, batch=218 
6111: loss=0.169, reward_mean=0.360, reward_bound=0.282, batch=220 
6112: loss=0.174, reward_mean=0.410, reward_bound=0.314, batch=195 
6113: loss=0.171, reward_mean=0.430, reward_bound=0.170, batch=206 
6114: loss=0.170, reward_mean=0.450, reward_bound=0.167, batch=212 
6115: loss=0.167, reward_mean=0.450, reward_bound=0.206, batch=222 
6116: loss=0.168, reward_mean=0.410, reward_bound=0.229, batch=224 
6117: loss=0.170, reward_mean=0.370, reward_bound=0.254, batch=224 
6118: loss=0.169, reward_mean=0.400, reward_bound=0.282, batch=217 
6119: loss=0.175, reward_mean=0.490, reward_bound=0.314, batch=216 
6120: loss=0.174, reward_mean=0.390, reward_bound=0.282, batch=219 
6121: loss=0.174, reward_mean=0.390, reward_bound=0.314, batch=221 
6122: loss=0.175, reward_mean=0.350, reward_bound=0.349, batch=187 
6123: loss=0.162, reward_mean=0.440, reward_bound=0.089, batch=202 
6124: loss=0.168, reward_mean=0.460, reward_bound=0.140, batch=211 
6125: loss=0.167, reward_mean=0.490, reward_bound=0.185, batch=217 
6126: loss=0.167, reward_mean=0.410, reward_bound=0.224, batch=222 
6127: loss=0.169, reward_mean=0.520, reward_bound=0.236, batch=225 
6128: loss=0.166, reward_mean=0.430, reward_bound=0.260, batch=227 
6129: loss=0.167, reward_mean=0.480, reward_bound=0.282, batch=227 
6130: loss=0.167, reward_mean=0.440, reward_bound=0.308, batch=229 
6131: loss=0.168, reward_mean=0.450, reward_bound=0.314, batch=221 
6132: loss=0.171, reward_mean=0.420, reward_bound=0.349, batch=211 
6133: loss=0.171, reward_mean=0.390, reward_bound=0.229, batch=217 
6134: loss=0.171, reward_mean=0.420, reward_bound=0.342, batch=222 
6135: loss=0.171, reward_mean=0.390, reward_bound=0.349, batch=223 
6136: loss=0.170, reward_mean=0.300, reward_bound=0.244, batch=226 
6137: loss=0.169, reward_mean=0.420, reward_bound=0.349, batch=227 
6138: loss=0.175, reward_mean=0.450, reward_bound=0.387, batch=177 
6139: loss=0.174, reward_mean=0.440, reward_bound=0.158, batch=194 
6140: loss=0.170, reward_mean=0.460, reward_bound=0.135, batch=205 
6141: loss=0.171, reward_mean=0.460, reward_bound=0.167, batch=212 
6142: loss=0.170, reward_mean=0.420, reward_bound=0.185, batch=217 
6143: loss=0.167, reward_mean=0.370, reward_bound=0.206, batch=221 
6144: loss=0.168, reward_mean=0.490, reward_bound=0.254, batch=217 
6145: loss=0.173, reward_mean=0.420, reward_bound=0.282, batch=215 
6146: loss=0.173, reward_mean=0.370, reward_bound=0.289, batch=220 
6147: loss=0.173, reward_mean=0.410, reward_bound=0.254, batch=223 
6148: loss=0.175, reward_mean=0.380, reward_bound=0.314, batch=219 
6149: loss=0.173, reward_mean=0.500, reward_bound=0.314, batch=222 
6150: loss=0.173, reward_mean=0.400, reward_bound=0.349, batch=217 
6151: loss=0.172, reward_mean=0.430, reward_bound=0.342, batch=222 
6152: loss=0.173, reward_mean=0.490, reward_bound=0.324, batch=225 
6153: loss=0.173, reward_mean=0.440, reward_bound=0.349, batch=225 
6154: loss=0.178, reward_mean=0.480, reward_bound=0.329, batch=227 
6155: loss=0.179, reward_mean=0.480, reward_bound=0.387, batch=214 
6156: loss=0.181, reward_mean=0.420, reward_bound=0.277, batch=220 
6157: loss=0.179, reward_mean=0.410, reward_bound=0.274, batch=224 
6158: loss=0.178, reward_mean=0.440, reward_bound=0.282, batch=226 
6159: loss=0.180, reward_mean=0.410, reward_bound=0.244, batch=228 
6160: loss=0.180, reward_mean=0.420, reward_bound=0.314, batch=225 
6161: loss=0.181, reward_mean=0.490, reward_bound=0.349, batch=225 
6162: loss=0.182, reward_mean=0.360, reward_bound=0.314, batch=226 
6163: loss=0.180, reward_mean=0.420, reward_bound=0.387, batch=223 
6164: loss=0.179, reward_mean=0.520, reward_bound=0.372, batch=226 
6165: loss=0.178, reward_mean=0.400, reward_bound=0.268, batch=228 
6166: loss=0.192, reward_mean=0.390, reward_bound=0.430, batch=169 
6167: loss=0.180, reward_mean=0.390, reward_bound=0.049, batch=188 
6168: loss=0.165, reward_mean=0.430, reward_bound=0.073, batch=201 
6169: loss=0.168, reward_mean=0.490, reward_bound=0.109, batch=210 
6170: loss=0.170, reward_mean=0.410, reward_bound=0.135, batch=212 
6171: loss=0.176, reward_mean=0.430, reward_bound=0.167, batch=217 
6172: loss=0.179, reward_mean=0.380, reward_bound=0.206, batch=220 
6173: loss=0.179, reward_mean=0.320, reward_bound=0.229, batch=219 
6174: loss=0.180, reward_mean=0.480, reward_bound=0.254, batch=214 
6175: loss=0.186, reward_mean=0.530, reward_bound=0.282, batch=208 
6176: loss=0.184, reward_mean=0.450, reward_bound=0.231, batch=215 
6177: loss=0.188, reward_mean=0.450, reward_bound=0.254, batch=219 
6178: loss=0.189, reward_mean=0.490, reward_bound=0.314, batch=210 
6179: loss=0.188, reward_mean=0.410, reward_bound=0.180, batch=217 
6180: loss=0.190, reward_mean=0.360, reward_bound=0.229, batch=221 
6181: loss=0.188, reward_mean=0.400, reward_bound=0.282, batch=221 
6182: loss=0.190, reward_mean=0.360, reward_bound=0.314, batch=223 
6183: loss=0.189, reward_mean=0.390, reward_bound=0.314, batch=225 
6184: loss=0.196, reward_mean=0.460, reward_bound=0.349, batch=211 
6185: loss=0.193, reward_mean=0.420, reward_bound=0.254, batch=216 
6186: loss=0.195, reward_mean=0.410, reward_bound=0.314, batch=217 
6187: loss=0.194, reward_mean=0.330, reward_bound=0.330, batch=222 
6188: loss=0.194, reward_mean=0.350, reward_bound=0.349, batch=223 
6189: loss=0.197, reward_mean=0.430, reward_bound=0.335, batch=226 
6190: loss=0.197, reward_mean=0.390, reward_bound=0.387, batch=208 
6191: loss=0.194, reward_mean=0.380, reward_bound=0.257, batch=215 
6192: loss=0.193, reward_mean=0.500, reward_bound=0.289, batch=220 
6193: loss=0.192, reward_mean=0.410, reward_bound=0.338, batch=224 
6194: loss=0.194, reward_mean=0.480, reward_bound=0.349, batch=223 
6195: loss=0.194, reward_mean=0.440, reward_bound=0.334, batch=226 
6196: loss=0.193, reward_mean=0.400, reward_bound=0.314, batch=227 
6197: loss=0.192, reward_mean=0.530, reward_bound=0.342, batch=229 
6198: loss=0.191, reward_mean=0.430, reward_bound=0.349, batch=229 
6199: loss=0.196, reward_mean=0.390, reward_bound=0.387, batch=224 
6200: loss=0.196, reward_mean=0.440, reward_bound=0.314, batch=226 
6201: loss=0.196, reward_mean=0.420, reward_bound=0.314, batch=227 
6202: loss=0.196, reward_mean=0.500, reward_bound=0.422, batch=229 
6203: loss=0.196, reward_mean=0.400, reward_bound=0.405, batch=230 
6204: loss=0.194, reward_mean=0.450, reward_bound=0.430, batch=205 
6205: loss=0.194, reward_mean=0.500, reward_bound=0.282, batch=212 
6206: loss=0.193, reward_mean=0.520, reward_bound=0.263, batch=218 
6207: loss=0.189, reward_mean=0.380, reward_bound=0.282, batch=220 
6208: loss=0.191, reward_mean=0.530, reward_bound=0.349, batch=223 
6209: loss=0.192, reward_mean=0.410, reward_bound=0.387, batch=219 
6210: loss=0.192, reward_mean=0.450, reward_bound=0.314, batch=221 
6211: loss=0.191, reward_mean=0.430, reward_bound=0.387, batch=223 
6212: loss=0.190, reward_mean=0.390, reward_bound=0.387, batch=224 
6213: loss=0.189, reward_mean=0.470, reward_bound=0.349, batch=226 
6214: loss=0.191, reward_mean=0.350, reward_bound=0.430, batch=223 
6215: loss=0.191, reward_mean=0.490, reward_bound=0.349, batch=224 
6216: loss=0.192, reward_mean=0.420, reward_bound=0.384, batch=227 
6217: loss=0.190, reward_mean=0.370, reward_bound=0.422, batch=229 
6218: loss=0.191, reward_mean=0.450, reward_bound=0.430, batch=228 
6219: loss=0.191, reward_mean=0.440, reward_bound=0.392, batch=229 
6220: loss=0.191, reward_mean=0.360, reward_bound=0.405, batch=230 
6221: loss=0.190, reward_mean=0.410, reward_bound=0.464, batch=231 
6222: loss=0.192, reward_mean=0.410, reward_bound=0.478, batch=147 
6223: loss=0.184, reward_mean=0.460, reward_bound=0.065, batch=171 
6224: loss=0.175, reward_mean=0.440, reward_bound=0.089, batch=189 
6225: loss=0.172, reward_mean=0.470, reward_bound=0.122, batch=200 
6226: loss=0.170, reward_mean=0.510, reward_bound=0.167, batch=206 
6227: loss=0.177, reward_mean=0.380, reward_bound=0.206, batch=211 
6228: loss=0.179, reward_mean=0.410, reward_bound=0.229, batch=206 
6229: loss=0.182, reward_mean=0.390, reward_bound=0.254, batch=206 
6230: loss=0.180, reward_mean=0.460, reward_bound=0.268, batch=214 
6231: loss=0.179, reward_mean=0.390, reward_bound=0.280, batch=220 
6232: loss=0.184, reward_mean=0.360, reward_bound=0.282, batch=214 
6233: loss=0.186, reward_mean=0.490, reward_bound=0.308, batch=220 
6234: loss=0.184, reward_mean=0.440, reward_bound=0.247, batch=224 
6235: loss=0.185, reward_mean=0.480, reward_bound=0.280, batch=227 
6236: loss=0.185, reward_mean=0.400, reward_bound=0.308, batch=229 
6237: loss=0.186, reward_mean=0.460, reward_bound=0.314, batch=216 
6238: loss=0.183, reward_mean=0.360, reward_bound=0.268, batch=221 
6239: loss=0.183, reward_mean=0.440, reward_bound=0.314, batch=224 
6240: loss=0.183, reward_mean=0.480, reward_bound=0.349, batch=206 
6241: loss=0.182, reward_mean=0.420, reward_bound=0.268, batch=214 
6242: loss=0.180, reward_mean=0.360, reward_bound=0.311, batch=220 
6243: loss=0.179, reward_mean=0.460, reward_bound=0.314, batch=222 
6244: loss=0.178, reward_mean=0.440, reward_bound=0.349, batch=218 
6245: loss=0.178, reward_mean=0.430, reward_bound=0.286, batch=222 
6246: loss=0.177, reward_mean=0.420, reward_bound=0.387, batch=196 
6247: loss=0.174, reward_mean=0.360, reward_bound=0.158, batch=207 
6248: loss=0.177, reward_mean=0.450, reward_bound=0.224, batch=215 
6249: loss=0.175, reward_mean=0.370, reward_bound=0.229, batch=213 
6250: loss=0.178, reward_mean=0.400, reward_bound=0.220, batch=219 
6251: loss=0.174, reward_mean=0.400, reward_bound=0.254, batch=222 
6252: loss=0.175, reward_mean=0.470, reward_bound=0.314, batch=218 
6253: loss=0.177, reward_mean=0.510, reward_bound=0.314, batch=220 
6254: loss=0.176, reward_mean=0.440, reward_bound=0.274, batch=224 
6255: loss=0.175, reward_mean=0.430, reward_bound=0.345, batch=227 
6256: loss=0.175, reward_mean=0.430, reward_bound=0.349, batch=218 
6257: loss=0.179, reward_mean=0.470, reward_bound=0.387, batch=216 
6258: loss=0.177, reward_mean=0.420, reward_bound=0.298, batch=221 
6259: loss=0.176, reward_mean=0.420, reward_bound=0.314, batch=223 
6260: loss=0.178, reward_mean=0.420, reward_bound=0.349, batch=224 
6261: loss=0.181, reward_mean=0.450, reward_bound=0.314, batch=226 
6262: loss=0.182, reward_mean=0.440, reward_bound=0.368, batch=228 
6263: loss=0.182, reward_mean=0.430, reward_bound=0.353, batch=229 
6264: loss=0.184, reward_mean=0.450, reward_bound=0.387, batch=224 
6265: loss=0.183, reward_mean=0.370, reward_bound=0.311, batch=227 
6266: loss=0.183, reward_mean=0.440, reward_bound=0.380, batch=229 
6267: loss=0.184, reward_mean=0.450, reward_bound=0.387, batch=229 
6268: loss=0.189, reward_mean=0.330, reward_bound=0.430, batch=191 
6269: loss=0.177, reward_mean=0.470, reward_bound=0.135, batch=202 
6270: loss=0.181, reward_mean=0.350, reward_bound=0.206, batch=212 
6271: loss=0.180, reward_mean=0.490, reward_bound=0.206, batch=219 
6272: loss=0.180, reward_mean=0.450, reward_bound=0.229, batch=219 
6273: loss=0.178, reward_mean=0.520, reward_bound=0.265, batch=223 
6274: loss=0.179, reward_mean=0.390, reward_bound=0.282, batch=222 
6275: loss=0.184, reward_mean=0.500, reward_bound=0.314, batch=220 
6276: loss=0.183, reward_mean=0.480, reward_bound=0.304, batch=224 
6277: loss=0.184, reward_mean=0.500, reward_bound=0.314, batch=226 
6278: loss=0.185, reward_mean=0.480, reward_bound=0.349, batch=224 
6279: loss=0.184, reward_mean=0.410, reward_bound=0.311, batch=227 
6280: loss=0.185, reward_mean=0.530, reward_bound=0.380, batch=229 
6281: loss=0.192, reward_mean=0.390, reward_bound=0.387, batch=213 
6282: loss=0.191, reward_mean=0.380, reward_bound=0.235, batch=219 
6283: loss=0.190, reward_mean=0.400, reward_bound=0.225, batch=223 
6284: loss=0.191, reward_mean=0.470, reward_bound=0.301, batch=226 
6285: loss=0.189, reward_mean=0.480, reward_bound=0.314, batch=226 
6286: loss=0.191, reward_mean=0.450, reward_bound=0.349, batch=226 
6287: loss=0.188, reward_mean=0.450, reward_bound=0.387, batch=226 
6288: loss=0.188, reward_mean=0.490, reward_bound=0.409, batch=228 
6289: loss=0.188, reward_mean=0.390, reward_bound=0.392, batch=229 
6290: loss=0.188, reward_mean=0.430, reward_bound=0.430, batch=215 
6291: loss=0.188, reward_mean=0.360, reward_bound=0.321, batch=220 
6292: loss=0.188, reward_mean=0.450, reward_bound=0.349, batch=222 
6293: loss=0.186, reward_mean=0.470, reward_bound=0.387, batch=221 
6294: loss=0.188, reward_mean=0.380, reward_bound=0.349, batch=224 
6295: loss=0.187, reward_mean=0.490, reward_bound=0.345, batch=227 
6296: loss=0.185, reward_mean=0.450, reward_bound=0.349, batch=228 
6297: loss=0.189, reward_mean=0.440, reward_bound=0.387, batch=228 
6298: loss=0.188, reward_mean=0.430, reward_bound=0.430, batch=222 
6299: loss=0.188, reward_mean=0.330, reward_bound=0.400, batch=225 
6300: loss=0.188, reward_mean=0.410, reward_bound=0.289, batch=227 
6301: loss=0.188, reward_mean=0.420, reward_bound=0.314, batch=228 
6302: loss=0.187, reward_mean=0.460, reward_bound=0.353, batch=229 
6303: loss=0.187, reward_mean=0.420, reward_bound=0.387, batch=229 
6304: loss=0.187, reward_mean=0.520, reward_bound=0.405, batch=230 
6305: loss=0.187, reward_mean=0.420, reward_bound=0.430, batch=226 
6306: loss=0.187, reward_mean=0.420, reward_bound=0.413, batch=228 
6307: loss=0.186, reward_mean=0.460, reward_bound=0.362, batch=229 
6308: loss=0.186, reward_mean=0.410, reward_bound=0.450, batch=230 
6309: loss=0.186, reward_mean=0.460, reward_bound=0.387, batch=230 
6310: loss=0.186, reward_mean=0.350, reward_bound=0.464, batch=231 
6311: loss=0.191, reward_mean=0.400, reward_bound=0.478, batch=182 
6312: loss=0.179, reward_mean=0.400, reward_bound=0.140, batch=197 
6313: loss=0.181, reward_mean=0.540, reward_bound=0.167, batch=206 
6314: loss=0.181, reward_mean=0.450, reward_bound=0.217, batch=214 
6315: loss=0.182, reward_mean=0.410, reward_bound=0.229, batch=214 
6316: loss=0.184, reward_mean=0.410, reward_bound=0.254, batch=210 
6317: loss=0.187, reward_mean=0.430, reward_bound=0.304, batch=217 
6318: loss=0.188, reward_mean=0.410, reward_bound=0.314, batch=218 
6319: loss=0.187, reward_mean=0.390, reward_bound=0.317, batch=222 
6320: loss=0.185, reward_mean=0.400, reward_bound=0.324, batch=225 
6321: loss=0.193, reward_mean=0.440, reward_bound=0.349, batch=217 
6322: loss=0.192, reward_mean=0.390, reward_bound=0.314, batch=221 
6323: loss=0.197, reward_mean=0.450, reward_bound=0.387, batch=207 
6324: loss=0.190, reward_mean=0.290, reward_bound=0.206, batch=214 
6325: loss=0.193, reward_mean=0.420, reward_bound=0.254, batch=219 
6326: loss=0.195, reward_mean=0.450, reward_bound=0.328, batch=223 
6327: loss=0.198, reward_mean=0.450, reward_bound=0.349, batch=224 
6328: loss=0.195, reward_mean=0.370, reward_bound=0.387, batch=224 
6329: loss=0.196, reward_mean=0.410, reward_bound=0.345, batch=227 
6330: loss=0.199, reward_mean=0.410, reward_bound=0.342, batch=229 
6331: loss=0.198, reward_mean=0.440, reward_bound=0.349, batch=227 
6332: loss=0.198, reward_mean=0.310, reward_bound=0.314, batch=227 
6333: loss=0.199, reward_mean=0.390, reward_bound=0.335, batch=229 
6334: loss=0.194, reward_mean=0.430, reward_bound=0.387, batch=228 
6335: loss=0.198, reward_mean=0.380, reward_bound=0.430, batch=210 
6336: loss=0.195, reward_mean=0.430, reward_bound=0.229, batch=216 
6337: loss=0.195, reward_mean=0.470, reward_bound=0.254, batch=219 
6338: loss=0.195, reward_mean=0.470, reward_bound=0.314, batch=221 
6339: loss=0.198, reward_mean=0.440, reward_bound=0.349, batch=224 
6340: loss=0.196, reward_mean=0.360, reward_bound=0.387, batch=225 
6341: loss=0.196, reward_mean=0.510, reward_bound=0.365, batch=227 
6342: loss=0.198, reward_mean=0.420, reward_bound=0.430, batch=218 
6343: loss=0.196, reward_mean=0.380, reward_bound=0.190, batch=222 
6344: loss=0.197, reward_mean=0.420, reward_bound=0.349, batch=221 
6345: loss=0.197, reward_mean=0.490, reward_bound=0.349, batch=224 
6346: loss=0.197, reward_mean=0.430, reward_bound=0.426, batch=227 
6347: loss=0.197, reward_mean=0.390, reward_bound=0.401, batch=229 
6348: loss=0.197, reward_mean=0.340, reward_bound=0.349, batch=229 
6349: loss=0.199, reward_mean=0.430, reward_bound=0.430, batch=226 
6350: loss=0.198, reward_mean=0.400, reward_bound=0.351, batch=228 
6351: loss=0.200, reward_mean=0.380, reward_bound=0.435, batch=229 
6352: loss=0.199, reward_mean=0.500, reward_bound=0.478, batch=231 
6353: loss=0.192, reward_mean=0.450, reward_bound=0.478, batch=199 
6354: loss=0.188, reward_mean=0.460, reward_bound=0.194, batch=209 
6355: loss=0.192, reward_mean=0.420, reward_bound=0.229, batch=215 
6356: loss=0.190, reward_mean=0.300, reward_bound=0.154, batch=220 
6357: loss=0.188, reward_mean=0.410, reward_bound=0.314, batch=217 
6358: loss=0.191, reward_mean=0.400, reward_bound=0.282, batch=221 
6359: loss=0.193, reward_mean=0.440, reward_bound=0.349, batch=216 
6360: loss=0.191, reward_mean=0.460, reward_bound=0.331, batch=221 
6361: loss=0.190, reward_mean=0.480, reward_bound=0.349, batch=224 
6362: loss=0.189, reward_mean=0.430, reward_bound=0.384, batch=227 
6363: loss=0.189, reward_mean=0.390, reward_bound=0.387, batch=224 
6364: loss=0.190, reward_mean=0.420, reward_bound=0.387, batch=226 
6365: loss=0.193, reward_mean=0.400, reward_bound=0.430, batch=215 
6366: loss=0.192, reward_mean=0.470, reward_bound=0.356, batch=220 
6367: loss=0.189, reward_mean=0.460, reward_bound=0.222, batch=224 
6368: loss=0.194, reward_mean=0.430, reward_bound=0.384, batch=227 
6369: loss=0.192, reward_mean=0.500, reward_bound=0.422, batch=229 
6370: loss=0.193, reward_mean=0.440, reward_bound=0.430, batch=219 
6371: loss=0.194, reward_mean=0.400, reward_bound=0.314, batch=222 
6372: loss=0.197, reward_mean=0.360, reward_bound=0.314, batch=224 
6373: loss=0.198, reward_mean=0.410, reward_bound=0.345, batch=227 
6374: loss=0.192, reward_mean=0.490, reward_bound=0.380, batch=229 
6375: loss=0.192, reward_mean=0.400, reward_bound=0.349, batch=229 
6376: loss=0.194, reward_mean=0.470, reward_bound=0.430, batch=225 
6377: loss=0.193, reward_mean=0.490, reward_bound=0.478, batch=209 
6378: loss=0.189, reward_mean=0.410, reward_bound=0.203, batch=216 
6379: loss=0.195, reward_mean=0.410, reward_bound=0.282, batch=220 
6380: loss=0.191, reward_mean=0.390, reward_bound=0.314, batch=220 
6381: loss=0.192, reward_mean=0.420, reward_bound=0.349, batch=221 
6382: loss=0.193, reward_mean=0.470, reward_bound=0.387, batch=219 
6383: loss=0.194, reward_mean=0.420, reward_bound=0.349, batch=221 
6384: loss=0.192, reward_mean=0.350, reward_bound=0.282, batch=224 
6385: loss=0.193, reward_mean=0.390, reward_bound=0.384, batch=227 
6386: loss=0.192, reward_mean=0.430, reward_bound=0.387, batch=225 
6387: loss=0.193, reward_mean=0.440, reward_bound=0.396, batch=227 
6388: loss=0.195, reward_mean=0.530, reward_bound=0.430, batch=217 
6389: loss=0.197, reward_mean=0.350, reward_bound=0.272, batch=222 
6390: loss=0.194, reward_mean=0.460, reward_bound=0.324, batch=225 
6391: loss=0.194, reward_mean=0.460, reward_bound=0.349, batch=223 
6392: loss=0.195, reward_mean=0.390, reward_bound=0.413, batch=226 
6393: loss=0.194, reward_mean=0.440, reward_bound=0.390, batch=228 
6394: loss=0.194, reward_mean=0.470, reward_bound=0.392, batch=229 
6395: loss=0.193, reward_mean=0.360, reward_bound=0.381, batch=230 
6396: loss=0.193, reward_mean=0.450, reward_bound=0.387, batch=230 
6397: loss=0.192, reward_mean=0.480, reward_bound=0.365, batch=231 
6398: loss=0.193, reward_mean=0.350, reward_bound=0.387, batch=230 
6399: loss=0.194, reward_mean=0.520, reward_bound=0.430, batch=226 
6400: loss=0.194, reward_mean=0.450, reward_bound=0.409, batch=228 
6401: loss=0.194, reward_mean=0.370, reward_bound=0.392, batch=229 
6402: loss=0.193, reward_mean=0.440, reward_bound=0.430, batch=227 
6403: loss=0.192, reward_mean=0.470, reward_bound=0.469, batch=229 
6404: loss=0.193, reward_mean=0.460, reward_bound=0.478, batch=231 
6405: loss=0.194, reward_mean=0.460, reward_bound=0.478, batch=219 
6406: loss=0.193, reward_mean=0.410, reward_bound=0.364, batch=223 
6407: loss=0.193, reward_mean=0.510, reward_bound=0.387, batch=223 
6408: loss=0.194, reward_mean=0.530, reward_bound=0.478, batch=223 
6409: loss=0.192, reward_mean=0.440, reward_bound=0.335, batch=226 
6410: loss=0.192, reward_mean=0.490, reward_bound=0.349, batch=227 
6411: loss=0.194, reward_mean=0.420, reward_bound=0.387, batch=227 
6412: loss=0.195, reward_mean=0.460, reward_bound=0.430, batch=225 
6413: loss=0.195, reward_mean=0.470, reward_bound=0.478, batch=226 
6414: loss=0.194, reward_mean=0.500, reward_bound=0.454, batch=228 
6415: loss=0.193, reward_mean=0.410, reward_bound=0.317, batch=229 
6416: loss=0.194, reward_mean=0.440, reward_bound=0.364, batch=230 
6417: loss=0.193, reward_mean=0.400, reward_bound=0.418, batch=231 
6418: loss=0.193, reward_mean=0.330, reward_bound=0.387, batch=231 
6419: loss=0.193, reward_mean=0.390, reward_bound=0.430, batch=231 
6420: loss=0.193, reward_mean=0.410, reward_bound=0.430, batch=231 
6421: loss=0.195, reward_mean=0.480, reward_bound=0.478, batch=228 
6422: loss=0.194, reward_mean=0.380, reward_bound=0.484, batch=229 
6423: loss=0.193, reward_mean=0.440, reward_bound=0.364, batch=230 
6424: loss=0.194, reward_mean=0.420, reward_bound=0.387, batch=230 
6425: loss=0.194, reward_mean=0.490, reward_bound=0.464, batch=231 
6427: loss=0.093, reward_mean=0.420, reward_bound=0.000, batch=42 
6428: loss=0.087, reward_mean=0.380, reward_bound=0.000, batch=80 
6429: loss=0.089, reward_mean=0.360, reward_bound=0.000, batch=116 
6430: loss=0.091, reward_mean=0.490, reward_bound=0.002, batch=150 
6431: loss=0.097, reward_mean=0.430, reward_bound=0.004, batch=175 
6432: loss=0.107, reward_mean=0.400, reward_bound=0.010, batch=190 
6433: loss=0.112, reward_mean=0.440, reward_bound=0.023, batch=202 
6434: loss=0.120, reward_mean=0.410, reward_bound=0.042, batch=202 
6435: loss=0.121, reward_mean=0.420, reward_bound=0.058, batch=209 
6436: loss=0.126, reward_mean=0.470, reward_bound=0.080, batch=209 
6437: loss=0.138, reward_mean=0.450, reward_bound=0.098, batch=212 
6438: loss=0.143, reward_mean=0.460, reward_bound=0.109, batch=205 
6439: loss=0.137, reward_mean=0.440, reward_bound=0.122, batch=210 
6440: loss=0.138, reward_mean=0.460, reward_bound=0.135, batch=212 
6441: loss=0.142, reward_mean=0.420, reward_bound=0.150, batch=200 
6442: loss=0.147, reward_mean=0.460, reward_bound=0.167, batch=194 
6443: loss=0.152, reward_mean=0.520, reward_bound=0.185, batch=190 
6444: loss=0.150, reward_mean=0.440, reward_bound=0.150, batch=202 
6445: loss=0.152, reward_mean=0.420, reward_bound=0.206, batch=212 
6446: loss=0.151, reward_mean=0.400, reward_bound=0.206, batch=223 
6447: loss=0.158, reward_mean=0.400, reward_bound=0.206, batch=209 
6448: loss=0.164, reward_mean=0.370, reward_bound=0.229, batch=183 
6449: loss=0.164, reward_mean=0.540, reward_bound=0.178, batch=198 
6450: loss=0.163, reward_mean=0.400, reward_bound=0.113, batch=208 
6451: loss=0.164, reward_mean=0.440, reward_bound=0.185, batch=213 
6452: loss=0.166, reward_mean=0.420, reward_bound=0.254, batch=189 
6453: loss=0.167, reward_mean=0.420, reward_bound=0.167, batch=200 
6454: loss=0.167, reward_mean=0.400, reward_bound=0.206, batch=211 
6455: loss=0.165, reward_mean=0.470, reward_bound=0.229, batch=215 
6456: loss=0.164, reward_mean=0.320, reward_bound=0.206, batch=219 
6457: loss=0.166, reward_mean=0.460, reward_bound=0.254, batch=221 
6458: loss=0.174, reward_mean=0.380, reward_bound=0.282, batch=178 
6459: loss=0.176, reward_mean=0.360, reward_bound=0.167, batch=193 
6460: loss=0.170, reward_mean=0.390, reward_bound=0.144, batch=205 
6461: loss=0.174, reward_mean=0.460, reward_bound=0.170, batch=213 
6462: loss=0.174, reward_mean=0.410, reward_bound=0.185, batch=217 
6463: loss=0.175, reward_mean=0.410, reward_bound=0.206, batch=221 
6464: loss=0.177, reward_mean=0.450, reward_bound=0.229, batch=223 
6465: loss=0.176, reward_mean=0.450, reward_bound=0.254, batch=222 
6466: loss=0.176, reward_mean=0.450, reward_bound=0.282, batch=217 
6467: loss=0.184, reward_mean=0.420, reward_bound=0.314, batch=181 
6468: loss=0.179, reward_mean=0.430, reward_bound=0.185, batch=196 
6469: loss=0.179, reward_mean=0.450, reward_bound=0.185, batch=203 
6470: loss=0.176, reward_mean=0.400, reward_bound=0.130, batch=212 
6471: loss=0.174, reward_mean=0.450, reward_bound=0.206, batch=223 
6472: loss=0.181, reward_mean=0.350, reward_bound=0.206, batch=223 
6473: loss=0.183, reward_mean=0.440, reward_bound=0.244, batch=226 
6474: loss=0.182, reward_mean=0.500, reward_bound=0.254, batch=223 
6475: loss=0.179, reward_mean=0.390, reward_bound=0.282, batch=225 
6476: loss=0.180, reward_mean=0.430, reward_bound=0.314, batch=225 
6477: loss=0.184, reward_mean=0.440, reward_bound=0.349, batch=173 
6478: loss=0.171, reward_mean=0.410, reward_bound=0.095, batch=191 
6479: loss=0.172, reward_mean=0.400, reward_bound=0.109, batch=202 
6480: loss=0.170, reward_mean=0.390, reward_bound=0.135, batch=208 
6481: loss=0.172, reward_mean=0.400, reward_bound=0.167, batch=210 
6482: loss=0.171, reward_mean=0.400, reward_bound=0.185, batch=211 
6483: loss=0.169, reward_mean=0.380, reward_bound=0.206, batch=215 
6484: loss=0.175, reward_mean=0.510, reward_bound=0.229, batch=216 
6485: loss=0.174, reward_mean=0.380, reward_bound=0.241, batch=221 
6486: loss=0.174, reward_mean=0.540, reward_bound=0.254, batch=221 
6487: loss=0.176, reward_mean=0.470, reward_bound=0.282, batch=223 
6488: loss=0.180, reward_mean=0.370, reward_bound=0.314, batch=215 
6489: loss=0.178, reward_mean=0.420, reward_bound=0.296, batch=220 
6490: loss=0.177, reward_mean=0.400, reward_bound=0.282, batch=222 
6491: loss=0.177, reward_mean=0.350, reward_bound=0.282, batch=224 
6492: loss=0.176, reward_mean=0.430, reward_bound=0.280, batch=227 
6493: loss=0.180, reward_mean=0.420, reward_bound=0.349, batch=219 
6494: loss=0.181, reward_mean=0.450, reward_bound=0.349, batch=221 
6495: loss=0.191, reward_mean=0.370, reward_bound=0.387, batch=143 
6496: loss=0.179, reward_mean=0.400, reward_bound=0.069, batch=170 
6497: loss=0.173, reward_mean=0.440, reward_bound=0.044, batch=189 
6498: loss=0.168, reward_mean=0.360, reward_bound=0.055, batch=202 
6499: loss=0.168, reward_mean=0.410, reward_bound=0.092, batch=211 
6500: loss=0.172, reward_mean=0.340, reward_bound=0.109, batch=212 
6501: loss=0.172, reward_mean=0.460, reward_bound=0.150, batch=214 
6502: loss=0.172, reward_mean=0.390, reward_bound=0.167, batch=217 
6503: loss=0.168, reward_mean=0.420, reward_bound=0.185, batch=217 
6504: loss=0.170, reward_mean=0.350, reward_bound=0.206, batch=217 
6505: loss=0.169, reward_mean=0.470, reward_bound=0.202, batch=222 
6506: loss=0.167, reward_mean=0.410, reward_bound=0.229, batch=222 
6507: loss=0.172, reward_mean=0.480, reward_bound=0.254, batch=218 
6508: loss=0.176, reward_mean=0.420, reward_bound=0.282, batch=211 
6509: loss=0.175, reward_mean=0.500, reward_bound=0.282, batch=217 
6510: loss=0.175, reward_mean=0.350, reward_bound=0.229, batch=220 
6511: loss=0.175, reward_mean=0.430, reward_bound=0.282, batch=222 
6512: loss=0.184, reward_mean=0.510, reward_bound=0.314, batch=203 
6513: loss=0.182, reward_mean=0.460, reward_bound=0.229, batch=211 
6514: loss=0.181, reward_mean=0.450, reward_bound=0.229, batch=216 
6515: loss=0.180, reward_mean=0.380, reward_bound=0.241, batch=221 
6516: loss=0.181, reward_mean=0.460, reward_bound=0.282, batch=222 
6517: loss=0.181, reward_mean=0.400, reward_bound=0.292, batch=225 
6518: loss=0.182, reward_mean=0.450, reward_bound=0.289, batch=227 
6519: loss=0.181, reward_mean=0.410, reward_bound=0.314, batch=227 
6520: loss=0.182, reward_mean=0.340, reward_bound=0.349, batch=203 
6521: loss=0.189, reward_mean=0.460, reward_bound=0.282, batch=211 
6522: loss=0.187, reward_mean=0.360, reward_bound=0.206, batch=216 
6523: loss=0.185, reward_mean=0.430, reward_bound=0.314, batch=215 
6524: loss=0.186, reward_mean=0.370, reward_bound=0.321, batch=220 
6525: loss=0.182, reward_mean=0.420, reward_bound=0.349, batch=218 
6526: loss=0.181, reward_mean=0.460, reward_bound=0.314, batch=221 
6527: loss=0.182, reward_mean=0.510, reward_bound=0.387, batch=200 
6528: loss=0.178, reward_mean=0.370, reward_bound=0.200, batch=210 
6529: loss=0.177, reward_mean=0.460, reward_bound=0.229, batch=216 
6530: loss=0.177, reward_mean=0.360, reward_bound=0.254, batch=218 
6531: loss=0.179, reward_mean=0.460, reward_bound=0.314, batch=219 
6532: loss=0.181, reward_mean=0.540, reward_bound=0.349, batch=214 
6533: loss=0.179, reward_mean=0.420, reward_bound=0.249, batch=220 
6534: loss=0.180, reward_mean=0.420, reward_bound=0.254, batch=222 
6535: loss=0.179, reward_mean=0.450, reward_bound=0.282, batch=224 
6536: loss=0.178, reward_mean=0.440, reward_bound=0.349, batch=225 
6537: loss=0.180, reward_mean=0.520, reward_bound=0.387, batch=216 
6538: loss=0.178, reward_mean=0.530, reward_bound=0.314, batch=220 
6539: loss=0.178, reward_mean=0.490, reward_bound=0.222, batch=224 
6540: loss=0.177, reward_mean=0.390, reward_bound=0.349, batch=224 
6541: loss=0.177, reward_mean=0.400, reward_bound=0.254, batch=226 
6542: loss=0.179, reward_mean=0.380, reward_bound=0.387, batch=225 
6543: loss=0.180, reward_mean=0.390, reward_bound=0.396, batch=227 
6544: loss=0.180, reward_mean=0.410, reward_bound=0.387, batch=228 
6545: loss=0.179, reward_mean=0.500, reward_bound=0.392, batch=229 
6546: loss=0.168, reward_mean=0.370, reward_bound=0.430, batch=121 
6547: loss=0.130, reward_mean=0.390, reward_bound=0.006, batch=153 
6548: loss=0.130, reward_mean=0.380, reward_bound=0.018, batch=177 
6549: loss=0.135, reward_mean=0.480, reward_bound=0.052, batch=190 
6550: loss=0.137, reward_mean=0.430, reward_bound=0.072, batch=200 
6551: loss=0.141, reward_mean=0.370, reward_bound=0.106, batch=210 
6552: loss=0.143, reward_mean=0.530, reward_bound=0.122, batch=216 
6553: loss=0.148, reward_mean=0.480, reward_bound=0.135, batch=219 
6554: loss=0.149, reward_mean=0.410, reward_bound=0.157, batch=223 
6555: loss=0.145, reward_mean=0.390, reward_bound=0.167, batch=224 
6556: loss=0.146, reward_mean=0.390, reward_bound=0.185, batch=217 
6557: loss=0.141, reward_mean=0.480, reward_bound=0.206, batch=219 
6558: loss=0.143, reward_mean=0.480, reward_bound=0.229, batch=219 
6559: loss=0.149, reward_mean=0.470, reward_bound=0.254, batch=209 
6560: loss=0.151, reward_mean=0.420, reward_bound=0.239, batch=216 
6561: loss=0.148, reward_mean=0.380, reward_bound=0.254, batch=220 
6562: loss=0.148, reward_mean=0.390, reward_bound=0.274, batch=224 
6563: loss=0.150, reward_mean=0.390, reward_bound=0.282, batch=209 
6564: loss=0.148, reward_mean=0.400, reward_bound=0.174, batch=216 
6565: loss=0.147, reward_mean=0.520, reward_bound=0.229, batch=220 
6566: loss=0.153, reward_mean=0.420, reward_bound=0.314, batch=197 
6567: loss=0.149, reward_mean=0.410, reward_bound=0.202, batch=208 
6568: loss=0.144, reward_mean=0.480, reward_bound=0.206, batch=212 
6569: loss=0.145, reward_mean=0.440, reward_bound=0.229, batch=216 
6570: loss=0.148, reward_mean=0.410, reward_bound=0.254, batch=218 
6571: loss=0.151, reward_mean=0.490, reward_bound=0.282, batch=215 
6572: loss=0.149, reward_mean=0.360, reward_bound=0.282, batch=219 
6573: loss=0.151, reward_mean=0.470, reward_bound=0.314, batch=220 
6574: loss=0.150, reward_mean=0.370, reward_bound=0.240, batch=224 
6575: loss=0.158, reward_mean=0.490, reward_bound=0.349, batch=192 
6576: loss=0.159, reward_mean=0.450, reward_bound=0.229, batch=203 
6577: loss=0.154, reward_mean=0.520, reward_bound=0.244, batch=212 
6578: loss=0.155, reward_mean=0.480, reward_bound=0.282, batch=212 
6579: loss=0.155, reward_mean=0.470, reward_bound=0.314, batch=213 
6580: loss=0.154, reward_mean=0.390, reward_bound=0.229, batch=218 
6581: loss=0.154, reward_mean=0.440, reward_bound=0.257, batch=222 
6582: loss=0.155, reward_mean=0.410, reward_bound=0.282, batch=221 
6583: loss=0.154, reward_mean=0.430, reward_bound=0.314, batch=223 
6584: loss=0.153, reward_mean=0.440, reward_bound=0.271, batch=226 
6585: loss=0.154, reward_mean=0.450, reward_bound=0.314, batch=224 
6586: loss=0.154, reward_mean=0.420, reward_bound=0.345, batch=227 
6587: loss=0.154, reward_mean=0.390, reward_bound=0.314, batch=228 
6588: loss=0.155, reward_mean=0.470, reward_bound=0.349, batch=222 
6589: loss=0.159, reward_mean=0.490, reward_bound=0.387, batch=192 
6590: loss=0.155, reward_mean=0.420, reward_bound=0.185, batch=203 
6591: loss=0.155, reward_mean=0.390, reward_bound=0.198, batch=212 
6592: loss=0.152, reward_mean=0.460, reward_bound=0.213, batch=218 
6593: loss=0.154, reward_mean=0.420, reward_bound=0.254, batch=220 
6594: loss=0.154, reward_mean=0.430, reward_bound=0.266, batch=224 
6595: loss=0.155, reward_mean=0.480, reward_bound=0.282, batch=221 
6596: loss=0.158, reward_mean=0.490, reward_bound=0.314, batch=221 
6597: loss=0.158, reward_mean=0.450, reward_bound=0.349, batch=213 
6598: loss=0.154, reward_mean=0.490, reward_bound=0.244, batch=219 
6599: loss=0.154, reward_mean=0.550, reward_bound=0.265, batch=223 
6600: loss=0.155, reward_mean=0.540, reward_bound=0.301, batch=226 
6601: loss=0.156, reward_mean=0.450, reward_bound=0.331, batch=228 
6602: loss=0.156, reward_mean=0.510, reward_bound=0.349, batch=226 
6603: loss=0.156, reward_mean=0.560, reward_bound=0.387, batch=218 
6604: loss=0.156, reward_mean=0.530, reward_bound=0.349, batch=221 
6605: loss=0.156, reward_mean=0.370, reward_bound=0.282, batch=224 
6606: loss=0.155, reward_mean=0.500, reward_bound=0.426, batch=227 
6607: loss=0.160, reward_mean=0.420, reward_bound=0.430, batch=180 
6608: loss=0.155, reward_mean=0.450, reward_bound=0.167, batch=195 
6609: loss=0.157, reward_mean=0.490, reward_bound=0.138, batch=206 
6610: loss=0.157, reward_mean=0.440, reward_bound=0.176, batch=214 
6611: loss=0.156, reward_mean=0.450, reward_bound=0.206, batch=215 
6612: loss=0.154, reward_mean=0.350, reward_bound=0.229, batch=217 
6613: loss=0.160, reward_mean=0.490, reward_bound=0.282, batch=218 
6614: loss=0.160, reward_mean=0.500, reward_bound=0.314, batch=209 
6615: loss=0.156, reward_mean=0.390, reward_bound=0.254, batch=215 
6616: loss=0.158, reward_mean=0.410, reward_bound=0.282, batch=219 
6617: loss=0.158, reward_mean=0.450, reward_bound=0.349, batch=208 
6618: loss=0.157, reward_mean=0.400, reward_bound=0.214, batch=215 
6619: loss=0.158, reward_mean=0.470, reward_bound=0.282, batch=215 
6620: loss=0.158, reward_mean=0.500, reward_bound=0.314, batch=218 
6621: loss=0.157, reward_mean=0.430, reward_bound=0.314, batch=221 
6622: loss=0.156, reward_mean=0.430, reward_bound=0.349, batch=220 
6623: loss=0.155, reward_mean=0.340, reward_bound=0.274, batch=224 
6624: loss=0.157, reward_mean=0.410, reward_bound=0.311, batch=227 
6625: loss=0.154, reward_mean=0.450, reward_bound=0.349, batch=227 
6626: loss=0.160, reward_mean=0.360, reward_bound=0.387, batch=208 
6627: loss=0.156, reward_mean=0.460, reward_bound=0.286, batch=215 
6628: loss=0.158, reward_mean=0.400, reward_bound=0.314, batch=214 
6629: loss=0.157, reward_mean=0.460, reward_bound=0.311, batch=220 
6630: loss=0.158, reward_mean=0.540, reward_bound=0.274, batch=224 
6631: loss=0.158, reward_mean=0.500, reward_bound=0.349, batch=221 
6632: loss=0.157, reward_mean=0.410, reward_bound=0.349, batch=224 
6633: loss=0.157, reward_mean=0.520, reward_bound=0.349, batch=224 
6634: loss=0.159, reward_mean=0.490, reward_bound=0.387, batch=220 
6635: loss=0.160, reward_mean=0.450, reward_bound=0.406, batch=224 
6636: loss=0.159, reward_mean=0.450, reward_bound=0.387, batch=225 
6637: loss=0.159, reward_mean=0.450, reward_bound=0.396, batch=227 
6638: loss=0.156, reward_mean=0.450, reward_bound=0.430, batch=206 
6639: loss=0.156, reward_mean=0.470, reward_bound=0.220, batch=214 
6640: loss=0.156, reward_mean=0.460, reward_bound=0.254, batch=216 
6641: loss=0.156, reward_mean=0.450, reward_bound=0.207, batch=221 
6642: loss=0.157, reward_mean=0.530, reward_bound=0.349, batch=220 
6643: loss=0.158, reward_mean=0.450, reward_bound=0.329, batch=224 
6644: loss=0.156, reward_mean=0.340, reward_bound=0.305, batch=227 
6645: loss=0.156, reward_mean=0.490, reward_bound=0.380, batch=229 
6646: loss=0.153, reward_mean=0.480, reward_bound=0.387, batch=224 
6647: loss=0.152, reward_mean=0.510, reward_bound=0.422, batch=227 
6648: loss=0.152, reward_mean=0.420, reward_bound=0.422, batch=229 
6649: loss=0.154, reward_mean=0.600, reward_bound=0.430, batch=215 
6650: loss=0.154, reward_mean=0.510, reward_bound=0.356, batch=220 
6651: loss=0.156, reward_mean=0.460, reward_bound=0.282, batch=222 
6652: loss=0.155, reward_mean=0.520, reward_bound=0.292, batch=225 
6653: loss=0.153, reward_mean=0.470, reward_bound=0.356, batch=227 
6654: loss=0.154, reward_mean=0.450, reward_bound=0.387, batch=225 
6655: loss=0.154, reward_mean=0.450, reward_bound=0.430, batch=223 
6656: loss=0.154, reward_mean=0.450, reward_bound=0.413, batch=226 
6657: loss=0.154, reward_mean=0.460, reward_bound=0.430, batch=227 
6658: loss=0.155, reward_mean=0.500, reward_bound=0.422, batch=229 
6659: loss=0.154, reward_mean=0.480, reward_bound=0.405, batch=230 
6660: loss=0.155, reward_mean=0.390, reward_bound=0.430, batch=228 
6661: loss=0.155, reward_mean=0.510, reward_bound=0.430, batch=228 
6662: loss=0.157, reward_mean=0.450, reward_bound=0.392, batch=229 
6663: loss=0.156, reward_mean=0.390, reward_bound=0.450, batch=230 
6664: loss=0.173, reward_mean=0.500, reward_bound=0.478, batch=95 
6665: loss=0.121, reward_mean=0.440, reward_bound=0.001, batch=136 
6666: loss=0.118, reward_mean=0.450, reward_bound=0.018, batch=164 
6667: loss=0.118, reward_mean=0.400, reward_bound=0.031, batch=182 
6668: loss=0.118, reward_mean=0.460, reward_bound=0.052, batch=195 
6669: loss=0.119, reward_mean=0.450, reward_bound=0.066, batch=206 
6670: loss=0.122, reward_mean=0.460, reward_bound=0.089, batch=205 
6671: loss=0.125, reward_mean=0.460, reward_bound=0.109, batch=218 
6672: loss=0.131, reward_mean=0.500, reward_bound=0.122, batch=216 
6673: loss=0.141, reward_mean=0.450, reward_bound=0.150, batch=212 
6674: loss=0.142, reward_mean=0.500, reward_bound=0.167, batch=215 
6675: loss=0.141, reward_mean=0.390, reward_bound=0.185, batch=211 
6676: loss=0.142, reward_mean=0.470, reward_bound=0.206, batch=207 
6677: loss=0.143, reward_mean=0.490, reward_bound=0.229, batch=201 
6678: loss=0.140, reward_mean=0.490, reward_bound=0.150, batch=209 
6679: loss=0.142, reward_mean=0.490, reward_bound=0.206, batch=211 
6680: loss=0.141, reward_mean=0.490, reward_bound=0.254, batch=202 
6681: loss=0.142, reward_mean=0.560, reward_bound=0.229, batch=209 
6682: loss=0.140, reward_mean=0.510, reward_bound=0.229, batch=214 
6683: loss=0.138, reward_mean=0.460, reward_bound=0.254, batch=213 
6684: loss=0.145, reward_mean=0.520, reward_bound=0.282, batch=196 
6685: loss=0.145, reward_mean=0.470, reward_bound=0.150, batch=206 
6686: loss=0.141, reward_mean=0.560, reward_bound=0.217, batch=214 
6687: loss=0.140, reward_mean=0.460, reward_bound=0.254, batch=217 
6688: loss=0.142, reward_mean=0.460, reward_bound=0.282, batch=216 
6689: loss=0.149, reward_mean=0.460, reward_bound=0.314, batch=190 
6690: loss=0.148, reward_mean=0.500, reward_bound=0.175, batch=203 
6691: loss=0.152, reward_mean=0.530, reward_bound=0.206, batch=211 
6692: loss=0.155, reward_mean=0.510, reward_bound=0.254, batch=209 
6693: loss=0.151, reward_mean=0.540, reward_bound=0.282, batch=213 
6694: loss=0.151, reward_mean=0.390, reward_bound=0.282, batch=218 
6695: loss=0.153, reward_mean=0.450, reward_bound=0.314, batch=215 
6696: loss=0.154, reward_mean=0.420, reward_bound=0.282, batch=219 
6697: loss=0.159, reward_mean=0.470, reward_bound=0.349, batch=179 
6698: loss=0.153, reward_mean=0.510, reward_bound=0.114, batch=195 
6699: loss=0.155, reward_mean=0.470, reward_bound=0.185, batch=203 
6700: loss=0.160, reward_mean=0.500, reward_bound=0.229, batch=210 
6701: loss=0.159, reward_mean=0.570, reward_bound=0.274, batch=217 
6702: loss=0.157, reward_mean=0.430, reward_bound=0.224, batch=222 
6703: loss=0.159, reward_mean=0.550, reward_bound=0.254, batch=224 
6704: loss=0.159, reward_mean=0.460, reward_bound=0.282, batch=217 
6705: loss=0.157, reward_mean=0.380, reward_bound=0.308, batch=222 
6706: loss=0.157, reward_mean=0.530, reward_bound=0.314, batch=218 
6707: loss=0.158, reward_mean=0.450, reward_bound=0.314, batch=221 
6708: loss=0.159, reward_mean=0.510, reward_bound=0.314, batch=224 
6709: loss=0.158, reward_mean=0.360, reward_bound=0.314, batch=226 
6710: loss=0.157, reward_mean=0.490, reward_bound=0.349, batch=217 
6711: loss=0.155, reward_mean=0.410, reward_bound=0.249, batch=222 
6712: loss=0.155, reward_mean=0.450, reward_bound=0.360, batch=225 
6713: loss=0.165, reward_mean=0.460, reward_bound=0.387, batch=183 
6714: loss=0.161, reward_mean=0.510, reward_bound=0.150, batch=196 
6715: loss=0.156, reward_mean=0.320, reward_bound=0.128, batch=207 
6716: loss=0.157, reward_mean=0.450, reward_bound=0.150, batch=213 
6717: loss=0.155, reward_mean=0.440, reward_bound=0.206, batch=217 
6718: loss=0.160, reward_mean=0.400, reward_bound=0.229, batch=216 
6719: loss=0.162, reward_mean=0.480, reward_bound=0.282, batch=215 
6720: loss=0.161, reward_mean=0.410, reward_bound=0.282, batch=219 
6721: loss=0.162, reward_mean=0.480, reward_bound=0.295, batch=223 
6722: loss=0.161, reward_mean=0.410, reward_bound=0.282, batch=225 
6723: loss=0.164, reward_mean=0.520, reward_bound=0.314, batch=218 
6724: loss=0.163, reward_mean=0.460, reward_bound=0.286, batch=222 
6725: loss=0.163, reward_mean=0.530, reward_bound=0.324, batch=225 
6726: loss=0.166, reward_mean=0.470, reward_bound=0.349, batch=214 
6727: loss=0.164, reward_mean=0.390, reward_bound=0.206, batch=218 
6728: loss=0.164, reward_mean=0.460, reward_bound=0.387, batch=214 
6729: loss=0.162, reward_mean=0.520, reward_bound=0.314, batch=219 
6730: loss=0.160, reward_mean=0.440, reward_bound=0.314, batch=222 
6731: loss=0.161, reward_mean=0.390, reward_bound=0.349, batch=222 
6732: loss=0.159, reward_mean=0.410, reward_bound=0.229, batch=224 
6733: loss=0.159, reward_mean=0.420, reward_bound=0.282, batch=226 
6734: loss=0.161, reward_mean=0.440, reward_bound=0.387, batch=223 
6735: loss=0.161, reward_mean=0.560, reward_bound=0.372, batch=226 
6736: loss=0.161, reward_mean=0.460, reward_bound=0.387, batch=227 
6737: loss=0.161, reward_mean=0.470, reward_bound=0.387, batch=227 
6738: loss=0.162, reward_mean=0.440, reward_bound=0.430, batch=170 
6739: loss=0.160, reward_mean=0.490, reward_bound=0.229, batch=188 
6740: loss=0.159, reward_mean=0.420, reward_bound=0.167, batch=200 
6741: loss=0.158, reward_mean=0.430, reward_bound=0.162, batch=210 
6742: loss=0.158, reward_mean=0.500, reward_bound=0.229, batch=216 
6743: loss=0.152, reward_mean=0.500, reward_bound=0.254, batch=212 
6744: loss=0.151, reward_mean=0.400, reward_bound=0.263, batch=218 
6745: loss=0.155, reward_mean=0.480, reward_bound=0.282, batch=219 
6746: loss=0.154, reward_mean=0.500, reward_bound=0.314, batch=211 
6747: loss=0.153, reward_mean=0.310, reward_bound=0.254, batch=217 
6748: loss=0.157, reward_mean=0.400, reward_bound=0.229, batch=221 
6749: loss=0.156, reward_mean=0.520, reward_bound=0.282, batch=223 
6750: loss=0.159, reward_mean=0.490, reward_bound=0.349, batch=216 
6751: loss=0.160, reward_mean=0.460, reward_bound=0.282, batch=220 
6752: loss=0.159, reward_mean=0.490, reward_bound=0.254, batch=222 
6753: loss=0.159, reward_mean=0.470, reward_bound=0.314, batch=224 
6754: loss=0.159, reward_mean=0.410, reward_bound=0.314, batch=226 
6755: loss=0.159, reward_mean=0.490, reward_bound=0.331, batch=228 
6756: loss=0.159, reward_mean=0.510, reward_bound=0.387, batch=207 
6757: loss=0.156, reward_mean=0.470, reward_bound=0.206, batch=214 
6758: loss=0.159, reward_mean=0.430, reward_bound=0.229, batch=218 
6759: loss=0.157, reward_mean=0.540, reward_bound=0.254, batch=221 
6760: loss=0.158, reward_mean=0.540, reward_bound=0.314, batch=221 
6761: loss=0.158, reward_mean=0.420, reward_bound=0.282, batch=224 
6762: loss=0.158, reward_mean=0.490, reward_bound=0.314, batch=226 
6763: loss=0.158, reward_mean=0.340, reward_bound=0.349, batch=223 
6764: loss=0.159, reward_mean=0.510, reward_bound=0.387, batch=218 
6765: loss=0.158, reward_mean=0.520, reward_bound=0.289, batch=222 
6766: loss=0.158, reward_mean=0.470, reward_bound=0.314, batch=224 
6767: loss=0.157, reward_mean=0.350, reward_bound=0.349, batch=226 
6768: loss=0.156, reward_mean=0.420, reward_bound=0.368, batch=228 
6769: loss=0.156, reward_mean=0.400, reward_bound=0.392, batch=229 
6770: loss=0.156, reward_mean=0.430, reward_bound=0.314, batch=229 
6771: loss=0.160, reward_mean=0.350, reward_bound=0.430, batch=203 
6772: loss=0.160, reward_mean=0.430, reward_bound=0.198, batch=212 
6773: loss=0.156, reward_mean=0.470, reward_bound=0.206, batch=221 
6774: loss=0.159, reward_mean=0.410, reward_bound=0.206, batch=223 
6775: loss=0.157, reward_mean=0.440, reward_bound=0.254, batch=225 
6776: loss=0.159, reward_mean=0.450, reward_bound=0.282, batch=225 
6777: loss=0.159, reward_mean=0.480, reward_bound=0.260, batch=227 
6778: loss=0.159, reward_mean=0.440, reward_bound=0.349, batch=221 
6779: loss=0.157, reward_mean=0.470, reward_bound=0.282, batch=224 
6780: loss=0.157, reward_mean=0.540, reward_bound=0.349, batch=226 
6781: loss=0.158, reward_mean=0.430, reward_bound=0.351, batch=228 
6782: loss=0.158, reward_mean=0.440, reward_bound=0.387, batch=217 
6783: loss=0.159, reward_mean=0.490, reward_bound=0.249, batch=222 
6784: loss=0.159, reward_mean=0.390, reward_bound=0.314, batch=223 
6785: loss=0.157, reward_mean=0.400, reward_bound=0.349, batch=225 
6786: loss=0.157, reward_mean=0.390, reward_bound=0.387, batch=225 
6787: loss=0.160, reward_mean=0.540, reward_bound=0.430, batch=214 
6788: loss=0.158, reward_mean=0.570, reward_bound=0.311, batch=220 
6789: loss=0.160, reward_mean=0.420, reward_bound=0.314, batch=223 
6790: loss=0.159, reward_mean=0.550, reward_bound=0.349, batch=224 
6791: loss=0.158, reward_mean=0.430, reward_bound=0.387, batch=224 
6792: loss=0.157, reward_mean=0.390, reward_bound=0.377, batch=227 
6793: loss=0.157, reward_mean=0.500, reward_bound=0.387, batch=227 
6794: loss=0.158, reward_mean=0.460, reward_bound=0.430, batch=226 
6795: loss=0.157, reward_mean=0.410, reward_bound=0.256, batch=228 
6796: loss=0.158, reward_mean=0.390, reward_bound=0.430, batch=227 
6797: loss=0.158, reward_mean=0.520, reward_bound=0.387, batch=228 
6798: loss=0.159, reward_mean=0.500, reward_bound=0.435, batch=229 
6799: loss=0.159, reward_mean=0.490, reward_bound=0.450, batch=230 
6800: loss=0.158, reward_mean=0.490, reward_bound=0.464, batch=231 
6801: loss=0.172, reward_mean=0.490, reward_bound=0.478, batch=151 
6802: loss=0.157, reward_mean=0.470, reward_bound=0.072, batch=174 
6803: loss=0.155, reward_mean=0.430, reward_bound=0.080, batch=190 
6804: loss=0.158, reward_mean=0.450, reward_bound=0.098, batch=201 
6805: loss=0.164, reward_mean=0.460, reward_bound=0.135, batch=210 
6806: loss=0.165, reward_mean=0.450, reward_bound=0.162, batch=217 
6807: loss=0.166, reward_mean=0.420, reward_bound=0.167, batch=221 
6808: loss=0.163, reward_mean=0.360, reward_bound=0.206, batch=218 
6809: loss=0.170, reward_mean=0.470, reward_bound=0.229, batch=218 
6810: loss=0.181, reward_mean=0.520, reward_bound=0.254, batch=220 
6811: loss=0.182, reward_mean=0.360, reward_bound=0.282, batch=211 
6812: loss=0.181, reward_mean=0.470, reward_bound=0.282, batch=216 
6813: loss=0.178, reward_mean=0.430, reward_bound=0.206, batch=220 
6814: loss=0.176, reward_mean=0.490, reward_bound=0.304, batch=224 
6815: loss=0.178, reward_mean=0.440, reward_bound=0.314, batch=221 
6816: loss=0.183, reward_mean=0.380, reward_bound=0.349, batch=209 
6817: loss=0.179, reward_mean=0.470, reward_bound=0.174, batch=216 
6818: loss=0.179, reward_mean=0.500, reward_bound=0.298, batch=221 
6819: loss=0.179, reward_mean=0.310, reward_bound=0.314, batch=222 
6820: loss=0.179, reward_mean=0.500, reward_bound=0.349, batch=222 
6821: loss=0.180, reward_mean=0.440, reward_bound=0.314, batch=224 
6822: loss=0.178, reward_mean=0.450, reward_bound=0.349, batch=226 
6823: loss=0.177, reward_mean=0.410, reward_bound=0.368, batch=228 
6824: loss=0.168, reward_mean=0.450, reward_bound=0.387, batch=192 
6825: loss=0.164, reward_mean=0.450, reward_bound=0.161, batch=204 
6826: loss=0.165, reward_mean=0.410, reward_bound=0.204, batch=213 
6827: loss=0.169, reward_mean=0.480, reward_bound=0.206, batch=212 
6828: loss=0.166, reward_mean=0.460, reward_bound=0.254, batch=213 
6829: loss=0.162, reward_mean=0.390, reward_bound=0.198, batch=219 
6830: loss=0.167, reward_mean=0.450, reward_bound=0.282, batch=216 
6831: loss=0.164, reward_mean=0.450, reward_bound=0.314, batch=214 
6832: loss=0.165, reward_mean=0.480, reward_bound=0.226, batch=220 
6833: loss=0.164, reward_mean=0.300, reward_bound=0.229, batch=223 
6834: loss=0.165, reward_mean=0.420, reward_bound=0.282, batch=225 
6835: loss=0.165, reward_mean=0.480, reward_bound=0.349, batch=219 
6836: loss=0.165, reward_mean=0.420, reward_bound=0.328, batch=223 
6837: loss=0.164, reward_mean=0.400, reward_bound=0.387, batch=214 
6838: loss=0.163, reward_mean=0.510, reward_bound=0.229, batch=219 
6839: loss=0.163, reward_mean=0.440, reward_bound=0.295, batch=223 
6840: loss=0.164, reward_mean=0.390, reward_bound=0.290, batch=226 
6841: loss=0.163, reward_mean=0.460, reward_bound=0.331, batch=228 
6842: loss=0.166, reward_mean=0.510, reward_bound=0.387, batch=224 
6843: loss=0.165, reward_mean=0.440, reward_bound=0.345, batch=227 
6844: loss=0.166, reward_mean=0.440, reward_bound=0.349, batch=227 
6845: loss=0.165, reward_mean=0.470, reward_bound=0.387, batch=227 
6846: loss=0.166, reward_mean=0.460, reward_bound=0.430, batch=196 
6847: loss=0.164, reward_mean=0.490, reward_bound=0.135, batch=206 
6848: loss=0.163, reward_mean=0.490, reward_bound=0.217, batch=214 
6849: loss=0.165, reward_mean=0.450, reward_bound=0.229, batch=218 
6850: loss=0.164, reward_mean=0.330, reward_bound=0.254, batch=216 
6851: loss=0.166, reward_mean=0.390, reward_bound=0.282, batch=214 
6852: loss=0.167, reward_mean=0.410, reward_bound=0.252, batch=220 
6853: loss=0.165, reward_mean=0.410, reward_bound=0.254, batch=223 
6854: loss=0.165, reward_mean=0.470, reward_bound=0.314, batch=223 
6855: loss=0.167, reward_mean=0.470, reward_bound=0.349, batch=221 
6856: loss=0.166, reward_mean=0.540, reward_bound=0.349, batch=222 
6857: loss=0.166, reward_mean=0.440, reward_bound=0.349, batch=224 
6858: loss=0.165, reward_mean=0.450, reward_bound=0.254, batch=226 
6859: loss=0.166, reward_mean=0.500, reward_bound=0.349, batch=226 
6860: loss=0.163, reward_mean=0.540, reward_bound=0.387, batch=214 
6861: loss=0.161, reward_mean=0.530, reward_bound=0.311, batch=220 
6862: loss=0.162, reward_mean=0.440, reward_bound=0.254, batch=223 
6863: loss=0.160, reward_mean=0.420, reward_bound=0.314, batch=224 
6864: loss=0.161, reward_mean=0.450, reward_bound=0.311, batch=227 
6865: loss=0.160, reward_mean=0.480, reward_bound=0.314, batch=226 
6866: loss=0.162, reward_mean=0.440, reward_bound=0.387, batch=223 
6867: loss=0.161, reward_mean=0.480, reward_bound=0.413, batch=226 
6868: loss=0.163, reward_mean=0.500, reward_bound=0.351, batch=228 
6869: loss=0.161, reward_mean=0.500, reward_bound=0.387, batch=227 
6870: loss=0.166, reward_mean=0.520, reward_bound=0.430, batch=211 
6871: loss=0.166, reward_mean=0.490, reward_bound=0.314, batch=216 
6872: loss=0.164, reward_mean=0.350, reward_bound=0.284, batch=221 
6873: loss=0.164, reward_mean=0.420, reward_bound=0.349, batch=222 
6874: loss=0.166, reward_mean=0.490, reward_bound=0.387, batch=223 
6875: loss=0.165, reward_mean=0.430, reward_bound=0.413, batch=226 
6876: loss=0.164, reward_mean=0.470, reward_bound=0.387, batch=227 
6877: loss=0.164, reward_mean=0.440, reward_bound=0.422, batch=229 
6878: loss=0.165, reward_mean=0.440, reward_bound=0.430, batch=222 
6879: loss=0.166, reward_mean=0.460, reward_bound=0.292, batch=225 
6880: loss=0.167, reward_mean=0.480, reward_bound=0.266, batch=227 
6881: loss=0.164, reward_mean=0.480, reward_bound=0.314, batch=227 
6882: loss=0.164, reward_mean=0.460, reward_bound=0.380, batch=229 
6883: loss=0.165, reward_mean=0.420, reward_bound=0.405, batch=230 
6884: loss=0.164, reward_mean=0.440, reward_bound=0.430, batch=227 
6885: loss=0.164, reward_mean=0.480, reward_bound=0.380, batch=229 
6886: loss=0.163, reward_mean=0.410, reward_bound=0.405, batch=230 
6887: loss=0.163, reward_mean=0.450, reward_bound=0.387, batch=230 
6888: loss=0.164, reward_mean=0.460, reward_bound=0.430, batch=229 
6889: loss=0.164, reward_mean=0.380, reward_bound=0.450, batch=230 
6890: loss=0.164, reward_mean=0.490, reward_bound=0.430, batch=230 
6891: loss=0.164, reward_mean=0.490, reward_bound=0.430, batch=230 
6892: loss=0.170, reward_mean=0.470, reward_bound=0.478, batch=182 
6893: loss=0.167, reward_mean=0.450, reward_bound=0.213, batch=197 
6894: loss=0.165, reward_mean=0.410, reward_bound=0.185, batch=207 
6895: loss=0.164, reward_mean=0.460, reward_bound=0.206, batch=214 
6896: loss=0.161, reward_mean=0.390, reward_bound=0.165, batch=220 
6897: loss=0.161, reward_mean=0.460, reward_bound=0.229, batch=223 
6898: loss=0.172, reward_mean=0.440, reward_bound=0.282, batch=215 
6899: loss=0.173, reward_mean=0.460, reward_bound=0.240, batch=220 
6900: loss=0.171, reward_mean=0.400, reward_bound=0.314, batch=220 
6901: loss=0.170, reward_mean=0.440, reward_bound=0.314, batch=223 
6902: loss=0.172, reward_mean=0.380, reward_bound=0.349, batch=219 
6903: loss=0.171, reward_mean=0.470, reward_bound=0.387, batch=215 
6904: loss=0.172, reward_mean=0.490, reward_bound=0.282, batch=219 
6905: loss=0.171, reward_mean=0.460, reward_bound=0.328, batch=223 
6906: loss=0.169, reward_mean=0.480, reward_bound=0.349, batch=222 
6907: loss=0.170, reward_mean=0.360, reward_bound=0.220, batch=225 
6908: loss=0.171, reward_mean=0.400, reward_bound=0.254, batch=226 
6909: loss=0.170, reward_mean=0.350, reward_bound=0.316, batch=228 
6910: loss=0.171, reward_mean=0.480, reward_bound=0.387, batch=227 
6911: loss=0.170, reward_mean=0.510, reward_bound=0.422, batch=229 
6912: loss=0.172, reward_mean=0.480, reward_bound=0.343, batch=230 
6913: loss=0.171, reward_mean=0.410, reward_bound=0.376, batch=231 
6914: loss=0.166, reward_mean=0.450, reward_bound=0.430, batch=214 
6915: loss=0.166, reward_mean=0.480, reward_bound=0.380, batch=220 
6916: loss=0.167, reward_mean=0.490, reward_bound=0.329, batch=224 
6917: loss=0.166, reward_mean=0.440, reward_bound=0.305, batch=227 
6918: loss=0.166, reward_mean=0.460, reward_bound=0.380, batch=229 
6919: loss=0.164, reward_mean=0.510, reward_bound=0.430, batch=225 
6920: loss=0.163, reward_mean=0.460, reward_bound=0.321, batch=227 
6921: loss=0.163, reward_mean=0.360, reward_bound=0.349, batch=227 
6922: loss=0.163, reward_mean=0.520, reward_bound=0.422, batch=229 
6923: loss=0.163, reward_mean=0.480, reward_bound=0.430, batch=227 
6924: loss=0.168, reward_mean=0.510, reward_bound=0.478, batch=203 
6925: loss=0.166, reward_mean=0.530, reward_bound=0.252, batch=212 
6926: loss=0.165, reward_mean=0.490, reward_bound=0.263, batch=218 
6927: loss=0.165, reward_mean=0.420, reward_bound=0.282, batch=220 
6928: loss=0.162, reward_mean=0.500, reward_bound=0.314, batch=220 
6929: loss=0.166, reward_mean=0.500, reward_bound=0.314, batch=223 
6930: loss=0.166, reward_mean=0.480, reward_bound=0.349, batch=223 
6931: loss=0.165, reward_mean=0.480, reward_bound=0.314, batch=224 
6932: loss=0.165, reward_mean=0.420, reward_bound=0.349, batch=226 
6933: loss=0.165, reward_mean=0.530, reward_bound=0.349, batch=227 
6934: loss=0.164, reward_mean=0.470, reward_bound=0.380, batch=229 
6935: loss=0.168, reward_mean=0.400, reward_bound=0.387, batch=218 
6936: loss=0.166, reward_mean=0.460, reward_bound=0.260, batch=222 
6937: loss=0.164, reward_mean=0.430, reward_bound=0.292, batch=225 
6938: loss=0.163, reward_mean=0.460, reward_bound=0.289, batch=227 
6939: loss=0.165, reward_mean=0.490, reward_bound=0.314, batch=225 
6940: loss=0.164, reward_mean=0.490, reward_bound=0.356, batch=227 
6941: loss=0.165, reward_mean=0.430, reward_bound=0.330, batch=229 
6942: loss=0.168, reward_mean=0.410, reward_bound=0.387, batch=222 
6943: loss=0.166, reward_mean=0.390, reward_bound=0.324, batch=225 
6944: loss=0.167, reward_mean=0.520, reward_bound=0.387, batch=226 
6945: loss=0.167, reward_mean=0.510, reward_bound=0.409, batch=228 
6946: loss=0.167, reward_mean=0.390, reward_bound=0.430, batch=223 
6947: loss=0.167, reward_mean=0.450, reward_bound=0.349, batch=223 
6948: loss=0.168, reward_mean=0.410, reward_bound=0.413, batch=226 
6949: loss=0.167, reward_mean=0.520, reward_bound=0.368, batch=228 
6950: loss=0.168, reward_mean=0.540, reward_bound=0.387, batch=228 
6951: loss=0.168, reward_mean=0.500, reward_bound=0.430, batch=225 
6952: loss=0.167, reward_mean=0.490, reward_bound=0.440, batch=227 
6953: loss=0.168, reward_mean=0.400, reward_bound=0.308, batch=229 
6954: loss=0.166, reward_mean=0.500, reward_bound=0.343, batch=230 
6955: loss=0.166, reward_mean=0.520, reward_bound=0.376, batch=231 
6956: loss=0.167, reward_mean=0.490, reward_bound=0.387, batch=231 
6957: loss=0.167, reward_mean=0.380, reward_bound=0.430, batch=230 
6958: loss=0.168, reward_mean=0.450, reward_bound=0.478, batch=214 
6959: loss=0.168, reward_mean=0.460, reward_bound=0.311, batch=220 
6960: loss=0.169, reward_mean=0.480, reward_bound=0.349, batch=219 
6961: loss=0.168, reward_mean=0.350, reward_bound=0.349, batch=221 
6962: loss=0.169, reward_mean=0.520, reward_bound=0.387, batch=224 
6963: loss=0.167, reward_mean=0.510, reward_bound=0.349, batch=226 
6964: loss=0.169, reward_mean=0.390, reward_bound=0.368, batch=228 
6965: loss=0.169, reward_mean=0.430, reward_bound=0.353, batch=229 
6966: loss=0.170, reward_mean=0.480, reward_bound=0.387, batch=228 
6967: loss=0.170, reward_mean=0.410, reward_bound=0.357, batch=229 
6968: loss=0.174, reward_mean=0.390, reward_bound=0.430, batch=225 
6969: loss=0.173, reward_mean=0.470, reward_bound=0.365, batch=227 
6970: loss=0.173, reward_mean=0.470, reward_bound=0.349, batch=228 
6971: loss=0.173, reward_mean=0.490, reward_bound=0.357, batch=229 
6972: loss=0.173, reward_mean=0.430, reward_bound=0.343, batch=230 
6973: loss=0.173, reward_mean=0.330, reward_bound=0.430, batch=228 
6974: loss=0.174, reward_mean=0.430, reward_bound=0.362, batch=229 
6975: loss=0.174, reward_mean=0.490, reward_bound=0.450, batch=230 
6976: loss=0.172, reward_mean=0.460, reward_bound=0.478, batch=220 
6977: loss=0.171, reward_mean=0.440, reward_bound=0.418, batch=224 
6978: loss=0.170, reward_mean=0.460, reward_bound=0.349, batch=226 
6979: loss=0.170, reward_mean=0.560, reward_bound=0.368, batch=228 
6980: loss=0.170, reward_mean=0.440, reward_bound=0.387, batch=226 
6981: loss=0.174, reward_mean=0.390, reward_bound=0.368, batch=228 
6982: loss=0.174, reward_mean=0.480, reward_bound=0.353, batch=229 
6983: loss=0.173, reward_mean=0.520, reward_bound=0.295, batch=230 
6984: loss=0.174, reward_mean=0.520, reward_bound=0.376, batch=231 
6985: loss=0.171, reward_mean=0.440, reward_bound=0.430, batch=227 
6986: loss=0.170, reward_mean=0.390, reward_bound=0.469, batch=229 
6987: loss=0.170, reward_mean=0.410, reward_bound=0.478, batch=232 
6988: loss=0.170, reward_mean=0.430, reward_bound=0.478, batch=227 
6989: loss=0.170, reward_mean=0.460, reward_bound=0.430, batch=227 
6990: loss=0.169, reward_mean=0.450, reward_bound=0.422, batch=229 
6991: loss=0.170, reward_mean=0.540, reward_bound=0.450, batch=230 
6992: loss=0.170, reward_mean=0.370, reward_bound=0.387, batch=230 
6993: loss=0.170, reward_mean=0.480, reward_bound=0.387, batch=230 
6994: loss=0.170, reward_mean=0.360, reward_bound=0.451, batch=231 
6995: loss=0.170, reward_mean=0.470, reward_bound=0.430, batch=231 
6996: loss=0.170, reward_mean=0.440, reward_bound=0.430, batch=231 
6997: loss=0.171, reward_mean=0.510, reward_bound=0.478, batch=231 
6999: loss=0.081, reward_mean=0.460, reward_bound=0.000, batch=46 
7000: loss=0.078, reward_mean=0.530, reward_bound=0.000, batch=99 
7001: loss=0.083, reward_mean=0.440, reward_bound=0.000, batch=139 
7002: loss=0.086, reward_mean=0.460, reward_bound=0.002, batch=167 
7003: loss=0.095, reward_mean=0.510, reward_bound=0.007, batch=185 
7004: loss=0.106, reward_mean=0.490, reward_bound=0.023, batch=195 
7005: loss=0.111, reward_mean=0.480, reward_bound=0.034, batch=203 
7006: loss=0.116, reward_mean=0.500, reward_bound=0.058, batch=204 
7007: loss=0.120, reward_mean=0.450, reward_bound=0.080, batch=210 
7008: loss=0.122, reward_mean=0.430, reward_bound=0.089, batch=212 
7009: loss=0.130, reward_mean=0.520, reward_bound=0.109, batch=209 
7010: loss=0.131, reward_mean=0.400, reward_bound=0.122, batch=207 
7011: loss=0.130, reward_mean=0.550, reward_bound=0.150, batch=202 
7012: loss=0.135, reward_mean=0.410, reward_bound=0.167, batch=190 
7013: loss=0.137, reward_mean=0.380, reward_bound=0.098, batch=202 
7014: loss=0.140, reward_mean=0.470, reward_bound=0.185, batch=192 
7015: loss=0.140, reward_mean=0.440, reward_bound=0.155, batch=204 
7016: loss=0.145, reward_mean=0.440, reward_bound=0.167, batch=212 
7017: loss=0.142, reward_mean=0.400, reward_bound=0.206, batch=221 
7018: loss=0.145, reward_mean=0.400, reward_bound=0.206, batch=199 
7019: loss=0.147, reward_mean=0.400, reward_bound=0.194, batch=209 
7020: loss=0.146, reward_mean=0.470, reward_bound=0.174, batch=216 
7021: loss=0.145, reward_mean=0.390, reward_bound=0.176, batch=221 
7022: loss=0.146, reward_mean=0.370, reward_bound=0.229, batch=197 
7023: loss=0.145, reward_mean=0.440, reward_bound=0.163, batch=208 
7024: loss=0.145, reward_mean=0.410, reward_bound=0.185, batch=214 
7025: loss=0.143, reward_mean=0.350, reward_bound=0.229, batch=219 
7026: loss=0.149, reward_mean=0.490, reward_bound=0.254, batch=183 
7027: loss=0.147, reward_mean=0.470, reward_bound=0.167, batch=197 
7028: loss=0.148, reward_mean=0.460, reward_bound=0.185, batch=204 
7029: loss=0.149, reward_mean=0.460, reward_bound=0.206, batch=212 
7030: loss=0.152, reward_mean=0.440, reward_bound=0.254, batch=213 
7031: loss=0.151, reward_mean=0.400, reward_bound=0.271, batch=219 
7032: loss=0.153, reward_mean=0.480, reward_bound=0.282, batch=183 
7033: loss=0.149, reward_mean=0.480, reward_bound=0.122, batch=197 
7034: loss=0.147, reward_mean=0.390, reward_bound=0.150, batch=206 
7035: loss=0.149, reward_mean=0.360, reward_bound=0.158, batch=214 
7036: loss=0.152, reward_mean=0.430, reward_bound=0.185, batch=218 
7037: loss=0.153, reward_mean=0.510, reward_bound=0.229, batch=218 
7038: loss=0.157, reward_mean=0.430, reward_bound=0.282, batch=215 
7039: loss=0.159, reward_mean=0.430, reward_bound=0.314, batch=166 
7040: loss=0.150, reward_mean=0.380, reward_bound=0.077, batch=186 
7041: loss=0.150, reward_mean=0.420, reward_bound=0.150, batch=197 
7042: loss=0.146, reward_mean=0.310, reward_bound=0.163, batch=208 
7043: loss=0.144, reward_mean=0.420, reward_bound=0.169, batch=215 
7044: loss=0.146, reward_mean=0.370, reward_bound=0.185, batch=218 
7045: loss=0.146, reward_mean=0.480, reward_bound=0.229, batch=219 
7046: loss=0.145, reward_mean=0.350, reward_bound=0.225, batch=223 
7047: loss=0.148, reward_mean=0.430, reward_bound=0.254, batch=217 
7048: loss=0.152, reward_mean=0.480, reward_bound=0.282, batch=210 
7049: loss=0.152, reward_mean=0.470, reward_bound=0.222, batch=217 
7050: loss=0.154, reward_mean=0.470, reward_bound=0.254, batch=220 
7051: loss=0.158, reward_mean=0.410, reward_bound=0.314, batch=205 
7052: loss=0.159, reward_mean=0.520, reward_bound=0.216, batch=213 
7053: loss=0.159, reward_mean=0.380, reward_bound=0.190, batch=219 
7054: loss=0.156, reward_mean=0.400, reward_bound=0.265, batch=223 
7055: loss=0.158, reward_mean=0.410, reward_bound=0.314, batch=216 
7056: loss=0.158, reward_mean=0.420, reward_bound=0.220, batch=221 
7057: loss=0.158, reward_mean=0.490, reward_bound=0.282, batch=224 
7058: loss=0.150, reward_mean=0.510, reward_bound=0.349, batch=165 
7059: loss=0.143, reward_mean=0.430, reward_bound=0.066, batch=185 
7060: loss=0.142, reward_mean=0.300, reward_bound=0.065, batch=198 
7061: loss=0.148, reward_mean=0.460, reward_bound=0.137, batch=208 
7062: loss=0.146, reward_mean=0.420, reward_bound=0.169, batch=215 
7063: loss=0.147, reward_mean=0.520, reward_bound=0.229, batch=217 
7064: loss=0.151, reward_mean=0.450, reward_bound=0.254, batch=217 
7065: loss=0.151, reward_mean=0.390, reward_bound=0.282, batch=214 
7066: loss=0.154, reward_mean=0.390, reward_bound=0.185, batch=219 
7067: loss=0.156, reward_mean=0.380, reward_bound=0.229, batch=222 
7068: loss=0.156, reward_mean=0.380, reward_bound=0.292, batch=225 
7069: loss=0.157, reward_mean=0.460, reward_bound=0.314, batch=220 
7070: loss=0.159, reward_mean=0.430, reward_bound=0.349, batch=211 
7071: loss=0.158, reward_mean=0.500, reward_bound=0.282, batch=217 
7072: loss=0.160, reward_mean=0.490, reward_bound=0.308, batch=222 
7073: loss=0.161, reward_mean=0.380, reward_bound=0.292, batch=225 
7074: loss=0.158, reward_mean=0.410, reward_bound=0.314, batch=222 
7075: loss=0.158, reward_mean=0.330, reward_bound=0.349, batch=223 
7076: loss=0.163, reward_mean=0.480, reward_bound=0.387, batch=144 
7077: loss=0.155, reward_mean=0.410, reward_bound=0.047, batch=171 
7078: loss=0.145, reward_mean=0.430, reward_bound=0.080, batch=189 
7079: loss=0.142, reward_mean=0.350, reward_bound=0.089, batch=201 
7080: loss=0.151, reward_mean=0.360, reward_bound=0.098, batch=210 
7081: loss=0.148, reward_mean=0.360, reward_bound=0.122, batch=213 
7082: loss=0.149, reward_mean=0.400, reward_bound=0.135, batch=213 
7083: loss=0.151, reward_mean=0.350, reward_bound=0.150, batch=213 
7084: loss=0.154, reward_mean=0.320, reward_bound=0.167, batch=212 
7085: loss=0.155, reward_mean=0.420, reward_bound=0.185, batch=214 
7086: loss=0.158, reward_mean=0.380, reward_bound=0.206, batch=213 
7087: loss=0.159, reward_mean=0.380, reward_bound=0.229, batch=214 
7088: loss=0.164, reward_mean=0.380, reward_bound=0.254, batch=201 
7089: loss=0.162, reward_mean=0.320, reward_bound=0.109, batch=210 
7090: loss=0.161, reward_mean=0.410, reward_bound=0.229, batch=216 
7091: loss=0.159, reward_mean=0.510, reward_bound=0.282, batch=209 
7092: loss=0.158, reward_mean=0.380, reward_bound=0.182, batch=216 
7093: loss=0.158, reward_mean=0.360, reward_bound=0.241, batch=221 
7094: loss=0.155, reward_mean=0.370, reward_bound=0.254, batch=222 
7095: loss=0.157, reward_mean=0.450, reward_bound=0.292, batch=225 
7096: loss=0.157, reward_mean=0.510, reward_bound=0.314, batch=211 
7097: loss=0.157, reward_mean=0.540, reward_bound=0.282, batch=217 
7098: loss=0.155, reward_mean=0.360, reward_bound=0.308, batch=222 
7099: loss=0.154, reward_mean=0.310, reward_bound=0.282, batch=224 
7100: loss=0.156, reward_mean=0.490, reward_bound=0.314, batch=226 
7101: loss=0.156, reward_mean=0.360, reward_bound=0.256, batch=228 
7102: loss=0.157, reward_mean=0.430, reward_bound=0.314, batch=228 
7103: loss=0.163, reward_mean=0.470, reward_bound=0.349, batch=208 
7104: loss=0.160, reward_mean=0.400, reward_bound=0.169, batch=215 
7105: loss=0.157, reward_mean=0.380, reward_bound=0.206, batch=219 
7106: loss=0.158, reward_mean=0.480, reward_bound=0.254, batch=222 
7107: loss=0.161, reward_mean=0.460, reward_bound=0.282, batch=222 
7108: loss=0.159, reward_mean=0.360, reward_bound=0.236, batch=225 
7109: loss=0.163, reward_mean=0.450, reward_bound=0.349, batch=223 
7110: loss=0.166, reward_mean=0.450, reward_bound=0.387, batch=200 
7111: loss=0.164, reward_mean=0.520, reward_bound=0.282, batch=207 
7112: loss=0.162, reward_mean=0.470, reward_bound=0.314, batch=212 
7113: loss=0.161, reward_mean=0.460, reward_bound=0.213, batch=218 
7114: loss=0.161, reward_mean=0.380, reward_bound=0.286, batch=222 
7115: loss=0.162, reward_mean=0.420, reward_bound=0.292, batch=225 
7116: loss=0.165, reward_mean=0.420, reward_bound=0.349, batch=215 
7117: loss=0.165, reward_mean=0.390, reward_bound=0.246, batch=220 
7118: loss=0.165, reward_mean=0.440, reward_bound=0.314, batch=222 
7119: loss=0.165, reward_mean=0.380, reward_bound=0.360, batch=225 
7120: loss=0.166, reward_mean=0.450, reward_bound=0.387, batch=222 
7121: loss=0.166, reward_mean=0.420, reward_bound=0.349, batch=222 
7122: loss=0.166, reward_mean=0.370, reward_bound=0.400, batch=225 
7123: loss=0.165, reward_mean=0.490, reward_bound=0.356, batch=227 
7124: loss=0.171, reward_mean=0.520, reward_bound=0.430, batch=122 
7125: loss=0.138, reward_mean=0.450, reward_bound=0.026, batch=155 
7126: loss=0.139, reward_mean=0.480, reward_bound=0.042, batch=177 
7127: loss=0.134, reward_mean=0.360, reward_bound=0.047, batch=191 
7128: loss=0.136, reward_mean=0.480, reward_bound=0.089, batch=201 
7129: loss=0.136, reward_mean=0.460, reward_bound=0.109, batch=210 
7130: loss=0.142, reward_mean=0.420, reward_bound=0.135, batch=209 
7131: loss=0.141, reward_mean=0.450, reward_bound=0.133, batch=216 
7132: loss=0.145, reward_mean=0.430, reward_bound=0.150, batch=213 
7133: loss=0.149, reward_mean=0.470, reward_bound=0.167, batch=216 
7134: loss=0.149, reward_mean=0.450, reward_bound=0.185, batch=219 
7135: loss=0.155, reward_mean=0.470, reward_bound=0.206, batch=219 
7136: loss=0.160, reward_mean=0.440, reward_bound=0.229, batch=214 
7137: loss=0.165, reward_mean=0.490, reward_bound=0.254, batch=201 
7138: loss=0.166, reward_mean=0.460, reward_bound=0.229, batch=209 
7139: loss=0.164, reward_mean=0.420, reward_bound=0.182, batch=216 
7140: loss=0.167, reward_mean=0.410, reward_bound=0.254, batch=219 
7141: loss=0.168, reward_mean=0.470, reward_bound=0.282, batch=209 
7142: loss=0.164, reward_mean=0.440, reward_bound=0.239, batch=216 
7143: loss=0.163, reward_mean=0.390, reward_bound=0.229, batch=220 
7144: loss=0.169, reward_mean=0.370, reward_bound=0.282, batch=223 
7145: loss=0.170, reward_mean=0.460, reward_bound=0.314, batch=208 
7146: loss=0.169, reward_mean=0.500, reward_bound=0.317, batch=215 
7147: loss=0.169, reward_mean=0.450, reward_bound=0.229, batch=217 
7148: loss=0.168, reward_mean=0.390, reward_bound=0.308, batch=222 
7149: loss=0.169, reward_mean=0.450, reward_bound=0.349, batch=199 
7150: loss=0.167, reward_mean=0.420, reward_bound=0.229, batch=208 
7151: loss=0.171, reward_mean=0.480, reward_bound=0.282, batch=213 
7152: loss=0.170, reward_mean=0.400, reward_bound=0.254, batch=218 
7153: loss=0.171, reward_mean=0.450, reward_bound=0.282, batch=221 
7154: loss=0.171, reward_mean=0.510, reward_bound=0.349, batch=214 
7155: loss=0.174, reward_mean=0.460, reward_bound=0.254, batch=219 
7156: loss=0.175, reward_mean=0.470, reward_bound=0.265, batch=223 
7157: loss=0.170, reward_mean=0.410, reward_bound=0.282, batch=225 
7158: loss=0.171, reward_mean=0.470, reward_bound=0.349, batch=220 
7159: loss=0.173, reward_mean=0.410, reward_bound=0.229, batch=223 
7160: loss=0.168, reward_mean=0.440, reward_bound=0.387, batch=190 
7161: loss=0.162, reward_mean=0.420, reward_bound=0.112, batch=203 
7162: loss=0.161, reward_mean=0.410, reward_bound=0.206, batch=210 
7163: loss=0.162, reward_mean=0.480, reward_bound=0.210, batch=217 
7164: loss=0.167, reward_mean=0.440, reward_bound=0.229, batch=221 
7165: loss=0.165, reward_mean=0.440, reward_bound=0.254, batch=221 
7166: loss=0.168, reward_mean=0.460, reward_bound=0.282, batch=218 
7167: loss=0.167, reward_mean=0.450, reward_bound=0.286, batch=222 
7168: loss=0.170, reward_mean=0.430, reward_bound=0.314, batch=219 
7169: loss=0.170, reward_mean=0.360, reward_bound=0.349, batch=217 
7170: loss=0.168, reward_mean=0.380, reward_bound=0.302, batch=222 
7171: loss=0.169, reward_mean=0.490, reward_bound=0.360, batch=225 
7172: loss=0.171, reward_mean=0.500, reward_bound=0.387, batch=214 
7173: loss=0.168, reward_mean=0.450, reward_bound=0.311, batch=220 
7174: loss=0.168, reward_mean=0.440, reward_bound=0.314, batch=223 
7175: loss=0.167, reward_mean=0.390, reward_bound=0.322, batch=226 
7176: loss=0.168, reward_mean=0.450, reward_bound=0.349, batch=224 
7177: loss=0.169, reward_mean=0.440, reward_bound=0.387, batch=224 
7178: loss=0.170, reward_mean=0.430, reward_bound=0.384, batch=227 
7179: loss=0.170, reward_mean=0.490, reward_bound=0.430, batch=183 
7180: loss=0.160, reward_mean=0.390, reward_bound=0.122, batch=195 
7181: loss=0.163, reward_mean=0.550, reward_bound=0.153, batch=206 
7182: loss=0.160, reward_mean=0.330, reward_bound=0.135, batch=213 
7183: loss=0.158, reward_mean=0.470, reward_bound=0.198, batch=219 
7184: loss=0.162, reward_mean=0.330, reward_bound=0.215, batch=223 
7185: loss=0.156, reward_mean=0.440, reward_bound=0.229, batch=224 
7186: loss=0.158, reward_mean=0.480, reward_bound=0.254, batch=224 
7187: loss=0.159, reward_mean=0.400, reward_bound=0.282, batch=225 
7188: loss=0.157, reward_mean=0.510, reward_bound=0.314, batch=226 
7189: loss=0.157, reward_mean=0.440, reward_bound=0.282, batch=227 
7190: loss=0.163, reward_mean=0.430, reward_bound=0.349, batch=209 
7191: loss=0.162, reward_mean=0.470, reward_bound=0.254, batch=215 
7192: loss=0.161, reward_mean=0.440, reward_bound=0.282, batch=219 
7193: loss=0.160, reward_mean=0.300, reward_bound=0.215, batch=223 
7194: loss=0.158, reward_mean=0.440, reward_bound=0.314, batch=224 
7195: loss=0.159, reward_mean=0.400, reward_bound=0.349, batch=223 
7196: loss=0.162, reward_mean=0.460, reward_bound=0.349, batch=225 
7197: loss=0.164, reward_mean=0.450, reward_bound=0.387, batch=217 
7198: loss=0.160, reward_mean=0.480, reward_bound=0.342, batch=222 
7199: loss=0.161, reward_mean=0.400, reward_bound=0.360, batch=225 
7200: loss=0.162, reward_mean=0.430, reward_bound=0.387, batch=223 
7201: loss=0.164, reward_mean=0.430, reward_bound=0.413, batch=226 
7202: loss=0.164, reward_mean=0.310, reward_bound=0.409, batch=228 
7203: loss=0.167, reward_mean=0.460, reward_bound=0.430, batch=203 
7204: loss=0.163, reward_mean=0.460, reward_bound=0.125, batch=212 
7205: loss=0.159, reward_mean=0.400, reward_bound=0.150, batch=217 
7206: loss=0.162, reward_mean=0.380, reward_bound=0.254, batch=217 
7207: loss=0.164, reward_mean=0.400, reward_bound=0.282, batch=220 
7208: loss=0.164, reward_mean=0.410, reward_bound=0.314, batch=219 
7209: loss=0.164, reward_mean=0.350, reward_bound=0.250, batch=223 
7210: loss=0.163, reward_mean=0.450, reward_bound=0.349, batch=221 
7211: loss=0.164, reward_mean=0.490, reward_bound=0.387, batch=220 
7212: loss=0.163, reward_mean=0.510, reward_bound=0.349, batch=223 
7213: loss=0.163, reward_mean=0.470, reward_bound=0.413, batch=226 
7214: loss=0.162, reward_mean=0.430, reward_bound=0.390, batch=228 
7215: loss=0.161, reward_mean=0.450, reward_bound=0.353, batch=229 
7216: loss=0.162, reward_mean=0.360, reward_bound=0.405, batch=230 
7217: loss=0.161, reward_mean=0.400, reward_bound=0.406, batch=231 
7218: loss=0.163, reward_mean=0.470, reward_bound=0.430, batch=224 
7219: loss=0.162, reward_mean=0.350, reward_bound=0.377, batch=227 
7220: loss=0.162, reward_mean=0.420, reward_bound=0.387, batch=228 
7221: loss=0.162, reward_mean=0.450, reward_bound=0.435, batch=229 
7222: loss=0.162, reward_mean=0.370, reward_bound=0.295, batch=230 
7223: loss=0.162, reward_mean=0.410, reward_bound=0.314, batch=230 
7224: loss=0.161, reward_mean=0.510, reward_bound=0.439, batch=231 
7225: loss=0.172, reward_mean=0.420, reward_bound=0.478, batch=110 
7226: loss=0.131, reward_mean=0.410, reward_bound=0.001, batch=147 
7227: loss=0.127, reward_mean=0.400, reward_bound=0.010, batch=172 
7228: loss=0.125, reward_mean=0.360, reward_bound=0.031, batch=189 
7229: loss=0.127, reward_mean=0.470, reward_bound=0.065, batch=201 
7230: loss=0.131, reward_mean=0.460, reward_bound=0.080, batch=209 
7231: loss=0.135, reward_mean=0.430, reward_bound=0.122, batch=209 
7232: loss=0.138, reward_mean=0.410, reward_bound=0.135, batch=209 
7233: loss=0.139, reward_mean=0.430, reward_bound=0.150, batch=214 
7234: loss=0.143, reward_mean=0.500, reward_bound=0.167, batch=214 
7235: loss=0.146, reward_mean=0.480, reward_bound=0.185, batch=217 
7236: loss=0.147, reward_mean=0.490, reward_bound=0.206, batch=212 
7237: loss=0.152, reward_mean=0.540, reward_bound=0.229, batch=205 
7238: loss=0.154, reward_mean=0.460, reward_bound=0.229, batch=212 
7239: loss=0.158, reward_mean=0.460, reward_bound=0.254, batch=205 
7240: loss=0.160, reward_mean=0.470, reward_bound=0.124, batch=213 
7241: loss=0.160, reward_mean=0.490, reward_bound=0.282, batch=202 
7242: loss=0.160, reward_mean=0.460, reward_bound=0.213, batch=211 
7243: loss=0.156, reward_mean=0.480, reward_bound=0.254, batch=215 
7244: loss=0.156, reward_mean=0.420, reward_bound=0.282, batch=218 
7245: loss=0.165, reward_mean=0.380, reward_bound=0.314, batch=194 
7246: loss=0.164, reward_mean=0.410, reward_bound=0.167, batch=204 
7247: loss=0.165, reward_mean=0.460, reward_bound=0.206, batch=211 
7248: loss=0.164, reward_mean=0.460, reward_bound=0.282, batch=216 
7249: loss=0.164, reward_mean=0.330, reward_bound=0.151, batch=221 
7250: loss=0.163, reward_mean=0.430, reward_bound=0.282, batch=223 
7251: loss=0.162, reward_mean=0.410, reward_bound=0.301, batch=226 
7252: loss=0.160, reward_mean=0.470, reward_bound=0.314, batch=226 
7253: loss=0.160, reward_mean=0.410, reward_bound=0.298, batch=228 
7254: loss=0.161, reward_mean=0.460, reward_bound=0.314, batch=228 
7255: loss=0.165, reward_mean=0.500, reward_bound=0.349, batch=201 
7256: loss=0.164, reward_mean=0.450, reward_bound=0.254, batch=209 
7257: loss=0.162, reward_mean=0.450, reward_bound=0.328, batch=216 
7258: loss=0.161, reward_mean=0.370, reward_bound=0.256, batch=221 
7259: loss=0.163, reward_mean=0.400, reward_bound=0.282, batch=223 
7260: loss=0.167, reward_mean=0.400, reward_bound=0.349, batch=220 
7261: loss=0.175, reward_mean=0.440, reward_bound=0.387, batch=189 
7262: loss=0.178, reward_mean=0.450, reward_bound=0.185, batch=201 
7263: loss=0.172, reward_mean=0.280, reward_bound=0.135, batch=208 
7264: loss=0.173, reward_mean=0.420, reward_bound=0.208, batch=215 
7265: loss=0.173, reward_mean=0.410, reward_bound=0.229, batch=218 
7266: loss=0.173, reward_mean=0.500, reward_bound=0.282, batch=215 
7267: loss=0.172, reward_mean=0.380, reward_bound=0.289, batch=220 
7268: loss=0.174, reward_mean=0.420, reward_bound=0.314, batch=219 
7269: loss=0.178, reward_mean=0.370, reward_bound=0.349, batch=212 
7270: loss=0.179, reward_mean=0.450, reward_bound=0.349, batch=217 
7271: loss=0.177, reward_mean=0.530, reward_bound=0.302, batch=222 
7272: loss=0.176, reward_mean=0.410, reward_bound=0.254, batch=223 
7273: loss=0.175, reward_mean=0.510, reward_bound=0.314, batch=224 
7274: loss=0.175, reward_mean=0.350, reward_bound=0.280, batch=227 
7275: loss=0.179, reward_mean=0.470, reward_bound=0.387, batch=219 
7276: loss=0.174, reward_mean=0.360, reward_bound=0.430, batch=167 
7277: loss=0.161, reward_mean=0.460, reward_bound=0.095, batch=187 
7278: loss=0.149, reward_mean=0.360, reward_bound=0.098, batch=200 
7279: loss=0.158, reward_mean=0.410, reward_bound=0.150, batch=207 
7280: loss=0.160, reward_mean=0.400, reward_bound=0.167, batch=212 
7281: loss=0.153, reward_mean=0.420, reward_bound=0.206, batch=220 
7282: loss=0.151, reward_mean=0.360, reward_bound=0.206, batch=228 
7283: loss=0.151, reward_mean=0.480, reward_bound=0.206, batch=227 
7284: loss=0.155, reward_mean=0.410, reward_bound=0.229, batch=226 
7285: loss=0.161, reward_mean=0.340, reward_bound=0.254, batch=221 
7286: loss=0.166, reward_mean=0.420, reward_bound=0.282, batch=221 
7287: loss=0.166, reward_mean=0.400, reward_bound=0.314, batch=210 
7288: loss=0.164, reward_mean=0.450, reward_bound=0.282, batch=216 
7289: loss=0.166, reward_mean=0.420, reward_bound=0.349, batch=207 
7290: loss=0.166, reward_mean=0.400, reward_bound=0.229, batch=214 
7291: loss=0.167, reward_mean=0.400, reward_bound=0.282, batch=218 
7292: loss=0.167, reward_mean=0.400, reward_bound=0.314, batch=221 
7293: loss=0.168, reward_mean=0.420, reward_bound=0.349, batch=218 
7294: loss=0.168, reward_mean=0.370, reward_bound=0.317, batch=222 
7295: loss=0.167, reward_mean=0.410, reward_bound=0.213, batch=225 
7296: loss=0.167, reward_mean=0.370, reward_bound=0.254, batch=226 
7297: loss=0.168, reward_mean=0.430, reward_bound=0.331, batch=228 
7298: loss=0.167, reward_mean=0.360, reward_bound=0.349, batch=226 
7299: loss=0.167, reward_mean=0.440, reward_bound=0.368, batch=228 
7300: loss=0.172, reward_mean=0.360, reward_bound=0.387, batch=209 
7301: loss=0.168, reward_mean=0.480, reward_bound=0.265, batch=216 
7302: loss=0.172, reward_mean=0.400, reward_bound=0.298, batch=221 
7303: loss=0.170, reward_mean=0.420, reward_bound=0.349, batch=218 
7304: loss=0.168, reward_mean=0.480, reward_bound=0.286, batch=222 
7305: loss=0.169, reward_mean=0.440, reward_bound=0.324, batch=225 
7306: loss=0.168, reward_mean=0.460, reward_bound=0.349, batch=224 
7307: loss=0.168, reward_mean=0.340, reward_bound=0.380, batch=227 
7308: loss=0.168, reward_mean=0.470, reward_bound=0.314, batch=228 
7309: loss=0.169, reward_mean=0.350, reward_bound=0.387, batch=222 
7310: loss=0.173, reward_mean=0.410, reward_bound=0.430, batch=203 
7311: loss=0.172, reward_mean=0.450, reward_bound=0.178, batch=212 
7312: loss=0.169, reward_mean=0.370, reward_bound=0.191, batch=218 
7313: loss=0.168, reward_mean=0.460, reward_bound=0.257, batch=222 
7314: loss=0.167, reward_mean=0.350, reward_bound=0.263, batch=225 
7315: loss=0.168, reward_mean=0.490, reward_bound=0.282, batch=225 
7316: loss=0.170, reward_mean=0.440, reward_bound=0.314, batch=225 
7317: loss=0.171, reward_mean=0.450, reward_bound=0.349, batch=223 
7318: loss=0.171, reward_mean=0.430, reward_bound=0.271, batch=226 
7319: loss=0.169, reward_mean=0.430, reward_bound=0.349, batch=226 
7320: loss=0.169, reward_mean=0.420, reward_bound=0.368, batch=228 
7321: loss=0.169, reward_mean=0.470, reward_bound=0.387, batch=221 
7322: loss=0.170, reward_mean=0.370, reward_bound=0.314, batch=224 
7323: loss=0.168, reward_mean=0.500, reward_bound=0.345, batch=227 
7324: loss=0.167, reward_mean=0.470, reward_bound=0.380, batch=229 
7325: loss=0.167, reward_mean=0.410, reward_bound=0.387, batch=228 
7326: loss=0.167, reward_mean=0.440, reward_bound=0.430, batch=220 
7327: loss=0.166, reward_mean=0.450, reward_bound=0.304, batch=224 
7328: loss=0.165, reward_mean=0.460, reward_bound=0.311, batch=227 
7329: loss=0.165, reward_mean=0.400, reward_bound=0.314, batch=228 
7330: loss=0.164, reward_mean=0.470, reward_bound=0.349, batch=227 
7331: loss=0.164, reward_mean=0.450, reward_bound=0.380, batch=229 
7332: loss=0.165, reward_mean=0.440, reward_bound=0.387, batch=229 
7333: loss=0.167, reward_mean=0.430, reward_bound=0.430, batch=225 
7334: loss=0.167, reward_mean=0.430, reward_bound=0.387, batch=226 
7335: loss=0.166, reward_mean=0.370, reward_bound=0.478, batch=153 
7336: loss=0.159, reward_mean=0.470, reward_bound=0.065, batch=176 
7337: loss=0.150, reward_mean=0.400, reward_bound=0.104, batch=193 
7338: loss=0.150, reward_mean=0.510, reward_bound=0.135, batch=204 
7339: loss=0.151, reward_mean=0.390, reward_bound=0.150, batch=209 
7340: loss=0.153, reward_mean=0.380, reward_bound=0.167, batch=208 
7341: loss=0.157, reward_mean=0.500, reward_bound=0.185, batch=212 
7342: loss=0.161, reward_mean=0.550, reward_bound=0.229, batch=214 
7343: loss=0.160, reward_mean=0.450, reward_bound=0.254, batch=214 
7344: loss=0.158, reward_mean=0.310, reward_bound=0.206, batch=219 
7345: loss=0.164, reward_mean=0.440, reward_bound=0.282, batch=214 
7346: loss=0.162, reward_mean=0.450, reward_bound=0.252, batch=220 
7347: loss=0.161, reward_mean=0.400, reward_bound=0.282, batch=223 
7348: loss=0.163, reward_mean=0.450, reward_bound=0.314, batch=210 
7349: loss=0.167, reward_mean=0.400, reward_bound=0.229, batch=215 
7350: loss=0.166, reward_mean=0.360, reward_bound=0.170, batch=220 
7351: loss=0.168, reward_mean=0.470, reward_bound=0.274, batch=224 
7352: loss=0.168, reward_mean=0.400, reward_bound=0.282, batch=223 
7353: loss=0.166, reward_mean=0.430, reward_bound=0.314, batch=225 
7354: loss=0.168, reward_mean=0.470, reward_bound=0.349, batch=210 
7355: loss=0.170, reward_mean=0.390, reward_bound=0.282, batch=215 
7356: loss=0.166, reward_mean=0.370, reward_bound=0.210, batch=220 
7357: loss=0.165, reward_mean=0.430, reward_bound=0.282, batch=223 
7358: loss=0.163, reward_mean=0.360, reward_bound=0.314, batch=224 
7359: loss=0.166, reward_mean=0.420, reward_bound=0.349, batch=220 
7360: loss=0.167, reward_mean=0.420, reward_bound=0.304, batch=224 
7361: loss=0.165, reward_mean=0.310, reward_bound=0.314, batch=226 
7362: loss=0.165, reward_mean=0.410, reward_bound=0.301, batch=228 
7363: loss=0.166, reward_mean=0.390, reward_bound=0.353, batch=229 
7364: loss=0.168, reward_mean=0.340, reward_bound=0.387, batch=202 
7365: loss=0.163, reward_mean=0.350, reward_bound=0.172, batch=211 
7366: loss=0.164, reward_mean=0.380, reward_bound=0.254, batch=215 
7367: loss=0.166, reward_mean=0.350, reward_bound=0.282, batch=217 
7368: loss=0.167, reward_mean=0.470, reward_bound=0.314, batch=220 
7369: loss=0.167, reward_mean=0.470, reward_bound=0.296, batch=224 
7370: loss=0.170, reward_mean=0.440, reward_bound=0.349, batch=224 
7371: loss=0.171, reward_mean=0.490, reward_bound=0.384, batch=227 
7372: loss=0.171, reward_mean=0.400, reward_bound=0.380, batch=229 
7373: loss=0.171, reward_mean=0.430, reward_bound=0.364, batch=230 
7374: loss=0.172, reward_mean=0.500, reward_bound=0.387, batch=223 
7375: loss=0.172, reward_mean=0.500, reward_bound=0.358, batch=226 
7376: loss=0.171, reward_mean=0.500, reward_bound=0.409, batch=228 
7377: loss=0.171, reward_mean=0.410, reward_bound=0.392, batch=229 
7378: loss=0.166, reward_mean=0.370, reward_bound=0.430, batch=203 
7379: loss=0.165, reward_mean=0.440, reward_bound=0.282, batch=210 
7380: loss=0.168, reward_mean=0.290, reward_bound=0.185, batch=215 
7381: loss=0.165, reward_mean=0.410, reward_bound=0.282, batch=219 
7382: loss=0.165, reward_mean=0.420, reward_bound=0.295, batch=223 
7383: loss=0.165, reward_mean=0.500, reward_bound=0.314, batch=223 
7384: loss=0.167, reward_mean=0.400, reward_bound=0.349, batch=223 
7385: loss=0.167, reward_mean=0.440, reward_bound=0.372, batch=226 
7386: loss=0.164, reward_mean=0.440, reward_bound=0.387, batch=218 
7387: loss=0.162, reward_mean=0.500, reward_bound=0.206, batch=221 
7388: loss=0.167, reward_mean=0.450, reward_bound=0.282, batch=224 
7389: loss=0.164, reward_mean=0.490, reward_bound=0.384, batch=227 
7390: loss=0.162, reward_mean=0.430, reward_bound=0.387, batch=228 
7391: loss=0.163, reward_mean=0.360, reward_bound=0.430, batch=218 
7392: loss=0.163, reward_mean=0.440, reward_bound=0.353, batch=222 
7393: loss=0.162, reward_mean=0.440, reward_bound=0.387, batch=224 
7394: loss=0.162, reward_mean=0.450, reward_bound=0.314, batch=224 
7395: loss=0.161, reward_mean=0.360, reward_bound=0.339, batch=227 
7396: loss=0.161, reward_mean=0.460, reward_bound=0.387, batch=228 
7397: loss=0.162, reward_mean=0.490, reward_bound=0.430, batch=227 
7398: loss=0.163, reward_mean=0.490, reward_bound=0.469, batch=229 
7399: loss=0.162, reward_mean=0.490, reward_bound=0.405, batch=230 
7400: loss=0.163, reward_mean=0.440, reward_bound=0.406, batch=231 
7401: loss=0.163, reward_mean=0.460, reward_bound=0.430, batch=230 
7402: loss=0.163, reward_mean=0.540, reward_bound=0.451, batch=231 
7403: loss=0.163, reward_mean=0.490, reward_bound=0.478, batch=192 
7404: loss=0.156, reward_mean=0.380, reward_bound=0.122, batch=202 
7405: loss=0.155, reward_mean=0.470, reward_bound=0.236, batch=211 
7406: loss=0.155, reward_mean=0.370, reward_bound=0.254, batch=215 
7407: loss=0.154, reward_mean=0.470, reward_bound=0.210, batch=220 
7408: loss=0.151, reward_mean=0.520, reward_bound=0.254, batch=223 
7409: loss=0.152, reward_mean=0.430, reward_bound=0.282, batch=224 
7410: loss=0.151, reward_mean=0.390, reward_bound=0.277, batch=227 
7411: loss=0.151, reward_mean=0.410, reward_bound=0.282, batch=228 
7412: loss=0.154, reward_mean=0.500, reward_bound=0.314, batch=221 
7413: loss=0.152, reward_mean=0.500, reward_bound=0.349, batch=221 
7414: loss=0.151, reward_mean=0.490, reward_bound=0.314, batch=223 
7415: loss=0.150, reward_mean=0.410, reward_bound=0.372, batch=226 
7416: loss=0.151, reward_mean=0.410, reward_bound=0.351, batch=228 
7417: loss=0.156, reward_mean=0.450, reward_bound=0.387, batch=214 
7418: loss=0.154, reward_mean=0.440, reward_bound=0.311, batch=220 
7419: loss=0.154, reward_mean=0.370, reward_bound=0.200, batch=224 
7420: loss=0.153, reward_mean=0.450, reward_bound=0.311, batch=227 
7421: loss=0.153, reward_mean=0.480, reward_bound=0.314, batch=225 
7422: loss=0.154, reward_mean=0.390, reward_bound=0.387, batch=222 
7423: loss=0.154, reward_mean=0.380, reward_bound=0.238, batch=225 
7424: loss=0.153, reward_mean=0.460, reward_bound=0.314, batch=226 
7425: loss=0.152, reward_mean=0.370, reward_bound=0.331, batch=228 
7426: loss=0.151, reward_mean=0.450, reward_bound=0.349, batch=228 
7427: loss=0.155, reward_mean=0.380, reward_bound=0.387, batch=227 
7428: loss=0.154, reward_mean=0.440, reward_bound=0.407, batch=229 
7429: loss=0.154, reward_mean=0.420, reward_bound=0.405, batch=230 
7430: loss=0.153, reward_mean=0.430, reward_bound=0.418, batch=231 
7431: loss=0.153, reward_mean=0.420, reward_bound=0.349, batch=231 
7432: loss=0.163, reward_mean=0.470, reward_bound=0.430, batch=213 
7433: loss=0.165, reward_mean=0.440, reward_bound=0.261, batch=219 
7434: loss=0.161, reward_mean=0.390, reward_bound=0.295, batch=223 
7435: loss=0.157, reward_mean=0.470, reward_bound=0.314, batch=224 
7436: loss=0.161, reward_mean=0.440, reward_bound=0.349, batch=223 
7437: loss=0.160, reward_mean=0.440, reward_bound=0.314, batch=225 
7438: loss=0.159, reward_mean=0.440, reward_bound=0.356, batch=227 
7439: loss=0.160, reward_mean=0.460, reward_bound=0.387, batch=224 
7440: loss=0.160, reward_mean=0.520, reward_bound=0.380, batch=227 
7441: loss=0.159, reward_mean=0.480, reward_bound=0.380, batch=229 
7442: loss=0.159, reward_mean=0.390, reward_bound=0.349, batch=229 
7443: loss=0.160, reward_mean=0.460, reward_bound=0.387, batch=228 
7444: loss=0.163, reward_mean=0.360, reward_bound=0.430, batch=220 
7445: loss=0.163, reward_mean=0.390, reward_bound=0.329, batch=224 
7446: loss=0.162, reward_mean=0.460, reward_bound=0.349, batch=225 
7447: loss=0.164, reward_mean=0.380, reward_bound=0.387, batch=226 
7448: loss=0.164, reward_mean=0.410, reward_bound=0.368, batch=228 
7449: loss=0.165, reward_mean=0.400, reward_bound=0.392, batch=229 
7450: loss=0.164, reward_mean=0.520, reward_bound=0.430, batch=228 
7451: loss=0.165, reward_mean=0.450, reward_bound=0.435, batch=229 
7452: loss=0.164, reward_mean=0.420, reward_bound=0.478, batch=232 
7453: loss=0.164, reward_mean=0.440, reward_bound=0.478, batch=207 
7454: loss=0.157, reward_mean=0.490, reward_bound=0.224, batch=215 
7455: loss=0.161, reward_mean=0.480, reward_bound=0.254, batch=219 
7456: loss=0.161, reward_mean=0.480, reward_bound=0.282, batch=220 
7457: loss=0.162, reward_mean=0.460, reward_bound=0.314, batch=222 
7458: loss=0.161, reward_mean=0.380, reward_bound=0.324, batch=225 
7459: loss=0.161, reward_mean=0.460, reward_bound=0.282, batch=225 
7460: loss=0.160, reward_mean=0.420, reward_bound=0.321, batch=227 
7461: loss=0.164, reward_mean=0.430, reward_bound=0.349, batch=224 
7462: loss=0.162, reward_mean=0.370, reward_bound=0.387, batch=220 
7463: loss=0.161, reward_mean=0.520, reward_bound=0.418, batch=224 
7464: loss=0.159, reward_mean=0.420, reward_bound=0.311, batch=227 
7465: loss=0.158, reward_mean=0.410, reward_bound=0.314, batch=228 
7466: loss=0.159, reward_mean=0.460, reward_bound=0.349, batch=228 
7467: loss=0.159, reward_mean=0.510, reward_bound=0.387, batch=227 
7468: loss=0.157, reward_mean=0.390, reward_bound=0.366, batch=229 
7469: loss=0.157, reward_mean=0.540, reward_bound=0.328, batch=230 
7470: loss=0.157, reward_mean=0.430, reward_bound=0.329, batch=231 
7471: loss=0.158, reward_mean=0.510, reward_bound=0.387, batch=229 
7472: loss=0.159, reward_mean=0.470, reward_bound=0.381, batch=230 
7473: loss=0.163, reward_mean=0.520, reward_bound=0.430, batch=220 
7474: loss=0.163, reward_mean=0.420, reward_bound=0.387, batch=222 
7475: loss=0.162, reward_mean=0.340, reward_bound=0.360, batch=225 
7476: loss=0.161, reward_mean=0.370, reward_bound=0.321, batch=227 
7477: loss=0.161, reward_mean=0.420, reward_bound=0.387, batch=228 
7478: loss=0.161, reward_mean=0.570, reward_bound=0.430, batch=227 
7479: loss=0.161, reward_mean=0.370, reward_bound=0.422, batch=229 
7480: loss=0.162, reward_mean=0.420, reward_bound=0.450, batch=230 
7481: loss=0.162, reward_mean=0.410, reward_bound=0.451, batch=231 
7482: loss=0.162, reward_mean=0.470, reward_bound=0.430, batch=231 
7483: loss=0.162, reward_mean=0.400, reward_bound=0.349, batch=231 
7484: loss=0.164, reward_mean=0.370, reward_bound=0.478, batch=220 
7485: loss=0.165, reward_mean=0.510, reward_bound=0.365, batch=224 
7486: loss=0.165, reward_mean=0.490, reward_bound=0.349, batch=226 
7487: loss=0.164, reward_mean=0.480, reward_bound=0.331, batch=228 
7488: loss=0.165, reward_mean=0.480, reward_bound=0.387, batch=225 
7489: loss=0.165, reward_mean=0.350, reward_bound=0.365, batch=227 
7490: loss=0.164, reward_mean=0.430, reward_bound=0.430, batch=227 
7491: loss=0.163, reward_mean=0.420, reward_bound=0.349, batch=228 
7492: loss=0.164, reward_mean=0.410, reward_bound=0.397, batch=229 
7493: loss=0.164, reward_mean=0.440, reward_bound=0.478, batch=231 
7494: loss=0.164, reward_mean=0.300, reward_bound=0.430, batch=231 
7495: loss=0.164, reward_mean=0.390, reward_bound=0.349, batch=231 
7496: loss=0.166, reward_mean=0.400, reward_bound=0.478, batch=224 
7497: loss=0.165, reward_mean=0.510, reward_bound=0.342, batch=227 
7498: loss=0.165, reward_mean=0.460, reward_bound=0.349, batch=228 
7499: loss=0.164, reward_mean=0.480, reward_bound=0.387, batch=228 
7500: loss=0.164, reward_mean=0.400, reward_bound=0.392, batch=229 
7501: loss=0.165, reward_mean=0.340, reward_bound=0.360, batch=230 
7502: loss=0.165, reward_mean=0.510, reward_bound=0.430, batch=228 
7503: loss=0.164, reward_mean=0.400, reward_bound=0.353, batch=229 
7504: loss=0.165, reward_mean=0.370, reward_bound=0.364, batch=230 
7505: loss=0.166, reward_mean=0.450, reward_bound=0.387, batch=229 
7506: loss=0.166, reward_mean=0.530, reward_bound=0.450, batch=230 
7507: loss=0.165, reward_mean=0.430, reward_bound=0.478, batch=227 
7508: loss=0.165, reward_mean=0.450, reward_bound=0.469, batch=229 
7509: loss=0.165, reward_mean=0.420, reward_bound=0.450, batch=230 
7510: loss=0.164, reward_mean=0.420, reward_bound=0.376, batch=231 
7511: loss=0.165, reward_mean=0.440, reward_bound=0.478, batch=229 
7512: loss=0.165, reward_mean=0.510, reward_bound=0.401, batch=230 
7513: loss=0.164, reward_mean=0.370, reward_bound=0.439, batch=231 
7514: loss=0.164, reward_mean=0.440, reward_bound=0.430, batch=231 
7515: loss=0.165, reward_mean=0.410, reward_bound=0.478, batch=230 
7516: loss=0.165, reward_mean=0.510, reward_bound=0.478, batch=230 
7517: loss=0.168, reward_mean=0.450, reward_bound=0.515, batch=231 
7518: loss=0.168, reward_mean=0.390, reward_bound=0.478, batch=231 
7520: loss=0.074, reward_mean=0.430, reward_bound=0.000, batch=43 
7521: loss=0.072, reward_mean=0.460, reward_bound=0.000, batch=89 
7522: loss=0.071, reward_mean=0.410, reward_bound=0.000, batch=130 
7523: loss=0.076, reward_mean=0.360, reward_bound=0.000, batch=161 
7524: loss=0.080, reward_mean=0.300, reward_bound=0.002, batch=182 
7525: loss=0.086, reward_mean=0.330, reward_bound=0.005, batch=197 
7526: loss=0.096, reward_mean=0.460, reward_bound=0.023, batch=205 
7527: loss=0.100, reward_mean=0.480, reward_bound=0.038, batch=210 
7528: loss=0.105, reward_mean=0.450, reward_bound=0.056, batch=217 
7529: loss=0.105, reward_mean=0.400, reward_bound=0.065, batch=217 
7530: loss=0.106, reward_mean=0.410, reward_bound=0.087, batch=222 
7531: loss=0.109, reward_mean=0.420, reward_bound=0.098, batch=215 
7532: loss=0.111, reward_mean=0.510, reward_bound=0.109, batch=240 
7533: loss=0.112, reward_mean=0.350, reward_bound=0.109, batch=233 
7534: loss=0.116, reward_mean=0.530, reward_bound=0.122, batch=232 
7535: loss=0.119, reward_mean=0.400, reward_bound=0.135, batch=224 
7536: loss=0.117, reward_mean=0.350, reward_bound=0.150, batch=206 
7537: loss=0.114, reward_mean=0.510, reward_bound=0.167, batch=198 
7538: loss=0.120, reward_mean=0.350, reward_bound=0.185, batch=191 
7539: loss=0.118, reward_mean=0.390, reward_bound=0.185, batch=202 
7540: loss=0.117, reward_mean=0.430, reward_bound=0.206, batch=215 
7541: loss=0.113, reward_mean=0.490, reward_bound=0.206, batch=194 
7542: loss=0.112, reward_mean=0.460, reward_bound=0.182, batch=206 
7543: loss=0.116, reward_mean=0.440, reward_bound=0.229, batch=173 
7544: loss=0.116, reward_mean=0.490, reward_bound=0.089, batch=189 
7545: loss=0.118, reward_mean=0.510, reward_bound=0.167, batch=201 
7546: loss=0.117, reward_mean=0.400, reward_bound=0.167, batch=209 
7547: loss=0.117, reward_mean=0.470, reward_bound=0.194, batch=216 
7548: loss=0.116, reward_mean=0.460, reward_bound=0.206, batch=216 
7549: loss=0.113, reward_mean=0.370, reward_bound=0.229, batch=220 
7550: loss=0.113, reward_mean=0.440, reward_bound=0.254, batch=184 
7551: loss=0.111, reward_mean=0.490, reward_bound=0.167, batch=198 
7552: loss=0.110, reward_mean=0.490, reward_bound=0.167, batch=207 
7553: loss=0.111, reward_mean=0.440, reward_bound=0.206, batch=214 
7554: loss=0.112, reward_mean=0.470, reward_bound=0.229, batch=216 
7555: loss=0.116, reward_mean=0.350, reward_bound=0.254, batch=217 
7556: loss=0.123, reward_mean=0.440, reward_bound=0.282, batch=171 
7557: loss=0.126, reward_mean=0.520, reward_bound=0.185, batch=188 
7558: loss=0.127, reward_mean=0.560, reward_bound=0.206, batch=198 
7559: loss=0.129, reward_mean=0.470, reward_bound=0.229, batch=204 
7560: loss=0.128, reward_mean=0.430, reward_bound=0.247, batch=213 
7561: loss=0.129, reward_mean=0.380, reward_bound=0.244, batch=219 
7562: loss=0.127, reward_mean=0.490, reward_bound=0.265, batch=223 
7563: loss=0.127, reward_mean=0.420, reward_bound=0.282, batch=222 
7564: loss=0.123, reward_mean=0.470, reward_bound=0.314, batch=177 
7565: loss=0.118, reward_mean=0.450, reward_bound=0.119, batch=194 
7566: loss=0.115, reward_mean=0.500, reward_bound=0.122, batch=204 
7567: loss=0.122, reward_mean=0.320, reward_bound=0.135, batch=211 
7568: loss=0.123, reward_mean=0.540, reward_bound=0.229, batch=215 
7569: loss=0.122, reward_mean=0.450, reward_bound=0.254, batch=215 
7570: loss=0.121, reward_mean=0.490, reward_bound=0.229, batch=219 
7571: loss=0.121, reward_mean=0.350, reward_bound=0.265, batch=223 
7572: loss=0.125, reward_mean=0.380, reward_bound=0.282, batch=212 
7573: loss=0.123, reward_mean=0.540, reward_bound=0.282, batch=217 
7574: loss=0.121, reward_mean=0.390, reward_bound=0.277, batch=222 
7575: loss=0.122, reward_mean=0.400, reward_bound=0.282, batch=223 
7576: loss=0.125, reward_mean=0.490, reward_bound=0.314, batch=218 
7577: loss=0.125, reward_mean=0.430, reward_bound=0.317, batch=222 
7578: loss=0.123, reward_mean=0.530, reward_bound=0.349, batch=166 
7579: loss=0.115, reward_mean=0.380, reward_bound=0.061, batch=186 
7580: loss=0.115, reward_mean=0.500, reward_bound=0.135, batch=199 
7581: loss=0.116, reward_mean=0.540, reward_bound=0.150, batch=208 
7582: loss=0.120, reward_mean=0.440, reward_bound=0.167, batch=213 
7583: loss=0.122, reward_mean=0.410, reward_bound=0.198, batch=219 
7584: loss=0.119, reward_mean=0.480, reward_bound=0.206, batch=222 
7585: loss=0.115, reward_mean=0.460, reward_bound=0.229, batch=224 
7586: loss=0.113, reward_mean=0.480, reward_bound=0.254, batch=221 
7587: loss=0.114, reward_mean=0.450, reward_bound=0.282, batch=220 
7588: loss=0.119, reward_mean=0.400, reward_bound=0.314, batch=209 
7589: loss=0.120, reward_mean=0.330, reward_bound=0.215, batch=216 
7590: loss=0.117, reward_mean=0.430, reward_bound=0.254, batch=219 
7591: loss=0.121, reward_mean=0.400, reward_bound=0.314, batch=221 
7592: loss=0.123, reward_mean=0.500, reward_bound=0.349, batch=212 
7593: loss=0.122, reward_mean=0.430, reward_bound=0.185, batch=217 
7594: loss=0.119, reward_mean=0.300, reward_bound=0.224, batch=222 
7595: loss=0.120, reward_mean=0.510, reward_bound=0.282, batch=221 
7596: loss=0.120, reward_mean=0.470, reward_bound=0.314, batch=221 
7597: loss=0.122, reward_mean=0.480, reward_bound=0.349, batch=222 
7598: loss=0.122, reward_mean=0.450, reward_bound=0.387, batch=144 
7599: loss=0.106, reward_mean=0.410, reward_bound=0.022, batch=171 
7600: loss=0.107, reward_mean=0.420, reward_bound=0.047, batch=189 
7601: loss=0.108, reward_mean=0.430, reward_bound=0.083, batch=202 
7602: loss=0.109, reward_mean=0.410, reward_bound=0.122, batch=208 
7603: loss=0.115, reward_mean=0.510, reward_bound=0.150, batch=211 
7604: loss=0.121, reward_mean=0.440, reward_bound=0.185, batch=211 
7605: loss=0.117, reward_mean=0.470, reward_bound=0.206, batch=214 
7606: loss=0.118, reward_mean=0.510, reward_bound=0.229, batch=211 
7607: loss=0.116, reward_mean=0.450, reward_bound=0.229, batch=217 
7608: loss=0.115, reward_mean=0.380, reward_bound=0.254, batch=211 
7609: loss=0.113, reward_mean=0.420, reward_bound=0.254, batch=216 
7610: loss=0.118, reward_mean=0.530, reward_bound=0.282, batch=211 
7611: loss=0.117, reward_mean=0.430, reward_bound=0.229, batch=217 
7612: loss=0.117, reward_mean=0.440, reward_bound=0.308, batch=222 
7613: loss=0.118, reward_mean=0.420, reward_bound=0.314, batch=208 
7614: loss=0.117, reward_mean=0.480, reward_bound=0.317, batch=215 
7615: loss=0.117, reward_mean=0.480, reward_bound=0.321, batch=220 
7616: loss=0.118, reward_mean=0.390, reward_bound=0.274, batch=224 
7617: loss=0.118, reward_mean=0.450, reward_bound=0.280, batch=227 
7618: loss=0.114, reward_mean=0.420, reward_bound=0.282, batch=225 
7619: loss=0.115, reward_mean=0.430, reward_bound=0.321, batch=227 
7620: loss=0.115, reward_mean=0.470, reward_bound=0.349, batch=211 
7621: loss=0.114, reward_mean=0.420, reward_bound=0.167, batch=217 
7622: loss=0.115, reward_mean=0.460, reward_bound=0.254, batch=216 
7623: loss=0.113, reward_mean=0.390, reward_bound=0.268, batch=221 
7624: loss=0.113, reward_mean=0.440, reward_bound=0.282, batch=222 
7625: loss=0.112, reward_mean=0.370, reward_bound=0.236, batch=225 
7626: loss=0.112, reward_mean=0.560, reward_bound=0.314, batch=221 
7627: loss=0.113, reward_mean=0.520, reward_bound=0.314, batch=224 
7628: loss=0.115, reward_mean=0.460, reward_bound=0.342, batch=227 
7629: loss=0.117, reward_mean=0.400, reward_bound=0.308, batch=229 
7630: loss=0.117, reward_mean=0.460, reward_bound=0.349, batch=225 
7631: loss=0.117, reward_mean=0.460, reward_bound=0.349, batch=225 
7632: loss=0.121, reward_mean=0.460, reward_bound=0.387, batch=193 
7633: loss=0.117, reward_mean=0.400, reward_bound=0.105, batch=205 
7634: loss=0.120, reward_mean=0.540, reward_bound=0.206, batch=212 
7635: loss=0.119, reward_mean=0.350, reward_bound=0.213, batch=218 
7636: loss=0.119, reward_mean=0.540, reward_bound=0.282, batch=220 
7637: loss=0.120, reward_mean=0.420, reward_bound=0.304, batch=224 
7638: loss=0.120, reward_mean=0.370, reward_bound=0.314, batch=225 
7639: loss=0.120, reward_mean=0.530, reward_bound=0.349, batch=222 
7640: loss=0.120, reward_mean=0.470, reward_bound=0.360, batch=225 
7641: loss=0.121, reward_mean=0.410, reward_bound=0.387, batch=214 
7642: loss=0.121, reward_mean=0.450, reward_bound=0.349, batch=219 
7643: loss=0.121, reward_mean=0.480, reward_bound=0.314, batch=222 
7644: loss=0.122, reward_mean=0.420, reward_bound=0.349, batch=224 
7645: loss=0.121, reward_mean=0.480, reward_bound=0.384, batch=227 
7646: loss=0.121, reward_mean=0.510, reward_bound=0.387, batch=225 
7647: loss=0.121, reward_mean=0.540, reward_bound=0.365, batch=227 
7648: loss=0.138, reward_mean=0.460, reward_bound=0.430, batch=119 
7649: loss=0.092, reward_mean=0.440, reward_bound=0.007, batch=153 
7650: loss=0.090, reward_mean=0.460, reward_bound=0.022, batch=177 
7651: loss=0.101, reward_mean=0.480, reward_bound=0.042, batch=194 
7652: loss=0.110, reward_mean=0.480, reward_bound=0.072, batch=205 
7653: loss=0.122, reward_mean=0.490, reward_bound=0.109, batch=214 
7654: loss=0.127, reward_mean=0.420, reward_bound=0.122, batch=213 
7655: loss=0.126, reward_mean=0.480, reward_bound=0.150, batch=213 
7656: loss=0.124, reward_mean=0.470, reward_bound=0.167, batch=212 
7657: loss=0.126, reward_mean=0.510, reward_bound=0.185, batch=214 
7658: loss=0.122, reward_mean=0.410, reward_bound=0.206, batch=219 
7659: loss=0.123, reward_mean=0.440, reward_bound=0.229, batch=213 
7660: loss=0.124, reward_mean=0.390, reward_bound=0.229, batch=218 
7661: loss=0.124, reward_mean=0.440, reward_bound=0.231, batch=222 
7662: loss=0.126, reward_mean=0.450, reward_bound=0.254, batch=210 
7663: loss=0.127, reward_mean=0.440, reward_bound=0.247, batch=217 
7664: loss=0.127, reward_mean=0.410, reward_bound=0.229, batch=221 
7665: loss=0.129, reward_mean=0.420, reward_bound=0.254, batch=222 
7666: loss=0.128, reward_mean=0.470, reward_bound=0.263, batch=225 
7667: loss=0.126, reward_mean=0.510, reward_bound=0.282, batch=216 
7668: loss=0.127, reward_mean=0.530, reward_bound=0.282, batch=220 
7669: loss=0.125, reward_mean=0.510, reward_bound=0.254, batch=223 
7670: loss=0.132, reward_mean=0.490, reward_bound=0.314, batch=205 
7671: loss=0.136, reward_mean=0.490, reward_bound=0.260, batch=213 
7672: loss=0.137, reward_mean=0.470, reward_bound=0.206, batch=218 
7673: loss=0.137, reward_mean=0.490, reward_bound=0.231, batch=222 
7674: loss=0.135, reward_mean=0.430, reward_bound=0.314, batch=222 
7675: loss=0.137, reward_mean=0.510, reward_bound=0.349, batch=199 
7676: loss=0.139, reward_mean=0.400, reward_bound=0.167, batch=208 
7677: loss=0.136, reward_mean=0.440, reward_bound=0.187, batch=215 
7678: loss=0.137, reward_mean=0.500, reward_bound=0.229, batch=217 
7679: loss=0.139, reward_mean=0.460, reward_bound=0.254, batch=221 
7680: loss=0.137, reward_mean=0.430, reward_bound=0.314, batch=221 
7681: loss=0.138, reward_mean=0.430, reward_bound=0.349, batch=219 
7682: loss=0.137, reward_mean=0.460, reward_bound=0.295, batch=223 
7683: loss=0.137, reward_mean=0.430, reward_bound=0.349, batch=221 
7684: loss=0.136, reward_mean=0.430, reward_bound=0.349, batch=224 
7685: loss=0.136, reward_mean=0.450, reward_bound=0.384, batch=227 
7686: loss=0.135, reward_mean=0.350, reward_bound=0.282, batch=228 
7687: loss=0.136, reward_mean=0.380, reward_bound=0.387, batch=202 
7688: loss=0.133, reward_mean=0.490, reward_bound=0.263, batch=211 
7689: loss=0.133, reward_mean=0.490, reward_bound=0.254, batch=217 
7690: loss=0.132, reward_mean=0.270, reward_bound=0.213, batch=222 
7691: loss=0.136, reward_mean=0.340, reward_bound=0.314, batch=222 
7692: loss=0.134, reward_mean=0.500, reward_bound=0.349, batch=224 
7693: loss=0.133, reward_mean=0.420, reward_bound=0.384, batch=227 
7694: loss=0.133, reward_mean=0.460, reward_bound=0.373, batch=229 
7695: loss=0.137, reward_mean=0.450, reward_bound=0.387, batch=220 
7696: loss=0.137, reward_mean=0.430, reward_bound=0.296, batch=224 
7697: loss=0.138, reward_mean=0.470, reward_bound=0.345, batch=227 
7698: loss=0.138, reward_mean=0.440, reward_bound=0.387, batch=226 
7699: loss=0.137, reward_mean=0.460, reward_bound=0.372, batch=228 
7700: loss=0.141, reward_mean=0.370, reward_bound=0.430, batch=173 
7701: loss=0.137, reward_mean=0.420, reward_bound=0.135, batch=190 
7702: loss=0.136, reward_mean=0.420, reward_bound=0.150, batch=202 
7703: loss=0.133, reward_mean=0.430, reward_bound=0.167, batch=208 
7704: loss=0.130, reward_mean=0.410, reward_bound=0.187, batch=215 
7705: loss=0.130, reward_mean=0.340, reward_bound=0.206, batch=213 
7706: loss=0.129, reward_mean=0.480, reward_bound=0.229, batch=216 
7707: loss=0.132, reward_mean=0.460, reward_bound=0.254, batch=208 
7708: loss=0.129, reward_mean=0.450, reward_bound=0.254, batch=214 
7709: loss=0.127, reward_mean=0.420, reward_bound=0.254, batch=219 
7710: loss=0.126, reward_mean=0.360, reward_bound=0.265, batch=223 
7711: loss=0.131, reward_mean=0.450, reward_bound=0.282, batch=216 
7712: loss=0.134, reward_mean=0.470, reward_bound=0.314, batch=212 
7713: loss=0.137, reward_mean=0.470, reward_bound=0.349, batch=205 
7714: loss=0.137, reward_mean=0.430, reward_bound=0.185, batch=211 
7715: loss=0.134, reward_mean=0.400, reward_bound=0.229, batch=217 
7716: loss=0.134, reward_mean=0.510, reward_bound=0.254, batch=218 
7717: loss=0.132, reward_mean=0.500, reward_bound=0.282, batch=219 
7718: loss=0.131, reward_mean=0.430, reward_bound=0.349, batch=222 
7719: loss=0.130, reward_mean=0.490, reward_bound=0.324, batch=225 
7720: loss=0.129, reward_mean=0.500, reward_bound=0.349, batch=226 
7721: loss=0.132, reward_mean=0.420, reward_bound=0.387, batch=207 
7722: loss=0.129, reward_mean=0.480, reward_bound=0.229, batch=214 
7723: loss=0.129, reward_mean=0.490, reward_bound=0.254, batch=216 
7724: loss=0.129, reward_mean=0.470, reward_bound=0.314, batch=219 
7725: loss=0.130, reward_mean=0.470, reward_bound=0.349, batch=220 
7726: loss=0.129, reward_mean=0.480, reward_bound=0.387, batch=220 
7727: loss=0.128, reward_mean=0.520, reward_bound=0.338, batch=224 
7728: loss=0.127, reward_mean=0.490, reward_bound=0.384, batch=227 
7729: loss=0.127, reward_mean=0.460, reward_bound=0.366, batch=229 
7730: loss=0.132, reward_mean=0.470, reward_bound=0.430, batch=203 
7731: loss=0.133, reward_mean=0.440, reward_bound=0.206, batch=209 
7732: loss=0.130, reward_mean=0.440, reward_bound=0.215, batch=216 
7733: loss=0.132, reward_mean=0.460, reward_bound=0.298, batch=221 
7734: loss=0.131, reward_mean=0.500, reward_bound=0.254, batch=224 
7735: loss=0.134, reward_mean=0.370, reward_bound=0.314, batch=226 
7736: loss=0.132, reward_mean=0.460, reward_bound=0.349, batch=224 
7737: loss=0.132, reward_mean=0.440, reward_bound=0.387, batch=221 
7738: loss=0.131, reward_mean=0.450, reward_bound=0.254, batch=224 
7739: loss=0.131, reward_mean=0.420, reward_bound=0.422, batch=227 
7740: loss=0.130, reward_mean=0.540, reward_bound=0.422, batch=229 
7741: loss=0.129, reward_mean=0.330, reward_bound=0.430, batch=221 
7742: loss=0.128, reward_mean=0.480, reward_bound=0.387, batch=223 
7743: loss=0.127, reward_mean=0.510, reward_bound=0.413, batch=226 
7744: loss=0.130, reward_mean=0.480, reward_bound=0.430, batch=225 
7745: loss=0.129, reward_mean=0.490, reward_bound=0.430, batch=226 
7746: loss=0.129, reward_mean=0.530, reward_bound=0.368, batch=228 
7747: loss=0.130, reward_mean=0.420, reward_bound=0.353, batch=229 
7748: loss=0.130, reward_mean=0.470, reward_bound=0.405, batch=230 
7749: loss=0.130, reward_mean=0.430, reward_bound=0.430, batch=230 
7750: loss=0.130, reward_mean=0.430, reward_bound=0.451, batch=231 
7751: loss=0.137, reward_mean=0.500, reward_bound=0.478, batch=89 
7752: loss=0.086, reward_mean=0.440, reward_bound=0.000, batch=132 
7753: loss=0.084, reward_mean=0.430, reward_bound=0.008, batch=161 
7754: loss=0.084, reward_mean=0.450, reward_bound=0.015, batch=182 
7755: loss=0.084, reward_mean=0.400, reward_bound=0.034, batch=195 
7756: loss=0.088, reward_mean=0.470, reward_bound=0.059, batch=206 
7757: loss=0.095, reward_mean=0.490, reward_bound=0.089, batch=210 
7758: loss=0.091, reward_mean=0.390, reward_bound=0.098, batch=211 
7759: loss=0.091, reward_mean=0.470, reward_bound=0.109, batch=216 
7760: loss=0.105, reward_mean=0.410, reward_bound=0.135, batch=211 
7761: loss=0.102, reward_mean=0.580, reward_bound=0.167, batch=204 
7762: loss=0.101, reward_mean=0.420, reward_bound=0.150, batch=212 
7763: loss=0.101, reward_mean=0.440, reward_bound=0.185, batch=210 
7764: loss=0.099, reward_mean=0.420, reward_bound=0.206, batch=226 
7765: loss=0.103, reward_mean=0.420, reward_bound=0.206, batch=220 
7766: loss=0.108, reward_mean=0.460, reward_bound=0.229, batch=215 
7767: loss=0.111, reward_mean=0.520, reward_bound=0.254, batch=206 
7768: loss=0.109, reward_mean=0.440, reward_bound=0.198, batch=214 
7769: loss=0.109, reward_mean=0.460, reward_bound=0.254, batch=219 
7770: loss=0.118, reward_mean=0.320, reward_bound=0.282, batch=201 
7771: loss=0.114, reward_mean=0.400, reward_bound=0.167, batch=210 
7772: loss=0.113, reward_mean=0.470, reward_bound=0.222, batch=217 
7773: loss=0.112, reward_mean=0.380, reward_bound=0.277, batch=222 
7774: loss=0.112, reward_mean=0.410, reward_bound=0.282, batch=223 
7775: loss=0.113, reward_mean=0.490, reward_bound=0.314, batch=201 
7776: loss=0.115, reward_mean=0.570, reward_bound=0.282, batch=209 
7777: loss=0.115, reward_mean=0.430, reward_bound=0.215, batch=216 
7778: loss=0.116, reward_mean=0.400, reward_bound=0.229, batch=220 
7779: loss=0.114, reward_mean=0.390, reward_bound=0.247, batch=224 
7780: loss=0.115, reward_mean=0.430, reward_bound=0.282, batch=224 
7781: loss=0.115, reward_mean=0.450, reward_bound=0.314, batch=223 
7782: loss=0.120, reward_mean=0.490, reward_bound=0.349, batch=189 
7783: loss=0.118, reward_mean=0.430, reward_bound=0.167, batch=201 
7784: loss=0.114, reward_mean=0.490, reward_bound=0.150, batch=210 
7785: loss=0.110, reward_mean=0.470, reward_bound=0.185, batch=216 
7786: loss=0.112, reward_mean=0.500, reward_bound=0.229, batch=219 
7787: loss=0.112, reward_mean=0.380, reward_bound=0.254, batch=219 
7788: loss=0.112, reward_mean=0.570, reward_bound=0.282, batch=221 
7789: loss=0.117, reward_mean=0.500, reward_bound=0.314, batch=218 
7790: loss=0.116, reward_mean=0.480, reward_bound=0.314, batch=220 
7791: loss=0.118, reward_mean=0.380, reward_bound=0.304, batch=224 
7792: loss=0.118, reward_mean=0.430, reward_bound=0.314, batch=224 
7793: loss=0.117, reward_mean=0.480, reward_bound=0.349, batch=217 
7794: loss=0.117, reward_mean=0.420, reward_bound=0.373, batch=222 
7795: loss=0.118, reward_mean=0.470, reward_bound=0.349, batch=223 
7796: loss=0.117, reward_mean=0.410, reward_bound=0.372, batch=226 
7797: loss=0.117, reward_mean=0.520, reward_bound=0.349, batch=227 
7798: loss=0.121, reward_mean=0.470, reward_bound=0.387, batch=188 
7799: loss=0.116, reward_mean=0.530, reward_bound=0.187, batch=201 
7800: loss=0.120, reward_mean=0.500, reward_bound=0.206, batch=206 
7801: loss=0.121, reward_mean=0.430, reward_bound=0.229, batch=211 
7802: loss=0.118, reward_mean=0.560, reward_bound=0.254, batch=212 
7803: loss=0.119, reward_mean=0.410, reward_bound=0.229, batch=217 
7804: loss=0.118, reward_mean=0.460, reward_bound=0.254, batch=220 
7805: loss=0.118, reward_mean=0.450, reward_bound=0.282, batch=217 
7806: loss=0.116, reward_mean=0.520, reward_bound=0.206, batch=221 
7807: loss=0.122, reward_mean=0.480, reward_bound=0.314, batch=223 
7808: loss=0.121, reward_mean=0.470, reward_bound=0.349, batch=222 
7809: loss=0.123, reward_mean=0.520, reward_bound=0.387, batch=209 
7810: loss=0.120, reward_mean=0.370, reward_bound=0.167, batch=215 
7811: loss=0.121, reward_mean=0.500, reward_bound=0.206, batch=217 
7812: loss=0.121, reward_mean=0.390, reward_bound=0.314, batch=220 
7813: loss=0.119, reward_mean=0.440, reward_bound=0.349, batch=222 
7814: loss=0.122, reward_mean=0.450, reward_bound=0.360, batch=225 
7815: loss=0.125, reward_mean=0.420, reward_bound=0.387, batch=224 
7816: loss=0.124, reward_mean=0.490, reward_bound=0.426, batch=227 
7817: loss=0.134, reward_mean=0.500, reward_bound=0.430, batch=164 
7818: loss=0.129, reward_mean=0.600, reward_bound=0.134, batch=185 
7819: loss=0.125, reward_mean=0.390, reward_bound=0.073, batch=199 
7820: loss=0.124, reward_mean=0.470, reward_bound=0.141, batch=209 
7821: loss=0.124, reward_mean=0.450, reward_bound=0.167, batch=208 
7822: loss=0.125, reward_mean=0.460, reward_bound=0.185, batch=208 
7823: loss=0.128, reward_mean=0.430, reward_bound=0.206, batch=211 
7824: loss=0.132, reward_mean=0.390, reward_bound=0.229, batch=212 
7825: loss=0.130, reward_mean=0.450, reward_bound=0.254, batch=209 
7826: loss=0.129, reward_mean=0.520, reward_bound=0.265, batch=216 
7827: loss=0.132, reward_mean=0.480, reward_bound=0.282, batch=213 
7828: loss=0.128, reward_mean=0.520, reward_bound=0.271, batch=219 
7829: loss=0.130, reward_mean=0.400, reward_bound=0.282, batch=220 
7830: loss=0.132, reward_mean=0.500, reward_bound=0.314, batch=212 
7831: loss=0.130, reward_mean=0.390, reward_bound=0.302, batch=218 
7832: loss=0.131, reward_mean=0.410, reward_bound=0.349, batch=210 
7833: loss=0.128, reward_mean=0.570, reward_bound=0.254, batch=216 
7834: loss=0.128, reward_mean=0.460, reward_bound=0.282, batch=219 
7835: loss=0.130, reward_mean=0.370, reward_bound=0.314, batch=219 
7836: loss=0.132, reward_mean=0.470, reward_bound=0.309, batch=223 
7837: loss=0.131, reward_mean=0.440, reward_bound=0.335, batch=226 
7838: loss=0.133, reward_mean=0.480, reward_bound=0.349, batch=226 
7839: loss=0.133, reward_mean=0.380, reward_bound=0.349, batch=227 
7840: loss=0.133, reward_mean=0.470, reward_bound=0.387, batch=208 
7841: loss=0.132, reward_mean=0.470, reward_bound=0.286, batch=215 
7842: loss=0.129, reward_mean=0.450, reward_bound=0.314, batch=219 
7843: loss=0.129, reward_mean=0.420, reward_bound=0.295, batch=223 
7844: loss=0.130, reward_mean=0.430, reward_bound=0.314, batch=224 
7845: loss=0.130, reward_mean=0.400, reward_bound=0.349, batch=223 
7846: loss=0.132, reward_mean=0.430, reward_bound=0.387, batch=225 
7847: loss=0.133, reward_mean=0.440, reward_bound=0.396, batch=227 
7848: loss=0.132, reward_mean=0.510, reward_bound=0.380, batch=229 
7849: loss=0.136, reward_mean=0.510, reward_bound=0.430, batch=200 
7850: loss=0.131, reward_mean=0.400, reward_bound=0.162, batch=210 
7851: loss=0.131, reward_mean=0.390, reward_bound=0.206, batch=218 
7852: loss=0.132, reward_mean=0.490, reward_bound=0.229, batch=220 
7853: loss=0.132, reward_mean=0.400, reward_bound=0.254, batch=222 
7854: loss=0.132, reward_mean=0.420, reward_bound=0.254, batch=224 
7855: loss=0.131, reward_mean=0.330, reward_bound=0.311, batch=227 
7856: loss=0.134, reward_mean=0.460, reward_bound=0.314, batch=223 
7857: loss=0.135, reward_mean=0.530, reward_bound=0.349, batch=222 
7858: loss=0.135, reward_mean=0.440, reward_bound=0.336, batch=225 
7859: loss=0.131, reward_mean=0.370, reward_bound=0.387, batch=218 
7860: loss=0.129, reward_mean=0.410, reward_bound=0.254, batch=221 
7861: loss=0.129, reward_mean=0.400, reward_bound=0.282, batch=223 
7862: loss=0.130, reward_mean=0.510, reward_bound=0.314, batch=223 
7863: loss=0.133, reward_mean=0.370, reward_bound=0.349, batch=225 
7864: loss=0.133, reward_mean=0.570, reward_bound=0.396, batch=227 
7865: loss=0.136, reward_mean=0.460, reward_bound=0.342, batch=229 
7866: loss=0.133, reward_mean=0.510, reward_bound=0.364, batch=230 
7867: loss=0.133, reward_mean=0.490, reward_bound=0.349, batch=230 
7868: loss=0.132, reward_mean=0.400, reward_bound=0.387, batch=229 
7869: loss=0.136, reward_mean=0.430, reward_bound=0.430, batch=216 
7870: loss=0.135, reward_mean=0.420, reward_bound=0.368, batch=221 
7871: loss=0.134, reward_mean=0.500, reward_bound=0.349, batch=223 
7872: loss=0.133, reward_mean=0.430, reward_bound=0.229, batch=224 
7873: loss=0.131, reward_mean=0.390, reward_bound=0.277, batch=227 
7874: loss=0.136, reward_mean=0.490, reward_bound=0.314, batch=228 
7875: loss=0.136, reward_mean=0.550, reward_bound=0.387, batch=226 
7876: loss=0.136, reward_mean=0.500, reward_bound=0.349, batch=227 
7877: loss=0.135, reward_mean=0.490, reward_bound=0.430, batch=226 
7878: loss=0.134, reward_mean=0.480, reward_bound=0.413, batch=228 
7879: loss=0.133, reward_mean=0.480, reward_bound=0.478, batch=230 
7880: loss=0.133, reward_mean=0.400, reward_bound=0.451, batch=231 
7881: loss=0.133, reward_mean=0.470, reward_bound=0.387, batch=231 
7882: loss=0.134, reward_mean=0.360, reward_bound=0.478, batch=150 
7883: loss=0.126, reward_mean=0.450, reward_bound=0.127, batch=175 
7884: loss=0.120, reward_mean=0.420, reward_bound=0.122, batch=191 
7885: loss=0.122, reward_mean=0.490, reward_bound=0.150, batch=198 
7886: loss=0.125, reward_mean=0.450, reward_bound=0.185, batch=206 
7887: loss=0.121, reward_mean=0.530, reward_bound=0.206, batch=208 
7888: loss=0.118, reward_mean=0.490, reward_bound=0.229, batch=211 
7889: loss=0.118, reward_mean=0.440, reward_bound=0.229, batch=214 
7890: loss=0.117, reward_mean=0.460, reward_bound=0.229, batch=218 
7891: loss=0.128, reward_mean=0.470, reward_bound=0.254, batch=207 
7892: loss=0.126, reward_mean=0.480, reward_bound=0.254, batch=214 
7893: loss=0.127, reward_mean=0.440, reward_bound=0.275, batch=220 
7894: loss=0.126, reward_mean=0.470, reward_bound=0.282, batch=212 
7895: loss=0.123, reward_mean=0.510, reward_bound=0.282, batch=217 
7896: loss=0.124, reward_mean=0.480, reward_bound=0.314, batch=207 
7897: loss=0.124, reward_mean=0.440, reward_bound=0.342, batch=215 
7898: loss=0.122, reward_mean=0.410, reward_bound=0.260, batch=220 
7899: loss=0.123, reward_mean=0.440, reward_bound=0.282, batch=222 
7900: loss=0.125, reward_mean=0.550, reward_bound=0.349, batch=210 
7901: loss=0.124, reward_mean=0.410, reward_bound=0.254, batch=216 
7902: loss=0.124, reward_mean=0.390, reward_bound=0.349, batch=218 
7903: loss=0.124, reward_mean=0.510, reward_bound=0.349, batch=221 
7904: loss=0.123, reward_mean=0.510, reward_bound=0.349, batch=224 
7905: loss=0.127, reward_mean=0.520, reward_bound=0.387, batch=200 
7906: loss=0.124, reward_mean=0.410, reward_bound=0.135, batch=209 
7907: loss=0.121, reward_mean=0.460, reward_bound=0.206, batch=215 
7908: loss=0.120, reward_mean=0.440, reward_bound=0.254, batch=215 
7909: loss=0.120, reward_mean=0.430, reward_bound=0.282, batch=219 
7910: loss=0.122, reward_mean=0.420, reward_bound=0.314, batch=219 
7911: loss=0.123, reward_mean=0.520, reward_bound=0.349, batch=218 
7912: loss=0.121, reward_mean=0.480, reward_bound=0.286, batch=222 
7913: loss=0.120, reward_mean=0.440, reward_bound=0.254, batch=224 
7914: loss=0.120, reward_mean=0.410, reward_bound=0.349, batch=225 
7915: loss=0.120, reward_mean=0.430, reward_bound=0.349, batch=226 
7916: loss=0.120, reward_mean=0.460, reward_bound=0.368, batch=228 
7917: loss=0.125, reward_mean=0.400, reward_bound=0.387, batch=220 
7918: loss=0.127, reward_mean=0.430, reward_bound=0.314, batch=223 
7919: loss=0.126, reward_mean=0.500, reward_bound=0.244, batch=226 
7920: loss=0.128, reward_mean=0.490, reward_bound=0.282, batch=227 
7921: loss=0.128, reward_mean=0.450, reward_bound=0.314, batch=227 
7922: loss=0.126, reward_mean=0.410, reward_bound=0.349, batch=227 
7923: loss=0.125, reward_mean=0.450, reward_bound=0.387, batch=227 
7924: loss=0.131, reward_mean=0.440, reward_bound=0.430, batch=195 
7925: loss=0.125, reward_mean=0.490, reward_bound=0.189, batch=206 
7926: loss=0.124, reward_mean=0.430, reward_bound=0.196, batch=214 
7927: loss=0.124, reward_mean=0.540, reward_bound=0.206, batch=218 
7928: loss=0.129, reward_mean=0.510, reward_bound=0.231, batch=222 
7929: loss=0.131, reward_mean=0.470, reward_bound=0.282, batch=219 
7930: loss=0.129, reward_mean=0.500, reward_bound=0.282, batch=222 
7931: loss=0.131, reward_mean=0.460, reward_bound=0.314, batch=214 
7932: loss=0.128, reward_mean=0.310, reward_bound=0.183, batch=220 
7933: loss=0.126, reward_mean=0.400, reward_bound=0.247, batch=224 
7934: loss=0.129, reward_mean=0.470, reward_bound=0.314, batch=221 
7935: loss=0.127, reward_mean=0.430, reward_bound=0.349, batch=222 
7936: loss=0.126, reward_mean=0.540, reward_bound=0.360, batch=225 
7937: loss=0.122, reward_mean=0.500, reward_bound=0.387, batch=221 
7938: loss=0.121, reward_mean=0.370, reward_bound=0.387, batch=223 
7939: loss=0.122, reward_mean=0.510, reward_bound=0.387, batch=224 
7940: loss=0.121, reward_mean=0.500, reward_bound=0.426, batch=227 
7941: loss=0.121, reward_mean=0.430, reward_bound=0.229, batch=228 
7942: loss=0.120, reward_mean=0.460, reward_bound=0.353, batch=229 
7943: loss=0.121, reward_mean=0.430, reward_bound=0.387, batch=229 
7944: loss=0.121, reward_mean=0.310, reward_bound=0.342, batch=230 
7945: loss=0.128, reward_mean=0.420, reward_bound=0.430, batch=210 
7946: loss=0.131, reward_mean=0.460, reward_bound=0.274, batch=217 
7947: loss=0.132, reward_mean=0.460, reward_bound=0.220, batch=222 
7948: loss=0.131, reward_mean=0.340, reward_bound=0.263, batch=225 
7949: loss=0.124, reward_mean=0.450, reward_bound=0.314, batch=225 
7950: loss=0.123, reward_mean=0.480, reward_bound=0.321, batch=227 
7951: loss=0.123, reward_mean=0.450, reward_bound=0.282, batch=228 
7952: loss=0.123, reward_mean=0.420, reward_bound=0.317, batch=229 
7953: loss=0.128, reward_mean=0.440, reward_bound=0.349, batch=223 
7954: loss=0.130, reward_mean=0.380, reward_bound=0.387, batch=221 
7955: loss=0.131, reward_mean=0.500, reward_bound=0.430, batch=221 
7956: loss=0.131, reward_mean=0.450, reward_bound=0.387, batch=224 
7957: loss=0.131, reward_mean=0.480, reward_bound=0.282, batch=226 
7958: loss=0.129, reward_mean=0.590, reward_bound=0.430, batch=226 
7959: loss=0.129, reward_mean=0.550, reward_bound=0.368, batch=228 
7960: loss=0.131, reward_mean=0.430, reward_bound=0.353, batch=229 
7961: loss=0.131, reward_mean=0.410, reward_bound=0.424, batch=230 
7962: loss=0.134, reward_mean=0.420, reward_bound=0.478, batch=188 
7963: loss=0.126, reward_mean=0.470, reward_bound=0.167, batch=200 
7964: loss=0.119, reward_mean=0.480, reward_bound=0.206, batch=212 
7965: loss=0.122, reward_mean=0.480, reward_bound=0.220, batch=218 
7966: loss=0.122, reward_mean=0.430, reward_bound=0.254, batch=220 
7967: loss=0.124, reward_mean=0.470, reward_bound=0.282, batch=212 
7968: loss=0.124, reward_mean=0.450, reward_bound=0.314, batch=213 
7969: loss=0.123, reward_mean=0.450, reward_bound=0.314, batch=218 
7970: loss=0.122, reward_mean=0.380, reward_bound=0.317, batch=222 
7971: loss=0.124, reward_mean=0.450, reward_bound=0.349, batch=214 
7972: loss=0.123, reward_mean=0.510, reward_bound=0.345, batch=220 
7973: loss=0.127, reward_mean=0.460, reward_bound=0.387, batch=212 
7974: loss=0.125, reward_mean=0.470, reward_bound=0.272, batch=218 
7975: loss=0.125, reward_mean=0.470, reward_bound=0.314, batch=218 
7976: loss=0.123, reward_mean=0.440, reward_bound=0.237, batch=222 
7977: loss=0.125, reward_mean=0.600, reward_bound=0.349, batch=218 
7978: loss=0.126, reward_mean=0.450, reward_bound=0.314, batch=221 
7979: loss=0.124, reward_mean=0.430, reward_bound=0.349, batch=224 
7980: loss=0.124, reward_mean=0.500, reward_bound=0.387, batch=221 
7981: loss=0.123, reward_mean=0.500, reward_bound=0.349, batch=224 
7982: loss=0.123, reward_mean=0.390, reward_bound=0.345, batch=227 
7983: loss=0.125, reward_mean=0.470, reward_bound=0.387, batch=227 
7984: loss=0.124, reward_mean=0.480, reward_bound=0.308, batch=229 
7985: loss=0.126, reward_mean=0.510, reward_bound=0.343, batch=230 
7986: loss=0.130, reward_mean=0.380, reward_bound=0.430, batch=212 
7987: loss=0.130, reward_mean=0.430, reward_bound=0.292, batch=218 
7988: loss=0.130, reward_mean=0.510, reward_bound=0.314, batch=219 
7989: loss=0.129, reward_mean=0.390, reward_bound=0.314, batch=222 
7990: loss=0.126, reward_mean=0.380, reward_bound=0.349, batch=224 
7991: loss=0.127, reward_mean=0.470, reward_bound=0.380, batch=227 
7992: loss=0.127, reward_mean=0.450, reward_bound=0.277, batch=229 
7993: loss=0.128, reward_mean=0.480, reward_bound=0.387, batch=225 
7994: loss=0.129, reward_mean=0.570, reward_bound=0.321, batch=227 
7995: loss=0.127, reward_mean=0.420, reward_bound=0.380, batch=229 
7996: loss=0.127, reward_mean=0.510, reward_bound=0.364, batch=230 
7997: loss=0.128, reward_mean=0.520, reward_bound=0.387, batch=230 
7998: loss=0.127, reward_mean=0.540, reward_bound=0.418, batch=231 
7999: loss=0.127, reward_mean=0.390, reward_bound=0.430, batch=222 
8000: loss=0.127, reward_mean=0.510, reward_bound=0.349, batch=224 
8001: loss=0.126, reward_mean=0.440, reward_bound=0.384, batch=227 
8002: loss=0.128, reward_mean=0.410, reward_bound=0.387, batch=228 
8003: loss=0.129, reward_mean=0.510, reward_bound=0.430, batch=226 
8004: loss=0.130, reward_mean=0.510, reward_bound=0.368, batch=228 
8005: loss=0.130, reward_mean=0.450, reward_bound=0.392, batch=229 
8006: loss=0.130, reward_mean=0.520, reward_bound=0.430, batch=228 
8007: loss=0.131, reward_mean=0.410, reward_bound=0.478, batch=230 
8008: loss=0.133, reward_mean=0.430, reward_bound=0.365, batch=231 
8009: loss=0.131, reward_mean=0.440, reward_bound=0.430, batch=231 
8010: loss=0.136, reward_mean=0.500, reward_bound=0.478, batch=206 
8011: loss=0.136, reward_mean=0.450, reward_bound=0.206, batch=213 
8012: loss=0.137, reward_mean=0.430, reward_bound=0.244, batch=219 
8013: loss=0.134, reward_mean=0.450, reward_bound=0.254, batch=221 
8014: loss=0.139, reward_mean=0.460, reward_bound=0.314, batch=218 
8015: loss=0.143, reward_mean=0.470, reward_bound=0.349, batch=220 
8016: loss=0.141, reward_mean=0.450, reward_bound=0.282, batch=223 
8017: loss=0.142, reward_mean=0.480, reward_bound=0.349, batch=222 
8018: loss=0.141, reward_mean=0.450, reward_bound=0.360, batch=225 
8019: loss=0.136, reward_mean=0.440, reward_bound=0.387, batch=221 
8020: loss=0.135, reward_mean=0.480, reward_bound=0.282, batch=224 
8021: loss=0.134, reward_mean=0.470, reward_bound=0.311, batch=227 
8022: loss=0.134, reward_mean=0.520, reward_bound=0.349, batch=228 
8023: loss=0.135, reward_mean=0.480, reward_bound=0.392, batch=229 
8024: loss=0.139, reward_mean=0.500, reward_bound=0.430, batch=217 
8025: loss=0.140, reward_mean=0.480, reward_bound=0.277, batch=222 
8026: loss=0.138, reward_mean=0.490, reward_bound=0.282, batch=223 
8027: loss=0.137, reward_mean=0.490, reward_bound=0.314, batch=223 
8028: loss=0.136, reward_mean=0.550, reward_bound=0.349, batch=224 
8029: loss=0.135, reward_mean=0.480, reward_bound=0.280, batch=227 
8030: loss=0.135, reward_mean=0.490, reward_bound=0.308, batch=229 
8031: loss=0.137, reward_mean=0.480, reward_bound=0.387, batch=223 
8032: loss=0.136, reward_mean=0.560, reward_bound=0.413, batch=226 
8033: loss=0.138, reward_mean=0.510, reward_bound=0.430, batch=221 
8034: loss=0.137, reward_mean=0.470, reward_bound=0.430, batch=222 
8035: loss=0.138, reward_mean=0.460, reward_bound=0.349, batch=224 
8036: loss=0.138, reward_mean=0.440, reward_bound=0.430, batch=226 
8037: loss=0.138, reward_mean=0.420, reward_bound=0.254, batch=227 
8038: loss=0.138, reward_mean=0.490, reward_bound=0.335, batch=229 
8039: loss=0.139, reward_mean=0.550, reward_bound=0.364, batch=230 
8040: loss=0.139, reward_mean=0.470, reward_bound=0.387, batch=230 
8041: loss=0.139, reward_mean=0.510, reward_bound=0.418, batch=231 
8042: loss=0.139, reward_mean=0.450, reward_bound=0.430, batch=231 
8043: loss=0.139, reward_mean=0.370, reward_bound=0.478, batch=218 
8044: loss=0.138, reward_mean=0.510, reward_bound=0.325, batch=222 
8045: loss=0.136, reward_mean=0.480, reward_bound=0.324, batch=225 
8046: loss=0.135, reward_mean=0.490, reward_bound=0.356, batch=227 
8047: loss=0.135, reward_mean=0.460, reward_bound=0.373, batch=229 
8048: loss=0.135, reward_mean=0.530, reward_bound=0.387, batch=228 
8049: loss=0.135, reward_mean=0.450, reward_bound=0.392, batch=229 
8050: loss=0.134, reward_mean=0.350, reward_bound=0.215, batch=230 
8051: loss=0.134, reward_mean=0.390, reward_bound=0.406, batch=231 
8052: loss=0.137, reward_mean=0.450, reward_bound=0.430, batch=223 
8053: loss=0.135, reward_mean=0.420, reward_bound=0.372, batch=226 
8054: loss=0.135, reward_mean=0.440, reward_bound=0.409, batch=228 
8055: loss=0.135, reward_mean=0.460, reward_bound=0.357, batch=229 
8056: loss=0.137, reward_mean=0.450, reward_bound=0.430, batch=228 
8057: loss=0.138, reward_mean=0.500, reward_bound=0.478, batch=232 
8058: loss=0.138, reward_mean=0.490, reward_bound=0.478, batch=222 
8059: loss=0.137, reward_mean=0.410, reward_bound=0.387, batch=224 
8060: loss=0.137, reward_mean=0.570, reward_bound=0.345, batch=227 
8061: loss=0.136, reward_mean=0.450, reward_bound=0.349, batch=228 
8062: loss=0.138, reward_mean=0.400, reward_bound=0.397, batch=229 
8063: loss=0.137, reward_mean=0.450, reward_bound=0.478, batch=231 
8064: loss=0.137, reward_mean=0.490, reward_bound=0.387, batch=231 
8065: loss=0.136, reward_mean=0.470, reward_bound=0.478, batch=225 
8066: loss=0.136, reward_mean=0.440, reward_bound=0.406, batch=227 
8067: loss=0.135, reward_mean=0.530, reward_bound=0.469, batch=229 
8068: loss=0.136, reward_mean=0.400, reward_bound=0.478, batch=232 
8069: loss=0.136, reward_mean=0.470, reward_bound=0.478, batch=227 
8070: loss=0.135, reward_mean=0.360, reward_bound=0.380, batch=229 
8071: loss=0.136, reward_mean=0.460, reward_bound=0.387, batch=229 
8072: loss=0.136, reward_mean=0.490, reward_bound=0.430, batch=229 
8073: loss=0.137, reward_mean=0.490, reward_bound=0.405, batch=230 
8074: loss=0.136, reward_mean=0.490, reward_bound=0.464, batch=231 
8075: loss=0.136, reward_mean=0.470, reward_bound=0.430, batch=231 
8076: loss=0.135, reward_mean=0.500, reward_bound=0.478, batch=228 
8077: loss=0.135, reward_mean=0.440, reward_bound=0.441, batch=229 
8078: loss=0.134, reward_mean=0.410, reward_bound=0.364, batch=230 
8079: loss=0.135, reward_mean=0.430, reward_bound=0.387, batch=230 
8080: loss=0.138, reward_mean=0.480, reward_bound=0.418, batch=231 
8081: loss=0.134, reward_mean=0.360, reward_bound=0.430, batch=231 
8082: loss=0.134, reward_mean=0.460, reward_bound=0.387, batch=231 
8084: loss=0.053, reward_mean=0.500, reward_bound=0.000, batch=50 
8085: loss=0.059, reward_mean=0.390, reward_bound=0.000, batch=89 
8086: loss=0.051, reward_mean=0.430, reward_bound=0.000, batch=132 
8087: loss=0.056, reward_mean=0.450, reward_bound=0.001, batch=162 
8088: loss=0.061, reward_mean=0.470, reward_bound=0.005, batch=182 
8089: loss=0.058, reward_mean=0.420, reward_bound=0.011, batch=197 
8090: loss=0.064, reward_mean=0.470, reward_bound=0.023, batch=207 
8091: loss=0.070, reward_mean=0.430, reward_bound=0.034, batch=214 
8092: loss=0.072, reward_mean=0.520, reward_bound=0.052, batch=218 
8093: loss=0.074, reward_mean=0.430, reward_bound=0.072, batch=215 
8094: loss=0.072, reward_mean=0.370, reward_bound=0.089, batch=222 
8095: loss=0.076, reward_mean=0.540, reward_bound=0.098, batch=219 
8096: loss=0.079, reward_mean=0.480, reward_bound=0.109, batch=222 
8097: loss=0.079, reward_mean=0.470, reward_bound=0.122, batch=218 
8098: loss=0.082, reward_mean=0.570, reward_bound=0.135, batch=213 
8099: loss=0.080, reward_mean=0.470, reward_bound=0.150, batch=207 
8100: loss=0.076, reward_mean=0.400, reward_bound=0.167, batch=201 
8101: loss=0.081, reward_mean=0.460, reward_bound=0.185, batch=185 
8102: loss=0.080, reward_mean=0.480, reward_bound=0.135, batch=197 
8103: loss=0.083, reward_mean=0.400, reward_bound=0.206, batch=185 
8104: loss=0.084, reward_mean=0.480, reward_bound=0.118, batch=199 
8105: loss=0.084, reward_mean=0.450, reward_bound=0.157, batch=209 
8106: loss=0.082, reward_mean=0.470, reward_bound=0.185, batch=215 
8107: loss=0.082, reward_mean=0.430, reward_bound=0.229, batch=191 
8108: loss=0.084, reward_mean=0.460, reward_bound=0.185, batch=203 
8109: loss=0.081, reward_mean=0.450, reward_bound=0.206, batch=210 
8110: loss=0.089, reward_mean=0.460, reward_bound=0.254, batch=185 
8111: loss=0.091, reward_mean=0.430, reward_bound=0.179, batch=199 
8112: loss=0.089, reward_mean=0.430, reward_bound=0.148, batch=209 
8113: loss=0.090, reward_mean=0.390, reward_bound=0.185, batch=215 
8114: loss=0.090, reward_mean=0.450, reward_bound=0.210, batch=220 
8115: loss=0.092, reward_mean=0.430, reward_bound=0.254, batch=222 
8116: loss=0.087, reward_mean=0.440, reward_bound=0.282, batch=188 
8117: loss=0.088, reward_mean=0.460, reward_bound=0.150, batch=199 
8118: loss=0.092, reward_mean=0.500, reward_bound=0.206, batch=206 
8119: loss=0.093, reward_mean=0.450, reward_bound=0.217, batch=214 
8120: loss=0.092, reward_mean=0.590, reward_bound=0.229, batch=218 
8121: loss=0.091, reward_mean=0.430, reward_bound=0.282, batch=219 
8122: loss=0.097, reward_mean=0.390, reward_bound=0.314, batch=169 
8123: loss=0.097, reward_mean=0.470, reward_bound=0.150, batch=186 
8124: loss=0.096, reward_mean=0.510, reward_bound=0.167, batch=199 
8125: loss=0.091, reward_mean=0.520, reward_bound=0.185, batch=205 
8126: loss=0.093, reward_mean=0.390, reward_bound=0.206, batch=209 
8127: loss=0.092, reward_mean=0.440, reward_bound=0.229, batch=214 
8128: loss=0.092, reward_mean=0.500, reward_bound=0.252, batch=220 
8129: loss=0.094, reward_mean=0.450, reward_bound=0.254, batch=220 
8130: loss=0.095, reward_mean=0.500, reward_bound=0.282, batch=217 
8131: loss=0.095, reward_mean=0.460, reward_bound=0.254, batch=221 
8132: loss=0.095, reward_mean=0.520, reward_bound=0.314, batch=208 
8133: loss=0.102, reward_mean=0.370, reward_bound=0.349, batch=153 
8134: loss=0.089, reward_mean=0.420, reward_bound=0.065, batch=176 
8135: loss=0.088, reward_mean=0.490, reward_bound=0.099, batch=193 
8136: loss=0.087, reward_mean=0.430, reward_bound=0.122, batch=202 
8137: loss=0.087, reward_mean=0.470, reward_bound=0.167, batch=210 
8138: loss=0.090, reward_mean=0.450, reward_bound=0.185, batch=211 
8139: loss=0.094, reward_mean=0.390, reward_bound=0.206, batch=211 
8140: loss=0.096, reward_mean=0.450, reward_bound=0.229, batch=211 
8141: loss=0.107, reward_mean=0.470, reward_bound=0.254, batch=211 
8142: loss=0.109, reward_mean=0.390, reward_bound=0.254, batch=215 
8143: loss=0.105, reward_mean=0.520, reward_bound=0.282, batch=213 
8144: loss=0.104, reward_mean=0.450, reward_bound=0.271, batch=219 
8145: loss=0.097, reward_mean=0.470, reward_bound=0.314, batch=206 
8146: loss=0.094, reward_mean=0.450, reward_bound=0.185, batch=213 
8147: loss=0.095, reward_mean=0.460, reward_bound=0.244, batch=219 
8148: loss=0.093, reward_mean=0.430, reward_bound=0.265, batch=223 
8149: loss=0.093, reward_mean=0.480, reward_bound=0.282, batch=225 
8150: loss=0.094, reward_mean=0.430, reward_bound=0.314, batch=222 
8151: loss=0.100, reward_mean=0.440, reward_bound=0.349, batch=202 
8152: loss=0.097, reward_mean=0.440, reward_bound=0.172, batch=211 
8153: loss=0.097, reward_mean=0.480, reward_bound=0.206, batch=217 
8154: loss=0.097, reward_mean=0.470, reward_bound=0.229, batch=220 
8155: loss=0.098, reward_mean=0.440, reward_bound=0.254, batch=223 
8156: loss=0.101, reward_mean=0.510, reward_bound=0.335, batch=226 
8157: loss=0.104, reward_mean=0.550, reward_bound=0.349, batch=227 
8158: loss=0.107, reward_mean=0.500, reward_bound=0.387, batch=154 
8159: loss=0.093, reward_mean=0.580, reward_bound=0.109, batch=175 
8160: loss=0.099, reward_mean=0.520, reward_bound=0.135, batch=191 
8161: loss=0.105, reward_mean=0.480, reward_bound=0.150, batch=200 
8162: loss=0.108, reward_mean=0.500, reward_bound=0.185, batch=206 
8163: loss=0.105, reward_mean=0.530, reward_bound=0.206, batch=212 
8164: loss=0.105, reward_mean=0.500, reward_bound=0.229, batch=210 
8165: loss=0.106, reward_mean=0.420, reward_bound=0.200, batch=217 
8166: loss=0.105, reward_mean=0.420, reward_bound=0.249, batch=222 
8167: loss=0.110, reward_mean=0.490, reward_bound=0.263, batch=225 
8168: loss=0.110, reward_mean=0.380, reward_bound=0.234, batch=227 
8169: loss=0.109, reward_mean=0.440, reward_bound=0.277, batch=229 
8170: loss=0.108, reward_mean=0.470, reward_bound=0.282, batch=220 
8171: loss=0.113, reward_mean=0.500, reward_bound=0.314, batch=208 
8172: loss=0.110, reward_mean=0.410, reward_bound=0.152, batch=215 
8173: loss=0.111, reward_mean=0.500, reward_bound=0.254, batch=218 
8174: loss=0.115, reward_mean=0.510, reward_bound=0.317, batch=222 
8175: loss=0.115, reward_mean=0.430, reward_bound=0.324, batch=225 
8176: loss=0.117, reward_mean=0.400, reward_bound=0.349, batch=209 
8177: loss=0.116, reward_mean=0.490, reward_bound=0.239, batch=216 
8178: loss=0.121, reward_mean=0.380, reward_bound=0.298, batch=221 
8179: loss=0.122, reward_mean=0.380, reward_bound=0.349, batch=218 
8180: loss=0.120, reward_mean=0.480, reward_bound=0.254, batch=221 
8181: loss=0.120, reward_mean=0.490, reward_bound=0.314, batch=224 
8182: loss=0.119, reward_mean=0.410, reward_bound=0.345, batch=227 
8183: loss=0.121, reward_mean=0.540, reward_bound=0.349, batch=228 
8184: loss=0.119, reward_mean=0.420, reward_bound=0.387, batch=207 
8185: loss=0.118, reward_mean=0.420, reward_bound=0.224, batch=215 
8186: loss=0.118, reward_mean=0.520, reward_bound=0.282, batch=218 
8187: loss=0.117, reward_mean=0.500, reward_bound=0.314, batch=220 
8188: loss=0.118, reward_mean=0.450, reward_bound=0.296, batch=224 
8189: loss=0.119, reward_mean=0.530, reward_bound=0.349, batch=225 
8190: loss=0.119, reward_mean=0.440, reward_bound=0.356, batch=227 
8191: loss=0.118, reward_mean=0.430, reward_bound=0.380, batch=229 
8192: loss=0.118, reward_mean=0.480, reward_bound=0.387, batch=221 
8193: loss=0.118, reward_mean=0.440, reward_bound=0.349, batch=223 
8194: loss=0.117, reward_mean=0.530, reward_bound=0.387, batch=224 
8195: loss=0.117, reward_mean=0.460, reward_bound=0.349, batch=225 
8196: loss=0.117, reward_mean=0.420, reward_bound=0.329, batch=227 
8197: loss=0.117, reward_mean=0.440, reward_bound=0.387, batch=227 
8198: loss=0.118, reward_mean=0.500, reward_bound=0.430, batch=123 
8199: loss=0.094, reward_mean=0.420, reward_bound=0.012, batch=156 
8200: loss=0.087, reward_mean=0.500, reward_bound=0.031, batch=179 
8201: loss=0.091, reward_mean=0.430, reward_bound=0.052, batch=195 
8202: loss=0.093, reward_mean=0.440, reward_bound=0.089, batch=207 
8203: loss=0.088, reward_mean=0.490, reward_bound=0.109, batch=219 
8204: loss=0.091, reward_mean=0.410, reward_bound=0.109, batch=222 
8205: loss=0.091, reward_mean=0.500, reward_bound=0.135, batch=224 
8206: loss=0.091, reward_mean=0.460, reward_bound=0.150, batch=226 
8207: loss=0.092, reward_mean=0.430, reward_bound=0.185, batch=220 
8208: loss=0.089, reward_mean=0.420, reward_bound=0.206, batch=237 
8209: loss=0.089, reward_mean=0.440, reward_bound=0.206, batch=226 
8210: loss=0.089, reward_mean=0.490, reward_bound=0.229, batch=224 
8211: loss=0.093, reward_mean=0.440, reward_bound=0.254, batch=216 
8212: loss=0.095, reward_mean=0.400, reward_bound=0.282, batch=210 
8213: loss=0.096, reward_mean=0.450, reward_bound=0.282, batch=216 
8214: loss=0.101, reward_mean=0.500, reward_bound=0.314, batch=205 
8215: loss=0.099, reward_mean=0.440, reward_bound=0.314, batch=210 
8216: loss=0.097, reward_mean=0.440, reward_bound=0.167, batch=216 
8217: loss=0.097, reward_mean=0.520, reward_bound=0.314, batch=217 
8218: loss=0.096, reward_mean=0.510, reward_bound=0.314, batch=221 
8219: loss=0.103, reward_mean=0.380, reward_bound=0.349, batch=197 
8220: loss=0.104, reward_mean=0.430, reward_bound=0.206, batch=207 
8221: loss=0.104, reward_mean=0.420, reward_bound=0.249, batch=215 
8222: loss=0.106, reward_mean=0.510, reward_bound=0.254, batch=217 
8223: loss=0.106, reward_mean=0.410, reward_bound=0.178, batch=222 
8224: loss=0.104, reward_mean=0.460, reward_bound=0.254, batch=224 
8225: loss=0.101, reward_mean=0.450, reward_bound=0.282, batch=223 
8226: loss=0.102, reward_mean=0.470, reward_bound=0.314, batch=224 
8227: loss=0.103, reward_mean=0.450, reward_bound=0.349, batch=221 
8228: loss=0.103, reward_mean=0.510, reward_bound=0.282, batch=224 
8229: loss=0.103, reward_mean=0.410, reward_bound=0.345, batch=227 
8230: loss=0.102, reward_mean=0.550, reward_bound=0.308, batch=229 
8231: loss=0.101, reward_mean=0.520, reward_bound=0.349, batch=228 
8232: loss=0.106, reward_mean=0.470, reward_bound=0.387, batch=195 
8233: loss=0.105, reward_mean=0.440, reward_bound=0.153, batch=206 
8234: loss=0.106, reward_mean=0.560, reward_bound=0.229, batch=212 
8235: loss=0.105, reward_mean=0.420, reward_bound=0.282, batch=216 
8236: loss=0.105, reward_mean=0.490, reward_bound=0.314, batch=211 
8237: loss=0.105, reward_mean=0.450, reward_bound=0.229, batch=217 
8238: loss=0.103, reward_mean=0.520, reward_bound=0.282, batch=221 
8239: loss=0.103, reward_mean=0.490, reward_bound=0.314, batch=222 
8240: loss=0.103, reward_mean=0.510, reward_bound=0.349, batch=218 
8241: loss=0.105, reward_mean=0.430, reward_bound=0.387, batch=218 
8242: loss=0.104, reward_mean=0.440, reward_bound=0.286, batch=222 
8243: loss=0.105, reward_mean=0.480, reward_bound=0.314, batch=224 
8244: loss=0.104, reward_mean=0.380, reward_bound=0.311, batch=227 
8245: loss=0.105, reward_mean=0.450, reward_bound=0.380, batch=229 
8246: loss=0.106, reward_mean=0.380, reward_bound=0.387, batch=228 
8247: loss=0.110, reward_mean=0.500, reward_bound=0.430, batch=174 
8248: loss=0.102, reward_mean=0.480, reward_bound=0.098, batch=191 
8249: loss=0.105, reward_mean=0.600, reward_bound=0.206, batch=200 
8250: loss=0.101, reward_mean=0.460, reward_bound=0.229, batch=207 
8251: loss=0.106, reward_mean=0.490, reward_bound=0.254, batch=208 
8252: loss=0.108, reward_mean=0.470, reward_bound=0.257, batch=215 
8253: loss=0.106, reward_mean=0.460, reward_bound=0.282, batch=214 
8254: loss=0.105, reward_mean=0.490, reward_bound=0.282, batch=218 
8255: loss=0.106, reward_mean=0.380, reward_bound=0.237, batch=222 
8256: loss=0.106, reward_mean=0.410, reward_bound=0.292, batch=225 
8257: loss=0.108, reward_mean=0.290, reward_bound=0.314, batch=215 
8258: loss=0.109, reward_mean=0.380, reward_bound=0.349, batch=212 
8259: loss=0.111, reward_mean=0.460, reward_bound=0.292, batch=218 
8260: loss=0.112, reward_mean=0.470, reward_bound=0.187, batch=222 
8261: loss=0.109, reward_mean=0.420, reward_bound=0.314, batch=221 
8262: loss=0.109, reward_mean=0.440, reward_bound=0.349, batch=222 
8263: loss=0.110, reward_mean=0.440, reward_bound=0.360, batch=225 
8264: loss=0.110, reward_mean=0.410, reward_bound=0.356, batch=227 
8265: loss=0.110, reward_mean=0.500, reward_bound=0.380, batch=229 
8266: loss=0.112, reward_mean=0.440, reward_bound=0.387, batch=206 
8267: loss=0.114, reward_mean=0.400, reward_bound=0.298, batch=214 
8268: loss=0.116, reward_mean=0.440, reward_bound=0.280, batch=220 
8269: loss=0.114, reward_mean=0.480, reward_bound=0.259, batch=224 
8270: loss=0.113, reward_mean=0.390, reward_bound=0.277, batch=227 
8271: loss=0.118, reward_mean=0.410, reward_bound=0.314, batch=222 
8272: loss=0.117, reward_mean=0.370, reward_bound=0.314, batch=224 
8273: loss=0.115, reward_mean=0.450, reward_bound=0.349, batch=224 
8274: loss=0.114, reward_mean=0.430, reward_bound=0.349, batch=226 
8275: loss=0.115, reward_mean=0.490, reward_bound=0.387, batch=224 
8276: loss=0.116, reward_mean=0.420, reward_bound=0.349, batch=226 
8277: loss=0.115, reward_mean=0.410, reward_bound=0.331, batch=228 
8278: loss=0.115, reward_mean=0.500, reward_bound=0.353, batch=229 
8279: loss=0.115, reward_mean=0.540, reward_bound=0.349, batch=229 
8280: loss=0.115, reward_mean=0.420, reward_bound=0.364, batch=230 
8281: loss=0.110, reward_mean=0.480, reward_bound=0.430, batch=205 
8282: loss=0.106, reward_mean=0.450, reward_bound=0.189, batch=213 
8283: loss=0.107, reward_mean=0.470, reward_bound=0.282, batch=215 
8284: loss=0.108, reward_mean=0.480, reward_bound=0.282, batch=219 
8285: loss=0.107, reward_mean=0.550, reward_bound=0.295, batch=223 
8286: loss=0.109, reward_mean=0.390, reward_bound=0.314, batch=219 
8287: loss=0.107, reward_mean=0.480, reward_bound=0.254, batch=222 
8288: loss=0.107, reward_mean=0.440, reward_bound=0.324, batch=225 
8289: loss=0.107, reward_mean=0.530, reward_bound=0.349, batch=220 
8290: loss=0.106, reward_mean=0.470, reward_bound=0.387, batch=220 
8291: loss=0.105, reward_mean=0.530, reward_bound=0.314, batch=223 
8292: loss=0.107, reward_mean=0.430, reward_bound=0.372, batch=226 
8293: loss=0.109, reward_mean=0.540, reward_bound=0.430, batch=222 
8294: loss=0.109, reward_mean=0.440, reward_bound=0.373, batch=225 
8295: loss=0.109, reward_mean=0.470, reward_bound=0.365, batch=227 
8296: loss=0.108, reward_mean=0.590, reward_bound=0.422, batch=229 
8297: loss=0.108, reward_mean=0.450, reward_bound=0.405, batch=230 
8298: loss=0.109, reward_mean=0.540, reward_bound=0.430, batch=228 
8299: loss=0.108, reward_mean=0.480, reward_bound=0.435, batch=229 
8300: loss=0.108, reward_mean=0.410, reward_bound=0.450, batch=230 
8301: loss=0.124, reward_mean=0.410, reward_bound=0.478, batch=103 
8302: loss=0.088, reward_mean=0.470, reward_bound=0.009, batch=142 
8303: loss=0.085, reward_mean=0.530, reward_bound=0.031, batch=168 
8304: loss=0.081, reward_mean=0.430, reward_bound=0.047, batch=189 
8305: loss=0.083, reward_mean=0.490, reward_bound=0.072, batch=197 
8306: loss=0.085, reward_mean=0.370, reward_bound=0.089, batch=209 
8307: loss=0.085, reward_mean=0.450, reward_bound=0.103, batch=216 
8308: loss=0.090, reward_mean=0.410, reward_bound=0.122, batch=217 
8309: loss=0.089, reward_mean=0.370, reward_bound=0.135, batch=220 
8310: loss=0.088, reward_mean=0.490, reward_bound=0.150, batch=219 
8311: loss=0.092, reward_mean=0.420, reward_bound=0.167, batch=219 
8312: loss=0.092, reward_mean=0.560, reward_bound=0.194, batch=223 
8313: loss=0.097, reward_mean=0.520, reward_bound=0.206, batch=221 
8314: loss=0.098, reward_mean=0.490, reward_bound=0.229, batch=211 
8315: loss=0.098, reward_mean=0.430, reward_bound=0.254, batch=201 
8316: loss=0.104, reward_mean=0.480, reward_bound=0.282, batch=178 
8317: loss=0.103, reward_mean=0.520, reward_bound=0.206, batch=192 
8318: loss=0.101, reward_mean=0.490, reward_bound=0.191, batch=204 
8319: loss=0.098, reward_mean=0.480, reward_bound=0.206, batch=212 
8320: loss=0.099, reward_mean=0.510, reward_bound=0.254, batch=217 
8321: loss=0.100, reward_mean=0.440, reward_bound=0.282, batch=221 
8322: loss=0.099, reward_mean=0.430, reward_bound=0.254, batch=223 
8323: loss=0.105, reward_mean=0.500, reward_bound=0.314, batch=198 
8324: loss=0.103, reward_mean=0.390, reward_bound=0.137, batch=208 
8325: loss=0.102, reward_mean=0.450, reward_bound=0.167, batch=214 
8326: loss=0.100, reward_mean=0.470, reward_bound=0.206, batch=218 
8327: loss=0.097, reward_mean=0.520, reward_bound=0.231, batch=222 
8328: loss=0.105, reward_mean=0.490, reward_bound=0.254, batch=221 
8329: loss=0.106, reward_mean=0.440, reward_bound=0.282, batch=217 
8330: loss=0.106, reward_mean=0.420, reward_bound=0.314, batch=219 
8331: loss=0.106, reward_mean=0.450, reward_bound=0.314, batch=221 
8332: loss=0.105, reward_mean=0.440, reward_bound=0.314, batch=224 
8333: loss=0.105, reward_mean=0.510, reward_bound=0.345, batch=227 
8334: loss=0.106, reward_mean=0.400, reward_bound=0.349, batch=206 
8335: loss=0.106, reward_mean=0.520, reward_bound=0.254, batch=213 
8336: loss=0.106, reward_mean=0.490, reward_bound=0.261, batch=219 
8337: loss=0.105, reward_mean=0.450, reward_bound=0.250, batch=223 
8338: loss=0.107, reward_mean=0.450, reward_bound=0.282, batch=225 
8339: loss=0.110, reward_mean=0.420, reward_bound=0.314, batch=225 
8340: loss=0.110, reward_mean=0.470, reward_bound=0.349, batch=225 
8341: loss=0.114, reward_mean=0.500, reward_bound=0.387, batch=176 
8342: loss=0.109, reward_mean=0.490, reward_bound=0.135, batch=191 
8343: loss=0.103, reward_mean=0.360, reward_bound=0.098, batch=203 
8344: loss=0.103, reward_mean=0.440, reward_bound=0.150, batch=208 
8345: loss=0.108, reward_mean=0.490, reward_bound=0.185, batch=214 
8346: loss=0.109, reward_mean=0.480, reward_bound=0.206, batch=214 
8347: loss=0.112, reward_mean=0.510, reward_bound=0.254, batch=213 
8348: loss=0.107, reward_mean=0.560, reward_bound=0.282, batch=213 
8349: loss=0.107, reward_mean=0.530, reward_bound=0.254, batch=218 
8350: loss=0.106, reward_mean=0.460, reward_bound=0.257, batch=222 
8351: loss=0.106, reward_mean=0.470, reward_bound=0.314, batch=222 
8352: loss=0.108, reward_mean=0.410, reward_bound=0.349, batch=214 
8353: loss=0.110, reward_mean=0.480, reward_bound=0.282, batch=218 
8354: loss=0.111, reward_mean=0.370, reward_bound=0.349, batch=219 
8355: loss=0.108, reward_mean=0.410, reward_bound=0.295, batch=223 
8356: loss=0.108, reward_mean=0.400, reward_bound=0.314, batch=225 
8357: loss=0.108, reward_mean=0.440, reward_bound=0.356, batch=227 
8358: loss=0.109, reward_mean=0.500, reward_bound=0.387, batch=217 
8359: loss=0.108, reward_mean=0.500, reward_bound=0.314, batch=220 
8360: loss=0.109, reward_mean=0.450, reward_bound=0.314, batch=223 
8361: loss=0.108, reward_mean=0.470, reward_bound=0.301, batch=226 
8362: loss=0.108, reward_mean=0.360, reward_bound=0.314, batch=227 
8363: loss=0.108, reward_mean=0.450, reward_bound=0.349, batch=227 
8364: loss=0.108, reward_mean=0.440, reward_bound=0.387, batch=225 
8365: loss=0.108, reward_mean=0.340, reward_bound=0.260, batch=227 
8366: loss=0.107, reward_mean=0.490, reward_bound=0.380, batch=229 
8367: loss=0.109, reward_mean=0.470, reward_bound=0.430, batch=174 
8368: loss=0.102, reward_mean=0.500, reward_bound=0.120, batch=192 
8369: loss=0.099, reward_mean=0.460, reward_bound=0.135, batch=203 
8370: loss=0.100, reward_mean=0.370, reward_bound=0.150, batch=211 
8371: loss=0.098, reward_mean=0.390, reward_bound=0.185, batch=216 
8372: loss=0.102, reward_mean=0.480, reward_bound=0.206, batch=218 
8373: loss=0.104, reward_mean=0.500, reward_bound=0.229, batch=221 
8374: loss=0.102, reward_mean=0.430, reward_bound=0.254, batch=220 
8375: loss=0.103, reward_mean=0.610, reward_bound=0.282, batch=222 
8376: loss=0.102, reward_mean=0.440, reward_bound=0.292, batch=225 
8377: loss=0.103, reward_mean=0.400, reward_bound=0.314, batch=220 
8378: loss=0.104, reward_mean=0.480, reward_bound=0.314, batch=223 
8379: loss=0.106, reward_mean=0.540, reward_bound=0.349, batch=215 
8380: loss=0.109, reward_mean=0.510, reward_bound=0.349, batch=219 
8381: loss=0.112, reward_mean=0.430, reward_bound=0.265, batch=223 
8382: loss=0.108, reward_mean=0.480, reward_bound=0.372, batch=226 
8383: loss=0.110, reward_mean=0.470, reward_bound=0.368, batch=228 
8384: loss=0.110, reward_mean=0.380, reward_bound=0.293, batch=229 
8385: loss=0.110, reward_mean=0.530, reward_bound=0.387, batch=213 
8386: loss=0.111, reward_mean=0.440, reward_bound=0.271, batch=219 
8387: loss=0.109, reward_mean=0.530, reward_bound=0.314, batch=221 
8388: loss=0.111, reward_mean=0.480, reward_bound=0.387, batch=222 
8389: loss=0.114, reward_mean=0.430, reward_bound=0.387, batch=224 
8390: loss=0.114, reward_mean=0.510, reward_bound=0.422, batch=227 
8391: loss=0.108, reward_mean=0.440, reward_bound=0.430, batch=203 
8392: loss=0.108, reward_mean=0.470, reward_bound=0.185, batch=211 
8393: loss=0.107, reward_mean=0.450, reward_bound=0.229, batch=216 
8394: loss=0.109, reward_mean=0.430, reward_bound=0.186, batch=221 
8395: loss=0.112, reward_mean=0.480, reward_bound=0.282, batch=222 
8396: loss=0.111, reward_mean=0.440, reward_bound=0.314, batch=223 
8397: loss=0.110, reward_mean=0.550, reward_bound=0.349, batch=219 
8398: loss=0.111, reward_mean=0.450, reward_bound=0.343, batch=223 
8399: loss=0.111, reward_mean=0.560, reward_bound=0.387, batch=221 
8400: loss=0.110, reward_mean=0.540, reward_bound=0.314, batch=224 
8401: loss=0.110, reward_mean=0.430, reward_bound=0.387, batch=225 
8402: loss=0.110, reward_mean=0.450, reward_bound=0.387, batch=226 
8403: loss=0.109, reward_mean=0.400, reward_bound=0.368, batch=228 
8404: loss=0.108, reward_mean=0.480, reward_bound=0.353, batch=229 
8405: loss=0.110, reward_mean=0.480, reward_bound=0.430, batch=217 
8406: loss=0.108, reward_mean=0.430, reward_bound=0.245, batch=222 
8407: loss=0.111, reward_mean=0.480, reward_bound=0.324, batch=225 
8408: loss=0.110, reward_mean=0.490, reward_bound=0.349, batch=225 
8409: loss=0.110, reward_mean=0.390, reward_bound=0.296, batch=227 
8410: loss=0.109, reward_mean=0.540, reward_bound=0.387, batch=225 
8411: loss=0.109, reward_mean=0.400, reward_bound=0.365, batch=227 
8412: loss=0.112, reward_mean=0.420, reward_bound=0.380, batch=229 
8413: loss=0.111, reward_mean=0.520, reward_bound=0.328, batch=230 
8414: loss=0.111, reward_mean=0.490, reward_bound=0.329, batch=231 
8415: loss=0.111, reward_mean=0.450, reward_bound=0.430, batch=227 
8416: loss=0.111, reward_mean=0.340, reward_bound=0.308, batch=229 
8417: loss=0.111, reward_mean=0.350, reward_bound=0.328, batch=230 
8418: loss=0.110, reward_mean=0.490, reward_bound=0.387, batch=230 
8419: loss=0.110, reward_mean=0.420, reward_bound=0.418, batch=231 
8420: loss=0.118, reward_mean=0.430, reward_bound=0.430, batch=231 
8421: loss=0.124, reward_mean=0.460, reward_bound=0.478, batch=152 
8422: loss=0.114, reward_mean=0.450, reward_bound=0.041, batch=176 
8423: loss=0.114, reward_mean=0.520, reward_bound=0.098, batch=192 
8424: loss=0.112, reward_mean=0.390, reward_bound=0.122, batch=203 
8425: loss=0.111, reward_mean=0.440, reward_bound=0.150, batch=208 
8426: loss=0.113, reward_mean=0.420, reward_bound=0.185, batch=210 
8427: loss=0.110, reward_mean=0.450, reward_bound=0.206, batch=223 
8428: loss=0.109, reward_mean=0.540, reward_bound=0.206, batch=219 
8429: loss=0.112, reward_mean=0.430, reward_bound=0.229, batch=219 
8430: loss=0.119, reward_mean=0.570, reward_bound=0.254, batch=214 
8431: loss=0.116, reward_mean=0.420, reward_bound=0.226, batch=220 
8432: loss=0.118, reward_mean=0.440, reward_bound=0.229, batch=223 
8433: loss=0.121, reward_mean=0.500, reward_bound=0.282, batch=214 
8434: loss=0.123, reward_mean=0.470, reward_bound=0.280, batch=220 
8435: loss=0.123, reward_mean=0.440, reward_bound=0.314, batch=207 
8436: loss=0.120, reward_mean=0.380, reward_bound=0.163, batch=215 
8437: loss=0.120, reward_mean=0.540, reward_bound=0.282, batch=216 
8438: loss=0.119, reward_mean=0.510, reward_bound=0.217, batch=221 
8439: loss=0.118, reward_mean=0.410, reward_bound=0.229, batch=224 
8440: loss=0.119, reward_mean=0.460, reward_bound=0.254, batch=226 
8441: loss=0.120, reward_mean=0.470, reward_bound=0.314, batch=222 
8442: loss=0.123, reward_mean=0.440, reward_bound=0.349, batch=203 
8443: loss=0.126, reward_mean=0.500, reward_bound=0.314, batch=211 
8444: loss=0.124, reward_mean=0.450, reward_bound=0.349, batch=217 
8445: loss=0.123, reward_mean=0.490, reward_bound=0.308, batch=222 
8446: loss=0.124, reward_mean=0.490, reward_bound=0.314, batch=221 
8447: loss=0.123, reward_mean=0.450, reward_bound=0.314, batch=224 
8448: loss=0.123, reward_mean=0.470, reward_bound=0.345, batch=227 
8449: loss=0.124, reward_mean=0.460, reward_bound=0.380, batch=229 
8450: loss=0.124, reward_mean=0.480, reward_bound=0.387, batch=201 
8451: loss=0.123, reward_mean=0.530, reward_bound=0.254, batch=209 
8452: loss=0.122, reward_mean=0.470, reward_bound=0.254, batch=215 
8453: loss=0.123, reward_mean=0.450, reward_bound=0.282, batch=217 
8454: loss=0.121, reward_mean=0.490, reward_bound=0.254, batch=220 
8455: loss=0.123, reward_mean=0.440, reward_bound=0.314, batch=219 
8456: loss=0.125, reward_mean=0.520, reward_bound=0.349, batch=216 
8457: loss=0.123, reward_mean=0.420, reward_bound=0.298, batch=221 
8458: loss=0.123, reward_mean=0.450, reward_bound=0.349, batch=223 
8459: loss=0.125, reward_mean=0.470, reward_bound=0.358, batch=226 
8460: loss=0.125, reward_mean=0.410, reward_bound=0.387, batch=218 
8461: loss=0.125, reward_mean=0.540, reward_bound=0.353, batch=222 
8462: loss=0.125, reward_mean=0.400, reward_bound=0.238, batch=225 
8463: loss=0.124, reward_mean=0.450, reward_bound=0.387, batch=224 
8464: loss=0.123, reward_mean=0.480, reward_bound=0.342, batch=227 
8465: loss=0.124, reward_mean=0.430, reward_bound=0.380, batch=229 
8466: loss=0.125, reward_mean=0.380, reward_bound=0.387, batch=229 
8467: loss=0.122, reward_mean=0.500, reward_bound=0.430, batch=190 
8468: loss=0.121, reward_mean=0.510, reward_bound=0.222, batch=203 
8469: loss=0.118, reward_mean=0.390, reward_bound=0.198, batch=212 
8470: loss=0.116, reward_mean=0.410, reward_bound=0.229, batch=214 
8471: loss=0.117, reward_mean=0.490, reward_bound=0.206, batch=219 
8472: loss=0.118, reward_mean=0.450, reward_bound=0.254, batch=218 
8473: loss=0.119, reward_mean=0.410, reward_bound=0.282, batch=221 
8474: loss=0.121, reward_mean=0.450, reward_bound=0.314, batch=218 
8475: loss=0.122, reward_mean=0.480, reward_bound=0.349, batch=211 
8476: loss=0.128, reward_mean=0.440, reward_bound=0.349, batch=217 
8477: loss=0.126, reward_mean=0.500, reward_bound=0.342, batch=222 
8478: loss=0.126, reward_mean=0.510, reward_bound=0.324, batch=225 
8479: loss=0.126, reward_mean=0.480, reward_bound=0.349, batch=226 
8480: loss=0.127, reward_mean=0.390, reward_bound=0.387, batch=218 
8481: loss=0.125, reward_mean=0.480, reward_bound=0.387, batch=221 
8482: loss=0.125, reward_mean=0.390, reward_bound=0.387, batch=222 
8483: loss=0.127, reward_mean=0.420, reward_bound=0.430, batch=209 
8484: loss=0.126, reward_mean=0.510, reward_bound=0.314, batch=215 
8485: loss=0.123, reward_mean=0.510, reward_bound=0.356, batch=220 
8486: loss=0.123, reward_mean=0.510, reward_bound=0.387, batch=220 
8487: loss=0.122, reward_mean=0.480, reward_bound=0.387, batch=223 
8488: loss=0.123, reward_mean=0.350, reward_bound=0.335, batch=226 
8489: loss=0.122, reward_mean=0.520, reward_bound=0.368, batch=228 
8490: loss=0.122, reward_mean=0.500, reward_bound=0.387, batch=227 
8491: loss=0.123, reward_mean=0.520, reward_bound=0.422, batch=229 
8492: loss=0.122, reward_mean=0.400, reward_bound=0.405, batch=230 
8493: loss=0.122, reward_mean=0.440, reward_bound=0.430, batch=223 
8494: loss=0.121, reward_mean=0.500, reward_bound=0.349, batch=224 
8495: loss=0.122, reward_mean=0.440, reward_bound=0.380, batch=227 
8496: loss=0.122, reward_mean=0.490, reward_bound=0.422, batch=229 
8497: loss=0.121, reward_mean=0.510, reward_bound=0.430, batch=226 
8498: loss=0.120, reward_mean=0.520, reward_bound=0.409, batch=228 
8499: loss=0.120, reward_mean=0.480, reward_bound=0.435, batch=229 
8500: loss=0.120, reward_mean=0.520, reward_bound=0.361, batch=230 
8501: loss=0.120, reward_mean=0.490, reward_bound=0.451, batch=231 
8502: loss=0.124, reward_mean=0.430, reward_bound=0.478, batch=186 
8503: loss=0.125, reward_mean=0.490, reward_bound=0.268, batch=200 
8504: loss=0.119, reward_mean=0.420, reward_bound=0.138, batch=210 
8505: loss=0.121, reward_mean=0.440, reward_bound=0.167, batch=213 
8506: loss=0.119, reward_mean=0.370, reward_bound=0.206, batch=214 
8507: loss=0.120, reward_mean=0.540, reward_bound=0.229, batch=219 
8508: loss=0.120, reward_mean=0.500, reward_bound=0.282, batch=220 
8509: loss=0.119, reward_mean=0.460, reward_bound=0.254, batch=223 
8510: loss=0.118, reward_mean=0.440, reward_bound=0.227, batch=226 
8511: loss=0.118, reward_mean=0.520, reward_bound=0.314, batch=217 
8512: loss=0.117, reward_mean=0.380, reward_bound=0.282, batch=221 
8513: loss=0.118, reward_mean=0.540, reward_bound=0.349, batch=215 
8514: loss=0.117, reward_mean=0.440, reward_bound=0.282, batch=218 
8515: loss=0.116, reward_mean=0.430, reward_bound=0.349, batch=221 
8516: loss=0.116, reward_mean=0.420, reward_bound=0.349, batch=224 
8517: loss=0.124, reward_mean=0.440, reward_bound=0.387, batch=211 
8518: loss=0.120, reward_mean=0.370, reward_bound=0.282, batch=217 
8519: loss=0.123, reward_mean=0.440, reward_bound=0.282, batch=221 
8520: loss=0.124, reward_mean=0.350, reward_bound=0.314, batch=222 
8521: loss=0.124, reward_mean=0.500, reward_bound=0.292, batch=225 
8522: loss=0.124, reward_mean=0.500, reward_bound=0.349, batch=225 
8523: loss=0.125, reward_mean=0.530, reward_bound=0.387, batch=219 
8524: loss=0.123, reward_mean=0.380, reward_bound=0.364, batch=223 
8525: loss=0.122, reward_mean=0.530, reward_bound=0.413, batch=226 
8526: loss=0.121, reward_mean=0.430, reward_bound=0.331, batch=228 
8527: loss=0.125, reward_mean=0.620, reward_bound=0.430, batch=214 
8528: loss=0.123, reward_mean=0.420, reward_bound=0.282, batch=218 
8529: loss=0.123, reward_mean=0.440, reward_bound=0.282, batch=221 
8530: loss=0.125, reward_mean=0.510, reward_bound=0.314, batch=224 
8531: loss=0.124, reward_mean=0.420, reward_bound=0.226, batch=227 
8532: loss=0.122, reward_mean=0.380, reward_bound=0.282, batch=228 
8533: loss=0.122, reward_mean=0.410, reward_bound=0.349, batch=226 
8534: loss=0.122, reward_mean=0.490, reward_bound=0.331, batch=228 
8535: loss=0.124, reward_mean=0.450, reward_bound=0.387, batch=226 
8536: loss=0.124, reward_mean=0.490, reward_bound=0.409, batch=228 
8537: loss=0.125, reward_mean=0.420, reward_bound=0.430, batch=226 
8538: loss=0.125, reward_mean=0.460, reward_bound=0.409, batch=228 
8539: loss=0.125, reward_mean=0.490, reward_bound=0.314, batch=228 
8540: loss=0.124, reward_mean=0.480, reward_bound=0.392, batch=229 
8541: loss=0.125, reward_mean=0.520, reward_bound=0.430, batch=228 
8542: loss=0.124, reward_mean=0.460, reward_bound=0.435, batch=229 
8543: loss=0.123, reward_mean=0.510, reward_bound=0.478, batch=231 
8544: loss=0.126, reward_mean=0.520, reward_bound=0.478, batch=210 
8545: loss=0.122, reward_mean=0.430, reward_bound=0.296, batch=217 
8546: loss=0.123, reward_mean=0.430, reward_bound=0.206, batch=221 
8547: loss=0.125, reward_mean=0.450, reward_bound=0.314, batch=221 
8548: loss=0.124, reward_mean=0.440, reward_bound=0.229, batch=224 
8549: loss=0.125, reward_mean=0.390, reward_bound=0.349, batch=219 
8550: loss=0.127, reward_mean=0.510, reward_bound=0.349, batch=222 
8551: loss=0.128, reward_mean=0.400, reward_bound=0.360, batch=225 
8552: loss=0.128, reward_mean=0.410, reward_bound=0.387, batch=224 
8553: loss=0.128, reward_mean=0.360, reward_bound=0.282, batch=226 
8554: loss=0.127, reward_mean=0.530, reward_bound=0.390, batch=228 
8555: loss=0.128, reward_mean=0.500, reward_bound=0.297, batch=229 
8556: loss=0.127, reward_mean=0.570, reward_bound=0.430, batch=221 
8557: loss=0.129, reward_mean=0.480, reward_bound=0.430, batch=224 
8558: loss=0.127, reward_mean=0.430, reward_bound=0.384, batch=227 
8559: loss=0.126, reward_mean=0.430, reward_bound=0.380, batch=229 
8560: loss=0.127, reward_mean=0.410, reward_bound=0.364, batch=230 
8561: loss=0.130, reward_mean=0.440, reward_bound=0.387, batch=228 
8562: loss=0.130, reward_mean=0.420, reward_bound=0.387, batch=228 
8563: loss=0.128, reward_mean=0.480, reward_bound=0.430, batch=225 
8564: loss=0.128, reward_mean=0.540, reward_bound=0.478, batch=219 
8565: loss=0.126, reward_mean=0.410, reward_bound=0.364, batch=223 
8566: loss=0.125, reward_mean=0.460, reward_bound=0.271, batch=226 
8567: loss=0.127, reward_mean=0.480, reward_bound=0.387, batch=226 
8568: loss=0.128, reward_mean=0.440, reward_bound=0.430, batch=227 
8569: loss=0.127, reward_mean=0.450, reward_bound=0.469, batch=229 
8570: loss=0.127, reward_mean=0.460, reward_bound=0.380, batch=230 
8571: loss=0.127, reward_mean=0.440, reward_bound=0.464, batch=231 
8572: loss=0.127, reward_mean=0.430, reward_bound=0.387, batch=231 
8573: loss=0.127, reward_mean=0.370, reward_bound=0.430, batch=231 
8574: loss=0.128, reward_mean=0.460, reward_bound=0.478, batch=227 
8575: loss=0.128, reward_mean=0.550, reward_bound=0.430, batch=228 
8576: loss=0.128, reward_mean=0.470, reward_bound=0.397, batch=229 
8577: loss=0.127, reward_mean=0.470, reward_bound=0.478, batch=231 
8578: loss=0.127, reward_mean=0.470, reward_bound=0.430, batch=231 
8579: loss=0.126, reward_mean=0.520, reward_bound=0.478, batch=230 
8580: loss=0.126, reward_mean=0.420, reward_bound=0.430, batch=230 
8581: loss=0.127, reward_mean=0.430, reward_bound=0.464, batch=231 
8582: loss=0.126, reward_mean=0.440, reward_bound=0.478, batch=230 
8583: loss=0.126, reward_mean=0.440, reward_bound=0.387, batch=230 
8584: loss=0.126, reward_mean=0.380, reward_bound=0.418, batch=231 
8585: loss=0.129, reward_mean=0.470, reward_bound=0.430, batch=231 
8586: loss=0.129, reward_mean=0.370, reward_bound=0.430, batch=231 
8588: loss=0.054, reward_mean=0.380, reward_bound=0.000, batch=38 
8589: loss=0.050, reward_mean=0.370, reward_bound=0.000, batch=75 
8590: loss=0.054, reward_mean=0.510, reward_bound=0.000, batch=121 
8591: loss=0.056, reward_mean=0.430, reward_bound=0.001, batch=154 
8592: loss=0.061, reward_mean=0.530, reward_bound=0.007, batch=177 
8593: loss=0.064, reward_mean=0.420, reward_bound=0.013, batch=197 
8594: loss=0.068, reward_mean=0.450, reward_bound=0.020, batch=205 
8595: loss=0.073, reward_mean=0.370, reward_bound=0.038, batch=206 
8596: loss=0.076, reward_mean=0.500, reward_bound=0.052, batch=206 
8597: loss=0.081, reward_mean=0.520, reward_bound=0.068, batch=214 
8598: loss=0.084, reward_mean=0.430, reward_bound=0.080, batch=219 
8599: loss=0.087, reward_mean=0.410, reward_bound=0.098, batch=207 
8600: loss=0.086, reward_mean=0.490, reward_bound=0.109, batch=225 
8601: loss=0.085, reward_mean=0.510, reward_bound=0.109, batch=245 
8602: loss=0.084, reward_mean=0.500, reward_bound=0.109, batch=263 
8603: loss=0.086, reward_mean=0.460, reward_bound=0.109, batch=249 
8604: loss=0.088, reward_mean=0.450, reward_bound=0.135, batch=223 
8605: loss=0.086, reward_mean=0.540, reward_bound=0.150, batch=220 
8606: loss=0.090, reward_mean=0.480, reward_bound=0.167, batch=205 
8607: loss=0.093, reward_mean=0.490, reward_bound=0.185, batch=195 
8608: loss=0.091, reward_mean=0.420, reward_bound=0.167, batch=205 
8609: loss=0.093, reward_mean=0.530, reward_bound=0.157, batch=213 
8610: loss=0.095, reward_mean=0.510, reward_bound=0.206, batch=201 
8611: loss=0.092, reward_mean=0.410, reward_bound=0.135, batch=210 
8612: loss=0.094, reward_mean=0.440, reward_bound=0.206, batch=219 
8613: loss=0.092, reward_mean=0.480, reward_bound=0.215, batch=223 
8614: loss=0.093, reward_mean=0.490, reward_bound=0.229, batch=196 
8615: loss=0.091, reward_mean=0.500, reward_bound=0.217, batch=207 
8616: loss=0.093, reward_mean=0.570, reward_bound=0.254, batch=172 
8617: loss=0.097, reward_mean=0.510, reward_bound=0.140, batch=190 
8618: loss=0.093, reward_mean=0.380, reward_bound=0.146, batch=203 
8619: loss=0.096, reward_mean=0.490, reward_bound=0.150, batch=210 
8620: loss=0.096, reward_mean=0.550, reward_bound=0.185, batch=216 
8621: loss=0.097, reward_mean=0.560, reward_bound=0.229, batch=212 
8622: loss=0.098, reward_mean=0.440, reward_bound=0.254, batch=212 
8623: loss=0.097, reward_mean=0.450, reward_bound=0.206, batch=219 
8624: loss=0.101, reward_mean=0.440, reward_bound=0.254, batch=222 
8625: loss=0.109, reward_mean=0.500, reward_bound=0.282, batch=190 
8626: loss=0.106, reward_mean=0.470, reward_bound=0.170, batch=203 
8627: loss=0.107, reward_mean=0.410, reward_bound=0.167, batch=211 
8628: loss=0.108, reward_mean=0.450, reward_bound=0.229, batch=212 
8629: loss=0.107, reward_mean=0.430, reward_bound=0.254, batch=216 
8630: loss=0.110, reward_mean=0.440, reward_bound=0.282, batch=216 
8631: loss=0.109, reward_mean=0.450, reward_bound=0.241, batch=221 
8632: loss=0.116, reward_mean=0.500, reward_bound=0.314, batch=169 
8633: loss=0.111, reward_mean=0.480, reward_bound=0.157, batch=188 
8634: loss=0.111, reward_mean=0.430, reward_bound=0.124, batch=201 
8635: loss=0.108, reward_mean=0.450, reward_bound=0.167, batch=209 
8636: loss=0.106, reward_mean=0.440, reward_bound=0.185, batch=215 
8637: loss=0.106, reward_mean=0.480, reward_bound=0.206, batch=214 
8638: loss=0.112, reward_mean=0.520, reward_bound=0.254, batch=214 
8639: loss=0.113, reward_mean=0.540, reward_bound=0.252, batch=220 
8640: loss=0.117, reward_mean=0.420, reward_bound=0.282, batch=215 
8641: loss=0.116, reward_mean=0.500, reward_bound=0.314, batch=204 
8642: loss=0.118, reward_mean=0.480, reward_bound=0.252, batch=213 
8643: loss=0.116, reward_mean=0.470, reward_bound=0.301, batch=219 
8644: loss=0.119, reward_mean=0.460, reward_bound=0.314, batch=218 
8645: loss=0.122, reward_mean=0.500, reward_bound=0.349, batch=170 
8646: loss=0.119, reward_mean=0.470, reward_bound=0.106, batch=189 
8647: loss=0.114, reward_mean=0.480, reward_bound=0.127, batch=202 
8648: loss=0.116, reward_mean=0.470, reward_bound=0.150, batch=210 
8649: loss=0.116, reward_mean=0.510, reward_bound=0.185, batch=215 
8650: loss=0.118, reward_mean=0.460, reward_bound=0.206, batch=216 
8651: loss=0.121, reward_mean=0.470, reward_bound=0.229, batch=214 
8652: loss=0.121, reward_mean=0.510, reward_bound=0.229, batch=219 
8653: loss=0.122, reward_mean=0.450, reward_bound=0.254, batch=217 
8654: loss=0.126, reward_mean=0.440, reward_bound=0.272, batch=222 
8655: loss=0.129, reward_mean=0.510, reward_bound=0.282, batch=218 
8656: loss=0.130, reward_mean=0.530, reward_bound=0.314, batch=211 
8657: loss=0.128, reward_mean=0.500, reward_bound=0.206, batch=217 
8658: loss=0.128, reward_mean=0.510, reward_bound=0.249, batch=222 
8659: loss=0.128, reward_mean=0.490, reward_bound=0.282, batch=224 
8660: loss=0.128, reward_mean=0.430, reward_bound=0.314, batch=225 
8661: loss=0.126, reward_mean=0.500, reward_bound=0.349, batch=213 
8662: loss=0.123, reward_mean=0.470, reward_bound=0.229, batch=218 
8663: loss=0.125, reward_mean=0.470, reward_bound=0.349, batch=221 
8664: loss=0.126, reward_mean=0.530, reward_bound=0.349, batch=224 
8665: loss=0.126, reward_mean=0.510, reward_bound=0.377, batch=227 
8666: loss=0.141, reward_mean=0.460, reward_bound=0.387, batch=162 
8667: loss=0.130, reward_mean=0.480, reward_bound=0.089, batch=180 
8668: loss=0.125, reward_mean=0.490, reward_bound=0.175, batch=196 
8669: loss=0.127, reward_mean=0.460, reward_bound=0.185, batch=202 
8670: loss=0.128, reward_mean=0.500, reward_bound=0.229, batch=202 
8671: loss=0.128, reward_mean=0.500, reward_bound=0.254, batch=203 
8672: loss=0.128, reward_mean=0.510, reward_bound=0.220, batch=212 
8673: loss=0.124, reward_mean=0.480, reward_bound=0.263, batch=218 
8674: loss=0.129, reward_mean=0.530, reward_bound=0.282, batch=216 
8675: loss=0.132, reward_mean=0.500, reward_bound=0.314, batch=210 
8676: loss=0.132, reward_mean=0.450, reward_bound=0.200, batch=217 
8677: loss=0.129, reward_mean=0.390, reward_bound=0.206, batch=221 
8678: loss=0.130, reward_mean=0.450, reward_bound=0.229, batch=223 
8679: loss=0.131, reward_mean=0.480, reward_bound=0.282, batch=223 
8680: loss=0.130, reward_mean=0.460, reward_bound=0.301, batch=226 
8681: loss=0.129, reward_mean=0.420, reward_bound=0.298, batch=228 
8682: loss=0.132, reward_mean=0.460, reward_bound=0.349, batch=206 
8683: loss=0.129, reward_mean=0.480, reward_bound=0.254, batch=213 
8684: loss=0.127, reward_mean=0.470, reward_bound=0.254, batch=217 
8685: loss=0.128, reward_mean=0.380, reward_bound=0.206, batch=221 
8686: loss=0.127, reward_mean=0.450, reward_bound=0.254, batch=223 
8687: loss=0.129, reward_mean=0.560, reward_bound=0.282, batch=221 
8688: loss=0.133, reward_mean=0.500, reward_bound=0.314, batch=221 
8689: loss=0.132, reward_mean=0.530, reward_bound=0.349, batch=218 
8690: loss=0.131, reward_mean=0.500, reward_bound=0.208, batch=222 
8691: loss=0.130, reward_mean=0.540, reward_bound=0.292, batch=225 
8692: loss=0.132, reward_mean=0.450, reward_bound=0.314, batch=225 
8693: loss=0.132, reward_mean=0.460, reward_bound=0.321, batch=227 
8694: loss=0.134, reward_mean=0.420, reward_bound=0.380, batch=229 
8695: loss=0.137, reward_mean=0.340, reward_bound=0.387, batch=202 
8696: loss=0.134, reward_mean=0.470, reward_bound=0.282, batch=208 
8697: loss=0.133, reward_mean=0.450, reward_bound=0.234, batch=215 
8698: loss=0.138, reward_mean=0.490, reward_bound=0.314, batch=218 
8699: loss=0.137, reward_mean=0.510, reward_bound=0.264, batch=222 
8700: loss=0.136, reward_mean=0.450, reward_bound=0.263, batch=225 
8701: loss=0.136, reward_mean=0.390, reward_bound=0.321, batch=227 
8702: loss=0.138, reward_mean=0.480, reward_bound=0.349, batch=224 
8703: loss=0.138, reward_mean=0.430, reward_bound=0.349, batch=226 
8704: loss=0.137, reward_mean=0.480, reward_bound=0.387, batch=218 
8705: loss=0.138, reward_mean=0.500, reward_bound=0.254, batch=221 
8706: loss=0.151, reward_mean=0.540, reward_bound=0.430, batch=112 
8707: loss=0.126, reward_mean=0.480, reward_bound=0.014, batch=148 
8708: loss=0.113, reward_mean=0.540, reward_bound=0.031, batch=171 
8709: loss=0.116, reward_mean=0.450, reward_bound=0.047, batch=188 
8710: loss=0.122, reward_mean=0.430, reward_bound=0.080, batch=199 
8711: loss=0.121, reward_mean=0.490, reward_bound=0.098, batch=205 
8712: loss=0.121, reward_mean=0.450, reward_bound=0.122, batch=207 
8713: loss=0.122, reward_mean=0.440, reward_bound=0.135, batch=209 
8714: loss=0.124, reward_mean=0.520, reward_bound=0.150, batch=215 
8715: loss=0.121, reward_mean=0.440, reward_bound=0.170, batch=220 
8716: loss=0.123, reward_mean=0.430, reward_bound=0.185, batch=218 
8717: loss=0.128, reward_mean=0.530, reward_bound=0.206, batch=214 
8718: loss=0.131, reward_mean=0.460, reward_bound=0.229, batch=207 
8719: loss=0.128, reward_mean=0.370, reward_bound=0.229, batch=214 
8720: loss=0.129, reward_mean=0.490, reward_bound=0.252, batch=220 
8721: loss=0.129, reward_mean=0.520, reward_bound=0.254, batch=211 
8722: loss=0.129, reward_mean=0.490, reward_bound=0.254, batch=216 
8723: loss=0.135, reward_mean=0.570, reward_bound=0.282, batch=207 
8724: loss=0.135, reward_mean=0.440, reward_bound=0.254, batch=213 
8725: loss=0.135, reward_mean=0.450, reward_bound=0.282, batch=218 
8726: loss=0.140, reward_mean=0.450, reward_bound=0.314, batch=199 
8727: loss=0.139, reward_mean=0.490, reward_bound=0.254, batch=207 
8728: loss=0.136, reward_mean=0.490, reward_bound=0.185, batch=214 
8729: loss=0.137, reward_mean=0.420, reward_bound=0.226, batch=220 
8730: loss=0.136, reward_mean=0.510, reward_bound=0.274, batch=224 
8731: loss=0.139, reward_mean=0.430, reward_bound=0.311, batch=227 
8732: loss=0.139, reward_mean=0.430, reward_bound=0.314, batch=226 
8733: loss=0.147, reward_mean=0.430, reward_bound=0.349, batch=194 
8734: loss=0.148, reward_mean=0.390, reward_bound=0.185, batch=204 
8735: loss=0.145, reward_mean=0.420, reward_bound=0.204, batch=213 
8736: loss=0.139, reward_mean=0.460, reward_bound=0.206, batch=218 
8737: loss=0.136, reward_mean=0.530, reward_bound=0.229, batch=221 
8738: loss=0.137, reward_mean=0.520, reward_bound=0.254, batch=223 
8739: loss=0.138, reward_mean=0.480, reward_bound=0.282, batch=224 
8740: loss=0.140, reward_mean=0.410, reward_bound=0.314, batch=218 
8741: loss=0.141, reward_mean=0.470, reward_bound=0.289, batch=222 
8742: loss=0.144, reward_mean=0.370, reward_bound=0.349, batch=217 
8743: loss=0.144, reward_mean=0.560, reward_bound=0.308, batch=222 
8744: loss=0.142, reward_mean=0.560, reward_bound=0.360, batch=225 
8745: loss=0.145, reward_mean=0.510, reward_bound=0.387, batch=185 
8746: loss=0.140, reward_mean=0.470, reward_bound=0.112, batch=199 
8747: loss=0.147, reward_mean=0.560, reward_bound=0.206, batch=203 
8748: loss=0.146, reward_mean=0.490, reward_bound=0.254, batch=211 
8749: loss=0.146, reward_mean=0.410, reward_bound=0.254, batch=217 
8750: loss=0.145, reward_mean=0.470, reward_bound=0.282, batch=218 
8751: loss=0.145, reward_mean=0.480, reward_bound=0.286, batch=222 
8752: loss=0.147, reward_mean=0.540, reward_bound=0.314, batch=217 
8753: loss=0.146, reward_mean=0.510, reward_bound=0.277, batch=222 
8754: loss=0.146, reward_mean=0.400, reward_bound=0.324, batch=225 
8755: loss=0.145, reward_mean=0.440, reward_bound=0.321, batch=227 
8756: loss=0.144, reward_mean=0.370, reward_bound=0.349, batch=216 
8757: loss=0.143, reward_mean=0.430, reward_bound=0.241, batch=221 
8758: loss=0.142, reward_mean=0.460, reward_bound=0.314, batch=224 
8759: loss=0.141, reward_mean=0.550, reward_bound=0.349, batch=223 
8760: loss=0.139, reward_mean=0.440, reward_bound=0.301, batch=226 
8761: loss=0.139, reward_mean=0.460, reward_bound=0.349, batch=227 
8762: loss=0.140, reward_mean=0.430, reward_bound=0.387, batch=213 
8763: loss=0.141, reward_mean=0.480, reward_bound=0.282, batch=217 
8764: loss=0.140, reward_mean=0.460, reward_bound=0.342, batch=222 
8765: loss=0.138, reward_mean=0.450, reward_bound=0.349, batch=223 
8766: loss=0.139, reward_mean=0.370, reward_bound=0.314, batch=225 
8767: loss=0.142, reward_mean=0.470, reward_bound=0.387, batch=220 
8768: loss=0.146, reward_mean=0.430, reward_bound=0.430, batch=171 
8769: loss=0.140, reward_mean=0.530, reward_bound=0.185, batch=187 
8770: loss=0.133, reward_mean=0.500, reward_bound=0.167, batch=199 
8771: loss=0.135, reward_mean=0.540, reward_bound=0.194, batch=209 
8772: loss=0.138, reward_mean=0.470, reward_bound=0.206, batch=214 
8773: loss=0.140, reward_mean=0.510, reward_bound=0.254, batch=217 
8774: loss=0.141, reward_mean=0.460, reward_bound=0.282, batch=219 
8775: loss=0.139, reward_mean=0.460, reward_bound=0.314, batch=218 
8776: loss=0.139, reward_mean=0.520, reward_bound=0.317, batch=222 
8777: loss=0.141, reward_mean=0.470, reward_bound=0.349, batch=213 
8778: loss=0.143, reward_mean=0.550, reward_bound=0.301, batch=219 
8779: loss=0.142, reward_mean=0.430, reward_bound=0.328, batch=223 
8780: loss=0.140, reward_mean=0.480, reward_bound=0.349, batch=222 
8781: loss=0.142, reward_mean=0.430, reward_bound=0.387, batch=202 
8782: loss=0.141, reward_mean=0.430, reward_bound=0.206, batch=212 
8783: loss=0.140, reward_mean=0.470, reward_bound=0.254, batch=216 
8784: loss=0.141, reward_mean=0.510, reward_bound=0.282, batch=218 
8785: loss=0.140, reward_mean=0.400, reward_bound=0.314, batch=219 
8786: loss=0.138, reward_mean=0.490, reward_bound=0.349, batch=220 
8787: loss=0.137, reward_mean=0.560, reward_bound=0.387, batch=213 
8788: loss=0.134, reward_mean=0.490, reward_bound=0.301, batch=219 
8789: loss=0.134, reward_mean=0.510, reward_bound=0.314, batch=222 
8790: loss=0.135, reward_mean=0.440, reward_bound=0.349, batch=223 
8791: loss=0.135, reward_mean=0.520, reward_bound=0.349, batch=225 
8792: loss=0.136, reward_mean=0.400, reward_bound=0.387, batch=225 
8793: loss=0.137, reward_mean=0.590, reward_bound=0.387, batch=226 
8794: loss=0.138, reward_mean=0.410, reward_bound=0.390, batch=228 
8795: loss=0.148, reward_mean=0.470, reward_bound=0.430, batch=194 
8796: loss=0.146, reward_mean=0.500, reward_bound=0.206, batch=203 
8797: loss=0.150, reward_mean=0.440, reward_bound=0.185, batch=211 
8798: loss=0.148, reward_mean=0.430, reward_bound=0.122, batch=217 
8799: loss=0.147, reward_mean=0.410, reward_bound=0.224, batch=222 
8800: loss=0.150, reward_mean=0.500, reward_bound=0.254, batch=224 
8801: loss=0.150, reward_mean=0.440, reward_bound=0.282, batch=217 
8802: loss=0.146, reward_mean=0.370, reward_bound=0.182, batch=222 
8803: loss=0.147, reward_mean=0.470, reward_bound=0.282, batch=224 
8804: loss=0.145, reward_mean=0.480, reward_bound=0.314, batch=223 
8805: loss=0.144, reward_mean=0.510, reward_bound=0.335, batch=226 
8806: loss=0.141, reward_mean=0.400, reward_bound=0.349, batch=224 
8807: loss=0.140, reward_mean=0.490, reward_bound=0.349, batch=226 
8808: loss=0.148, reward_mean=0.570, reward_bound=0.387, batch=214 
8809: loss=0.145, reward_mean=0.440, reward_bound=0.314, batch=219 
8810: loss=0.142, reward_mean=0.420, reward_bound=0.295, batch=223 
8811: loss=0.142, reward_mean=0.440, reward_bound=0.301, batch=226 
8812: loss=0.143, reward_mean=0.520, reward_bound=0.349, batch=223 
8813: loss=0.143, reward_mean=0.480, reward_bound=0.358, batch=226 
8814: loss=0.144, reward_mean=0.440, reward_bound=0.331, batch=228 
8815: loss=0.144, reward_mean=0.510, reward_bound=0.392, batch=229 
8816: loss=0.144, reward_mean=0.470, reward_bound=0.430, batch=218 
8817: loss=0.144, reward_mean=0.480, reward_bound=0.257, batch=222 
8818: loss=0.143, reward_mean=0.450, reward_bound=0.324, batch=225 
8819: loss=0.144, reward_mean=0.510, reward_bound=0.356, batch=227 
8820: loss=0.144, reward_mean=0.550, reward_bound=0.387, batch=228 
8821: loss=0.144, reward_mean=0.460, reward_bound=0.392, batch=229 
8822: loss=0.143, reward_mean=0.470, reward_bound=0.430, batch=227 
8823: loss=0.143, reward_mean=0.440, reward_bound=0.460, batch=229 
8824: loss=0.143, reward_mean=0.410, reward_bound=0.401, batch=230 
8825: loss=0.143, reward_mean=0.420, reward_bound=0.439, batch=231 
8826: loss=0.143, reward_mean=0.370, reward_bound=0.430, batch=231 
8827: loss=0.143, reward_mean=0.480, reward_bound=0.430, batch=231 
8828: loss=0.150, reward_mean=0.420, reward_bound=0.478, batch=87 
8829: loss=0.101, reward_mean=0.520, reward_bound=0.005, batch=131 
8830: loss=0.107, reward_mean=0.410, reward_bound=0.008, batch=161 
8831: loss=0.109, reward_mean=0.450, reward_bound=0.020, batch=179 
8832: loss=0.120, reward_mean=0.570, reward_bound=0.052, batch=192 
8833: loss=0.112, reward_mean=0.450, reward_bound=0.065, batch=202 
8834: loss=0.117, reward_mean=0.470, reward_bound=0.080, batch=208 
8835: loss=0.118, reward_mean=0.410, reward_bound=0.098, batch=214 
8836: loss=0.119, reward_mean=0.520, reward_bound=0.122, batch=214 
8837: loss=0.123, reward_mean=0.490, reward_bound=0.150, batch=209 
8838: loss=0.130, reward_mean=0.440, reward_bound=0.167, batch=207 
8839: loss=0.126, reward_mean=0.450, reward_bound=0.185, batch=203 
8840: loss=0.126, reward_mean=0.520, reward_bound=0.206, batch=196 
8841: loss=0.128, reward_mean=0.430, reward_bound=0.206, batch=205 
8842: loss=0.128, reward_mean=0.430, reward_bound=0.185, batch=212 
8843: loss=0.126, reward_mean=0.420, reward_bound=0.213, batch=218 
8844: loss=0.131, reward_mean=0.450, reward_bound=0.229, batch=205 
8845: loss=0.130, reward_mean=0.430, reward_bound=0.234, batch=213 
8846: loss=0.136, reward_mean=0.560, reward_bound=0.254, batch=197 
8847: loss=0.134, reward_mean=0.450, reward_bound=0.224, batch=208 
8848: loss=0.135, reward_mean=0.490, reward_bound=0.254, batch=212 
8849: loss=0.135, reward_mean=0.450, reward_bound=0.191, batch=218 
8850: loss=0.149, reward_mean=0.450, reward_bound=0.282, batch=201 
8851: loss=0.145, reward_mean=0.450, reward_bound=0.229, batch=210 
8852: loss=0.143, reward_mean=0.400, reward_bound=0.234, batch=217 
8853: loss=0.143, reward_mean=0.490, reward_bound=0.254, batch=221 
8854: loss=0.144, reward_mean=0.450, reward_bound=0.314, batch=186 
8855: loss=0.143, reward_mean=0.550, reward_bound=0.128, batch=200 
8856: loss=0.146, reward_mean=0.570, reward_bound=0.150, batch=209 
8857: loss=0.146, reward_mean=0.470, reward_bound=0.185, batch=213 
8858: loss=0.143, reward_mean=0.440, reward_bound=0.206, batch=215 
8859: loss=0.145, reward_mean=0.490, reward_bound=0.260, batch=220 
8860: loss=0.146, reward_mean=0.420, reward_bound=0.282, batch=220 
8861: loss=0.147, reward_mean=0.480, reward_bound=0.314, batch=220 
8862: loss=0.147, reward_mean=0.540, reward_bound=0.304, batch=224 
8863: loss=0.153, reward_mean=0.490, reward_bound=0.349, batch=198 
8864: loss=0.152, reward_mean=0.430, reward_bound=0.254, batch=207 
8865: loss=0.149, reward_mean=0.390, reward_bound=0.198, batch=215 
8866: loss=0.153, reward_mean=0.490, reward_bound=0.260, batch=220 
8867: loss=0.153, reward_mean=0.400, reward_bound=0.282, batch=222 
8868: loss=0.155, reward_mean=0.410, reward_bound=0.314, batch=219 
8869: loss=0.153, reward_mean=0.460, reward_bound=0.328, batch=223 
8870: loss=0.154, reward_mean=0.420, reward_bound=0.290, batch=226 
8871: loss=0.152, reward_mean=0.560, reward_bound=0.331, batch=228 
8872: loss=0.150, reward_mean=0.460, reward_bound=0.349, batch=228 
8873: loss=0.155, reward_mean=0.500, reward_bound=0.387, batch=182 
8874: loss=0.151, reward_mean=0.420, reward_bound=0.185, batch=196 
8875: loss=0.146, reward_mean=0.410, reward_bound=0.151, batch=207 
8876: loss=0.149, reward_mean=0.490, reward_bound=0.206, batch=211 
8877: loss=0.148, reward_mean=0.450, reward_bound=0.229, batch=213 
8878: loss=0.146, reward_mean=0.350, reward_bound=0.211, batch=219 
8879: loss=0.149, reward_mean=0.480, reward_bound=0.239, batch=223 
8880: loss=0.151, reward_mean=0.510, reward_bound=0.254, batch=221 
8881: loss=0.152, reward_mean=0.450, reward_bound=0.282, batch=223 
8882: loss=0.154, reward_mean=0.470, reward_bound=0.314, batch=222 
8883: loss=0.151, reward_mean=0.440, reward_bound=0.349, batch=215 
8884: loss=0.151, reward_mean=0.460, reward_bound=0.289, batch=220 
8885: loss=0.150, reward_mean=0.500, reward_bound=0.365, batch=224 
8886: loss=0.150, reward_mean=0.460, reward_bound=0.345, batch=227 
8887: loss=0.150, reward_mean=0.460, reward_bound=0.342, batch=229 
8888: loss=0.150, reward_mean=0.410, reward_bound=0.364, batch=230 
8889: loss=0.152, reward_mean=0.440, reward_bound=0.387, batch=209 
8890: loss=0.154, reward_mean=0.440, reward_bound=0.265, batch=216 
8891: loss=0.158, reward_mean=0.500, reward_bound=0.256, batch=221 
8892: loss=0.151, reward_mean=0.510, reward_bound=0.282, batch=222 
8893: loss=0.150, reward_mean=0.450, reward_bound=0.292, batch=225 
8894: loss=0.152, reward_mean=0.480, reward_bound=0.349, batch=225 
8895: loss=0.152, reward_mean=0.510, reward_bound=0.387, batch=223 
8896: loss=0.153, reward_mean=0.440, reward_bound=0.430, batch=166 
8897: loss=0.149, reward_mean=0.400, reward_bound=0.115, batch=186 
8898: loss=0.141, reward_mean=0.470, reward_bound=0.128, batch=200 
8899: loss=0.142, reward_mean=0.470, reward_bound=0.180, batch=210 
8900: loss=0.142, reward_mean=0.330, reward_bound=0.131, batch=217 
8901: loss=0.140, reward_mean=0.510, reward_bound=0.206, batch=214 
8902: loss=0.142, reward_mean=0.510, reward_bound=0.226, batch=220 
8903: loss=0.139, reward_mean=0.440, reward_bound=0.229, batch=219 
8904: loss=0.139, reward_mean=0.390, reward_bound=0.254, batch=215 
8905: loss=0.143, reward_mean=0.360, reward_bound=0.282, batch=209 
8906: loss=0.140, reward_mean=0.510, reward_bound=0.215, batch=216 
8907: loss=0.141, reward_mean=0.420, reward_bound=0.229, batch=220 
8908: loss=0.142, reward_mean=0.500, reward_bound=0.274, batch=224 
8909: loss=0.144, reward_mean=0.450, reward_bound=0.311, batch=227 
8910: loss=0.148, reward_mean=0.430, reward_bound=0.314, batch=214 
8911: loss=0.146, reward_mean=0.430, reward_bound=0.314, batch=219 
8912: loss=0.147, reward_mean=0.580, reward_bound=0.349, batch=214 
8913: loss=0.149, reward_mean=0.580, reward_bound=0.384, batch=220 
8914: loss=0.147, reward_mean=0.380, reward_bound=0.229, batch=223 
8915: loss=0.150, reward_mean=0.510, reward_bound=0.282, batch=225 
8916: loss=0.151, reward_mean=0.450, reward_bound=0.321, batch=227 
8917: loss=0.150, reward_mean=0.420, reward_bound=0.387, batch=208 
8918: loss=0.150, reward_mean=0.470, reward_bound=0.286, batch=215 
8919: loss=0.149, reward_mean=0.440, reward_bound=0.314, batch=218 
8920: loss=0.149, reward_mean=0.510, reward_bound=0.349, batch=220 
8921: loss=0.151, reward_mean=0.460, reward_bound=0.338, batch=224 
8922: loss=0.149, reward_mean=0.460, reward_bound=0.387, batch=221 
8923: loss=0.150, reward_mean=0.490, reward_bound=0.387, batch=223 
8924: loss=0.153, reward_mean=0.500, reward_bound=0.314, batch=225 
8925: loss=0.153, reward_mean=0.520, reward_bound=0.387, batch=225 
8926: loss=0.152, reward_mean=0.570, reward_bound=0.396, batch=227 
8927: loss=0.153, reward_mean=0.580, reward_bound=0.342, batch=229 
8928: loss=0.151, reward_mean=0.540, reward_bound=0.364, batch=230 
8929: loss=0.151, reward_mean=0.450, reward_bound=0.365, batch=231 
8930: loss=0.151, reward_mean=0.430, reward_bound=0.387, batch=230 
8931: loss=0.150, reward_mean=0.340, reward_bound=0.376, batch=231 
8932: loss=0.150, reward_mean=0.380, reward_bound=0.387, batch=230 
8933: loss=0.150, reward_mean=0.430, reward_bound=0.418, batch=231 
8934: loss=0.153, reward_mean=0.490, reward_bound=0.430, batch=199 
8935: loss=0.145, reward_mean=0.470, reward_bound=0.148, batch=209 
8936: loss=0.145, reward_mean=0.410, reward_bound=0.174, batch=216 
8937: loss=0.145, reward_mean=0.440, reward_bound=0.206, batch=219 
8938: loss=0.144, reward_mean=0.370, reward_bound=0.265, batch=223 
8939: loss=0.146, reward_mean=0.470, reward_bound=0.282, batch=221 
8940: loss=0.145, reward_mean=0.380, reward_bound=0.314, batch=219 
8941: loss=0.148, reward_mean=0.510, reward_bound=0.225, batch=223 
8942: loss=0.147, reward_mean=0.450, reward_bound=0.349, batch=220 
8943: loss=0.147, reward_mean=0.500, reward_bound=0.387, batch=218 
8944: loss=0.149, reward_mean=0.450, reward_bound=0.282, batch=220 
8945: loss=0.145, reward_mean=0.410, reward_bound=0.314, batch=223 
8946: loss=0.145, reward_mean=0.480, reward_bound=0.349, batch=225 
8947: loss=0.145, reward_mean=0.440, reward_bound=0.387, batch=224 
8948: loss=0.145, reward_mean=0.440, reward_bound=0.387, batch=225 
8949: loss=0.149, reward_mean=0.520, reward_bound=0.430, batch=215 
8950: loss=0.147, reward_mean=0.460, reward_bound=0.282, batch=217 
8951: loss=0.145, reward_mean=0.480, reward_bound=0.308, batch=222 
8952: loss=0.149, reward_mean=0.430, reward_bound=0.314, batch=224 
8953: loss=0.150, reward_mean=0.560, reward_bound=0.345, batch=227 
8954: loss=0.151, reward_mean=0.510, reward_bound=0.349, batch=224 
8955: loss=0.150, reward_mean=0.420, reward_bound=0.314, batch=226 
8956: loss=0.148, reward_mean=0.460, reward_bound=0.331, batch=228 
8957: loss=0.148, reward_mean=0.470, reward_bound=0.387, batch=222 
8958: loss=0.147, reward_mean=0.450, reward_bound=0.387, batch=223 
8959: loss=0.151, reward_mean=0.450, reward_bound=0.335, batch=226 
8960: loss=0.148, reward_mean=0.510, reward_bound=0.349, batch=225 
8961: loss=0.147, reward_mean=0.530, reward_bound=0.349, batch=226 
8962: loss=0.146, reward_mean=0.480, reward_bound=0.331, batch=228 
8963: loss=0.148, reward_mean=0.440, reward_bound=0.353, batch=229 
8964: loss=0.147, reward_mean=0.420, reward_bound=0.387, batch=227 
8965: loss=0.146, reward_mean=0.450, reward_bound=0.308, batch=229 
8966: loss=0.145, reward_mean=0.300, reward_bound=0.263, batch=230 
8967: loss=0.146, reward_mean=0.520, reward_bound=0.338, batch=231 
8968: loss=0.146, reward_mean=0.540, reward_bound=0.387, batch=229 
8969: loss=0.148, reward_mean=0.450, reward_bound=0.430, batch=221 
8970: loss=0.150, reward_mean=0.380, reward_bound=0.282, batch=224 
8971: loss=0.149, reward_mean=0.470, reward_bound=0.314, batch=225 
8972: loss=0.149, reward_mean=0.430, reward_bound=0.349, batch=225 
8973: loss=0.150, reward_mean=0.490, reward_bound=0.387, batch=226 
8974: loss=0.150, reward_mean=0.520, reward_bound=0.387, batch=227 
8975: loss=0.151, reward_mean=0.440, reward_bound=0.430, batch=227 
8976: loss=0.150, reward_mean=0.480, reward_bound=0.452, batch=229 
8977: loss=0.150, reward_mean=0.510, reward_bound=0.478, batch=231 
8978: loss=0.151, reward_mean=0.500, reward_bound=0.478, batch=163 
8979: loss=0.134, reward_mean=0.490, reward_bound=0.085, batch=184 
8980: loss=0.131, reward_mean=0.430, reward_bound=0.109, batch=198 
8981: loss=0.131, reward_mean=0.510, reward_bound=0.150, batch=205 
8982: loss=0.130, reward_mean=0.420, reward_bound=0.185, batch=211 
8983: loss=0.132, reward_mean=0.510, reward_bound=0.206, batch=217 
8984: loss=0.135, reward_mean=0.350, reward_bound=0.229, batch=211 
8985: loss=0.134, reward_mean=0.470, reward_bound=0.150, batch=216 
8986: loss=0.132, reward_mean=0.460, reward_bound=0.254, batch=216 
8987: loss=0.136, reward_mean=0.380, reward_bound=0.282, batch=214 
8988: loss=0.138, reward_mean=0.480, reward_bound=0.280, batch=220 
8989: loss=0.142, reward_mean=0.530, reward_bound=0.314, batch=207 
8990: loss=0.141, reward_mean=0.450, reward_bound=0.308, batch=215 
8991: loss=0.139, reward_mean=0.440, reward_bound=0.314, batch=218 
8992: loss=0.140, reward_mean=0.480, reward_bound=0.349, batch=212 
8993: loss=0.141, reward_mean=0.430, reward_bound=0.229, batch=217 
8994: loss=0.138, reward_mean=0.380, reward_bound=0.220, batch=222 
8995: loss=0.142, reward_mean=0.480, reward_bound=0.314, batch=223 
8996: loss=0.141, reward_mean=0.490, reward_bound=0.349, batch=225 
8997: loss=0.146, reward_mean=0.530, reward_bound=0.387, batch=200 
8998: loss=0.144, reward_mean=0.450, reward_bound=0.247, batch=210 
8999: loss=0.144, reward_mean=0.500, reward_bound=0.206, batch=221 
9000: loss=0.144, reward_mean=0.430, reward_bound=0.206, batch=224 
9001: loss=0.143, reward_mean=0.330, reward_bound=0.252, batch=227 
9002: loss=0.143, reward_mean=0.460, reward_bound=0.282, batch=227 
9003: loss=0.144, reward_mean=0.480, reward_bound=0.308, batch=229 
9004: loss=0.144, reward_mean=0.450, reward_bound=0.328, batch=230 
9005: loss=0.144, reward_mean=0.450, reward_bound=0.349, batch=227 
9006: loss=0.144, reward_mean=0.430, reward_bound=0.335, batch=229 
9007: loss=0.145, reward_mean=0.470, reward_bound=0.387, batch=220 
9008: loss=0.146, reward_mean=0.460, reward_bound=0.338, batch=224 
9009: loss=0.146, reward_mean=0.460, reward_bound=0.254, batch=226 
9010: loss=0.148, reward_mean=0.420, reward_bound=0.349, batch=225 
9011: loss=0.146, reward_mean=0.470, reward_bound=0.387, batch=226 
9012: loss=0.151, reward_mean=0.490, reward_bound=0.430, batch=197 
9013: loss=0.147, reward_mean=0.540, reward_bound=0.254, batch=206 
9014: loss=0.148, reward_mean=0.570, reward_bound=0.254, batch=212 
9015: loss=0.147, reward_mean=0.410, reward_bound=0.254, batch=217 
9016: loss=0.147, reward_mean=0.440, reward_bound=0.282, batch=218 
9017: loss=0.147, reward_mean=0.430, reward_bound=0.286, batch=222 
9018: loss=0.146, reward_mean=0.390, reward_bound=0.236, batch=225 
9019: loss=0.145, reward_mean=0.460, reward_bound=0.314, batch=220 
9020: loss=0.143, reward_mean=0.450, reward_bound=0.338, batch=224 
9021: loss=0.143, reward_mean=0.410, reward_bound=0.311, batch=227 
9022: loss=0.143, reward_mean=0.450, reward_bound=0.349, batch=221 
9023: loss=0.145, reward_mean=0.470, reward_bound=0.387, batch=212 
9024: loss=0.142, reward_mean=0.440, reward_bound=0.360, batch=218 
9025: loss=0.142, reward_mean=0.500, reward_bound=0.349, batch=221 
9026: loss=0.141, reward_mean=0.510, reward_bound=0.387, batch=222 
9027: loss=0.140, reward_mean=0.530, reward_bound=0.336, batch=225 
9028: loss=0.140, reward_mean=0.490, reward_bound=0.387, batch=225 
9029: loss=0.140, reward_mean=0.510, reward_bound=0.396, batch=227 
9030: loss=0.145, reward_mean=0.510, reward_bound=0.430, batch=215 
9031: loss=0.146, reward_mean=0.470, reward_bound=0.349, batch=219 
9032: loss=0.146, reward_mean=0.390, reward_bound=0.265, batch=223 
9033: loss=0.147, reward_mean=0.440, reward_bound=0.282, batch=223 
9034: loss=0.150, reward_mean=0.440, reward_bound=0.349, batch=225 
9035: loss=0.147, reward_mean=0.560, reward_bound=0.387, batch=223 
9036: loss=0.147, reward_mean=0.470, reward_bound=0.349, batch=225 
9037: loss=0.148, reward_mean=0.520, reward_bound=0.349, batch=226 
9038: loss=0.148, reward_mean=0.430, reward_bound=0.430, batch=225 
9039: loss=0.148, reward_mean=0.460, reward_bound=0.321, batch=227 
9040: loss=0.148, reward_mean=0.530, reward_bound=0.430, batch=225 
9041: loss=0.148, reward_mean=0.430, reward_bound=0.430, batch=226 
9042: loss=0.147, reward_mean=0.520, reward_bound=0.430, batch=227 
9043: loss=0.147, reward_mean=0.410, reward_bound=0.430, batch=228 
9044: loss=0.148, reward_mean=0.470, reward_bound=0.435, batch=229 
9045: loss=0.149, reward_mean=0.460, reward_bound=0.450, batch=230 
9046: loss=0.149, reward_mean=0.410, reward_bound=0.439, batch=231 
9047: loss=0.149, reward_mean=0.400, reward_bound=0.478, batch=191 
9048: loss=0.143, reward_mean=0.530, reward_bound=0.185, batch=203 
9049: loss=0.144, reward_mean=0.410, reward_bound=0.190, batch=212 
9050: loss=0.141, reward_mean=0.440, reward_bound=0.185, batch=216 
9051: loss=0.140, reward_mean=0.460, reward_bound=0.254, batch=220 
9052: loss=0.143, reward_mean=0.530, reward_bound=0.282, batch=221 
9053: loss=0.143, reward_mean=0.460, reward_bound=0.254, batch=222 
9054: loss=0.144, reward_mean=0.390, reward_bound=0.314, batch=218 
9055: loss=0.144, reward_mean=0.440, reward_bound=0.349, batch=217 
9056: loss=0.141, reward_mean=0.500, reward_bound=0.342, batch=222 
9057: loss=0.141, reward_mean=0.460, reward_bound=0.302, batch=225 
9058: loss=0.141, reward_mean=0.470, reward_bound=0.296, batch=227 
9059: loss=0.143, reward_mean=0.500, reward_bound=0.349, batch=226 
9060: loss=0.142, reward_mean=0.440, reward_bound=0.335, batch=228 
9061: loss=0.142, reward_mean=0.500, reward_bound=0.321, batch=229 
9062: loss=0.142, reward_mean=0.390, reward_bound=0.364, batch=230 
9063: loss=0.142, reward_mean=0.480, reward_bound=0.349, batch=230 
9064: loss=0.146, reward_mean=0.420, reward_bound=0.387, batch=216 
9065: loss=0.145, reward_mean=0.540, reward_bound=0.331, batch=221 
9066: loss=0.147, reward_mean=0.550, reward_bound=0.349, batch=222 
9067: loss=0.146, reward_mean=0.380, reward_bound=0.360, batch=225 
9068: loss=0.146, reward_mean=0.440, reward_bound=0.356, batch=227 
9069: loss=0.146, reward_mean=0.380, reward_bound=0.314, batch=228 
9070: loss=0.146, reward_mean=0.430, reward_bound=0.387, batch=226 
9071: loss=0.146, reward_mean=0.470, reward_bound=0.335, batch=228 
9072: loss=0.146, reward_mean=0.440, reward_bound=0.392, batch=229 
9073: loss=0.145, reward_mean=0.440, reward_bound=0.295, batch=230 
9074: loss=0.145, reward_mean=0.350, reward_bound=0.376, batch=231 
9075: loss=0.145, reward_mean=0.560, reward_bound=0.387, batch=231 
9076: loss=0.147, reward_mean=0.480, reward_bound=0.430, batch=215 
9077: loss=0.149, reward_mean=0.440, reward_bound=0.282, batch=219 
9078: loss=0.147, reward_mean=0.440, reward_bound=0.314, batch=221 
9079: loss=0.146, reward_mean=0.400, reward_bound=0.349, batch=221 
9080: loss=0.146, reward_mean=0.420, reward_bound=0.349, batch=222 
9081: loss=0.145, reward_mean=0.490, reward_bound=0.400, batch=225 
9082: loss=0.144, reward_mean=0.530, reward_bound=0.387, batch=226 
9083: loss=0.144, reward_mean=0.440, reward_bound=0.387, batch=226 
9084: loss=0.144, reward_mean=0.450, reward_bound=0.387, batch=227 
9085: loss=0.143, reward_mean=0.470, reward_bound=0.342, batch=229 
9086: loss=0.143, reward_mean=0.450, reward_bound=0.381, batch=230 
9087: loss=0.146, reward_mean=0.550, reward_bound=0.430, batch=222 
9088: loss=0.148, reward_mean=0.450, reward_bound=0.400, batch=225 
9089: loss=0.149, reward_mean=0.460, reward_bound=0.387, batch=226 
9090: loss=0.150, reward_mean=0.420, reward_bound=0.351, batch=228 
9091: loss=0.147, reward_mean=0.470, reward_bound=0.392, batch=229 
9092: loss=0.145, reward_mean=0.460, reward_bound=0.430, batch=225 
9093: loss=0.144, reward_mean=0.520, reward_bound=0.430, batch=226 
9094: loss=0.144, reward_mean=0.490, reward_bound=0.396, batch=228 
9095: loss=0.144, reward_mean=0.410, reward_bound=0.387, batch=228 
9096: loss=0.144, reward_mean=0.470, reward_bound=0.397, batch=229 
9097: loss=0.144, reward_mean=0.620, reward_bound=0.430, batch=229 
9098: loss=0.145, reward_mean=0.570, reward_bound=0.478, batch=231 
9099: loss=0.145, reward_mean=0.570, reward_bound=0.430, batch=231 
9100: loss=0.152, reward_mean=0.380, reward_bound=0.478, batch=205 
9101: loss=0.155, reward_mean=0.410, reward_bound=0.189, batch=213 
9102: loss=0.155, reward_mean=0.520, reward_bound=0.282, batch=217 
9103: loss=0.156, reward_mean=0.410, reward_bound=0.254, batch=221 
9104: loss=0.155, reward_mean=0.450, reward_bound=0.314, batch=222 
9105: loss=0.155, reward_mean=0.450, reward_bound=0.387, batch=221 
9106: loss=0.154, reward_mean=0.460, reward_bound=0.314, batch=224 
9107: loss=0.156, reward_mean=0.480, reward_bound=0.349, batch=226 
9108: loss=0.156, reward_mean=0.470, reward_bound=0.351, batch=228 
9109: loss=0.157, reward_mean=0.440, reward_bound=0.392, batch=229 
9110: loss=0.158, reward_mean=0.500, reward_bound=0.405, batch=230 
9111: loss=0.158, reward_mean=0.380, reward_bound=0.395, batch=231 
9112: loss=0.158, reward_mean=0.510, reward_bound=0.387, batch=231 
9113: loss=0.154, reward_mean=0.430, reward_bound=0.430, batch=222 
9114: loss=0.153, reward_mean=0.390, reward_bound=0.360, batch=225 
9115: loss=0.154, reward_mean=0.560, reward_bound=0.387, batch=226 
9116: loss=0.153, reward_mean=0.470, reward_bound=0.409, batch=228 
9117: loss=0.153, reward_mean=0.380, reward_bound=0.430, batch=228 
9118: loss=0.152, reward_mean=0.460, reward_bound=0.478, batch=230 
9119: loss=0.151, reward_mean=0.500, reward_bound=0.451, batch=231 
9120: loss=0.152, reward_mean=0.570, reward_bound=0.478, batch=214 
9121: loss=0.152, reward_mean=0.440, reward_bound=0.342, batch=220 
9122: loss=0.154, reward_mean=0.530, reward_bound=0.338, batch=224 
9123: loss=0.152, reward_mean=0.540, reward_bound=0.349, batch=226 
9124: loss=0.152, reward_mean=0.440, reward_bound=0.368, batch=228 
9125: loss=0.153, reward_mean=0.550, reward_bound=0.387, batch=225 
9126: loss=0.152, reward_mean=0.460, reward_bound=0.430, batch=222 
9127: loss=0.152, reward_mean=0.430, reward_bound=0.349, batch=223 
9128: loss=0.153, reward_mean=0.480, reward_bound=0.372, batch=226 
9129: loss=0.152, reward_mean=0.440, reward_bound=0.387, batch=226 
9130: loss=0.152, reward_mean=0.410, reward_bound=0.430, batch=224 
9131: loss=0.150, reward_mean=0.460, reward_bound=0.384, batch=227 
9132: loss=0.150, reward_mean=0.450, reward_bound=0.277, batch=229 
9133: loss=0.150, reward_mean=0.430, reward_bound=0.387, batch=228 
9134: loss=0.150, reward_mean=0.460, reward_bound=0.478, batch=230 
9135: loss=0.150, reward_mean=0.480, reward_bound=0.387, batch=230 
9136: loss=0.150, reward_mean=0.420, reward_bound=0.451, batch=231 
9137: loss=0.150, reward_mean=0.470, reward_bound=0.430, batch=231 
9138: loss=0.150, reward_mean=0.500, reward_bound=0.478, batch=224 
9139: loss=0.149, reward_mean=0.470, reward_bound=0.384, batch=227 
9140: loss=0.149, reward_mean=0.530, reward_bound=0.422, batch=229 
9141: loss=0.148, reward_mean=0.510, reward_bound=0.405, batch=230 
9142: loss=0.148, reward_mean=0.490, reward_bound=0.430, batch=229 
9143: loss=0.149, reward_mean=0.470, reward_bound=0.360, batch=230 
9144: loss=0.147, reward_mean=0.420, reward_bound=0.464, batch=231 
9145: loss=0.147, reward_mean=0.500, reward_bound=0.430, batch=231 
9146: loss=0.150, reward_mean=0.600, reward_bound=0.478, batch=225 
9147: loss=0.149, reward_mean=0.460, reward_bound=0.321, batch=227 
9148: loss=0.148, reward_mean=0.540, reward_bound=0.342, batch=229 
9149: loss=0.148, reward_mean=0.500, reward_bound=0.349, batch=229 
9150: loss=0.148, reward_mean=0.510, reward_bound=0.387, batch=228 
9151: loss=0.148, reward_mean=0.520, reward_bound=0.387, batch=228 
9152: loss=0.149, reward_mean=0.400, reward_bound=0.430, batch=227 
9153: loss=0.148, reward_mean=0.440, reward_bound=0.349, batch=228 
9154: loss=0.150, reward_mean=0.560, reward_bound=0.430, batch=228 
9155: loss=0.151, reward_mean=0.550, reward_bound=0.435, batch=229 
9156: loss=0.151, reward_mean=0.480, reward_bound=0.405, batch=230 
9157: loss=0.152, reward_mean=0.390, reward_bound=0.430, batch=230 
9158: loss=0.152, reward_mean=0.450, reward_bound=0.464, batch=231 
9159: loss=0.150, reward_mean=0.530, reward_bound=0.478, batch=229 
9160: loss=0.150, reward_mean=0.470, reward_bound=0.478, batch=232 
9161: loss=0.150, reward_mean=0.440, reward_bound=0.415, batch=232 
9162: loss=0.150, reward_mean=0.480, reward_bound=0.478, batch=230 
9163: loss=0.149, reward_mean=0.510, reward_bound=0.501, batch=231 
9164: loss=0.149, reward_mean=0.480, reward_bound=0.430, batch=231 
9165: loss=0.149, reward_mean=0.410, reward_bound=0.430, batch=231 
9167: loss=0.067, reward_mean=0.390, reward_bound=0.000, batch=39 
9168: loss=0.069, reward_mean=0.520, reward_bound=0.000, batch=91 
9169: loss=0.078, reward_mean=0.520, reward_bound=0.001, batch=132 
9170: loss=0.087, reward_mean=0.550, reward_bound=0.007, batch=162 
9171: loss=0.092, reward_mean=0.550, reward_bound=0.020, batch=181 
9172: loss=0.099, reward_mean=0.560, reward_bound=0.038, batch=192 
9173: loss=0.101, reward_mean=0.470, reward_bound=0.052, batch=199 
9174: loss=0.105, reward_mean=0.480, reward_bound=0.065, batch=201 
9175: loss=0.109, reward_mean=0.420, reward_bound=0.080, batch=201 
9176: loss=0.108, reward_mean=0.400, reward_bound=0.089, batch=208 
9177: loss=0.107, reward_mean=0.410, reward_bound=0.098, batch=209 
9178: loss=0.108, reward_mean=0.450, reward_bound=0.109, batch=215 
9179: loss=0.108, reward_mean=0.460, reward_bound=0.135, batch=205 
9180: loss=0.106, reward_mean=0.460, reward_bound=0.150, batch=197 
9181: loss=0.104, reward_mean=0.460, reward_bound=0.163, batch=208 
9182: loss=0.106, reward_mean=0.500, reward_bound=0.167, batch=207 
9183: loss=0.113, reward_mean=0.550, reward_bound=0.185, batch=191 
9184: loss=0.119, reward_mean=0.470, reward_bound=0.206, batch=181 
9185: loss=0.115, reward_mean=0.510, reward_bound=0.185, batch=195 
9186: loss=0.116, reward_mean=0.520, reward_bound=0.206, batch=203 
9187: loss=0.120, reward_mean=0.450, reward_bound=0.229, batch=182 
9188: loss=0.115, reward_mean=0.460, reward_bound=0.109, batch=196 
9189: loss=0.117, reward_mean=0.540, reward_bound=0.185, batch=205 
9190: loss=0.116, reward_mean=0.480, reward_bound=0.206, batch=210 
9191: loss=0.118, reward_mean=0.450, reward_bound=0.229, batch=215 
9192: loss=0.122, reward_mean=0.500, reward_bound=0.254, batch=196 
9193: loss=0.119, reward_mean=0.410, reward_bound=0.168, batch=207 
9194: loss=0.121, reward_mean=0.450, reward_bound=0.254, batch=214 
9195: loss=0.121, reward_mean=0.520, reward_bound=0.282, batch=179 
9196: loss=0.119, reward_mean=0.490, reward_bound=0.089, batch=194 
9197: loss=0.124, reward_mean=0.430, reward_bound=0.150, batch=203 
9198: loss=0.125, reward_mean=0.430, reward_bound=0.167, batch=211 
9199: loss=0.125, reward_mean=0.430, reward_bound=0.185, batch=217 
9200: loss=0.122, reward_mean=0.450, reward_bound=0.229, batch=215 
9201: loss=0.124, reward_mean=0.550, reward_bound=0.254, batch=214 
9202: loss=0.123, reward_mean=0.450, reward_bound=0.282, batch=216 
9203: loss=0.123, reward_mean=0.450, reward_bound=0.284, batch=221 
9204: loss=0.125, reward_mean=0.430, reward_bound=0.314, batch=173 
9205: loss=0.122, reward_mean=0.470, reward_bound=0.095, batch=191 
9206: loss=0.118, reward_mean=0.460, reward_bound=0.122, batch=203 
9207: loss=0.116, reward_mean=0.560, reward_bound=0.206, batch=210 
9208: loss=0.117, reward_mean=0.450, reward_bound=0.229, batch=216 
9209: loss=0.117, reward_mean=0.470, reward_bound=0.254, batch=217 
9210: loss=0.120, reward_mean=0.550, reward_bound=0.282, batch=215 
9211: loss=0.124, reward_mean=0.540, reward_bound=0.289, batch=220 
9212: loss=0.126, reward_mean=0.550, reward_bound=0.314, batch=213 
9213: loss=0.135, reward_mean=0.440, reward_bound=0.349, batch=153 
9214: loss=0.123, reward_mean=0.450, reward_bound=0.050, batch=177 
9215: loss=0.118, reward_mean=0.430, reward_bound=0.080, batch=192 
9216: loss=0.125, reward_mean=0.530, reward_bound=0.135, batch=198 
9217: loss=0.123, reward_mean=0.420, reward_bound=0.150, batch=206 
9218: loss=0.121, reward_mean=0.410, reward_bound=0.196, batch=214 
9219: loss=0.118, reward_mean=0.440, reward_bound=0.206, batch=216 
9220: loss=0.124, reward_mean=0.420, reward_bound=0.229, batch=215 
9221: loss=0.124, reward_mean=0.460, reward_bound=0.234, batch=220 
9222: loss=0.124, reward_mean=0.440, reward_bound=0.254, batch=215 
9223: loss=0.126, reward_mean=0.520, reward_bound=0.282, batch=211 
9224: loss=0.125, reward_mean=0.480, reward_bound=0.282, batch=217 
9225: loss=0.127, reward_mean=0.470, reward_bound=0.314, batch=206 
9226: loss=0.124, reward_mean=0.440, reward_bound=0.229, batch=211 
9227: loss=0.125, reward_mean=0.460, reward_bound=0.254, batch=216 
9228: loss=0.125, reward_mean=0.480, reward_bound=0.314, batch=217 
9229: loss=0.125, reward_mean=0.390, reward_bound=0.245, batch=222 
9230: loss=0.125, reward_mean=0.470, reward_bound=0.254, batch=222 
9231: loss=0.126, reward_mean=0.410, reward_bound=0.324, batch=225 
9232: loss=0.127, reward_mean=0.460, reward_bound=0.349, batch=208 
9233: loss=0.127, reward_mean=0.390, reward_bound=0.286, batch=215 
9234: loss=0.126, reward_mean=0.450, reward_bound=0.282, batch=219 
9235: loss=0.128, reward_mean=0.480, reward_bound=0.254, batch=221 
9236: loss=0.128, reward_mean=0.380, reward_bound=0.282, batch=224 
9237: loss=0.128, reward_mean=0.430, reward_bound=0.314, batch=226 
9238: loss=0.128, reward_mean=0.430, reward_bound=0.349, batch=226 
9239: loss=0.130, reward_mean=0.440, reward_bound=0.316, batch=228 
9240: loss=0.132, reward_mean=0.410, reward_bound=0.289, batch=229 
9241: loss=0.139, reward_mean=0.430, reward_bound=0.387, batch=143 
9242: loss=0.142, reward_mean=0.430, reward_bound=0.085, batch=170 
9243: loss=0.137, reward_mean=0.490, reward_bound=0.080, batch=188 
9244: loss=0.135, reward_mean=0.530, reward_bound=0.109, batch=199 
9245: loss=0.131, reward_mean=0.390, reward_bound=0.135, batch=206 
9246: loss=0.139, reward_mean=0.520, reward_bound=0.167, batch=211 
9247: loss=0.140, reward_mean=0.500, reward_bound=0.185, batch=214 
9248: loss=0.145, reward_mean=0.580, reward_bound=0.229, batch=213 
9249: loss=0.150, reward_mean=0.430, reward_bound=0.254, batch=206 
9250: loss=0.150, reward_mean=0.480, reward_bound=0.167, batch=213 
9251: loss=0.147, reward_mean=0.440, reward_bound=0.254, batch=217 
9252: loss=0.150, reward_mean=0.420, reward_bound=0.282, batch=211 
9253: loss=0.153, reward_mean=0.490, reward_bound=0.314, batch=205 
9254: loss=0.151, reward_mean=0.410, reward_bound=0.254, batch=212 
9255: loss=0.149, reward_mean=0.410, reward_bound=0.292, batch=218 
9256: loss=0.149, reward_mean=0.490, reward_bound=0.286, batch=222 
9257: loss=0.151, reward_mean=0.520, reward_bound=0.314, batch=222 
9258: loss=0.150, reward_mean=0.500, reward_bound=0.229, batch=224 
9259: loss=0.151, reward_mean=0.460, reward_bound=0.314, batch=226 
9260: loss=0.146, reward_mean=0.520, reward_bound=0.349, batch=207 
9261: loss=0.147, reward_mean=0.510, reward_bound=0.349, batch=211 
9262: loss=0.149, reward_mean=0.510, reward_bound=0.349, batch=217 
9263: loss=0.148, reward_mean=0.420, reward_bound=0.277, batch=222 
9264: loss=0.151, reward_mean=0.410, reward_bound=0.282, batch=222 
9265: loss=0.149, reward_mean=0.520, reward_bound=0.314, batch=222 
9266: loss=0.150, reward_mean=0.450, reward_bound=0.349, batch=224 
9267: loss=0.148, reward_mean=0.520, reward_bound=0.387, batch=195 
9268: loss=0.146, reward_mean=0.610, reward_bound=0.314, batch=203 
9269: loss=0.144, reward_mean=0.400, reward_bound=0.229, batch=211 
9270: loss=0.146, reward_mean=0.560, reward_bound=0.254, batch=214 
9271: loss=0.146, reward_mean=0.430, reward_bound=0.277, batch=220 
9272: loss=0.143, reward_mean=0.500, reward_bound=0.282, batch=220 
9273: loss=0.143, reward_mean=0.430, reward_bound=0.254, batch=222 
9274: loss=0.145, reward_mean=0.580, reward_bound=0.349, batch=219 
9275: loss=0.146, reward_mean=0.460, reward_bound=0.314, batch=222 
9276: loss=0.145, reward_mean=0.460, reward_bound=0.236, batch=225 
9277: loss=0.145, reward_mean=0.460, reward_bound=0.254, batch=225 
9278: loss=0.144, reward_mean=0.580, reward_bound=0.349, batch=226 
9279: loss=0.144, reward_mean=0.460, reward_bound=0.331, batch=228 
9280: loss=0.147, reward_mean=0.460, reward_bound=0.387, batch=218 
9281: loss=0.145, reward_mean=0.350, reward_bound=0.234, batch=222 
9282: loss=0.146, reward_mean=0.450, reward_bound=0.314, batch=224 
9283: loss=0.148, reward_mean=0.480, reward_bound=0.349, batch=226 
9284: loss=0.148, reward_mean=0.430, reward_bound=0.368, batch=228 
9285: loss=0.148, reward_mean=0.460, reward_bound=0.392, batch=229 
9286: loss=0.149, reward_mean=0.370, reward_bound=0.381, batch=230 
9287: loss=0.148, reward_mean=0.380, reward_bound=0.304, batch=231 
9288: loss=0.138, reward_mean=0.460, reward_bound=0.430, batch=122 
9289: loss=0.113, reward_mean=0.500, reward_bound=0.025, batch=154 
9290: loss=0.111, reward_mean=0.410, reward_bound=0.034, batch=178 
9291: loss=0.108, reward_mean=0.430, reward_bound=0.047, batch=196 
9292: loss=0.115, reward_mean=0.570, reward_bound=0.076, batch=207 
9293: loss=0.120, reward_mean=0.460, reward_bound=0.109, batch=217 
9294: loss=0.121, reward_mean=0.440, reward_bound=0.135, batch=221 
9295: loss=0.124, reward_mean=0.410, reward_bound=0.167, batch=214 
9296: loss=0.129, reward_mean=0.500, reward_bound=0.206, batch=213 
9297: loss=0.124, reward_mean=0.460, reward_bound=0.229, batch=211 
9298: loss=0.123, reward_mean=0.500, reward_bound=0.206, batch=217 
9299: loss=0.126, reward_mean=0.440, reward_bound=0.254, batch=213 
9300: loss=0.126, reward_mean=0.510, reward_bound=0.244, batch=219 
9301: loss=0.134, reward_mean=0.560, reward_bound=0.282, batch=199 
9302: loss=0.130, reward_mean=0.480, reward_bound=0.206, batch=208 
9303: loss=0.131, reward_mean=0.480, reward_bound=0.206, batch=214 
9304: loss=0.130, reward_mean=0.500, reward_bound=0.229, batch=218 
9305: loss=0.131, reward_mean=0.500, reward_bound=0.282, batch=220 
9306: loss=0.133, reward_mean=0.440, reward_bound=0.314, batch=200 
9307: loss=0.130, reward_mean=0.430, reward_bound=0.189, batch=210 
9308: loss=0.130, reward_mean=0.550, reward_bound=0.229, batch=216 
9309: loss=0.128, reward_mean=0.450, reward_bound=0.254, batch=219 
9310: loss=0.128, reward_mean=0.430, reward_bound=0.282, batch=221 
9311: loss=0.130, reward_mean=0.440, reward_bound=0.314, batch=220 
9312: loss=0.128, reward_mean=0.390, reward_bound=0.338, batch=224 
9313: loss=0.127, reward_mean=0.460, reward_bound=0.345, batch=227 
9314: loss=0.127, reward_mean=0.480, reward_bound=0.314, batch=228 
9315: loss=0.135, reward_mean=0.610, reward_bound=0.349, batch=203 
9316: loss=0.135, reward_mean=0.560, reward_bound=0.282, batch=211 
9317: loss=0.132, reward_mean=0.580, reward_bound=0.282, batch=217 
9318: loss=0.132, reward_mean=0.450, reward_bound=0.224, batch=222 
9319: loss=0.131, reward_mean=0.450, reward_bound=0.282, batch=224 
9320: loss=0.131, reward_mean=0.520, reward_bound=0.314, batch=223 
9321: loss=0.131, reward_mean=0.530, reward_bound=0.387, batch=192 
9322: loss=0.132, reward_mean=0.400, reward_bound=0.206, batch=205 
9323: loss=0.133, reward_mean=0.420, reward_bound=0.229, batch=211 
9324: loss=0.131, reward_mean=0.580, reward_bound=0.229, batch=216 
9325: loss=0.132, reward_mean=0.410, reward_bound=0.254, batch=218 
9326: loss=0.129, reward_mean=0.410, reward_bound=0.286, batch=222 
9327: loss=0.130, reward_mean=0.470, reward_bound=0.314, batch=214 
9328: loss=0.130, reward_mean=0.440, reward_bound=0.308, batch=220 
9329: loss=0.129, reward_mean=0.490, reward_bound=0.314, batch=223 
9330: loss=0.128, reward_mean=0.420, reward_bound=0.335, batch=226 
9331: loss=0.129, reward_mean=0.440, reward_bound=0.349, batch=219 
9332: loss=0.130, reward_mean=0.460, reward_bound=0.387, batch=216 
9333: loss=0.129, reward_mean=0.510, reward_bound=0.254, batch=218 
9334: loss=0.129, reward_mean=0.440, reward_bound=0.317, batch=222 
9335: loss=0.129, reward_mean=0.460, reward_bound=0.349, batch=224 
9336: loss=0.129, reward_mean=0.450, reward_bound=0.384, batch=227 
9337: loss=0.128, reward_mean=0.490, reward_bound=0.373, batch=229 
9338: loss=0.128, reward_mean=0.450, reward_bound=0.364, batch=230 
9339: loss=0.128, reward_mean=0.430, reward_bound=0.387, batch=226 
9340: loss=0.136, reward_mean=0.420, reward_bound=0.430, batch=178 
9341: loss=0.128, reward_mean=0.460, reward_bound=0.111, batch=194 
9342: loss=0.126, reward_mean=0.430, reward_bound=0.134, batch=206 
9343: loss=0.127, reward_mean=0.500, reward_bound=0.167, batch=213 
9344: loss=0.126, reward_mean=0.510, reward_bound=0.185, batch=218 
9345: loss=0.125, reward_mean=0.450, reward_bound=0.229, batch=214 
9346: loss=0.128, reward_mean=0.440, reward_bound=0.254, batch=219 
9347: loss=0.129, reward_mean=0.430, reward_bound=0.282, batch=220 
9348: loss=0.127, reward_mean=0.430, reward_bound=0.274, batch=224 
9349: loss=0.125, reward_mean=0.430, reward_bound=0.280, batch=227 
9350: loss=0.132, reward_mean=0.540, reward_bound=0.314, batch=214 
9351: loss=0.130, reward_mean=0.350, reward_bound=0.254, batch=219 
9352: loss=0.130, reward_mean=0.390, reward_bound=0.282, batch=220 
9353: loss=0.133, reward_mean=0.420, reward_bound=0.296, batch=224 
9354: loss=0.135, reward_mean=0.420, reward_bound=0.314, batch=225 
9355: loss=0.135, reward_mean=0.370, reward_bound=0.266, batch=227 
9356: loss=0.134, reward_mean=0.400, reward_bound=0.342, batch=229 
9357: loss=0.132, reward_mean=0.430, reward_bound=0.349, batch=218 
9358: loss=0.131, reward_mean=0.430, reward_bound=0.353, batch=222 
9359: loss=0.133, reward_mean=0.550, reward_bound=0.387, batch=211 
9360: loss=0.133, reward_mean=0.460, reward_bound=0.206, batch=216 
9361: loss=0.131, reward_mean=0.460, reward_bound=0.229, batch=220 
9362: loss=0.132, reward_mean=0.460, reward_bound=0.282, batch=223 
9363: loss=0.131, reward_mean=0.510, reward_bound=0.349, batch=224 
9364: loss=0.131, reward_mean=0.510, reward_bound=0.387, batch=221 
9365: loss=0.135, reward_mean=0.490, reward_bound=0.430, batch=207 
9366: loss=0.131, reward_mean=0.430, reward_bound=0.263, batch=215 
9367: loss=0.129, reward_mean=0.480, reward_bound=0.234, batch=220 
9368: loss=0.130, reward_mean=0.490, reward_bound=0.282, batch=221 
9369: loss=0.131, reward_mean=0.510, reward_bound=0.314, batch=224 
9370: loss=0.131, reward_mean=0.490, reward_bound=0.342, batch=227 
9371: loss=0.130, reward_mean=0.470, reward_bound=0.349, batch=227 
9372: loss=0.130, reward_mean=0.410, reward_bound=0.366, batch=229 
9373: loss=0.130, reward_mean=0.470, reward_bound=0.387, batch=220 
9374: loss=0.129, reward_mean=0.400, reward_bound=0.365, batch=224 
9375: loss=0.129, reward_mean=0.420, reward_bound=0.387, batch=225 
9376: loss=0.129, reward_mean=0.420, reward_bound=0.321, batch=227 
9377: loss=0.128, reward_mean=0.390, reward_bound=0.342, batch=229 
9378: loss=0.128, reward_mean=0.540, reward_bound=0.405, batch=230 
9379: loss=0.131, reward_mean=0.470, reward_bound=0.430, batch=220 
9380: loss=0.131, reward_mean=0.500, reward_bound=0.304, batch=224 
9381: loss=0.133, reward_mean=0.420, reward_bound=0.345, batch=227 
9382: loss=0.133, reward_mean=0.400, reward_bound=0.349, batch=228 
9383: loss=0.133, reward_mean=0.490, reward_bound=0.387, batch=228 
9384: loss=0.133, reward_mean=0.420, reward_bound=0.430, batch=228 
9385: loss=0.132, reward_mean=0.530, reward_bound=0.357, batch=229 
9386: loss=0.132, reward_mean=0.390, reward_bound=0.405, batch=230 
9387: loss=0.133, reward_mean=0.520, reward_bound=0.430, batch=229 
9388: loss=0.132, reward_mean=0.500, reward_bound=0.450, batch=230 
9389: loss=0.132, reward_mean=0.530, reward_bound=0.296, batch=231 
9390: loss=0.132, reward_mean=0.360, reward_bound=0.349, batch=231 
9391: loss=0.135, reward_mean=0.460, reward_bound=0.478, batch=90 
9392: loss=0.082, reward_mean=0.490, reward_bound=0.002, batch=133 
9393: loss=0.079, reward_mean=0.420, reward_bound=0.003, batch=163 
9394: loss=0.082, reward_mean=0.410, reward_bound=0.011, batch=182 
9395: loss=0.087, reward_mean=0.470, reward_bound=0.028, batch=195 
9396: loss=0.091, reward_mean=0.410, reward_bound=0.052, batch=204 
9397: loss=0.093, reward_mean=0.560, reward_bound=0.080, batch=211 
9398: loss=0.100, reward_mean=0.470, reward_bound=0.089, batch=216 
9399: loss=0.106, reward_mean=0.480, reward_bound=0.109, batch=210 
9400: loss=0.109, reward_mean=0.430, reward_bound=0.135, batch=210 
9401: loss=0.117, reward_mean=0.420, reward_bound=0.150, batch=209 
9402: loss=0.108, reward_mean=0.540, reward_bound=0.185, batch=202 
9403: loss=0.106, reward_mean=0.450, reward_bound=0.206, batch=217 
9404: loss=0.103, reward_mean=0.480, reward_bound=0.206, batch=217 
9405: loss=0.107, reward_mean=0.440, reward_bound=0.229, batch=203 
9406: loss=0.104, reward_mean=0.420, reward_bound=0.229, batch=211 
9407: loss=0.102, reward_mean=0.500, reward_bound=0.229, batch=216 
9408: loss=0.106, reward_mean=0.480, reward_bound=0.254, batch=204 
9409: loss=0.106, reward_mean=0.470, reward_bound=0.229, batch=212 
9410: loss=0.115, reward_mean=0.410, reward_bound=0.282, batch=194 
9411: loss=0.112, reward_mean=0.450, reward_bound=0.200, batch=206 
9412: loss=0.115, reward_mean=0.410, reward_bound=0.206, batch=211 
9413: loss=0.119, reward_mean=0.500, reward_bound=0.229, batch=214 
9414: loss=0.114, reward_mean=0.550, reward_bound=0.254, batch=217 
9415: loss=0.116, reward_mean=0.520, reward_bound=0.282, batch=218 
9416: loss=0.116, reward_mean=0.440, reward_bound=0.314, batch=202 
9417: loss=0.116, reward_mean=0.460, reward_bound=0.213, batch=211 
9418: loss=0.113, reward_mean=0.450, reward_bound=0.229, batch=217 
9419: loss=0.112, reward_mean=0.460, reward_bound=0.254, batch=220 
9420: loss=0.115, reward_mean=0.440, reward_bound=0.282, batch=218 
9421: loss=0.120, reward_mean=0.500, reward_bound=0.349, batch=180 
9422: loss=0.119, reward_mean=0.550, reward_bound=0.109, batch=194 
9423: loss=0.117, reward_mean=0.540, reward_bound=0.204, batch=206 
9424: loss=0.121, reward_mean=0.450, reward_bound=0.206, batch=210 
9425: loss=0.123, reward_mean=0.430, reward_bound=0.222, batch=217 
9426: loss=0.119, reward_mean=0.470, reward_bound=0.249, batch=222 
9427: loss=0.125, reward_mean=0.470, reward_bound=0.254, batch=223 
9428: loss=0.128, reward_mean=0.400, reward_bound=0.282, batch=223 
9429: loss=0.129, reward_mean=0.500, reward_bound=0.314, batch=223 
9430: loss=0.130, reward_mean=0.470, reward_bound=0.311, batch=226 
9431: loss=0.128, reward_mean=0.460, reward_bound=0.349, batch=219 
9432: loss=0.128, reward_mean=0.480, reward_bound=0.314, batch=222 
9433: loss=0.127, reward_mean=0.510, reward_bound=0.349, batch=223 
9434: loss=0.132, reward_mean=0.510, reward_bound=0.387, batch=183 
9435: loss=0.125, reward_mean=0.480, reward_bound=0.130, batch=198 
9436: loss=0.123, reward_mean=0.520, reward_bound=0.167, batch=207 
9437: loss=0.122, reward_mean=0.420, reward_bound=0.185, batch=214 
9438: loss=0.124, reward_mean=0.380, reward_bound=0.229, batch=217 
9439: loss=0.126, reward_mean=0.420, reward_bound=0.254, batch=219 
9440: loss=0.125, reward_mean=0.470, reward_bound=0.229, batch=221 
9441: loss=0.126, reward_mean=0.450, reward_bound=0.282, batch=221 
9442: loss=0.130, reward_mean=0.380, reward_bound=0.314, batch=219 
9443: loss=0.130, reward_mean=0.460, reward_bound=0.265, batch=223 
9444: loss=0.127, reward_mean=0.390, reward_bound=0.314, batch=224 
9445: loss=0.125, reward_mean=0.470, reward_bound=0.349, batch=218 
9446: loss=0.125, reward_mean=0.430, reward_bound=0.257, batch=222 
9447: loss=0.126, reward_mean=0.470, reward_bound=0.302, batch=225 
9448: loss=0.126, reward_mean=0.410, reward_bound=0.349, batch=222 
9449: loss=0.125, reward_mean=0.560, reward_bound=0.324, batch=225 
9450: loss=0.126, reward_mean=0.410, reward_bound=0.314, batch=226 
9451: loss=0.128, reward_mean=0.440, reward_bound=0.387, batch=213 
9452: loss=0.130, reward_mean=0.530, reward_bound=0.271, batch=219 
9453: loss=0.128, reward_mean=0.380, reward_bound=0.282, batch=222 
9454: loss=0.127, reward_mean=0.520, reward_bound=0.349, batch=223 
9455: loss=0.127, reward_mean=0.550, reward_bound=0.387, batch=223 
9456: loss=0.130, reward_mean=0.530, reward_bound=0.372, batch=226 
9457: loss=0.129, reward_mean=0.430, reward_bound=0.387, batch=226 
9458: loss=0.129, reward_mean=0.420, reward_bound=0.314, batch=227 
9459: loss=0.129, reward_mean=0.430, reward_bound=0.401, batch=229 
9460: loss=0.129, reward_mean=0.420, reward_bound=0.405, batch=230 
9461: loss=0.132, reward_mean=0.430, reward_bound=0.430, batch=162 
9462: loss=0.119, reward_mean=0.420, reward_bound=0.067, batch=183 
9463: loss=0.125, reward_mean=0.440, reward_bound=0.109, batch=197 
9464: loss=0.125, reward_mean=0.510, reward_bound=0.167, batch=206 
9465: loss=0.128, reward_mean=0.490, reward_bound=0.206, batch=207 
9466: loss=0.124, reward_mean=0.430, reward_bound=0.224, batch=215 
9467: loss=0.123, reward_mean=0.390, reward_bound=0.229, batch=216 
9468: loss=0.123, reward_mean=0.550, reward_bound=0.254, batch=214 
9469: loss=0.123, reward_mean=0.450, reward_bound=0.273, batch=220 
9470: loss=0.125, reward_mean=0.400, reward_bound=0.282, batch=212 
9471: loss=0.126, reward_mean=0.410, reward_bound=0.263, batch=218 
9472: loss=0.123, reward_mean=0.540, reward_bound=0.314, batch=211 
9473: loss=0.124, reward_mean=0.440, reward_bound=0.282, batch=216 
9474: loss=0.123, reward_mean=0.490, reward_bound=0.254, batch=220 
9475: loss=0.129, reward_mean=0.430, reward_bound=0.349, batch=211 
9476: loss=0.125, reward_mean=0.490, reward_bound=0.185, batch=217 
9477: loss=0.125, reward_mean=0.500, reward_bound=0.206, batch=220 
9478: loss=0.126, reward_mean=0.400, reward_bound=0.222, batch=224 
9479: loss=0.127, reward_mean=0.430, reward_bound=0.229, batch=226 
9480: loss=0.123, reward_mean=0.460, reward_bound=0.314, batch=225 
9481: loss=0.127, reward_mean=0.530, reward_bound=0.349, batch=223 
9482: loss=0.128, reward_mean=0.480, reward_bound=0.387, batch=207 
9483: loss=0.127, reward_mean=0.460, reward_bound=0.206, batch=213 
9484: loss=0.127, reward_mean=0.410, reward_bound=0.229, batch=218 
9485: loss=0.131, reward_mean=0.430, reward_bound=0.257, batch=222 
9486: loss=0.127, reward_mean=0.510, reward_bound=0.314, batch=223 
9487: loss=0.126, reward_mean=0.450, reward_bound=0.349, batch=221 
9488: loss=0.126, reward_mean=0.410, reward_bound=0.387, batch=217 
9489: loss=0.125, reward_mean=0.420, reward_bound=0.335, batch=222 
9490: loss=0.127, reward_mean=0.470, reward_bound=0.360, batch=225 
9491: loss=0.125, reward_mean=0.480, reward_bound=0.387, batch=224 
9492: loss=0.124, reward_mean=0.530, reward_bound=0.339, batch=227 
9493: loss=0.132, reward_mean=0.470, reward_bound=0.430, batch=202 
9494: loss=0.133, reward_mean=0.490, reward_bound=0.254, batch=210 
9495: loss=0.133, reward_mean=0.450, reward_bound=0.254, batch=215 
9496: loss=0.129, reward_mean=0.510, reward_bound=0.314, batch=217 
9497: loss=0.127, reward_mean=0.500, reward_bound=0.249, batch=222 
9498: loss=0.127, reward_mean=0.460, reward_bound=0.314, batch=224 
9499: loss=0.129, reward_mean=0.420, reward_bound=0.349, batch=221 
9500: loss=0.128, reward_mean=0.460, reward_bound=0.349, batch=223 
9501: loss=0.128, reward_mean=0.440, reward_bound=0.349, batch=225 
9502: loss=0.131, reward_mean=0.420, reward_bound=0.387, batch=218 
9503: loss=0.131, reward_mean=0.500, reward_bound=0.282, batch=221 
9504: loss=0.131, reward_mean=0.530, reward_bound=0.349, batch=223 
9505: loss=0.130, reward_mean=0.470, reward_bound=0.301, batch=226 
9506: loss=0.129, reward_mean=0.440, reward_bound=0.368, batch=228 
9507: loss=0.128, reward_mean=0.560, reward_bound=0.387, batch=226 
9508: loss=0.133, reward_mean=0.460, reward_bound=0.430, batch=215 
9509: loss=0.133, reward_mean=0.440, reward_bound=0.234, batch=220 
9510: loss=0.132, reward_mean=0.510, reward_bound=0.296, batch=224 
9511: loss=0.133, reward_mean=0.540, reward_bound=0.345, batch=227 
9512: loss=0.133, reward_mean=0.480, reward_bound=0.349, batch=226 
9513: loss=0.133, reward_mean=0.410, reward_bound=0.331, batch=228 
9514: loss=0.134, reward_mean=0.500, reward_bound=0.387, batch=222 
9515: loss=0.134, reward_mean=0.510, reward_bound=0.349, batch=223 
9516: loss=0.132, reward_mean=0.470, reward_bound=0.301, batch=226 
9517: loss=0.132, reward_mean=0.560, reward_bound=0.349, batch=227 
9518: loss=0.132, reward_mean=0.490, reward_bound=0.387, batch=227 
9519: loss=0.131, reward_mean=0.530, reward_bound=0.430, batch=222 
9520: loss=0.131, reward_mean=0.550, reward_bound=0.445, batch=225 
9521: loss=0.131, reward_mean=0.510, reward_bound=0.387, batch=225 
9522: loss=0.130, reward_mean=0.500, reward_bound=0.396, batch=227 
9523: loss=0.133, reward_mean=0.470, reward_bound=0.469, batch=229 
9524: loss=0.133, reward_mean=0.480, reward_bound=0.360, batch=230 
9525: loss=0.132, reward_mean=0.500, reward_bound=0.464, batch=231 
9526: loss=0.132, reward_mean=0.510, reward_bound=0.387, batch=231 
9527: loss=0.132, reward_mean=0.410, reward_bound=0.387, batch=231 
9528: loss=0.132, reward_mean=0.460, reward_bound=0.387, batch=231 
9529: loss=0.131, reward_mean=0.460, reward_bound=0.478, batch=148 
9530: loss=0.110, reward_mean=0.400, reward_bound=0.039, batch=173 
9531: loss=0.106, reward_mean=0.380, reward_bound=0.042, batch=190 
9532: loss=0.115, reward_mean=0.460, reward_bound=0.072, batch=202 
9533: loss=0.121, reward_mean=0.450, reward_bound=0.109, batch=208 
9534: loss=0.125, reward_mean=0.400, reward_bound=0.123, batch=215 
9535: loss=0.123, reward_mean=0.410, reward_bound=0.150, batch=219 
9536: loss=0.122, reward_mean=0.380, reward_bound=0.174, batch=223 
9537: loss=0.116, reward_mean=0.540, reward_bound=0.206, batch=214 
9538: loss=0.119, reward_mean=0.470, reward_bound=0.229, batch=210 
9539: loss=0.120, reward_mean=0.470, reward_bound=0.254, batch=206 
9540: loss=0.121, reward_mean=0.370, reward_bound=0.282, batch=204 
9541: loss=0.124, reward_mean=0.520, reward_bound=0.314, batch=197 
9542: loss=0.116, reward_mean=0.450, reward_bound=0.147, batch=208 
9543: loss=0.119, reward_mean=0.400, reward_bound=0.169, batch=215 
9544: loss=0.117, reward_mean=0.420, reward_bound=0.210, batch=220 
9545: loss=0.116, reward_mean=0.470, reward_bound=0.254, batch=222 
9546: loss=0.116, reward_mean=0.590, reward_bound=0.263, batch=225 
9547: loss=0.118, reward_mean=0.410, reward_bound=0.282, batch=221 
9548: loss=0.118, reward_mean=0.490, reward_bound=0.229, batch=224 
9549: loss=0.121, reward_mean=0.470, reward_bound=0.311, batch=227 
9550: loss=0.125, reward_mean=0.410, reward_bound=0.314, batch=220 
9551: loss=0.126, reward_mean=0.510, reward_bound=0.349, batch=205 
9552: loss=0.124, reward_mean=0.440, reward_bound=0.206, batch=212 
9553: loss=0.124, reward_mean=0.390, reward_bound=0.236, batch=218 
9554: loss=0.121, reward_mean=0.480, reward_bound=0.254, batch=219 
9555: loss=0.123, reward_mean=0.460, reward_bound=0.282, batch=221 
9556: loss=0.124, reward_mean=0.470, reward_bound=0.314, batch=223 
9557: loss=0.123, reward_mean=0.390, reward_bound=0.349, batch=221 
9558: loss=0.124, reward_mean=0.450, reward_bound=0.349, batch=224 
9559: loss=0.120, reward_mean=0.560, reward_bound=0.387, batch=202 
9560: loss=0.124, reward_mean=0.450, reward_bound=0.282, batch=210 
9561: loss=0.122, reward_mean=0.460, reward_bound=0.254, batch=215 
9562: loss=0.120, reward_mean=0.510, reward_bound=0.254, batch=218 
9563: loss=0.120, reward_mean=0.520, reward_bound=0.314, batch=219 
9564: loss=0.118, reward_mean=0.500, reward_bound=0.309, batch=223 
9565: loss=0.120, reward_mean=0.420, reward_bound=0.349, batch=220 
9566: loss=0.120, reward_mean=0.460, reward_bound=0.347, batch=224 
9567: loss=0.121, reward_mean=0.520, reward_bound=0.384, batch=227 
9568: loss=0.120, reward_mean=0.470, reward_bound=0.387, batch=222 
9569: loss=0.120, reward_mean=0.410, reward_bound=0.229, batch=224 
9570: loss=0.121, reward_mean=0.410, reward_bound=0.282, batch=226 
9571: loss=0.120, reward_mean=0.470, reward_bound=0.368, batch=228 
9572: loss=0.120, reward_mean=0.420, reward_bound=0.349, batch=228 
9573: loss=0.119, reward_mean=0.470, reward_bound=0.387, batch=226 
9574: loss=0.118, reward_mean=0.450, reward_bound=0.390, batch=228 
9575: loss=0.117, reward_mean=0.420, reward_bound=0.392, batch=229 
9576: loss=0.122, reward_mean=0.460, reward_bound=0.430, batch=192 
9577: loss=0.121, reward_mean=0.430, reward_bound=0.150, batch=204 
9578: loss=0.122, reward_mean=0.500, reward_bound=0.185, batch=210 
9579: loss=0.116, reward_mean=0.420, reward_bound=0.229, batch=215 
9580: loss=0.117, reward_mean=0.450, reward_bound=0.254, batch=216 
9581: loss=0.117, reward_mean=0.550, reward_bound=0.282, batch=215 
9582: loss=0.117, reward_mean=0.480, reward_bound=0.314, batch=214 
9583: loss=0.116, reward_mean=0.550, reward_bound=0.254, batch=218 
9584: loss=0.118, reward_mean=0.490, reward_bound=0.349, batch=215 
9585: loss=0.118, reward_mean=0.470, reward_bound=0.266, batch=220 
9586: loss=0.117, reward_mean=0.500, reward_bound=0.296, batch=224 
9587: loss=0.120, reward_mean=0.520, reward_bound=0.314, batch=226 
9588: loss=0.117, reward_mean=0.410, reward_bound=0.349, batch=226 
9589: loss=0.117, reward_mean=0.500, reward_bound=0.314, batch=227 
9590: loss=0.115, reward_mean=0.540, reward_bound=0.342, batch=229 
9591: loss=0.116, reward_mean=0.400, reward_bound=0.387, batch=219 
9592: loss=0.114, reward_mean=0.540, reward_bound=0.314, batch=222 
9593: loss=0.114, reward_mean=0.450, reward_bound=0.324, batch=225 
9594: loss=0.119, reward_mean=0.370, reward_bound=0.349, batch=225 
9595: loss=0.117, reward_mean=0.430, reward_bound=0.387, batch=226 
9596: loss=0.120, reward_mean=0.410, reward_bound=0.409, batch=228 
9597: loss=0.120, reward_mean=0.500, reward_bound=0.387, batch=228 
9598: loss=0.124, reward_mean=0.470, reward_bound=0.392, batch=229 
9599: loss=0.125, reward_mean=0.490, reward_bound=0.405, batch=230 
9600: loss=0.126, reward_mean=0.550, reward_bound=0.418, batch=231 
9601: loss=0.119, reward_mean=0.450, reward_bound=0.430, batch=215 
9602: loss=0.118, reward_mean=0.460, reward_bound=0.216, batch=220 
9603: loss=0.119, reward_mean=0.450, reward_bound=0.338, batch=224 
9604: loss=0.119, reward_mean=0.450, reward_bound=0.311, batch=227 
9605: loss=0.118, reward_mean=0.480, reward_bound=0.314, batch=227 
9606: loss=0.122, reward_mean=0.360, reward_bound=0.349, batch=225 
9607: loss=0.124, reward_mean=0.470, reward_bound=0.329, batch=227 
9608: loss=0.120, reward_mean=0.550, reward_bound=0.387, batch=226 
9609: loss=0.119, reward_mean=0.450, reward_bound=0.298, batch=228 
9610: loss=0.119, reward_mean=0.480, reward_bound=0.357, batch=229 
9611: loss=0.118, reward_mean=0.530, reward_bound=0.405, batch=230 
9612: loss=0.120, reward_mean=0.430, reward_bound=0.430, batch=224 
9613: loss=0.122, reward_mean=0.560, reward_bound=0.280, batch=227 
9614: loss=0.122, reward_mean=0.460, reward_bound=0.422, batch=229 
9615: loss=0.122, reward_mean=0.440, reward_bound=0.430, batch=226 
9616: loss=0.121, reward_mean=0.500, reward_bound=0.282, batch=227 
9617: loss=0.122, reward_mean=0.460, reward_bound=0.349, batch=228 
9618: loss=0.121, reward_mean=0.440, reward_bound=0.392, batch=229 
9619: loss=0.121, reward_mean=0.470, reward_bound=0.430, batch=228 
9620: loss=0.120, reward_mean=0.480, reward_bound=0.289, batch=229 
9621: loss=0.122, reward_mean=0.510, reward_bound=0.430, batch=229 
9622: loss=0.121, reward_mean=0.470, reward_bound=0.381, batch=230 
9623: loss=0.122, reward_mean=0.460, reward_bound=0.430, batch=229 
9624: loss=0.121, reward_mean=0.530, reward_bound=0.405, batch=230 
9625: loss=0.121, reward_mean=0.410, reward_bound=0.464, batch=231 
9626: loss=0.121, reward_mean=0.530, reward_bound=0.430, batch=231 
9627: loss=0.121, reward_mean=0.480, reward_bound=0.387, batch=231 
9628: loss=0.126, reward_mean=0.500, reward_bound=0.478, batch=179 
9629: loss=0.123, reward_mean=0.480, reward_bound=0.229, batch=192 
9630: loss=0.118, reward_mean=0.440, reward_bound=0.098, batch=202 
9631: loss=0.129, reward_mean=0.620, reward_bound=0.229, batch=209 
9632: loss=0.128, reward_mean=0.470, reward_bound=0.239, batch=216 
9633: loss=0.127, reward_mean=0.560, reward_bound=0.254, batch=213 
9634: loss=0.124, reward_mean=0.420, reward_bound=0.211, batch=219 
9635: loss=0.129, reward_mean=0.440, reward_bound=0.282, batch=215 
9636: loss=0.131, reward_mean=0.430, reward_bound=0.314, batch=215 
9637: loss=0.128, reward_mean=0.410, reward_bound=0.206, batch=219 
9638: loss=0.127, reward_mean=0.530, reward_bound=0.349, batch=212 
9639: loss=0.124, reward_mean=0.520, reward_bound=0.282, batch=217 
9640: loss=0.126, reward_mean=0.530, reward_bound=0.342, batch=222 
9641: loss=0.125, reward_mean=0.490, reward_bound=0.349, batch=223 
9642: loss=0.125, reward_mean=0.470, reward_bound=0.301, batch=226 
9643: loss=0.126, reward_mean=0.480, reward_bound=0.331, batch=228 
9644: loss=0.127, reward_mean=0.520, reward_bound=0.387, batch=223 
9645: loss=0.125, reward_mean=0.500, reward_bound=0.413, batch=226 
9646: loss=0.125, reward_mean=0.500, reward_bound=0.349, batch=227 
9647: loss=0.127, reward_mean=0.460, reward_bound=0.430, batch=208 
9648: loss=0.125, reward_mean=0.540, reward_bound=0.254, batch=214 
9649: loss=0.124, reward_mean=0.480, reward_bound=0.308, batch=220 
9650: loss=0.122, reward_mean=0.500, reward_bound=0.314, batch=221 
9651: loss=0.123, reward_mean=0.470, reward_bound=0.282, batch=224 
9652: loss=0.129, reward_mean=0.530, reward_bound=0.349, batch=223 
9653: loss=0.131, reward_mean=0.510, reward_bound=0.387, batch=220 
9654: loss=0.128, reward_mean=0.430, reward_bound=0.180, batch=224 
9655: loss=0.132, reward_mean=0.470, reward_bound=0.349, batch=225 
9656: loss=0.133, reward_mean=0.360, reward_bound=0.387, batch=224 
9657: loss=0.132, reward_mean=0.540, reward_bound=0.345, batch=227 
9658: loss=0.132, reward_mean=0.450, reward_bound=0.387, batch=226 
9659: loss=0.132, reward_mean=0.550, reward_bound=0.430, batch=222 
9660: loss=0.131, reward_mean=0.430, reward_bound=0.360, batch=225 
9661: loss=0.131, reward_mean=0.530, reward_bound=0.387, batch=226 
9662: loss=0.130, reward_mean=0.520, reward_bound=0.409, batch=228 
9663: loss=0.130, reward_mean=0.500, reward_bound=0.392, batch=229 
9664: loss=0.131, reward_mean=0.550, reward_bound=0.430, batch=227 
9665: loss=0.130, reward_mean=0.520, reward_bound=0.380, batch=229 
9666: loss=0.130, reward_mean=0.410, reward_bound=0.430, batch=229 
9667: loss=0.130, reward_mean=0.490, reward_bound=0.450, batch=230 
9668: loss=0.131, reward_mean=0.560, reward_bound=0.451, batch=231 
9669: loss=0.129, reward_mean=0.460, reward_bound=0.478, batch=203 
9670: loss=0.132, reward_mean=0.470, reward_bound=0.282, batch=210 
9671: loss=0.130, reward_mean=0.510, reward_bound=0.314, batch=214 
9672: loss=0.126, reward_mean=0.500, reward_bound=0.185, batch=219 
9673: loss=0.129, reward_mean=0.520, reward_bound=0.328, batch=223 
9674: loss=0.133, reward_mean=0.480, reward_bound=0.349, batch=220 
9675: loss=0.134, reward_mean=0.480, reward_bound=0.349, batch=223 
9676: loss=0.132, reward_mean=0.500, reward_bound=0.358, batch=226 
9677: loss=0.132, reward_mean=0.470, reward_bound=0.387, batch=220 
9678: loss=0.132, reward_mean=0.430, reward_bound=0.338, batch=224 
9679: loss=0.131, reward_mean=0.460, reward_bound=0.349, batch=225 
9680: loss=0.131, reward_mean=0.370, reward_bound=0.349, batch=226 
9681: loss=0.131, reward_mean=0.530, reward_bound=0.316, batch=228 
9682: loss=0.132, reward_mean=0.410, reward_bound=0.430, batch=222 
9683: loss=0.130, reward_mean=0.350, reward_bound=0.236, batch=225 
9684: loss=0.131, reward_mean=0.420, reward_bound=0.289, batch=227 
9685: loss=0.133, reward_mean=0.410, reward_bound=0.349, batch=227 
9686: loss=0.130, reward_mean=0.440, reward_bound=0.387, batch=228 
9687: loss=0.131, reward_mean=0.430, reward_bound=0.430, batch=226 
9688: loss=0.131, reward_mean=0.480, reward_bound=0.390, batch=228 
9689: loss=0.132, reward_mean=0.390, reward_bound=0.430, batch=228 
9690: loss=0.132, reward_mean=0.510, reward_bound=0.435, batch=229 
9691: loss=0.131, reward_mean=0.490, reward_bound=0.405, batch=230 
9692: loss=0.129, reward_mean=0.460, reward_bound=0.478, batch=216 
9693: loss=0.128, reward_mean=0.560, reward_bound=0.349, batch=220 
9694: loss=0.129, reward_mean=0.470, reward_bound=0.338, batch=224 
9695: loss=0.130, reward_mean=0.400, reward_bound=0.349, batch=225 
9696: loss=0.132, reward_mean=0.560, reward_bound=0.396, batch=227 
9697: loss=0.132, reward_mean=0.510, reward_bound=0.314, batch=228 
9698: loss=0.132, reward_mean=0.440, reward_bound=0.317, batch=229 
9699: loss=0.132, reward_mean=0.480, reward_bound=0.430, batch=221 
9700: loss=0.132, reward_mean=0.470, reward_bound=0.430, batch=223 
9701: loss=0.131, reward_mean=0.430, reward_bound=0.387, batch=225 
9702: loss=0.130, reward_mean=0.480, reward_bound=0.356, batch=227 
9703: loss=0.130, reward_mean=0.510, reward_bound=0.387, batch=226 
9704: loss=0.131, reward_mean=0.540, reward_bound=0.351, batch=228 
9705: loss=0.132, reward_mean=0.510, reward_bound=0.430, batch=228 
9706: loss=0.132, reward_mean=0.480, reward_bound=0.264, batch=229 
9707: loss=0.131, reward_mean=0.460, reward_bound=0.349, batch=229 
9708: loss=0.133, reward_mean=0.490, reward_bound=0.387, batch=229 
9709: loss=0.133, reward_mean=0.510, reward_bound=0.430, batch=229 
9710: loss=0.133, reward_mean=0.620, reward_bound=0.380, batch=230 
9711: loss=0.133, reward_mean=0.530, reward_bound=0.387, batch=230 
9712: loss=0.130, reward_mean=0.430, reward_bound=0.478, batch=222 
9713: loss=0.129, reward_mean=0.450, reward_bound=0.349, batch=225 
9714: loss=0.130, reward_mean=0.480, reward_bound=0.387, batch=226 
9715: loss=0.130, reward_mean=0.460, reward_bound=0.430, batch=225 
9716: loss=0.131, reward_mean=0.410, reward_bound=0.365, batch=227 
9717: loss=0.131, reward_mean=0.500, reward_bound=0.380, batch=229 
9718: loss=0.131, reward_mean=0.510, reward_bound=0.364, batch=230 
9719: loss=0.131, reward_mean=0.380, reward_bound=0.387, batch=230 
9720: loss=0.130, reward_mean=0.500, reward_bound=0.430, batch=229 
9721: loss=0.129, reward_mean=0.460, reward_bound=0.478, batch=231 
9722: loss=0.129, reward_mean=0.460, reward_bound=0.349, batch=231 
9723: loss=0.130, reward_mean=0.350, reward_bound=0.478, batch=223 
9724: loss=0.128, reward_mean=0.460, reward_bound=0.372, batch=226 
9725: loss=0.128, reward_mean=0.510, reward_bound=0.368, batch=228 
9726: loss=0.128, reward_mean=0.420, reward_bound=0.387, batch=227 
9727: loss=0.127, reward_mean=0.450, reward_bound=0.277, batch=229 
9728: loss=0.127, reward_mean=0.450, reward_bound=0.349, batch=229 
9729: loss=0.131, reward_mean=0.450, reward_bound=0.430, batch=227 
9730: loss=0.130, reward_mean=0.450, reward_bound=0.380, batch=229 
9731: loss=0.133, reward_mean=0.400, reward_bound=0.450, batch=230 
9732: loss=0.132, reward_mean=0.500, reward_bound=0.464, batch=231 
9733: loss=0.131, reward_mean=0.510, reward_bound=0.478, batch=227 
9734: loss=0.132, reward_mean=0.540, reward_bound=0.469, batch=229 
9735: loss=0.131, reward_mean=0.470, reward_bound=0.478, batch=231 
9736: loss=0.131, reward_mean=0.430, reward_bound=0.478, batch=227 
9737: loss=0.131, reward_mean=0.520, reward_bound=0.430, batch=228 
9738: loss=0.132, reward_mean=0.510, reward_bound=0.478, batch=231 
9739: loss=0.132, reward_mean=0.510, reward_bound=0.387, batch=231 
9740: loss=0.132, reward_mean=0.400, reward_bound=0.478, batch=228 
9741: loss=0.133, reward_mean=0.410, reward_bound=0.484, batch=229 
9742: loss=0.133, reward_mean=0.470, reward_bound=0.445, batch=230 
9743: loss=0.132, reward_mean=0.360, reward_bound=0.488, batch=231 
9745: loss=0.064, reward_mean=0.450, reward_bound=0.000, batch=45 
9746: loss=0.061, reward_mean=0.500, reward_bound=0.000, batch=95 
9747: loss=0.062, reward_mean=0.450, reward_bound=0.000, batch=136 
9748: loss=0.068, reward_mean=0.450, reward_bound=0.003, batch=165 
9749: loss=0.080, reward_mean=0.520, reward_bound=0.010, batch=185 
9750: loss=0.079, reward_mean=0.470, reward_bound=0.023, batch=197 
9751: loss=0.084, reward_mean=0.470, reward_bound=0.042, batch=201 
9752: loss=0.086, reward_mean=0.450, reward_bound=0.052, batch=203 
9753: loss=0.086, reward_mean=0.480, reward_bound=0.065, batch=210 
9754: loss=0.094, reward_mean=0.460, reward_bound=0.080, batch=214 
9755: loss=0.094, reward_mean=0.540, reward_bound=0.089, batch=219 
9756: loss=0.099, reward_mean=0.510, reward_bound=0.109, batch=218 
9757: loss=0.101, reward_mean=0.440, reward_bound=0.122, batch=220 
9758: loss=0.100, reward_mean=0.500, reward_bound=0.135, batch=223 
9759: loss=0.105, reward_mean=0.420, reward_bound=0.150, batch=213 
9760: loss=0.100, reward_mean=0.490, reward_bound=0.167, batch=215 
9761: loss=0.103, reward_mean=0.540, reward_bound=0.185, batch=209 
9762: loss=0.108, reward_mean=0.440, reward_bound=0.206, batch=193 
9763: loss=0.110, reward_mean=0.550, reward_bound=0.167, batch=204 
9764: loss=0.109, reward_mean=0.440, reward_bound=0.206, batch=211 
9765: loss=0.107, reward_mean=0.520, reward_bound=0.229, batch=187 
9766: loss=0.107, reward_mean=0.460, reward_bound=0.206, batch=199 
9767: loss=0.107, reward_mean=0.470, reward_bound=0.185, batch=208 
9768: loss=0.106, reward_mean=0.530, reward_bound=0.169, batch=215 
9769: loss=0.108, reward_mean=0.500, reward_bound=0.229, batch=216 
9770: loss=0.107, reward_mean=0.520, reward_bound=0.241, batch=221 
9771: loss=0.105, reward_mean=0.460, reward_bound=0.254, batch=191 
9772: loss=0.107, reward_mean=0.450, reward_bound=0.089, batch=203 
9773: loss=0.107, reward_mean=0.440, reward_bound=0.130, batch=212 
9774: loss=0.107, reward_mean=0.530, reward_bound=0.191, batch=218 
9775: loss=0.107, reward_mean=0.480, reward_bound=0.229, batch=221 
9776: loss=0.115, reward_mean=0.500, reward_bound=0.282, batch=181 
9777: loss=0.115, reward_mean=0.490, reward_bound=0.098, batch=196 
9778: loss=0.110, reward_mean=0.440, reward_bound=0.115, batch=207 
9779: loss=0.112, reward_mean=0.470, reward_bound=0.150, batch=212 
9780: loss=0.110, reward_mean=0.520, reward_bound=0.167, batch=217 
9781: loss=0.111, reward_mean=0.430, reward_bound=0.229, batch=218 
9782: loss=0.113, reward_mean=0.520, reward_bound=0.254, batch=214 
9783: loss=0.116, reward_mean=0.480, reward_bound=0.282, batch=211 
9784: loss=0.114, reward_mean=0.400, reward_bound=0.229, batch=217 
9785: loss=0.114, reward_mean=0.530, reward_bound=0.308, batch=222 
9786: loss=0.117, reward_mean=0.580, reward_bound=0.314, batch=177 
9787: loss=0.119, reward_mean=0.580, reward_bound=0.245, batch=194 
9788: loss=0.119, reward_mean=0.490, reward_bound=0.167, batch=205 
9789: loss=0.116, reward_mean=0.400, reward_bound=0.185, batch=212 
9790: loss=0.121, reward_mean=0.470, reward_bound=0.213, batch=218 
9791: loss=0.120, reward_mean=0.420, reward_bound=0.187, batch=222 
9792: loss=0.117, reward_mean=0.470, reward_bound=0.236, batch=225 
9793: loss=0.117, reward_mean=0.470, reward_bound=0.254, batch=222 
9794: loss=0.118, reward_mean=0.570, reward_bound=0.282, batch=220 
9795: loss=0.118, reward_mean=0.480, reward_bound=0.247, batch=224 
9796: loss=0.121, reward_mean=0.490, reward_bound=0.314, batch=211 
9797: loss=0.120, reward_mean=0.400, reward_bound=0.206, batch=217 
9798: loss=0.119, reward_mean=0.490, reward_bound=0.254, batch=220 
9799: loss=0.120, reward_mean=0.540, reward_bound=0.282, batch=221 
9800: loss=0.118, reward_mean=0.510, reward_bound=0.314, batch=224 
9801: loss=0.121, reward_mean=0.530, reward_bound=0.204, batch=227 
9802: loss=0.117, reward_mean=0.400, reward_bound=0.314, batch=228 
9803: loss=0.122, reward_mean=0.500, reward_bound=0.349, batch=171 
9804: loss=0.118, reward_mean=0.480, reward_bound=0.098, batch=188 
9805: loss=0.113, reward_mean=0.400, reward_bound=0.091, batch=201 
9806: loss=0.113, reward_mean=0.470, reward_bound=0.135, batch=210 
9807: loss=0.115, reward_mean=0.470, reward_bound=0.167, batch=215 
9808: loss=0.118, reward_mean=0.370, reward_bound=0.185, batch=215 
9809: loss=0.119, reward_mean=0.440, reward_bound=0.206, batch=214 
9810: loss=0.119, reward_mean=0.430, reward_bound=0.252, batch=220 
9811: loss=0.118, reward_mean=0.480, reward_bound=0.247, batch=224 
9812: loss=0.116, reward_mean=0.540, reward_bound=0.254, batch=220 
9813: loss=0.116, reward_mean=0.490, reward_bound=0.282, batch=216 
9814: loss=0.114, reward_mean=0.410, reward_bound=0.206, batch=220 
9815: loss=0.116, reward_mean=0.610, reward_bound=0.282, batch=223 
9816: loss=0.118, reward_mean=0.550, reward_bound=0.314, batch=217 
9817: loss=0.117, reward_mean=0.510, reward_bound=0.342, batch=222 
9818: loss=0.117, reward_mean=0.490, reward_bound=0.302, batch=225 
9819: loss=0.119, reward_mean=0.460, reward_bound=0.349, batch=211 
9820: loss=0.119, reward_mean=0.490, reward_bound=0.185, batch=217 
9821: loss=0.120, reward_mean=0.490, reward_bound=0.254, batch=219 
9822: loss=0.121, reward_mean=0.430, reward_bound=0.314, batch=221 
9823: loss=0.120, reward_mean=0.450, reward_bound=0.254, batch=222 
9824: loss=0.121, reward_mean=0.490, reward_bound=0.349, batch=224 
9825: loss=0.121, reward_mean=0.400, reward_bound=0.384, batch=227 
9826: loss=0.120, reward_mean=0.470, reward_bound=0.387, batch=149 
9827: loss=0.114, reward_mean=0.550, reward_bound=0.067, batch=174 
9828: loss=0.117, reward_mean=0.490, reward_bound=0.109, batch=191 
9829: loss=0.115, reward_mean=0.490, reward_bound=0.122, batch=200 
9830: loss=0.111, reward_mean=0.470, reward_bound=0.146, batch=210 
9831: loss=0.110, reward_mean=0.560, reward_bound=0.150, batch=213 
9832: loss=0.110, reward_mean=0.470, reward_bound=0.185, batch=217 
9833: loss=0.111, reward_mean=0.600, reward_bound=0.229, batch=211 
9834: loss=0.113, reward_mean=0.500, reward_bound=0.254, batch=209 
9835: loss=0.111, reward_mean=0.400, reward_bound=0.141, batch=216 
9836: loss=0.112, reward_mean=0.440, reward_bound=0.229, batch=219 
9837: loss=0.116, reward_mean=0.470, reward_bound=0.282, batch=210 
9838: loss=0.117, reward_mean=0.440, reward_bound=0.210, batch=217 
9839: loss=0.116, reward_mean=0.500, reward_bound=0.229, batch=221 
9840: loss=0.113, reward_mean=0.430, reward_bound=0.282, batch=222 
9841: loss=0.116, reward_mean=0.540, reward_bound=0.314, batch=207 
9842: loss=0.114, reward_mean=0.430, reward_bound=0.198, batch=215 
9843: loss=0.118, reward_mean=0.480, reward_bound=0.254, batch=217 
9844: loss=0.117, reward_mean=0.510, reward_bound=0.314, batch=220 
9845: loss=0.117, reward_mean=0.420, reward_bound=0.349, batch=209 
9846: loss=0.115, reward_mean=0.460, reward_bound=0.229, batch=215 
9847: loss=0.116, reward_mean=0.510, reward_bound=0.282, batch=218 
9848: loss=0.119, reward_mean=0.430, reward_bound=0.349, batch=220 
9849: loss=0.117, reward_mean=0.470, reward_bound=0.274, batch=224 
9850: loss=0.119, reward_mean=0.450, reward_bound=0.314, batch=225 
9851: loss=0.118, reward_mean=0.390, reward_bound=0.349, batch=224 
9852: loss=0.117, reward_mean=0.480, reward_bound=0.345, batch=227 
9853: loss=0.117, reward_mean=0.490, reward_bound=0.342, batch=229 
9854: loss=0.116, reward_mean=0.530, reward_bound=0.364, batch=230 
9855: loss=0.117, reward_mean=0.440, reward_bound=0.387, batch=204 
9856: loss=0.117, reward_mean=0.580, reward_bound=0.282, batch=209 
9857: loss=0.116, reward_mean=0.480, reward_bound=0.250, batch=216 
9858: loss=0.114, reward_mean=0.430, reward_bound=0.282, batch=219 
9859: loss=0.116, reward_mean=0.480, reward_bound=0.349, batch=218 
9860: loss=0.115, reward_mean=0.510, reward_bound=0.387, batch=217 
9861: loss=0.114, reward_mean=0.520, reward_bound=0.277, batch=222 
9862: loss=0.114, reward_mean=0.440, reward_bound=0.282, batch=222 
9863: loss=0.113, reward_mean=0.520, reward_bound=0.254, batch=224 
9864: loss=0.113, reward_mean=0.470, reward_bound=0.311, batch=227 
9865: loss=0.115, reward_mean=0.560, reward_bound=0.314, batch=227 
9866: loss=0.114, reward_mean=0.560, reward_bound=0.349, batch=228 
9867: loss=0.113, reward_mean=0.440, reward_bound=0.387, batch=225 
9868: loss=0.113, reward_mean=0.440, reward_bound=0.329, batch=227 
9869: loss=0.113, reward_mean=0.610, reward_bound=0.422, batch=229 
9870: loss=0.115, reward_mean=0.380, reward_bound=0.430, batch=118 
9871: loss=0.094, reward_mean=0.490, reward_bound=0.011, batch=152 
9872: loss=0.085, reward_mean=0.540, reward_bound=0.017, batch=176 
9873: loss=0.090, reward_mean=0.480, reward_bound=0.047, batch=191 
9874: loss=0.093, reward_mean=0.480, reward_bound=0.089, batch=202 
9875: loss=0.098, reward_mean=0.390, reward_bound=0.109, batch=204 
9876: loss=0.103, reward_mean=0.550, reward_bound=0.150, batch=207 
9877: loss=0.103, reward_mean=0.480, reward_bound=0.185, batch=205 
9878: loss=0.102, reward_mean=0.430, reward_bound=0.185, batch=212 
9879: loss=0.100, reward_mean=0.430, reward_bound=0.206, batch=221 
9880: loss=0.106, reward_mean=0.530, reward_bound=0.206, batch=217 
9881: loss=0.106, reward_mean=0.580, reward_bound=0.229, batch=209 
9882: loss=0.108, reward_mean=0.450, reward_bound=0.254, batch=204 
9883: loss=0.114, reward_mean=0.630, reward_bound=0.282, batch=202 
9884: loss=0.112, reward_mean=0.440, reward_bound=0.191, batch=211 
9885: loss=0.109, reward_mean=0.410, reward_bound=0.254, batch=212 
9886: loss=0.107, reward_mean=0.490, reward_bound=0.254, batch=216 
9887: loss=0.110, reward_mean=0.520, reward_bound=0.282, batch=220 
9888: loss=0.100, reward_mean=0.510, reward_bound=0.314, batch=196 
9889: loss=0.100, reward_mean=0.510, reward_bound=0.314, batch=206 
9890: loss=0.097, reward_mean=0.460, reward_bound=0.254, batch=213 
9891: loss=0.095, reward_mean=0.540, reward_bound=0.206, batch=218 
9892: loss=0.099, reward_mean=0.520, reward_bound=0.282, batch=221 
9893: loss=0.098, reward_mean=0.450, reward_bound=0.282, batch=224 
9894: loss=0.098, reward_mean=0.520, reward_bound=0.314, batch=223 
9895: loss=0.099, reward_mean=0.520, reward_bound=0.349, batch=200 
9896: loss=0.097, reward_mean=0.550, reward_bound=0.200, batch=210 
9897: loss=0.095, reward_mean=0.570, reward_bound=0.247, batch=217 
9898: loss=0.099, reward_mean=0.500, reward_bound=0.308, batch=222 
9899: loss=0.103, reward_mean=0.470, reward_bound=0.314, batch=222 
9900: loss=0.102, reward_mean=0.530, reward_bound=0.314, batch=224 
9901: loss=0.102, reward_mean=0.580, reward_bound=0.342, batch=227 
9902: loss=0.100, reward_mean=0.480, reward_bound=0.349, batch=222 
9903: loss=0.099, reward_mean=0.430, reward_bound=0.282, batch=224 
9904: loss=0.100, reward_mean=0.460, reward_bound=0.345, batch=227 
9905: loss=0.100, reward_mean=0.540, reward_bound=0.282, batch=228 
9906: loss=0.099, reward_mean=0.430, reward_bound=0.349, batch=227 
9907: loss=0.099, reward_mean=0.530, reward_bound=0.349, batch=228 
9908: loss=0.102, reward_mean=0.460, reward_bound=0.387, batch=193 
9909: loss=0.102, reward_mean=0.450, reward_bound=0.122, batch=204 
9910: loss=0.103, reward_mean=0.460, reward_bound=0.167, batch=212 
9911: loss=0.101, reward_mean=0.410, reward_bound=0.206, batch=219 
9912: loss=0.102, reward_mean=0.510, reward_bound=0.254, batch=219 
9913: loss=0.101, reward_mean=0.460, reward_bound=0.282, batch=220 
9914: loss=0.101, reward_mean=0.500, reward_bound=0.282, batch=222 
9915: loss=0.103, reward_mean=0.530, reward_bound=0.314, batch=222 
9916: loss=0.103, reward_mean=0.450, reward_bound=0.349, batch=221 
9917: loss=0.101, reward_mean=0.480, reward_bound=0.387, batch=218 
9918: loss=0.099, reward_mean=0.560, reward_bound=0.317, batch=222 
9919: loss=0.101, reward_mean=0.480, reward_bound=0.349, batch=224 
9920: loss=0.101, reward_mean=0.470, reward_bound=0.308, batch=227 
9921: loss=0.100, reward_mean=0.470, reward_bound=0.380, batch=229 
9922: loss=0.099, reward_mean=0.440, reward_bound=0.387, batch=224 
9923: loss=0.099, reward_mean=0.410, reward_bound=0.311, batch=227 
9924: loss=0.098, reward_mean=0.460, reward_bound=0.414, batch=229 
9925: loss=0.097, reward_mean=0.410, reward_bound=0.364, batch=230 
9926: loss=0.109, reward_mean=0.500, reward_bound=0.430, batch=181 
9927: loss=0.109, reward_mean=0.500, reward_bound=0.122, batch=196 
9928: loss=0.103, reward_mean=0.440, reward_bound=0.150, batch=205 
9929: loss=0.107, reward_mean=0.440, reward_bound=0.170, batch=213 
9930: loss=0.105, reward_mean=0.480, reward_bound=0.206, batch=217 
9931: loss=0.106, reward_mean=0.390, reward_bound=0.206, batch=221 
9932: loss=0.104, reward_mean=0.450, reward_bound=0.254, batch=217 
9933: loss=0.104, reward_mean=0.520, reward_bound=0.282, batch=215 
9934: loss=0.104, reward_mean=0.570, reward_bound=0.189, batch=220 
9935: loss=0.103, reward_mean=0.420, reward_bound=0.247, batch=224 
9936: loss=0.104, reward_mean=0.530, reward_bound=0.254, batch=226 
9937: loss=0.104, reward_mean=0.420, reward_bound=0.282, batch=227 
9938: loss=0.103, reward_mean=0.460, reward_bound=0.314, batch=218 
9939: loss=0.103, reward_mean=0.510, reward_bound=0.282, batch=221 
9940: loss=0.102, reward_mean=0.500, reward_bound=0.314, batch=224 
9941: loss=0.101, reward_mean=0.420, reward_bound=0.314, batch=225 
9942: loss=0.106, reward_mean=0.540, reward_bound=0.349, batch=208 
9943: loss=0.104, reward_mean=0.460, reward_bound=0.211, batch=215 
9944: loss=0.105, reward_mean=0.480, reward_bound=0.260, batch=220 
9945: loss=0.105, reward_mean=0.540, reward_bound=0.282, batch=220 
9946: loss=0.106, reward_mean=0.520, reward_bound=0.296, batch=224 
9947: loss=0.108, reward_mean=0.510, reward_bound=0.311, batch=227 
9948: loss=0.106, reward_mean=0.500, reward_bound=0.314, batch=226 
9949: loss=0.106, reward_mean=0.590, reward_bound=0.349, batch=226 
9950: loss=0.107, reward_mean=0.530, reward_bound=0.387, batch=216 
9951: loss=0.107, reward_mean=0.520, reward_bound=0.335, batch=221 
9952: loss=0.107, reward_mean=0.490, reward_bound=0.387, batch=220 
9953: loss=0.113, reward_mean=0.430, reward_bound=0.430, batch=202 
9954: loss=0.106, reward_mean=0.440, reward_bound=0.206, batch=212 
9955: loss=0.110, reward_mean=0.500, reward_bound=0.292, batch=218 
9956: loss=0.110, reward_mean=0.510, reward_bound=0.282, batch=221 
9957: loss=0.110, reward_mean=0.520, reward_bound=0.314, batch=221 
9958: loss=0.110, reward_mean=0.410, reward_bound=0.254, batch=223 
9959: loss=0.111, reward_mean=0.450, reward_bound=0.301, batch=226 
9960: loss=0.116, reward_mean=0.470, reward_bound=0.349, batch=226 
9961: loss=0.112, reward_mean=0.470, reward_bound=0.387, batch=221 
9962: loss=0.111, reward_mean=0.570, reward_bound=0.430, batch=219 
9963: loss=0.113, reward_mean=0.490, reward_bound=0.328, batch=223 
9964: loss=0.113, reward_mean=0.520, reward_bound=0.398, batch=226 
9965: loss=0.113, reward_mean=0.480, reward_bound=0.430, batch=225 
9966: loss=0.113, reward_mean=0.500, reward_bound=0.375, batch=227 
9967: loss=0.112, reward_mean=0.480, reward_bound=0.373, batch=229 
9968: loss=0.113, reward_mean=0.440, reward_bound=0.343, batch=230 
9969: loss=0.112, reward_mean=0.540, reward_bound=0.430, batch=230 
9970: loss=0.112, reward_mean=0.430, reward_bound=0.464, batch=231 
9971: loss=0.112, reward_mean=0.430, reward_bound=0.430, batch=231 
9972: loss=0.127, reward_mean=0.520, reward_bound=0.478, batch=96 
9973: loss=0.092, reward_mean=0.610, reward_bound=0.013, batch=137 
9974: loss=0.099, reward_mean=0.500, reward_bound=0.025, batch=164 
9975: loss=0.097, reward_mean=0.510, reward_bound=0.038, batch=183 
9976: loss=0.099, reward_mean=0.520, reward_bound=0.065, batch=195 
9977: loss=0.100, reward_mean=0.560, reward_bound=0.089, batch=210 
9978: loss=0.107, reward_mean=0.480, reward_bound=0.109, batch=215 
9979: loss=0.108, reward_mean=0.520, reward_bound=0.135, batch=214 
9980: loss=0.112, reward_mean=0.440, reward_bound=0.167, batch=204 
9981: loss=0.115, reward_mean=0.500, reward_bound=0.185, batch=201 
9982: loss=0.116, reward_mean=0.360, reward_bound=0.206, batch=195 
9983: loss=0.115, reward_mean=0.480, reward_bound=0.206, batch=205 
9984: loss=0.112, reward_mean=0.470, reward_bound=0.185, batch=212 
9985: loss=0.119, reward_mean=0.520, reward_bound=0.229, batch=211 
9986: loss=0.120, reward_mean=0.450, reward_bound=0.206, batch=217 
9987: loss=0.124, reward_mean=0.490, reward_bound=0.254, batch=203 
9988: loss=0.126, reward_mean=0.520, reward_bound=0.220, batch=212 
9989: loss=0.132, reward_mean=0.500, reward_bound=0.282, batch=198 
9990: loss=0.132, reward_mean=0.460, reward_bound=0.282, batch=205 
9991: loss=0.130, reward_mean=0.430, reward_bound=0.210, batch=213 
9992: loss=0.127, reward_mean=0.440, reward_bound=0.271, batch=219 
9993: loss=0.127, reward_mean=0.480, reward_bound=0.282, batch=218 
9994: loss=0.128, reward_mean=0.460, reward_bound=0.257, batch=222 
9995: loss=0.127, reward_mean=0.480, reward_bound=0.245, batch=225 
9996: loss=0.128, reward_mean=0.520, reward_bound=0.314, batch=199 
9997: loss=0.128, reward_mean=0.520, reward_bound=0.194, batch=209 
9998: loss=0.124, reward_mean=0.500, reward_bound=0.206, batch=215 
9999: loss=0.126, reward_mean=0.530, reward_bound=0.282, batch=217 
10000: loss=0.129, reward_mean=0.460, reward_bound=0.314, batch=215 
10001: loss=0.133, reward_mean=0.470, reward_bound=0.349, batch=184 
10002: loss=0.129, reward_mean=0.520, reward_bound=0.204, batch=199 
10003: loss=0.134, reward_mean=0.480, reward_bound=0.206, batch=208 
10004: loss=0.133, reward_mean=0.360, reward_bound=0.229, batch=212 
10005: loss=0.131, reward_mean=0.490, reward_bound=0.213, batch=218 
10006: loss=0.132, reward_mean=0.470, reward_bound=0.229, batch=218 
10007: loss=0.132, reward_mean=0.480, reward_bound=0.254, batch=221 
10008: loss=0.132, reward_mean=0.490, reward_bound=0.282, batch=224 
10009: loss=0.133, reward_mean=0.470, reward_bound=0.314, batch=225 
10010: loss=0.129, reward_mean=0.400, reward_bound=0.349, batch=217 
10011: loss=0.129, reward_mean=0.460, reward_bound=0.308, batch=222 
10012: loss=0.129, reward_mean=0.540, reward_bound=0.314, batch=224 
10013: loss=0.128, reward_mean=0.520, reward_bound=0.349, batch=225 
10014: loss=0.128, reward_mean=0.550, reward_bound=0.282, batch=226 
10015: loss=0.127, reward_mean=0.410, reward_bound=0.368, batch=228 
10016: loss=0.127, reward_mean=0.450, reward_bound=0.353, batch=229 
10017: loss=0.124, reward_mean=0.420, reward_bound=0.387, batch=184 
10018: loss=0.121, reward_mean=0.490, reward_bound=0.119, batch=199 
10019: loss=0.120, reward_mean=0.470, reward_bound=0.122, batch=208 
10020: loss=0.119, reward_mean=0.520, reward_bound=0.150, batch=214 
10021: loss=0.120, reward_mean=0.460, reward_bound=0.183, batch=220 
10022: loss=0.121, reward_mean=0.490, reward_bound=0.185, batch=222 
10023: loss=0.120, reward_mean=0.600, reward_bound=0.229, batch=223 
10024: loss=0.123, reward_mean=0.500, reward_bound=0.254, batch=223 
10025: loss=0.124, reward_mean=0.450, reward_bound=0.282, batch=220 
10026: loss=0.123, reward_mean=0.520, reward_bound=0.282, batch=222 
10027: loss=0.123, reward_mean=0.590, reward_bound=0.314, batch=221 
10028: loss=0.123, reward_mean=0.520, reward_bound=0.349, batch=214 
10029: loss=0.122, reward_mean=0.400, reward_bound=0.282, batch=219 
10030: loss=0.122, reward_mean=0.430, reward_bound=0.265, batch=223 
10031: loss=0.122, reward_mean=0.460, reward_bound=0.314, batch=224 
10032: loss=0.123, reward_mean=0.410, reward_bound=0.349, batch=223 
10033: loss=0.122, reward_mean=0.450, reward_bound=0.349, batch=225 
10034: loss=0.122, reward_mean=0.390, reward_bound=0.387, batch=212 
10035: loss=0.122, reward_mean=0.460, reward_bound=0.292, batch=218 
10036: loss=0.126, reward_mean=0.410, reward_bound=0.286, batch=222 
10037: loss=0.125, reward_mean=0.480, reward_bound=0.314, batch=223 
10038: loss=0.126, reward_mean=0.470, reward_bound=0.335, batch=226 
10039: loss=0.127, reward_mean=0.510, reward_bound=0.368, batch=228 
10040: loss=0.127, reward_mean=0.500, reward_bound=0.321, batch=229 
10041: loss=0.126, reward_mean=0.560, reward_bound=0.387, batch=226 
10042: loss=0.127, reward_mean=0.570, reward_bound=0.368, batch=228 
10043: loss=0.127, reward_mean=0.420, reward_bound=0.353, batch=229 
10044: loss=0.126, reward_mean=0.460, reward_bound=0.405, batch=230 
10045: loss=0.132, reward_mean=0.440, reward_bound=0.430, batch=161 
10046: loss=0.125, reward_mean=0.520, reward_bound=0.122, batch=182 
10047: loss=0.119, reward_mean=0.410, reward_bound=0.126, batch=197 
10048: loss=0.120, reward_mean=0.490, reward_bound=0.167, batch=206 
10049: loss=0.127, reward_mean=0.580, reward_bound=0.185, batch=211 
10050: loss=0.124, reward_mean=0.460, reward_bound=0.229, batch=209 
10051: loss=0.124, reward_mean=0.550, reward_bound=0.239, batch=216 
10052: loss=0.132, reward_mean=0.410, reward_bound=0.254, batch=212 
10053: loss=0.131, reward_mean=0.440, reward_bound=0.236, batch=218 
10054: loss=0.130, reward_mean=0.490, reward_bound=0.257, batch=222 
10055: loss=0.129, reward_mean=0.460, reward_bound=0.282, batch=217 
10056: loss=0.131, reward_mean=0.460, reward_bound=0.314, batch=212 
10057: loss=0.132, reward_mean=0.490, reward_bound=0.349, batch=198 
10058: loss=0.130, reward_mean=0.540, reward_bound=0.206, batch=206 
10059: loss=0.129, reward_mean=0.460, reward_bound=0.229, batch=212 
10060: loss=0.129, reward_mean=0.490, reward_bound=0.213, batch=218 
10061: loss=0.131, reward_mean=0.480, reward_bound=0.254, batch=221 
10062: loss=0.132, reward_mean=0.390, reward_bound=0.282, batch=224 
10063: loss=0.135, reward_mean=0.550, reward_bound=0.314, batch=223 
10064: loss=0.136, reward_mean=0.570, reward_bound=0.349, batch=219 
10065: loss=0.135, reward_mean=0.460, reward_bound=0.364, batch=223 
10066: loss=0.134, reward_mean=0.590, reward_bound=0.372, batch=226 
10067: loss=0.137, reward_mean=0.450, reward_bound=0.387, batch=207 
10068: loss=0.138, reward_mean=0.490, reward_bound=0.206, batch=214 
10069: loss=0.139, reward_mean=0.500, reward_bound=0.229, batch=216 
10070: loss=0.138, reward_mean=0.500, reward_bound=0.298, batch=221 
10071: loss=0.135, reward_mean=0.440, reward_bound=0.314, batch=218 
10072: loss=0.136, reward_mean=0.480, reward_bound=0.317, batch=222 
10073: loss=0.137, reward_mean=0.520, reward_bound=0.349, batch=222 
10074: loss=0.139, reward_mean=0.460, reward_bound=0.314, batch=224 
10075: loss=0.136, reward_mean=0.470, reward_bound=0.387, batch=221 
10076: loss=0.136, reward_mean=0.470, reward_bound=0.430, batch=199 
10077: loss=0.137, reward_mean=0.530, reward_bound=0.185, batch=207 
10078: loss=0.132, reward_mean=0.470, reward_bound=0.224, batch=215 
10079: loss=0.130, reward_mean=0.480, reward_bound=0.282, batch=215 
10080: loss=0.132, reward_mean=0.500, reward_bound=0.349, batch=215 
10081: loss=0.131, reward_mean=0.470, reward_bound=0.282, batch=218 
10082: loss=0.131, reward_mean=0.490, reward_bound=0.349, batch=220 
10083: loss=0.130, reward_mean=0.420, reward_bound=0.274, batch=224 
10084: loss=0.130, reward_mean=0.480, reward_bound=0.345, batch=227 
10085: loss=0.130, reward_mean=0.510, reward_bound=0.380, batch=229 
10086: loss=0.134, reward_mean=0.540, reward_bound=0.387, batch=220 
10087: loss=0.134, reward_mean=0.490, reward_bound=0.338, batch=224 
10088: loss=0.134, reward_mean=0.420, reward_bound=0.430, batch=213 
10089: loss=0.130, reward_mean=0.480, reward_bound=0.211, batch=219 
10090: loss=0.138, reward_mean=0.430, reward_bound=0.295, batch=223 
10091: loss=0.140, reward_mean=0.520, reward_bound=0.349, batch=221 
10092: loss=0.140, reward_mean=0.480, reward_bound=0.314, batch=224 
10093: loss=0.139, reward_mean=0.500, reward_bound=0.229, batch=226 
10094: loss=0.139, reward_mean=0.500, reward_bound=0.349, batch=226 
10095: loss=0.137, reward_mean=0.470, reward_bound=0.351, batch=228 
10096: loss=0.137, reward_mean=0.520, reward_bound=0.353, batch=229 
10097: loss=0.139, reward_mean=0.540, reward_bound=0.387, batch=223 
10098: loss=0.138, reward_mean=0.530, reward_bound=0.372, batch=226 
10099: loss=0.140, reward_mean=0.470, reward_bound=0.387, batch=226 
10100: loss=0.139, reward_mean=0.490, reward_bound=0.430, batch=223 
10101: loss=0.138, reward_mean=0.430, reward_bound=0.371, batch=226 
10102: loss=0.138, reward_mean=0.480, reward_bound=0.409, batch=228 
10103: loss=0.138, reward_mean=0.510, reward_bound=0.430, batch=228 
10104: loss=0.138, reward_mean=0.550, reward_bound=0.397, batch=229 
10105: loss=0.138, reward_mean=0.490, reward_bound=0.478, batch=231 
10106: loss=0.138, reward_mean=0.500, reward_bound=0.387, batch=231 
10107: loss=0.134, reward_mean=0.510, reward_bound=0.478, batch=165 
10108: loss=0.130, reward_mean=0.460, reward_bound=0.124, batch=185 
10109: loss=0.131, reward_mean=0.480, reward_bound=0.138, batch=199 
10110: loss=0.127, reward_mean=0.480, reward_bound=0.150, batch=208 
10111: loss=0.128, reward_mean=0.510, reward_bound=0.185, batch=211 
10112: loss=0.126, reward_mean=0.460, reward_bound=0.206, batch=211 
10113: loss=0.124, reward_mean=0.480, reward_bound=0.229, batch=211 
10114: loss=0.127, reward_mean=0.450, reward_bound=0.254, batch=215 
10115: loss=0.124, reward_mean=0.530, reward_bound=0.210, batch=220 
10116: loss=0.126, reward_mean=0.420, reward_bound=0.274, batch=224 
10117: loss=0.127, reward_mean=0.400, reward_bound=0.282, batch=213 
10118: loss=0.127, reward_mean=0.480, reward_bound=0.220, batch=219 
10119: loss=0.125, reward_mean=0.450, reward_bound=0.254, batch=221 
10120: loss=0.129, reward_mean=0.500, reward_bound=0.314, batch=210 
10121: loss=0.127, reward_mean=0.490, reward_bound=0.247, batch=217 
10122: loss=0.127, reward_mean=0.440, reward_bound=0.342, batch=222 
10123: loss=0.129, reward_mean=0.480, reward_bound=0.254, batch=224 
10124: loss=0.128, reward_mean=0.420, reward_bound=0.342, batch=227 
10125: loss=0.132, reward_mean=0.430, reward_bound=0.349, batch=207 
10126: loss=0.128, reward_mean=0.490, reward_bound=0.224, batch=215 
10127: loss=0.131, reward_mean=0.420, reward_bound=0.254, batch=217 
10128: loss=0.130, reward_mean=0.440, reward_bound=0.282, batch=219 
10129: loss=0.129, reward_mean=0.510, reward_bound=0.328, batch=223 
10130: loss=0.132, reward_mean=0.470, reward_bound=0.349, batch=222 
10131: loss=0.132, reward_mean=0.430, reward_bound=0.314, batch=223 
10132: loss=0.131, reward_mean=0.490, reward_bound=0.322, batch=226 
10133: loss=0.135, reward_mean=0.390, reward_bound=0.298, batch=228 
10134: loss=0.131, reward_mean=0.500, reward_bound=0.349, batch=227 
10135: loss=0.131, reward_mean=0.530, reward_bound=0.387, batch=212 
10136: loss=0.128, reward_mean=0.430, reward_bound=0.213, batch=218 
10137: loss=0.129, reward_mean=0.450, reward_bound=0.286, batch=222 
10138: loss=0.128, reward_mean=0.590, reward_bound=0.292, batch=225 
10139: loss=0.129, reward_mean=0.540, reward_bound=0.314, batch=225 
10140: loss=0.128, reward_mean=0.360, reward_bound=0.349, batch=225 
10141: loss=0.129, reward_mean=0.430, reward_bound=0.387, batch=224 
10142: loss=0.128, reward_mean=0.550, reward_bound=0.387, batch=226 
10143: loss=0.128, reward_mean=0.460, reward_bound=0.282, batch=227 
10144: loss=0.127, reward_mean=0.420, reward_bound=0.342, batch=229 
10145: loss=0.127, reward_mean=0.450, reward_bound=0.405, batch=230 
10146: loss=0.127, reward_mean=0.440, reward_bound=0.338, batch=231 
10147: loss=0.126, reward_mean=0.520, reward_bound=0.430, batch=200 
10148: loss=0.126, reward_mean=0.540, reward_bound=0.304, batch=210 
10149: loss=0.124, reward_mean=0.500, reward_bound=0.314, batch=213 
10150: loss=0.126, reward_mean=0.520, reward_bound=0.271, batch=219 
10151: loss=0.123, reward_mean=0.490, reward_bound=0.282, batch=221 
10152: loss=0.124, reward_mean=0.490, reward_bound=0.254, batch=224 
10153: loss=0.123, reward_mean=0.430, reward_bound=0.349, batch=219 
10154: loss=0.123, reward_mean=0.480, reward_bound=0.328, batch=223 
10155: loss=0.123, reward_mean=0.470, reward_bound=0.349, batch=223 
10156: loss=0.122, reward_mean=0.490, reward_bound=0.387, batch=217 
10157: loss=0.120, reward_mean=0.390, reward_bound=0.224, batch=222 
10158: loss=0.121, reward_mean=0.500, reward_bound=0.360, batch=225 
10159: loss=0.122, reward_mean=0.500, reward_bound=0.356, batch=227 
10160: loss=0.121, reward_mean=0.410, reward_bound=0.373, batch=229 
10161: loss=0.125, reward_mean=0.510, reward_bound=0.387, batch=228 
10162: loss=0.125, reward_mean=0.450, reward_bound=0.314, batch=228 
10163: loss=0.125, reward_mean=0.520, reward_bound=0.430, batch=215 
10164: loss=0.125, reward_mean=0.480, reward_bound=0.349, batch=217 
10165: loss=0.124, reward_mean=0.530, reward_bound=0.314, batch=221 
10166: loss=0.123, reward_mean=0.510, reward_bound=0.314, batch=224 
10167: loss=0.123, reward_mean=0.410, reward_bound=0.387, batch=221 
10168: loss=0.122, reward_mean=0.520, reward_bound=0.387, batch=224 
10169: loss=0.122, reward_mean=0.460, reward_bound=0.387, batch=226 
10170: loss=0.123, reward_mean=0.430, reward_bound=0.430, batch=223 
10171: loss=0.124, reward_mean=0.430, reward_bound=0.430, batch=224 
10172: loss=0.124, reward_mean=0.500, reward_bound=0.430, batch=226 
10173: loss=0.124, reward_mean=0.550, reward_bound=0.433, batch=228 
10174: loss=0.125, reward_mean=0.410, reward_bound=0.435, batch=229 
10175: loss=0.124, reward_mean=0.450, reward_bound=0.324, batch=230 
10176: loss=0.124, reward_mean=0.560, reward_bound=0.464, batch=231 
10177: loss=0.124, reward_mean=0.480, reward_bound=0.430, batch=231 
10178: loss=0.124, reward_mean=0.440, reward_bound=0.430, batch=231 
10179: loss=0.128, reward_mean=0.430, reward_bound=0.478, batch=190 
10180: loss=0.124, reward_mean=0.480, reward_bound=0.167, batch=200 
10181: loss=0.124, reward_mean=0.470, reward_bound=0.146, batch=210 
10182: loss=0.127, reward_mean=0.490, reward_bound=0.229, batch=213 
10183: loss=0.125, reward_mean=0.460, reward_bound=0.254, batch=216 
10184: loss=0.123, reward_mean=0.480, reward_bound=0.241, batch=221 
10185: loss=0.125, reward_mean=0.500, reward_bound=0.282, batch=223 
10186: loss=0.123, reward_mean=0.490, reward_bound=0.314, batch=221 
10187: loss=0.127, reward_mean=0.560, reward_bound=0.349, batch=213 
10188: loss=0.126, reward_mean=0.520, reward_bound=0.314, batch=217 
10189: loss=0.124, reward_mean=0.470, reward_bound=0.342, batch=222 
10190: loss=0.123, reward_mean=0.480, reward_bound=0.324, batch=225 
10191: loss=0.126, reward_mean=0.450, reward_bound=0.387, batch=219 
10192: loss=0.124, reward_mean=0.500, reward_bound=0.295, batch=223 
10193: loss=0.123, reward_mean=0.570, reward_bound=0.372, batch=226 
10194: loss=0.123, reward_mean=0.430, reward_bound=0.368, batch=228 
10195: loss=0.123, reward_mean=0.430, reward_bound=0.353, batch=229 
10196: loss=0.125, reward_mean=0.440, reward_bound=0.387, batch=228 
10197: loss=0.125, reward_mean=0.550, reward_bound=0.317, batch=229 
10198: loss=0.130, reward_mean=0.500, reward_bound=0.430, batch=211 
10199: loss=0.130, reward_mean=0.480, reward_bound=0.314, batch=215 
10200: loss=0.135, reward_mean=0.460, reward_bound=0.266, batch=220 
10201: loss=0.133, reward_mean=0.510, reward_bound=0.314, batch=222 
10202: loss=0.130, reward_mean=0.430, reward_bound=0.349, batch=224 
10203: loss=0.129, reward_mean=0.460, reward_bound=0.349, batch=226 
10204: loss=0.131, reward_mean=0.450, reward_bound=0.387, batch=225 
10205: loss=0.132, reward_mean=0.510, reward_bound=0.430, batch=222 
10206: loss=0.131, reward_mean=0.480, reward_bound=0.415, batch=225 
10207: loss=0.131, reward_mean=0.390, reward_bound=0.396, batch=227 
10208: loss=0.133, reward_mean=0.450, reward_bound=0.422, batch=229 
10209: loss=0.132, reward_mean=0.410, reward_bound=0.314, batch=229 
10210: loss=0.132, reward_mean=0.510, reward_bound=0.405, batch=230 
10211: loss=0.132, reward_mean=0.430, reward_bound=0.406, batch=231 
10212: loss=0.130, reward_mean=0.510, reward_bound=0.430, batch=229 
10213: loss=0.130, reward_mean=0.490, reward_bound=0.349, batch=229 
10214: loss=0.130, reward_mean=0.550, reward_bound=0.478, batch=231 
10215: loss=0.130, reward_mean=0.360, reward_bound=0.387, batch=231 
10216: loss=0.130, reward_mean=0.480, reward_bound=0.430, batch=231 
10217: loss=0.130, reward_mean=0.470, reward_bound=0.430, batch=231 
10218: loss=0.130, reward_mean=0.430, reward_bound=0.430, batch=231 
10219: loss=0.130, reward_mean=0.530, reward_bound=0.430, batch=231 
10220: loss=0.130, reward_mean=0.520, reward_bound=0.430, batch=231 
10221: loss=0.131, reward_mean=0.560, reward_bound=0.478, batch=207 
10222: loss=0.128, reward_mean=0.450, reward_bound=0.277, batch=215 
10223: loss=0.127, reward_mean=0.450, reward_bound=0.282, batch=219 
10224: loss=0.131, reward_mean=0.470, reward_bound=0.314, batch=222 
10225: loss=0.129, reward_mean=0.460, reward_bound=0.349, batch=219 
10226: loss=0.129, reward_mean=0.450, reward_bound=0.349, batch=222 
10227: loss=0.128, reward_mean=0.340, reward_bound=0.360, batch=225 
10228: loss=0.127, reward_mean=0.590, reward_bound=0.356, batch=227 
10229: loss=0.130, reward_mean=0.420, reward_bound=0.387, batch=223 
10230: loss=0.128, reward_mean=0.540, reward_bound=0.398, batch=226 
10231: loss=0.127, reward_mean=0.500, reward_bound=0.390, batch=228 
10232: loss=0.130, reward_mean=0.400, reward_bound=0.430, batch=220 
10233: loss=0.127, reward_mean=0.420, reward_bound=0.304, batch=224 
10234: loss=0.126, reward_mean=0.500, reward_bound=0.345, batch=227 
10235: loss=0.126, reward_mean=0.500, reward_bound=0.349, batch=228 
10236: loss=0.128, reward_mean=0.490, reward_bound=0.387, batch=227 
10237: loss=0.127, reward_mean=0.500, reward_bound=0.422, batch=229 
10238: loss=0.127, reward_mean=0.440, reward_bound=0.360, batch=230 
10239: loss=0.126, reward_mean=0.450, reward_bound=0.406, batch=231 
10240: loss=0.129, reward_mean=0.500, reward_bound=0.430, batch=230 
10241: loss=0.129, reward_mean=0.480, reward_bound=0.451, batch=231 
10242: loss=0.132, reward_mean=0.430, reward_bound=0.478, batch=218 
10243: loss=0.134, reward_mean=0.490, reward_bound=0.317, batch=222 
10244: loss=0.132, reward_mean=0.540, reward_bound=0.324, batch=225 
10245: loss=0.131, reward_mean=0.490, reward_bound=0.349, batch=225 
10246: loss=0.131, reward_mean=0.480, reward_bound=0.349, batch=226 
10247: loss=0.130, reward_mean=0.450, reward_bound=0.387, batch=226 
10248: loss=0.132, reward_mean=0.500, reward_bound=0.390, batch=228 
10249: loss=0.130, reward_mean=0.560, reward_bound=0.430, batch=226 
10250: loss=0.131, reward_mean=0.460, reward_bound=0.409, batch=228 
10251: loss=0.133, reward_mean=0.480, reward_bound=0.289, batch=229 
10252: loss=0.132, reward_mean=0.530, reward_bound=0.450, batch=230 
10253: loss=0.132, reward_mean=0.440, reward_bound=0.464, batch=231 
10254: loss=0.132, reward_mean=0.380, reward_bound=0.430, batch=231 
10255: loss=0.133, reward_mean=0.440, reward_bound=0.478, batch=226 
10256: loss=0.132, reward_mean=0.410, reward_bound=0.368, batch=228 
10257: loss=0.132, reward_mean=0.550, reward_bound=0.430, batch=228 
10258: loss=0.131, reward_mean=0.480, reward_bound=0.478, batch=231 
10259: loss=0.131, reward_mean=0.510, reward_bound=0.387, batch=231 
10260: loss=0.132, reward_mean=0.450, reward_bound=0.478, batch=228 
10261: loss=0.134, reward_mean=0.380, reward_bound=0.392, batch=229 
10262: loss=0.134, reward_mean=0.440, reward_bound=0.364, batch=230 
10263: loss=0.133, reward_mean=0.470, reward_bound=0.418, batch=231 
10264: loss=0.132, reward_mean=0.500, reward_bound=0.430, batch=230 
10265: loss=0.132, reward_mean=0.430, reward_bound=0.478, batch=230 
10266: loss=0.132, reward_mean=0.410, reward_bound=0.418, batch=231 
10267: loss=0.132, reward_mean=0.430, reward_bound=0.430, batch=231 
10268: loss=0.132, reward_mean=0.480, reward_bound=0.478, batch=230 
10269: loss=0.132, reward_mean=0.450, reward_bound=0.478, batch=230 
10270: loss=0.132, reward_mean=0.410, reward_bound=0.466, batch=231 
10272: loss=0.058, reward_mean=0.420, reward_bound=0.000, batch=42 
10273: loss=0.063, reward_mean=0.480, reward_bound=0.000, batch=90 
10274: loss=0.067, reward_mean=0.490, reward_bound=0.000, batch=133 
10275: loss=0.071, reward_mean=0.430, reward_bound=0.003, batch=163 
10276: loss=0.081, reward_mean=0.510, reward_bound=0.016, batch=184 
10277: loss=0.084, reward_mean=0.480, reward_bound=0.025, batch=199 
10278: loss=0.089, reward_mean=0.530, reward_bound=0.038, batch=206 
10279: loss=0.089, reward_mean=0.490, reward_bound=0.052, batch=212 
10280: loss=0.093, reward_mean=0.430, reward_bound=0.065, batch=214 
10281: loss=0.094, reward_mean=0.550, reward_bound=0.072, batch=219 
10282: loss=0.096, reward_mean=0.500, reward_bound=0.098, batch=215 
10283: loss=0.096, reward_mean=0.490, reward_bound=0.109, batch=231 
10284: loss=0.095, reward_mean=0.430, reward_bound=0.122, batch=214 
10285: loss=0.097, reward_mean=0.460, reward_bound=0.135, batch=217 
10286: loss=0.100, reward_mean=0.450, reward_bound=0.150, batch=218 
10287: loss=0.099, reward_mean=0.520, reward_bound=0.167, batch=209 
10288: loss=0.099, reward_mean=0.510, reward_bound=0.185, batch=210 
10289: loss=0.100, reward_mean=0.510, reward_bound=0.206, batch=225 
10290: loss=0.099, reward_mean=0.490, reward_bound=0.206, batch=204 
10291: loss=0.098, reward_mean=0.400, reward_bound=0.229, batch=184 
10292: loss=0.100, reward_mean=0.540, reward_bound=0.183, batch=199 
10293: loss=0.102, reward_mean=0.540, reward_bound=0.239, batch=209 
10294: loss=0.100, reward_mean=0.420, reward_bound=0.225, batch=216 
10295: loss=0.103, reward_mean=0.550, reward_bound=0.254, batch=184 
10296: loss=0.098, reward_mean=0.480, reward_bound=0.167, batch=198 
10297: loss=0.098, reward_mean=0.410, reward_bound=0.152, batch=208 
10298: loss=0.099, reward_mean=0.510, reward_bound=0.206, batch=211 
10299: loss=0.103, reward_mean=0.460, reward_bound=0.229, batch=215 
10300: loss=0.104, reward_mean=0.550, reward_bound=0.282, batch=174 
10301: loss=0.103, reward_mean=0.520, reward_bound=0.135, batch=191 
10302: loss=0.103, reward_mean=0.510, reward_bound=0.229, batch=201 
10303: loss=0.104, reward_mean=0.480, reward_bound=0.206, batch=210 
10304: loss=0.104, reward_mean=0.470, reward_bound=0.216, batch=217 
10305: loss=0.105, reward_mean=0.550, reward_bound=0.277, batch=222 
10306: loss=0.106, reward_mean=0.560, reward_bound=0.282, batch=219 
10307: loss=0.105, reward_mean=0.450, reward_bound=0.295, batch=223 
10308: loss=0.107, reward_mean=0.540, reward_bound=0.314, batch=170 
10309: loss=0.101, reward_mean=0.500, reward_bound=0.106, batch=189 
10310: loss=0.102, reward_mean=0.440, reward_bound=0.109, batch=201 
10311: loss=0.098, reward_mean=0.420, reward_bound=0.135, batch=209 
10312: loss=0.096, reward_mean=0.400, reward_bound=0.157, batch=216 
10313: loss=0.097, reward_mean=0.470, reward_bound=0.167, batch=220 
10314: loss=0.097, reward_mean=0.590, reward_bound=0.206, batch=230 
10315: loss=0.098, reward_mean=0.410, reward_bound=0.206, batch=238 
10316: loss=0.098, reward_mean=0.480, reward_bound=0.206, batch=234 
10317: loss=0.100, reward_mean=0.510, reward_bound=0.229, batch=229 
10318: loss=0.101, reward_mean=0.500, reward_bound=0.254, batch=227 
10319: loss=0.103, reward_mean=0.550, reward_bound=0.282, batch=227 
10320: loss=0.106, reward_mean=0.510, reward_bound=0.314, batch=215 
10321: loss=0.106, reward_mean=0.490, reward_bound=0.260, batch=220 
10322: loss=0.108, reward_mean=0.460, reward_bound=0.349, batch=168 
10323: loss=0.100, reward_mean=0.400, reward_bound=0.065, batch=186 
10324: loss=0.098, reward_mean=0.430, reward_bound=0.084, batch=200 
10325: loss=0.110, reward_mean=0.620, reward_bound=0.150, batch=209 
10326: loss=0.110, reward_mean=0.480, reward_bound=0.174, batch=216 
10327: loss=0.111, reward_mean=0.540, reward_bound=0.185, batch=216 
10328: loss=0.108, reward_mean=0.480, reward_bound=0.206, batch=220 
10329: loss=0.107, reward_mean=0.450, reward_bound=0.229, batch=219 
10330: loss=0.109, reward_mean=0.490, reward_bound=0.254, batch=219 
10331: loss=0.111, reward_mean=0.490, reward_bound=0.265, batch=223 
10332: loss=0.113, reward_mean=0.460, reward_bound=0.282, batch=220 
10333: loss=0.111, reward_mean=0.470, reward_bound=0.314, batch=211 
10334: loss=0.109, reward_mean=0.470, reward_bound=0.150, batch=217 
10335: loss=0.113, reward_mean=0.510, reward_bound=0.229, batch=220 
10336: loss=0.110, reward_mean=0.440, reward_bound=0.304, batch=224 
10337: loss=0.108, reward_mean=0.430, reward_bound=0.314, batch=225 
10338: loss=0.109, reward_mean=0.430, reward_bound=0.349, batch=204 
10339: loss=0.111, reward_mean=0.430, reward_bound=0.229, batch=212 
10340: loss=0.111, reward_mean=0.520, reward_bound=0.254, batch=217 
10341: loss=0.112, reward_mean=0.460, reward_bound=0.254, batch=221 
10342: loss=0.114, reward_mean=0.680, reward_bound=0.314, batch=223 
10343: loss=0.114, reward_mean=0.450, reward_bound=0.322, batch=226 
10344: loss=0.113, reward_mean=0.440, reward_bound=0.331, batch=228 
10345: loss=0.113, reward_mean=0.460, reward_bound=0.349, batch=226 
10346: loss=0.117, reward_mean=0.510, reward_bound=0.387, batch=145 
10347: loss=0.109, reward_mean=0.500, reward_bound=0.073, batch=171 
10348: loss=0.106, reward_mean=0.480, reward_bound=0.098, batch=189 
10349: loss=0.111, reward_mean=0.480, reward_bound=0.122, batch=199 
10350: loss=0.109, reward_mean=0.440, reward_bound=0.135, batch=205 
10351: loss=0.106, reward_mean=0.490, reward_bound=0.185, batch=204 
10352: loss=0.107, reward_mean=0.530, reward_bound=0.206, batch=209 
10353: loss=0.117, reward_mean=0.510, reward_bound=0.229, batch=206 
10354: loss=0.117, reward_mean=0.520, reward_bound=0.241, batch=214 
10355: loss=0.114, reward_mean=0.530, reward_bound=0.254, batch=218 
10356: loss=0.112, reward_mean=0.510, reward_bound=0.282, batch=211 
10357: loss=0.112, reward_mean=0.500, reward_bound=0.254, batch=217 
10358: loss=0.112, reward_mean=0.490, reward_bound=0.254, batch=221 
10359: loss=0.114, reward_mean=0.580, reward_bound=0.314, batch=209 
10360: loss=0.114, reward_mean=0.420, reward_bound=0.202, batch=216 
10361: loss=0.114, reward_mean=0.570, reward_bound=0.314, batch=217 
10362: loss=0.114, reward_mean=0.540, reward_bound=0.254, batch=220 
10363: loss=0.116, reward_mean=0.470, reward_bound=0.349, batch=203 
10364: loss=0.115, reward_mean=0.440, reward_bound=0.254, batch=211 
10365: loss=0.116, reward_mean=0.470, reward_bound=0.282, batch=212 
10366: loss=0.121, reward_mean=0.490, reward_bound=0.314, batch=216 
10367: loss=0.120, reward_mean=0.460, reward_bound=0.268, batch=221 
10368: loss=0.120, reward_mean=0.510, reward_bound=0.229, batch=224 
10369: loss=0.120, reward_mean=0.430, reward_bound=0.314, batch=223 
10370: loss=0.122, reward_mean=0.450, reward_bound=0.349, batch=218 
10371: loss=0.121, reward_mean=0.470, reward_bound=0.349, batch=220 
10372: loss=0.123, reward_mean=0.470, reward_bound=0.314, batch=223 
10373: loss=0.122, reward_mean=0.420, reward_bound=0.290, batch=226 
10374: loss=0.121, reward_mean=0.490, reward_bound=0.349, batch=227 
10375: loss=0.119, reward_mean=0.500, reward_bound=0.387, batch=209 
10376: loss=0.117, reward_mean=0.480, reward_bound=0.185, batch=214 
10377: loss=0.116, reward_mean=0.490, reward_bound=0.185, batch=219 
10378: loss=0.117, reward_mean=0.450, reward_bound=0.254, batch=222 
10379: loss=0.118, reward_mean=0.390, reward_bound=0.282, batch=223 
10380: loss=0.119, reward_mean=0.570, reward_bound=0.349, batch=222 
10381: loss=0.120, reward_mean=0.500, reward_bound=0.360, batch=225 
10382: loss=0.119, reward_mean=0.550, reward_bound=0.387, batch=225 
10383: loss=0.125, reward_mean=0.520, reward_bound=0.430, batch=114 
10384: loss=0.081, reward_mean=0.400, reward_bound=0.006, batch=150 
10385: loss=0.085, reward_mean=0.520, reward_bound=0.030, batch=175 
10386: loss=0.093, reward_mean=0.520, reward_bound=0.066, batch=192 
10387: loss=0.101, reward_mean=0.500, reward_bound=0.098, batch=203 
10388: loss=0.096, reward_mean=0.510, reward_bound=0.122, batch=208 
10389: loss=0.099, reward_mean=0.520, reward_bound=0.135, batch=208 
10390: loss=0.106, reward_mean=0.490, reward_bound=0.150, batch=211 
10391: loss=0.105, reward_mean=0.470, reward_bound=0.167, batch=207 
10392: loss=0.107, reward_mean=0.470, reward_bound=0.185, batch=205 
10393: loss=0.107, reward_mean=0.420, reward_bound=0.118, batch=213 
10394: loss=0.108, reward_mean=0.560, reward_bound=0.206, batch=216 
10395: loss=0.108, reward_mean=0.380, reward_bound=0.229, batch=208 
10396: loss=0.115, reward_mean=0.550, reward_bound=0.254, batch=198 
10397: loss=0.117, reward_mean=0.470, reward_bound=0.257, batch=208 
10398: loss=0.117, reward_mean=0.490, reward_bound=0.208, batch=215 
10399: loss=0.118, reward_mean=0.510, reward_bound=0.282, batch=206 
10400: loss=0.118, reward_mean=0.560, reward_bound=0.314, batch=192 
10401: loss=0.116, reward_mean=0.540, reward_bound=0.172, batch=204 
10402: loss=0.116, reward_mean=0.490, reward_bound=0.206, batch=212 
10403: loss=0.117, reward_mean=0.500, reward_bound=0.254, batch=212 
10404: loss=0.116, reward_mean=0.440, reward_bound=0.229, batch=218 
10405: loss=0.116, reward_mean=0.480, reward_bound=0.282, batch=221 
10406: loss=0.113, reward_mean=0.430, reward_bound=0.314, batch=219 
10407: loss=0.117, reward_mean=0.480, reward_bound=0.349, batch=194 
10408: loss=0.117, reward_mean=0.420, reward_bound=0.282, batch=201 
10409: loss=0.118, reward_mean=0.490, reward_bound=0.282, batch=210 
10410: loss=0.118, reward_mean=0.500, reward_bound=0.253, batch=217 
10411: loss=0.119, reward_mean=0.450, reward_bound=0.254, batch=221 
10412: loss=0.116, reward_mean=0.460, reward_bound=0.282, batch=224 
10413: loss=0.114, reward_mean=0.490, reward_bound=0.280, batch=227 
10414: loss=0.116, reward_mean=0.510, reward_bound=0.314, batch=218 
10415: loss=0.116, reward_mean=0.520, reward_bound=0.349, batch=215 
10416: loss=0.115, reward_mean=0.580, reward_bound=0.349, batch=219 
10417: loss=0.114, reward_mean=0.440, reward_bound=0.314, batch=222 
10418: loss=0.115, reward_mean=0.490, reward_bound=0.349, batch=223 
10419: loss=0.115, reward_mean=0.530, reward_bound=0.301, batch=226 
10420: loss=0.116, reward_mean=0.550, reward_bound=0.387, batch=192 
10421: loss=0.116, reward_mean=0.470, reward_bound=0.161, batch=204 
10422: loss=0.113, reward_mean=0.500, reward_bound=0.229, batch=211 
10423: loss=0.115, reward_mean=0.490, reward_bound=0.206, batch=217 
10424: loss=0.109, reward_mean=0.460, reward_bound=0.229, batch=220 
10425: loss=0.108, reward_mean=0.460, reward_bound=0.254, batch=222 
10426: loss=0.109, reward_mean=0.540, reward_bound=0.282, batch=223 
10427: loss=0.110, reward_mean=0.530, reward_bound=0.290, batch=226 
10428: loss=0.112, reward_mean=0.430, reward_bound=0.298, batch=228 
10429: loss=0.118, reward_mean=0.520, reward_bound=0.314, batch=222 
10430: loss=0.125, reward_mean=0.500, reward_bound=0.324, batch=225 
10431: loss=0.114, reward_mean=0.500, reward_bound=0.349, batch=217 
10432: loss=0.113, reward_mean=0.530, reward_bound=0.314, batch=221 
10433: loss=0.113, reward_mean=0.500, reward_bound=0.349, batch=221 
10434: loss=0.115, reward_mean=0.540, reward_bound=0.387, batch=212 
10435: loss=0.115, reward_mean=0.460, reward_bound=0.254, batch=217 
10436: loss=0.113, reward_mean=0.450, reward_bound=0.314, batch=220 
10437: loss=0.113, reward_mean=0.430, reward_bound=0.254, batch=223 
10438: loss=0.113, reward_mean=0.460, reward_bound=0.244, batch=226 
10439: loss=0.113, reward_mean=0.470, reward_bound=0.314, batch=226 
10440: loss=0.112, reward_mean=0.450, reward_bound=0.349, batch=225 
10441: loss=0.112, reward_mean=0.470, reward_bound=0.321, batch=227 
10442: loss=0.113, reward_mean=0.400, reward_bound=0.349, batch=228 
10443: loss=0.115, reward_mean=0.520, reward_bound=0.387, batch=228 
10444: loss=0.114, reward_mean=0.440, reward_bound=0.357, batch=229 
10445: loss=0.117, reward_mean=0.490, reward_bound=0.430, batch=174 
10446: loss=0.111, reward_mean=0.490, reward_bound=0.089, batch=191 
10447: loss=0.106, reward_mean=0.460, reward_bound=0.109, batch=203 
10448: loss=0.108, reward_mean=0.480, reward_bound=0.135, batch=211 
10449: loss=0.112, reward_mean=0.480, reward_bound=0.167, batch=215 
10450: loss=0.112, reward_mean=0.450, reward_bound=0.206, batch=213 
10451: loss=0.113, reward_mean=0.460, reward_bound=0.254, batch=204 
10452: loss=0.109, reward_mean=0.470, reward_bound=0.122, batch=212 
10453: loss=0.113, reward_mean=0.420, reward_bound=0.206, batch=219 
10454: loss=0.115, reward_mean=0.480, reward_bound=0.206, batch=222 
10455: loss=0.110, reward_mean=0.510, reward_bound=0.282, batch=216 
10456: loss=0.108, reward_mean=0.390, reward_bound=0.284, batch=221 
10457: loss=0.110, reward_mean=0.380, reward_bound=0.314, batch=217 
10458: loss=0.110, reward_mean=0.490, reward_bound=0.277, batch=222 
10459: loss=0.109, reward_mean=0.460, reward_bound=0.324, batch=225 
10460: loss=0.108, reward_mean=0.510, reward_bound=0.296, batch=227 
10461: loss=0.109, reward_mean=0.490, reward_bound=0.349, batch=216 
10462: loss=0.108, reward_mean=0.500, reward_bound=0.254, batch=220 
10463: loss=0.108, reward_mean=0.500, reward_bound=0.349, batch=222 
10464: loss=0.106, reward_mean=0.460, reward_bound=0.283, batch=225 
10465: loss=0.111, reward_mean=0.510, reward_bound=0.387, batch=216 
10466: loss=0.113, reward_mean=0.540, reward_bound=0.298, batch=221 
10467: loss=0.109, reward_mean=0.440, reward_bound=0.314, batch=222 
10468: loss=0.107, reward_mean=0.530, reward_bound=0.324, batch=225 
10469: loss=0.107, reward_mean=0.400, reward_bound=0.321, batch=227 
10470: loss=0.107, reward_mean=0.380, reward_bound=0.349, batch=227 
10471: loss=0.111, reward_mean=0.460, reward_bound=0.342, batch=229 
10472: loss=0.107, reward_mean=0.560, reward_bound=0.349, batch=228 
10473: loss=0.109, reward_mean=0.440, reward_bound=0.387, batch=228 
10474: loss=0.113, reward_mean=0.510, reward_bound=0.430, batch=203 
10475: loss=0.108, reward_mean=0.470, reward_bound=0.185, batch=210 
10476: loss=0.111, reward_mean=0.500, reward_bound=0.229, batch=216 
10477: loss=0.110, reward_mean=0.420, reward_bound=0.254, batch=218 
10478: loss=0.112, reward_mean=0.450, reward_bound=0.282, batch=221 
10479: loss=0.109, reward_mean=0.450, reward_bound=0.314, batch=224 
10480: loss=0.108, reward_mean=0.500, reward_bound=0.339, batch=227 
10481: loss=0.111, reward_mean=0.430, reward_bound=0.349, batch=225 
10482: loss=0.113, reward_mean=0.530, reward_bound=0.387, batch=218 
10483: loss=0.115, reward_mean=0.490, reward_bound=0.237, batch=222 
10484: loss=0.113, reward_mean=0.540, reward_bound=0.387, batch=224 
10485: loss=0.112, reward_mean=0.540, reward_bound=0.430, batch=214 
10486: loss=0.110, reward_mean=0.470, reward_bound=0.384, batch=220 
10487: loss=0.110, reward_mean=0.480, reward_bound=0.387, batch=221 
10488: loss=0.109, reward_mean=0.480, reward_bound=0.314, batch=224 
10489: loss=0.108, reward_mean=0.490, reward_bound=0.426, batch=227 
10490: loss=0.107, reward_mean=0.460, reward_bound=0.330, batch=229 
10491: loss=0.107, reward_mean=0.470, reward_bound=0.364, batch=230 
10492: loss=0.108, reward_mean=0.520, reward_bound=0.387, batch=230 
10493: loss=0.111, reward_mean=0.420, reward_bound=0.430, batch=224 
10494: loss=0.111, reward_mean=0.470, reward_bound=0.426, batch=227 
10495: loss=0.111, reward_mean=0.560, reward_bound=0.430, batch=227 
10496: loss=0.111, reward_mean=0.470, reward_bound=0.349, batch=228 
10497: loss=0.112, reward_mean=0.510, reward_bound=0.478, batch=231 
10498: loss=0.112, reward_mean=0.420, reward_bound=0.349, batch=231 
10499: loss=0.116, reward_mean=0.550, reward_bound=0.478, batch=96 
10500: loss=0.081, reward_mean=0.460, reward_bound=0.004, batch=137 
10501: loss=0.079, reward_mean=0.560, reward_bound=0.018, batch=164 
10502: loss=0.086, reward_mean=0.500, reward_bound=0.042, batch=185 
10503: loss=0.082, reward_mean=0.530, reward_bound=0.066, batch=199 
10504: loss=0.083, reward_mean=0.440, reward_bound=0.093, batch=209 
10505: loss=0.082, reward_mean=0.470, reward_bound=0.109, batch=206 
10506: loss=0.086, reward_mean=0.520, reward_bound=0.128, batch=214 
10507: loss=0.091, reward_mean=0.510, reward_bound=0.150, batch=213 
10508: loss=0.093, reward_mean=0.520, reward_bound=0.167, batch=215 
10509: loss=0.096, reward_mean=0.540, reward_bound=0.185, batch=217 
10510: loss=0.097, reward_mean=0.560, reward_bound=0.206, batch=215 
10511: loss=0.099, reward_mean=0.470, reward_bound=0.229, batch=214 
10512: loss=0.105, reward_mean=0.470, reward_bound=0.254, batch=203 
10513: loss=0.104, reward_mean=0.360, reward_bound=0.149, batch=212 
10514: loss=0.102, reward_mean=0.460, reward_bound=0.236, batch=218 
10515: loss=0.104, reward_mean=0.500, reward_bound=0.282, batch=201 
10516: loss=0.102, reward_mean=0.530, reward_bound=0.229, batch=210 
10517: loss=0.103, reward_mean=0.550, reward_bound=0.247, batch=217 
10518: loss=0.104, reward_mean=0.500, reward_bound=0.254, batch=221 
10519: loss=0.105, reward_mean=0.430, reward_bound=0.282, batch=223 
10520: loss=0.103, reward_mean=0.560, reward_bound=0.314, batch=201 
10521: loss=0.101, reward_mean=0.480, reward_bound=0.185, batch=210 
10522: loss=0.102, reward_mean=0.540, reward_bound=0.254, batch=214 
10523: loss=0.101, reward_mean=0.460, reward_bound=0.229, batch=219 
10524: loss=0.099, reward_mean=0.520, reward_bound=0.282, batch=215 
10525: loss=0.097, reward_mean=0.490, reward_bound=0.254, batch=219 
10526: loss=0.100, reward_mean=0.450, reward_bound=0.314, batch=216 
10527: loss=0.101, reward_mean=0.420, reward_bound=0.349, batch=189 
10528: loss=0.100, reward_mean=0.520, reward_bound=0.148, batch=202 
10529: loss=0.098, reward_mean=0.440, reward_bound=0.185, batch=208 
10530: loss=0.098, reward_mean=0.590, reward_bound=0.254, batch=213 
10531: loss=0.096, reward_mean=0.530, reward_bound=0.282, batch=215 
10532: loss=0.096, reward_mean=0.430, reward_bound=0.289, batch=220 
10533: loss=0.097, reward_mean=0.470, reward_bound=0.282, batch=223 
10534: loss=0.098, reward_mean=0.490, reward_bound=0.314, batch=220 
10535: loss=0.101, reward_mean=0.540, reward_bound=0.349, batch=215 
10536: loss=0.096, reward_mean=0.520, reward_bound=0.387, batch=180 
10537: loss=0.097, reward_mean=0.360, reward_bound=0.122, batch=195 
10538: loss=0.095, reward_mean=0.450, reward_bound=0.135, batch=204 
10539: loss=0.094, reward_mean=0.540, reward_bound=0.167, batch=212 
10540: loss=0.092, reward_mean=0.480, reward_bound=0.206, batch=220 
10541: loss=0.093, reward_mean=0.550, reward_bound=0.247, batch=224 
10542: loss=0.095, reward_mean=0.480, reward_bound=0.254, batch=226 
10543: loss=0.099, reward_mean=0.480, reward_bound=0.282, batch=223 
10544: loss=0.098, reward_mean=0.510, reward_bound=0.314, batch=220 
10545: loss=0.097, reward_mean=0.560, reward_bound=0.349, batch=214 
10546: loss=0.097, reward_mean=0.550, reward_bound=0.311, batch=220 
10547: loss=0.096, reward_mean=0.380, reward_bound=0.254, batch=223 
10548: loss=0.096, reward_mean=0.440, reward_bound=0.314, batch=224 
10549: loss=0.097, reward_mean=0.550, reward_bound=0.349, batch=223 
10550: loss=0.098, reward_mean=0.440, reward_bound=0.322, batch=226 
10551: loss=0.097, reward_mean=0.500, reward_bound=0.387, batch=213 
10552: loss=0.097, reward_mean=0.500, reward_bound=0.178, batch=219 
10553: loss=0.097, reward_mean=0.460, reward_bound=0.314, batch=220 
10554: loss=0.096, reward_mean=0.520, reward_bound=0.338, batch=224 
10555: loss=0.097, reward_mean=0.520, reward_bound=0.349, batch=226 
10556: loss=0.095, reward_mean=0.450, reward_bound=0.387, batch=222 
10557: loss=0.096, reward_mean=0.490, reward_bound=0.282, batch=224 
10558: loss=0.096, reward_mean=0.380, reward_bound=0.311, batch=227 
10559: loss=0.095, reward_mean=0.480, reward_bound=0.349, batch=227 
10560: loss=0.093, reward_mean=0.440, reward_bound=0.422, batch=229 
10561: loss=0.101, reward_mean=0.470, reward_bound=0.430, batch=159 
10562: loss=0.086, reward_mean=0.510, reward_bound=0.044, batch=181 
10563: loss=0.089, reward_mean=0.470, reward_bound=0.098, batch=195 
10564: loss=0.091, reward_mean=0.490, reward_bound=0.124, batch=206 
10565: loss=0.089, reward_mean=0.430, reward_bound=0.143, batch=214 
10566: loss=0.086, reward_mean=0.490, reward_bound=0.167, batch=217 
10567: loss=0.088, reward_mean=0.520, reward_bound=0.206, batch=217 
10568: loss=0.088, reward_mean=0.360, reward_bound=0.182, batch=222 
10569: loss=0.094, reward_mean=0.500, reward_bound=0.229, batch=215 
10570: loss=0.095, reward_mean=0.480, reward_bound=0.254, batch=212 
10571: loss=0.095, reward_mean=0.520, reward_bound=0.282, batch=204 
10572: loss=0.093, reward_mean=0.500, reward_bound=0.254, batch=212 
10573: loss=0.100, reward_mean=0.570, reward_bound=0.314, batch=207 
10574: loss=0.098, reward_mean=0.590, reward_bound=0.277, batch=215 
10575: loss=0.096, reward_mean=0.520, reward_bound=0.260, batch=220 
10576: loss=0.097, reward_mean=0.560, reward_bound=0.282, batch=222 
10577: loss=0.098, reward_mean=0.450, reward_bound=0.314, batch=224 
10578: loss=0.097, reward_mean=0.500, reward_bound=0.254, batch=226 
10579: loss=0.096, reward_mean=0.570, reward_bound=0.349, batch=206 
10580: loss=0.095, reward_mean=0.450, reward_bound=0.206, batch=212 
10581: loss=0.102, reward_mean=0.550, reward_bound=0.314, batch=215 
10582: loss=0.101, reward_mean=0.470, reward_bound=0.314, batch=218 
10583: loss=0.101, reward_mean=0.480, reward_bound=0.286, batch=222 
10584: loss=0.100, reward_mean=0.410, reward_bound=0.282, batch=224 
10585: loss=0.100, reward_mean=0.530, reward_bound=0.345, batch=227 
10586: loss=0.096, reward_mean=0.500, reward_bound=0.349, batch=224 
10587: loss=0.095, reward_mean=0.520, reward_bound=0.345, batch=227 
10588: loss=0.095, reward_mean=0.450, reward_bound=0.335, batch=229 
10589: loss=0.094, reward_mean=0.470, reward_bound=0.364, batch=230 
10590: loss=0.102, reward_mean=0.490, reward_bound=0.387, batch=206 
10591: loss=0.099, reward_mean=0.510, reward_bound=0.207, batch=214 
10592: loss=0.100, reward_mean=0.500, reward_bound=0.254, batch=219 
10593: loss=0.102, reward_mean=0.500, reward_bound=0.282, batch=222 
10594: loss=0.102, reward_mean=0.530, reward_bound=0.314, batch=222 
10595: loss=0.101, reward_mean=0.540, reward_bound=0.349, batch=220 
10596: loss=0.099, reward_mean=0.560, reward_bound=0.387, batch=217 
10597: loss=0.099, reward_mean=0.510, reward_bound=0.314, batch=221 
10598: loss=0.099, reward_mean=0.530, reward_bound=0.349, batch=224 
10599: loss=0.098, reward_mean=0.480, reward_bound=0.282, batch=226 
10600: loss=0.098, reward_mean=0.530, reward_bound=0.387, batch=226 
10601: loss=0.099, reward_mean=0.490, reward_bound=0.409, batch=228 
10602: loss=0.098, reward_mean=0.600, reward_bound=0.317, batch=229 
10603: loss=0.097, reward_mean=0.540, reward_bound=0.430, batch=201 
10604: loss=0.095, reward_mean=0.520, reward_bound=0.206, batch=210 
10605: loss=0.095, reward_mean=0.400, reward_bound=0.175, batch=217 
10606: loss=0.096, reward_mean=0.510, reward_bound=0.229, batch=219 
10607: loss=0.096, reward_mean=0.580, reward_bound=0.282, batch=218 
10608: loss=0.094, reward_mean=0.480, reward_bound=0.286, batch=222 
10609: loss=0.094, reward_mean=0.510, reward_bound=0.314, batch=222 
10610: loss=0.096, reward_mean=0.560, reward_bound=0.349, batch=219 
10611: loss=0.095, reward_mean=0.500, reward_bound=0.282, batch=222 
10612: loss=0.097, reward_mean=0.470, reward_bound=0.387, batch=217 
10613: loss=0.095, reward_mean=0.580, reward_bound=0.342, batch=222 
10614: loss=0.097, reward_mean=0.490, reward_bound=0.360, batch=225 
10615: loss=0.096, reward_mean=0.420, reward_bound=0.387, batch=226 
10616: loss=0.095, reward_mean=0.460, reward_bound=0.349, batch=227 
10617: loss=0.096, reward_mean=0.520, reward_bound=0.380, batch=229 
10618: loss=0.096, reward_mean=0.520, reward_bound=0.387, batch=226 
10619: loss=0.095, reward_mean=0.650, reward_bound=0.298, batch=228 
10620: loss=0.097, reward_mean=0.520, reward_bound=0.430, batch=214 
10621: loss=0.096, reward_mean=0.510, reward_bound=0.254, batch=219 
10622: loss=0.096, reward_mean=0.500, reward_bound=0.282, batch=222 
10623: loss=0.096, reward_mean=0.470, reward_bound=0.387, batch=223 
10624: loss=0.097, reward_mean=0.540, reward_bound=0.398, batch=226 
10625: loss=0.096, reward_mean=0.550, reward_bound=0.430, batch=223 
10626: loss=0.095, reward_mean=0.570, reward_bound=0.282, batch=225 
10627: loss=0.103, reward_mean=0.490, reward_bound=0.478, batch=140 
10628: loss=0.095, reward_mean=0.520, reward_bound=0.052, batch=167 
10629: loss=0.088, reward_mean=0.460, reward_bound=0.080, batch=185 
10630: loss=0.083, reward_mean=0.450, reward_bound=0.089, batch=201 
10631: loss=0.087, reward_mean=0.490, reward_bound=0.122, batch=210 
10632: loss=0.093, reward_mean=0.510, reward_bound=0.167, batch=211 
10633: loss=0.091, reward_mean=0.500, reward_bound=0.185, batch=212 
10634: loss=0.095, reward_mean=0.510, reward_bound=0.206, batch=227 
10635: loss=0.093, reward_mean=0.460, reward_bound=0.206, batch=224 
10636: loss=0.095, reward_mean=0.520, reward_bound=0.229, batch=219 
10637: loss=0.097, reward_mean=0.460, reward_bound=0.254, batch=212 
10638: loss=0.096, reward_mean=0.510, reward_bound=0.263, batch=218 
10639: loss=0.095, reward_mean=0.510, reward_bound=0.282, batch=208 
10640: loss=0.093, reward_mean=0.540, reward_bound=0.286, batch=215 
10641: loss=0.092, reward_mean=0.440, reward_bound=0.282, batch=218 
10642: loss=0.091, reward_mean=0.460, reward_bound=0.190, batch=222 
10643: loss=0.099, reward_mean=0.510, reward_bound=0.314, batch=208 
10644: loss=0.098, reward_mean=0.480, reward_bound=0.254, batch=213 
10645: loss=0.097, reward_mean=0.450, reward_bound=0.282, batch=217 
10646: loss=0.095, reward_mean=0.510, reward_bound=0.272, batch=222 
10647: loss=0.096, reward_mean=0.570, reward_bound=0.282, batch=222 
10648: loss=0.096, reward_mean=0.530, reward_bound=0.324, batch=225 
10649: loss=0.108, reward_mean=0.600, reward_bound=0.349, batch=205 
10650: loss=0.107, reward_mean=0.550, reward_bound=0.260, batch=213 
10651: loss=0.104, reward_mean=0.460, reward_bound=0.167, batch=218 
10652: loss=0.105, reward_mean=0.440, reward_bound=0.254, batch=221 
10653: loss=0.106, reward_mean=0.470, reward_bound=0.314, batch=221 
10654: loss=0.104, reward_mean=0.470, reward_bound=0.349, batch=219 
10655: loss=0.103, reward_mean=0.520, reward_bound=0.364, batch=223 
10656: loss=0.110, reward_mean=0.480, reward_bound=0.387, batch=198 
10657: loss=0.113, reward_mean=0.450, reward_bound=0.206, batch=206 
10658: loss=0.112, reward_mean=0.510, reward_bound=0.314, batch=209 
10659: loss=0.110, reward_mean=0.400, reward_bound=0.167, batch=215 
10660: loss=0.111, reward_mean=0.570, reward_bound=0.282, batch=217 
10661: loss=0.109, reward_mean=0.510, reward_bound=0.185, batch=221 
10662: loss=0.108, reward_mean=0.430, reward_bound=0.282, batch=223 
10663: loss=0.108, reward_mean=0.420, reward_bound=0.314, batch=222 
10664: loss=0.108, reward_mean=0.490, reward_bound=0.349, batch=221 
10665: loss=0.107, reward_mean=0.510, reward_bound=0.349, batch=223 
10666: loss=0.110, reward_mean=0.490, reward_bound=0.322, batch=226 
10667: loss=0.105, reward_mean=0.450, reward_bound=0.387, batch=221 
10668: loss=0.105, reward_mean=0.430, reward_bound=0.282, batch=224 
10669: loss=0.105, reward_mean=0.460, reward_bound=0.384, batch=227 
10670: loss=0.105, reward_mean=0.480, reward_bound=0.380, batch=229 
10671: loss=0.106, reward_mean=0.470, reward_bound=0.387, batch=227 
10672: loss=0.106, reward_mean=0.510, reward_bound=0.414, batch=229 
10673: loss=0.106, reward_mean=0.530, reward_bound=0.387, batch=229 
10674: loss=0.106, reward_mean=0.560, reward_bound=0.381, batch=230 
10675: loss=0.106, reward_mean=0.440, reward_bound=0.406, batch=231 
10676: loss=0.114, reward_mean=0.390, reward_bound=0.430, batch=190 
10677: loss=0.111, reward_mean=0.430, reward_bound=0.206, batch=204 
10678: loss=0.111, reward_mean=0.460, reward_bound=0.229, batch=212 
10679: loss=0.115, reward_mean=0.490, reward_bound=0.263, batch=218 
10680: loss=0.115, reward_mean=0.460, reward_bound=0.282, batch=221 
10681: loss=0.113, reward_mean=0.460, reward_bound=0.282, batch=224 
10682: loss=0.113, reward_mean=0.480, reward_bound=0.311, batch=227 
10683: loss=0.115, reward_mean=0.530, reward_bound=0.314, batch=222 
10684: loss=0.113, reward_mean=0.470, reward_bound=0.349, batch=222 
10685: loss=0.112, reward_mean=0.440, reward_bound=0.360, batch=225 
10686: loss=0.112, reward_mean=0.500, reward_bound=0.314, batch=226 
10687: loss=0.113, reward_mean=0.510, reward_bound=0.368, batch=228 
10688: loss=0.113, reward_mean=0.500, reward_bound=0.321, batch=229 
10689: loss=0.109, reward_mean=0.520, reward_bound=0.387, batch=220 
10690: loss=0.110, reward_mean=0.510, reward_bound=0.418, batch=224 
10691: loss=0.109, reward_mean=0.430, reward_bound=0.345, batch=227 
10692: loss=0.110, reward_mean=0.380, reward_bound=0.380, batch=229 
10693: loss=0.113, reward_mean=0.450, reward_bound=0.430, batch=211 
10694: loss=0.114, reward_mean=0.510, reward_bound=0.254, batch=217 
10695: loss=0.112, reward_mean=0.470, reward_bound=0.277, batch=222 
10696: loss=0.110, reward_mean=0.470, reward_bound=0.314, batch=219 
10697: loss=0.109, reward_mean=0.430, reward_bound=0.328, batch=223 
10698: loss=0.110, reward_mean=0.420, reward_bound=0.349, batch=223 
10699: loss=0.113, reward_mean=0.440, reward_bound=0.387, batch=225 
10700: loss=0.113, reward_mean=0.470, reward_bound=0.430, batch=218 
10701: loss=0.115, reward_mean=0.620, reward_bound=0.353, batch=222 
10702: loss=0.114, reward_mean=0.450, reward_bound=0.263, batch=225 
10703: loss=0.113, reward_mean=0.490, reward_bound=0.387, batch=226 
10704: loss=0.113, reward_mean=0.440, reward_bound=0.409, batch=228 
10705: loss=0.112, reward_mean=0.520, reward_bound=0.392, batch=229 
10706: loss=0.112, reward_mean=0.470, reward_bound=0.364, batch=230 
10707: loss=0.111, reward_mean=0.510, reward_bound=0.365, batch=231 
10708: loss=0.112, reward_mean=0.430, reward_bound=0.387, batch=230 
10709: loss=0.114, reward_mean=0.520, reward_bound=0.430, batch=226 
10710: loss=0.114, reward_mean=0.440, reward_bound=0.433, batch=228 
10711: loss=0.114, reward_mean=0.570, reward_bound=0.435, batch=229 
10712: loss=0.114, reward_mean=0.510, reward_bound=0.450, batch=230 
10713: loss=0.115, reward_mean=0.490, reward_bound=0.464, batch=231 
10714: loss=0.106, reward_mean=0.470, reward_bound=0.478, batch=179 
10715: loss=0.100, reward_mean=0.530, reward_bound=0.135, batch=194 
10716: loss=0.099, reward_mean=0.490, reward_bound=0.167, batch=202 
10717: loss=0.100, reward_mean=0.520, reward_bound=0.185, batch=207 
10718: loss=0.102, reward_mean=0.470, reward_bound=0.206, batch=210 
10719: loss=0.106, reward_mean=0.380, reward_bound=0.229, batch=212 
10720: loss=0.107, reward_mean=0.520, reward_bound=0.254, batch=212 
10721: loss=0.107, reward_mean=0.530, reward_bound=0.236, batch=218 
10722: loss=0.104, reward_mean=0.470, reward_bound=0.282, batch=220 
10723: loss=0.103, reward_mean=0.450, reward_bound=0.314, batch=215 
10724: loss=0.100, reward_mean=0.510, reward_bound=0.210, batch=220 
10725: loss=0.099, reward_mean=0.540, reward_bound=0.274, batch=224 
10726: loss=0.101, reward_mean=0.610, reward_bound=0.314, batch=225 
10727: loss=0.100, reward_mean=0.520, reward_bound=0.321, batch=227 
10728: loss=0.099, reward_mean=0.530, reward_bound=0.349, batch=216 
10729: loss=0.098, reward_mean=0.550, reward_bound=0.268, batch=221 
10730: loss=0.102, reward_mean=0.530, reward_bound=0.387, batch=204 
10731: loss=0.105, reward_mean=0.470, reward_bound=0.282, batch=210 
10732: loss=0.104, reward_mean=0.480, reward_bound=0.314, batch=216 
10733: loss=0.104, reward_mean=0.410, reward_bound=0.256, batch=221 
10734: loss=0.103, reward_mean=0.480, reward_bound=0.314, batch=222 
10735: loss=0.101, reward_mean=0.520, reward_bound=0.349, batch=221 
10736: loss=0.100, reward_mean=0.570, reward_bound=0.314, batch=224 
10737: loss=0.101, reward_mean=0.400, reward_bound=0.311, batch=227 
10738: loss=0.104, reward_mean=0.510, reward_bound=0.277, batch=229 
10739: loss=0.103, reward_mean=0.440, reward_bound=0.349, batch=229 
10740: loss=0.104, reward_mean=0.540, reward_bound=0.387, batch=221 
10741: loss=0.105, reward_mean=0.500, reward_bound=0.349, batch=223 
10742: loss=0.104, reward_mean=0.500, reward_bound=0.413, batch=226 
10743: loss=0.104, reward_mean=0.530, reward_bound=0.349, batch=227 
10744: loss=0.107, reward_mean=0.510, reward_bound=0.430, batch=210 
10745: loss=0.106, reward_mean=0.460, reward_bound=0.247, batch=217 
10746: loss=0.106, reward_mean=0.500, reward_bound=0.229, batch=221 
10747: loss=0.105, reward_mean=0.440, reward_bound=0.282, batch=220 
10748: loss=0.104, reward_mean=0.530, reward_bound=0.314, batch=222 
10749: loss=0.104, reward_mean=0.420, reward_bound=0.292, batch=225 
10750: loss=0.107, reward_mean=0.500, reward_bound=0.349, batch=223 
10751: loss=0.106, reward_mean=0.470, reward_bound=0.372, batch=226 
10752: loss=0.105, reward_mean=0.500, reward_bound=0.351, batch=228 
10753: loss=0.105, reward_mean=0.440, reward_bound=0.387, batch=223 
10754: loss=0.105, reward_mean=0.430, reward_bound=0.252, batch=226 
10755: loss=0.105, reward_mean=0.430, reward_bound=0.409, batch=228 
10756: loss=0.105, reward_mean=0.570, reward_bound=0.392, batch=229 
10757: loss=0.106, reward_mean=0.440, reward_bound=0.430, batch=219 
10758: loss=0.107, reward_mean=0.530, reward_bound=0.215, batch=223 
10759: loss=0.107, reward_mean=0.440, reward_bound=0.254, batch=225 
10760: loss=0.105, reward_mean=0.450, reward_bound=0.356, batch=227 
10761: loss=0.105, reward_mean=0.500, reward_bound=0.349, batch=228 
10762: loss=0.105, reward_mean=0.500, reward_bound=0.353, batch=229 
10763: loss=0.106, reward_mean=0.490, reward_bound=0.364, batch=230 
10764: loss=0.105, reward_mean=0.410, reward_bound=0.387, batch=226 
10765: loss=0.105, reward_mean=0.430, reward_bound=0.409, batch=228 
10766: loss=0.104, reward_mean=0.540, reward_bound=0.325, batch=229 
10767: loss=0.106, reward_mean=0.530, reward_bound=0.430, batch=224 
10768: loss=0.107, reward_mean=0.490, reward_bound=0.308, batch=227 
10769: loss=0.107, reward_mean=0.500, reward_bound=0.387, batch=226 
10770: loss=0.107, reward_mean=0.570, reward_bound=0.390, batch=228 
10771: loss=0.107, reward_mean=0.490, reward_bound=0.430, batch=226 
10772: loss=0.108, reward_mean=0.470, reward_bound=0.454, batch=228 
10773: loss=0.109, reward_mean=0.540, reward_bound=0.435, batch=229 
10774: loss=0.109, reward_mean=0.450, reward_bound=0.450, batch=230 
10775: loss=0.109, reward_mean=0.550, reward_bound=0.387, batch=230 
10776: loss=0.109, reward_mean=0.550, reward_bound=0.376, batch=231 
10777: loss=0.104, reward_mean=0.450, reward_bound=0.478, batch=199 
10778: loss=0.105, reward_mean=0.450, reward_bound=0.206, batch=207 
10779: loss=0.103, reward_mean=0.510, reward_bound=0.206, batch=212 
10780: loss=0.102, reward_mean=0.510, reward_bound=0.229, batch=214 
10781: loss=0.103, reward_mean=0.530, reward_bound=0.282, batch=218 
10782: loss=0.104, reward_mean=0.410, reward_bound=0.286, batch=222 
10783: loss=0.103, reward_mean=0.450, reward_bound=0.314, batch=220 
10784: loss=0.102, reward_mean=0.520, reward_bound=0.282, batch=222 
10785: loss=0.102, reward_mean=0.430, reward_bound=0.324, batch=225 
10786: loss=0.101, reward_mean=0.540, reward_bound=0.349, batch=221 
10787: loss=0.101, reward_mean=0.570, reward_bound=0.349, batch=221 
10788: loss=0.103, reward_mean=0.460, reward_bound=0.387, batch=217 
10789: loss=0.101, reward_mean=0.500, reward_bound=0.308, batch=222 
10790: loss=0.101, reward_mean=0.550, reward_bound=0.349, batch=223 
10791: loss=0.104, reward_mean=0.490, reward_bound=0.413, batch=226 
10792: loss=0.104, reward_mean=0.550, reward_bound=0.387, batch=227 
10793: loss=0.106, reward_mean=0.570, reward_bound=0.430, batch=217 
10794: loss=0.103, reward_mean=0.540, reward_bound=0.277, batch=222 
10795: loss=0.105, reward_mean=0.490, reward_bound=0.360, batch=225 
10796: loss=0.105, reward_mean=0.480, reward_bound=0.387, batch=225 
10797: loss=0.107, reward_mean=0.550, reward_bound=0.289, batch=227 
10798: loss=0.105, reward_mean=0.550, reward_bound=0.422, batch=229 
10799: loss=0.105, reward_mean=0.470, reward_bound=0.430, batch=222 
10800: loss=0.106, reward_mean=0.540, reward_bound=0.478, batch=214 
10801: loss=0.105, reward_mean=0.550, reward_bound=0.384, batch=220 
10802: loss=0.105, reward_mean=0.660, reward_bound=0.387, batch=221 
10803: loss=0.106, reward_mean=0.440, reward_bound=0.349, batch=224 
10804: loss=0.105, reward_mean=0.480, reward_bound=0.282, batch=226 
10805: loss=0.107, reward_mean=0.410, reward_bound=0.331, batch=228 
10806: loss=0.106, reward_mean=0.460, reward_bound=0.349, batch=227 
10807: loss=0.106, reward_mean=0.460, reward_bound=0.422, batch=229 
10808: loss=0.106, reward_mean=0.430, reward_bound=0.430, batch=224 
10809: loss=0.105, reward_mean=0.510, reward_bound=0.387, batch=226 
10810: loss=0.105, reward_mean=0.460, reward_bound=0.430, batch=225 
10811: loss=0.105, reward_mean=0.540, reward_bound=0.478, batch=220 
10812: loss=0.108, reward_mean=0.430, reward_bound=0.387, batch=223 
10813: loss=0.104, reward_mean=0.400, reward_bound=0.430, batch=222 
10814: loss=0.103, reward_mean=0.440, reward_bound=0.272, batch=225 
10815: loss=0.103, reward_mean=0.490, reward_bound=0.321, batch=227 
10816: loss=0.103, reward_mean=0.480, reward_bound=0.314, batch=228 
10817: loss=0.103, reward_mean=0.540, reward_bound=0.349, batch=227 
10818: loss=0.104, reward_mean=0.420, reward_bound=0.422, batch=229 
10819: loss=0.105, reward_mean=0.470, reward_bound=0.430, batch=227 
10820: loss=0.105, reward_mean=0.490, reward_bound=0.422, batch=229 
10821: loss=0.105, reward_mean=0.450, reward_bound=0.360, batch=230 
10822: loss=0.105, reward_mean=0.410, reward_bound=0.464, batch=231 
10823: loss=0.104, reward_mean=0.530, reward_bound=0.478, batch=223 
10824: loss=0.103, reward_mean=0.460, reward_bound=0.387, batch=224 
10825: loss=0.102, reward_mean=0.570, reward_bound=0.384, batch=227 
10826: loss=0.105, reward_mean=0.480, reward_bound=0.387, batch=228 
10827: loss=0.105, reward_mean=0.460, reward_bound=0.357, batch=229 
10828: loss=0.106, reward_mean=0.550, reward_bound=0.430, batch=229 
10829: loss=0.106, reward_mean=0.550, reward_bound=0.450, batch=230 
10830: loss=0.105, reward_mean=0.610, reward_bound=0.478, batch=225 
10831: loss=0.106, reward_mean=0.480, reward_bound=0.406, batch=227 
10832: loss=0.106, reward_mean=0.490, reward_bound=0.460, batch=229 
10833: loss=0.105, reward_mean=0.510, reward_bound=0.500, batch=230 
10834: loss=0.105, reward_mean=0.500, reward_bound=0.464, batch=231 
10835: loss=0.105, reward_mean=0.450, reward_bound=0.478, batch=231 
10836: loss=0.105, reward_mean=0.550, reward_bound=0.430, batch=231 
10837: loss=0.105, reward_mean=0.470, reward_bound=0.478, batch=231 
10838: loss=0.105, reward_mean=0.500, reward_bound=0.478, batch=231 
10839: loss=0.105, reward_mean=0.530, reward_bound=0.478, batch=231 
10840: loss=0.105, reward_mean=0.460, reward_bound=0.478, batch=231 
10841: loss=0.105, reward_mean=0.450, reward_bound=0.349, batch=231 
10843: loss=0.051, reward_mean=0.540, reward_bound=0.000, batch=54 
10844: loss=0.048, reward_mean=0.460, reward_bound=0.000, batch=100 
10845: loss=0.057, reward_mean=0.540, reward_bound=0.003, batch=139 
10846: loss=0.059, reward_mean=0.490, reward_bound=0.006, batch=165 
10847: loss=0.072, reward_mean=0.540, reward_bound=0.018, batch=182 
10848: loss=0.067, reward_mean=0.470, reward_bound=0.028, batch=190 
10849: loss=0.070, reward_mean=0.560, reward_bound=0.047, batch=201 
10850: loss=0.071, reward_mean=0.520, reward_bound=0.058, batch=207 
10851: loss=0.073, reward_mean=0.540, reward_bound=0.072, batch=204 
10852: loss=0.076, reward_mean=0.550, reward_bound=0.089, batch=204 
10853: loss=0.080, reward_mean=0.470, reward_bound=0.098, batch=207 
10854: loss=0.078, reward_mean=0.470, reward_bound=0.122, batch=198 
10855: loss=0.080, reward_mean=0.470, reward_bound=0.135, batch=200 
10856: loss=0.077, reward_mean=0.530, reward_bound=0.150, batch=202 
10857: loss=0.070, reward_mean=0.440, reward_bound=0.167, batch=187 
10858: loss=0.069, reward_mean=0.520, reward_bound=0.185, batch=180 
10859: loss=0.065, reward_mean=0.430, reward_bound=0.096, batch=196 
10860: loss=0.066, reward_mean=0.620, reward_bound=0.122, batch=204 
10861: loss=0.064, reward_mean=0.520, reward_bound=0.150, batch=212 
10862: loss=0.064, reward_mean=0.560, reward_bound=0.206, batch=219 
10863: loss=0.064, reward_mean=0.500, reward_bound=0.206, batch=195 
10864: loss=0.064, reward_mean=0.480, reward_bound=0.194, batch=206 
10865: loss=0.071, reward_mean=0.480, reward_bound=0.229, batch=184 
10866: loss=0.069, reward_mean=0.560, reward_bound=0.183, batch=199 
10867: loss=0.066, reward_mean=0.500, reward_bound=0.194, batch=209 
10868: loss=0.068, reward_mean=0.430, reward_bound=0.206, batch=212 
10869: loss=0.069, reward_mean=0.540, reward_bound=0.229, batch=213 
10870: loss=0.069, reward_mean=0.480, reward_bound=0.254, batch=188 
10871: loss=0.067, reward_mean=0.560, reward_bound=0.150, batch=200 
10872: loss=0.067, reward_mean=0.570, reward_bound=0.185, batch=206 
10873: loss=0.067, reward_mean=0.530, reward_bound=0.206, batch=213 
10874: loss=0.066, reward_mean=0.560, reward_bound=0.229, batch=217 
10875: loss=0.071, reward_mean=0.440, reward_bound=0.254, batch=220 
10876: loss=0.069, reward_mean=0.530, reward_bound=0.282, batch=186 
10877: loss=0.069, reward_mean=0.530, reward_bound=0.167, batch=199 
10878: loss=0.069, reward_mean=0.540, reward_bound=0.206, batch=208 
10879: loss=0.068, reward_mean=0.430, reward_bound=0.126, batch=215 
10880: loss=0.069, reward_mean=0.510, reward_bound=0.229, batch=214 
10881: loss=0.070, reward_mean=0.480, reward_bound=0.282, batch=215 
10882: loss=0.071, reward_mean=0.370, reward_bound=0.260, batch=220 
10883: loss=0.072, reward_mean=0.530, reward_bound=0.304, batch=224 
10884: loss=0.079, reward_mean=0.450, reward_bound=0.314, batch=182 
10885: loss=0.082, reward_mean=0.540, reward_bound=0.172, batch=197 
10886: loss=0.083, reward_mean=0.550, reward_bound=0.182, batch=208 
10887: loss=0.079, reward_mean=0.530, reward_bound=0.206, batch=211 
10888: loss=0.077, reward_mean=0.510, reward_bound=0.254, batch=211 
10889: loss=0.079, reward_mean=0.500, reward_bound=0.229, batch=217 
10890: loss=0.079, reward_mean=0.500, reward_bound=0.277, batch=222 
10891: loss=0.077, reward_mean=0.490, reward_bound=0.282, batch=223 
10892: loss=0.077, reward_mean=0.590, reward_bound=0.314, batch=221 
10893: loss=0.076, reward_mean=0.570, reward_bound=0.349, batch=162 
10894: loss=0.072, reward_mean=0.450, reward_bound=0.082, batch=183 
10895: loss=0.072, reward_mean=0.530, reward_bound=0.098, batch=197 
10896: loss=0.072, reward_mean=0.460, reward_bound=0.135, batch=204 
10897: loss=0.071, reward_mean=0.460, reward_bound=0.185, batch=209 
10898: loss=0.069, reward_mean=0.550, reward_bound=0.206, batch=212 
10899: loss=0.073, reward_mean=0.510, reward_bound=0.236, batch=218 
10900: loss=0.071, reward_mean=0.500, reward_bound=0.282, batch=217 
10901: loss=0.070, reward_mean=0.480, reward_bound=0.308, batch=222 
10902: loss=0.071, reward_mean=0.480, reward_bound=0.314, batch=214 
10903: loss=0.070, reward_mean=0.510, reward_bound=0.345, batch=220 
10904: loss=0.071, reward_mean=0.570, reward_bound=0.349, batch=213 
10905: loss=0.071, reward_mean=0.500, reward_bound=0.282, batch=218 
10906: loss=0.071, reward_mean=0.570, reward_bound=0.353, batch=222 
10907: loss=0.070, reward_mean=0.510, reward_bound=0.314, batch=224 
10908: loss=0.070, reward_mean=0.490, reward_bound=0.384, batch=227 
10909: loss=0.070, reward_mean=0.430, reward_bound=0.380, batch=229 
10910: loss=0.070, reward_mean=0.490, reward_bound=0.364, batch=230 
10911: loss=0.070, reward_mean=0.540, reward_bound=0.376, batch=231 
10912: loss=0.067, reward_mean=0.510, reward_bound=0.387, batch=165 
10913: loss=0.061, reward_mean=0.450, reward_bound=0.109, batch=186 
10914: loss=0.059, reward_mean=0.520, reward_bound=0.115, batch=200 
10915: loss=0.064, reward_mean=0.470, reward_bound=0.150, batch=205 
10916: loss=0.065, reward_mean=0.520, reward_bound=0.185, batch=212 
10917: loss=0.069, reward_mean=0.570, reward_bound=0.213, batch=218 
10918: loss=0.067, reward_mean=0.510, reward_bound=0.208, batch=222 
10919: loss=0.070, reward_mean=0.610, reward_bound=0.254, batch=221 
10920: loss=0.069, reward_mean=0.520, reward_bound=0.206, batch=224 
10921: loss=0.067, reward_mean=0.600, reward_bound=0.282, batch=217 
10922: loss=0.068, reward_mean=0.590, reward_bound=0.254, batch=221 
10923: loss=0.065, reward_mean=0.490, reward_bound=0.314, batch=216 
10924: loss=0.064, reward_mean=0.460, reward_bound=0.298, batch=221 
10925: loss=0.063, reward_mean=0.520, reward_bound=0.349, batch=210 
10926: loss=0.063, reward_mean=0.500, reward_bound=0.288, batch=217 
10927: loss=0.061, reward_mean=0.460, reward_bound=0.342, batch=222 
10928: loss=0.062, reward_mean=0.580, reward_bound=0.349, batch=221 
10929: loss=0.063, reward_mean=0.520, reward_bound=0.387, batch=201 
10930: loss=0.062, reward_mean=0.480, reward_bound=0.150, batch=210 
10931: loss=0.066, reward_mean=0.530, reward_bound=0.222, batch=217 
10932: loss=0.060, reward_mean=0.530, reward_bound=0.254, batch=220 
10933: loss=0.060, reward_mean=0.460, reward_bound=0.282, batch=222 
10934: loss=0.059, reward_mean=0.550, reward_bound=0.314, batch=222 
10935: loss=0.059, reward_mean=0.490, reward_bound=0.324, batch=225 
10936: loss=0.060, reward_mean=0.610, reward_bound=0.349, batch=224 
10937: loss=0.060, reward_mean=0.340, reward_bound=0.387, batch=219 
10938: loss=0.060, reward_mean=0.460, reward_bound=0.360, batch=223 
10939: loss=0.059, reward_mean=0.520, reward_bound=0.384, batch=226 
10940: loss=0.059, reward_mean=0.510, reward_bound=0.301, batch=228 
10941: loss=0.053, reward_mean=0.500, reward_bound=0.430, batch=117 
10942: loss=0.046, reward_mean=0.510, reward_bound=0.020, batch=151 
10943: loss=0.045, reward_mean=0.550, reward_bound=0.052, batch=175 
10944: loss=0.045, reward_mean=0.510, reward_bound=0.072, batch=191 
10945: loss=0.045, reward_mean=0.470, reward_bound=0.089, batch=198 
10946: loss=0.046, reward_mean=0.540, reward_bound=0.109, batch=206 
10947: loss=0.040, reward_mean=0.540, reward_bound=0.135, batch=208 
10948: loss=0.043, reward_mean=0.450, reward_bound=0.150, batch=214 
10949: loss=0.046, reward_mean=0.440, reward_bound=0.167, batch=215 
10950: loss=0.048, reward_mean=0.500, reward_bound=0.185, batch=217 
10951: loss=0.043, reward_mean=0.560, reward_bound=0.206, batch=218 
10952: loss=0.043, reward_mean=0.500, reward_bound=0.229, batch=214 
10953: loss=0.048, reward_mean=0.530, reward_bound=0.254, batch=199 
10954: loss=0.050, reward_mean=0.520, reward_bound=0.254, batch=207 
10955: loss=0.049, reward_mean=0.500, reward_bound=0.182, batch=215 
10956: loss=0.049, reward_mean=0.460, reward_bound=0.254, batch=216 
10957: loss=0.046, reward_mean=0.530, reward_bound=0.282, batch=204 
10958: loss=0.045, reward_mean=0.520, reward_bound=0.224, batch=213 
10959: loss=0.044, reward_mean=0.490, reward_bound=0.229, batch=218 
10960: loss=0.046, reward_mean=0.500, reward_bound=0.254, batch=220 
10961: loss=0.048, reward_mean=0.520, reward_bound=0.282, batch=223 
10962: loss=0.049, reward_mean=0.530, reward_bound=0.314, batch=204 
10963: loss=0.049, reward_mean=0.490, reward_bound=0.224, batch=213 
10964: loss=0.049, reward_mean=0.520, reward_bound=0.301, batch=219 
10965: loss=0.048, reward_mean=0.470, reward_bound=0.282, batch=222 
10966: loss=0.047, reward_mean=0.430, reward_bound=0.263, batch=225 
10967: loss=0.047, reward_mean=0.490, reward_bound=0.289, batch=227 
10968: loss=0.047, reward_mean=0.480, reward_bound=0.282, batch=228 
10969: loss=0.048, reward_mean=0.420, reward_bound=0.314, batch=225 
10970: loss=0.047, reward_mean=0.510, reward_bound=0.321, batch=227 
10971: loss=0.051, reward_mean=0.380, reward_bound=0.349, batch=202 
10972: loss=0.051, reward_mean=0.540, reward_bound=0.254, batch=210 
10973: loss=0.052, reward_mean=0.550, reward_bound=0.229, batch=215 
10974: loss=0.049, reward_mean=0.570, reward_bound=0.282, batch=217 
10975: loss=0.050, reward_mean=0.470, reward_bound=0.150, batch=221 
10976: loss=0.048, reward_mean=0.500, reward_bound=0.282, batch=224 
10977: loss=0.047, reward_mean=0.440, reward_bound=0.308, batch=227 
10978: loss=0.050, reward_mean=0.550, reward_bound=0.314, batch=225 
10979: loss=0.048, reward_mean=0.500, reward_bound=0.349, batch=221 
10980: loss=0.047, reward_mean=0.440, reward_bound=0.185, batch=224 
10981: loss=0.046, reward_mean=0.510, reward_bound=0.342, batch=227 
10982: loss=0.047, reward_mean=0.510, reward_bound=0.349, batch=226 
10983: loss=0.047, reward_mean=0.500, reward_bound=0.349, batch=227 
10984: loss=0.051, reward_mean=0.520, reward_bound=0.387, batch=192 
10985: loss=0.054, reward_mean=0.490, reward_bound=0.145, batch=204 
10986: loss=0.052, reward_mean=0.470, reward_bound=0.149, batch=213 
10987: loss=0.054, reward_mean=0.470, reward_bound=0.220, batch=219 
10988: loss=0.050, reward_mean=0.470, reward_bound=0.229, batch=221 
10989: loss=0.051, reward_mean=0.460, reward_bound=0.254, batch=220 
10990: loss=0.051, reward_mean=0.570, reward_bound=0.304, batch=224 
10991: loss=0.050, reward_mean=0.410, reward_bound=0.311, batch=227 
10992: loss=0.049, reward_mean=0.490, reward_bound=0.314, batch=218 
10993: loss=0.048, reward_mean=0.450, reward_bound=0.254, batch=221 
10994: loss=0.048, reward_mean=0.450, reward_bound=0.254, batch=224 
10995: loss=0.047, reward_mean=0.500, reward_bound=0.342, batch=227 
10996: loss=0.051, reward_mean=0.610, reward_bound=0.349, batch=222 
10997: loss=0.052, reward_mean=0.400, reward_bound=0.263, batch=225 
10998: loss=0.052, reward_mean=0.540, reward_bound=0.289, batch=227 
10999: loss=0.052, reward_mean=0.500, reward_bound=0.342, batch=229 
11000: loss=0.055, reward_mean=0.510, reward_bound=0.387, batch=214 
11001: loss=0.055, reward_mean=0.430, reward_bound=0.249, batch=220 
11002: loss=0.053, reward_mean=0.440, reward_bound=0.314, batch=222 
11003: loss=0.052, reward_mean=0.530, reward_bound=0.324, batch=225 
11004: loss=0.053, reward_mean=0.570, reward_bound=0.387, batch=222 
11005: loss=0.052, reward_mean=0.400, reward_bound=0.292, batch=225 
11006: loss=0.052, reward_mean=0.430, reward_bound=0.349, batch=226 
11007: loss=0.055, reward_mean=0.500, reward_bound=0.430, batch=175 
11008: loss=0.051, reward_mean=0.620, reward_bound=0.112, batch=192 
11009: loss=0.054, reward_mean=0.520, reward_bound=0.150, batch=202 
11010: loss=0.058, reward_mean=0.540, reward_bound=0.213, batch=211 
11011: loss=0.059, reward_mean=0.520, reward_bound=0.229, batch=215 
11012: loss=0.059, reward_mean=0.500, reward_bound=0.254, batch=217 
11013: loss=0.058, reward_mean=0.550, reward_bound=0.249, batch=222 
11014: loss=0.057, reward_mean=0.440, reward_bound=0.263, batch=225 
11015: loss=0.059, reward_mean=0.510, reward_bound=0.282, batch=223 
11016: loss=0.057, reward_mean=0.440, reward_bound=0.314, batch=213 
11017: loss=0.058, reward_mean=0.460, reward_bound=0.314, batch=217 
11018: loss=0.059, reward_mean=0.540, reward_bound=0.277, batch=222 
11019: loss=0.059, reward_mean=0.510, reward_bound=0.349, batch=215 
11020: loss=0.054, reward_mean=0.570, reward_bound=0.387, batch=208 
11021: loss=0.053, reward_mean=0.510, reward_bound=0.254, batch=214 
11022: loss=0.054, reward_mean=0.530, reward_bound=0.311, batch=220 
11023: loss=0.054, reward_mean=0.550, reward_bound=0.314, batch=221 
11024: loss=0.055, reward_mean=0.480, reward_bound=0.282, batch=224 
11025: loss=0.056, reward_mean=0.500, reward_bound=0.349, batch=222 
11026: loss=0.056, reward_mean=0.470, reward_bound=0.185, batch=225 
11027: loss=0.057, reward_mean=0.460, reward_bound=0.282, batch=226 
11028: loss=0.057, reward_mean=0.520, reward_bound=0.298, batch=228 
11029: loss=0.057, reward_mean=0.470, reward_bound=0.317, batch=229 
11030: loss=0.055, reward_mean=0.470, reward_bound=0.349, batch=227 
11031: loss=0.055, reward_mean=0.590, reward_bound=0.387, batch=223 
11032: loss=0.054, reward_mean=0.560, reward_bound=0.387, batch=225 
11033: loss=0.054, reward_mean=0.490, reward_bound=0.430, batch=200 
11034: loss=0.055, reward_mean=0.510, reward_bound=0.240, batch=210 
11035: loss=0.056, reward_mean=0.450, reward_bound=0.254, batch=213 
11036: loss=0.055, reward_mean=0.510, reward_bound=0.254, batch=217 
11037: loss=0.052, reward_mean=0.550, reward_bound=0.308, batch=222 
11038: loss=0.052, reward_mean=0.520, reward_bound=0.245, batch=225 
11039: loss=0.051, reward_mean=0.520, reward_bound=0.349, batch=222 
11040: loss=0.051, reward_mean=0.480, reward_bound=0.229, batch=224 
11041: loss=0.050, reward_mean=0.470, reward_bound=0.384, batch=227 
11042: loss=0.051, reward_mean=0.500, reward_bound=0.387, batch=223 
11043: loss=0.051, reward_mean=0.520, reward_bound=0.430, batch=215 
11044: loss=0.052, reward_mean=0.430, reward_bound=0.289, batch=220 
11045: loss=0.050, reward_mean=0.520, reward_bound=0.349, batch=223 
11046: loss=0.049, reward_mean=0.450, reward_bound=0.413, batch=226 
11047: loss=0.050, reward_mean=0.420, reward_bound=0.430, batch=222 
11048: loss=0.050, reward_mean=0.480, reward_bound=0.387, batch=224 
11049: loss=0.049, reward_mean=0.440, reward_bound=0.384, batch=227 
11050: loss=0.051, reward_mean=0.500, reward_bound=0.380, batch=229 
11051: loss=0.051, reward_mean=0.530, reward_bound=0.387, batch=228 
11052: loss=0.051, reward_mean=0.540, reward_bound=0.392, batch=229 
11053: loss=0.052, reward_mean=0.440, reward_bound=0.360, batch=230 
11054: loss=0.052, reward_mean=0.590, reward_bound=0.430, batch=230 
11055: loss=0.052, reward_mean=0.480, reward_bound=0.464, batch=231 
11056: loss=0.052, reward_mean=0.490, reward_bound=0.387, batch=231 
11057: loss=0.057, reward_mean=0.420, reward_bound=0.478, batch=87 
11058: loss=0.049, reward_mean=0.500, reward_bound=0.006, batch=131 
11059: loss=0.047, reward_mean=0.520, reward_bound=0.010, batch=161 
11060: loss=0.044, reward_mean=0.460, reward_bound=0.031, batch=182 
11061: loss=0.041, reward_mean=0.460, reward_bound=0.044, batch=197 
11062: loss=0.041, reward_mean=0.530, reward_bound=0.070, batch=208 
11063: loss=0.038, reward_mean=0.440, reward_bound=0.089, batch=212 
11064: loss=0.039, reward_mean=0.480, reward_bound=0.109, batch=214 
11065: loss=0.040, reward_mean=0.490, reward_bound=0.122, batch=213 
11066: loss=0.045, reward_mean=0.510, reward_bound=0.150, batch=208 
11067: loss=0.049, reward_mean=0.490, reward_bound=0.167, batch=207 
11068: loss=0.051, reward_mean=0.480, reward_bound=0.185, batch=209 
11069: loss=0.049, reward_mean=0.520, reward_bound=0.206, batch=202 
11070: loss=0.049, reward_mean=0.440, reward_bound=0.167, batch=210 
11071: loss=0.050, reward_mean=0.550, reward_bound=0.229, batch=205 
11072: loss=0.058, reward_mean=0.480, reward_bound=0.254, batch=187 
11073: loss=0.060, reward_mean=0.440, reward_bound=0.132, batch=201 
11074: loss=0.060, reward_mean=0.450, reward_bound=0.167, batch=206 
11075: loss=0.057, reward_mean=0.500, reward_bound=0.217, batch=214 
11076: loss=0.054, reward_mean=0.570, reward_bound=0.229, batch=217 
11077: loss=0.056, reward_mean=0.490, reward_bound=0.254, batch=217 
11078: loss=0.056, reward_mean=0.470, reward_bound=0.282, batch=200 
11079: loss=0.054, reward_mean=0.450, reward_bound=0.175, batch=210 
11080: loss=0.057, reward_mean=0.550, reward_bound=0.254, batch=215 
11081: loss=0.047, reward_mean=0.500, reward_bound=0.314, batch=192 
11082: loss=0.043, reward_mean=0.410, reward_bound=0.113, batch=204 
11083: loss=0.041, reward_mean=0.510, reward_bound=0.167, batch=211 
11084: loss=0.042, reward_mean=0.500, reward_bound=0.185, batch=217 
11085: loss=0.044, reward_mean=0.510, reward_bound=0.229, batch=218 
11086: loss=0.044, reward_mean=0.460, reward_bound=0.254, batch=219 
11087: loss=0.044, reward_mean=0.590, reward_bound=0.282, batch=217 
11088: loss=0.045, reward_mean=0.570, reward_bound=0.282, batch=221 
11089: loss=0.045, reward_mean=0.450, reward_bound=0.314, batch=215 
11090: loss=0.044, reward_mean=0.470, reward_bound=0.254, batch=219 
11091: loss=0.046, reward_mean=0.600, reward_bound=0.349, batch=190 
11092: loss=0.044, reward_mean=0.460, reward_bound=0.150, batch=202 
11093: loss=0.042, reward_mean=0.440, reward_bound=0.167, batch=210 
11094: loss=0.044, reward_mean=0.540, reward_bound=0.180, batch=217 
11095: loss=0.046, reward_mean=0.500, reward_bound=0.206, batch=219 
11096: loss=0.043, reward_mean=0.540, reward_bound=0.254, batch=218 
11097: loss=0.042, reward_mean=0.540, reward_bound=0.282, batch=219 
11098: loss=0.044, reward_mean=0.490, reward_bound=0.314, batch=220 
11099: loss=0.043, reward_mean=0.510, reward_bound=0.274, batch=224 
11100: loss=0.042, reward_mean=0.520, reward_bound=0.345, batch=227 
11101: loss=0.043, reward_mean=0.490, reward_bound=0.349, batch=226 
11102: loss=0.043, reward_mean=0.500, reward_bound=0.335, batch=228 
11103: loss=0.049, reward_mean=0.560, reward_bound=0.387, batch=175 
11104: loss=0.049, reward_mean=0.480, reward_bound=0.109, batch=194 
11105: loss=0.053, reward_mean=0.500, reward_bound=0.164, batch=206 
11106: loss=0.051, reward_mean=0.490, reward_bound=0.185, batch=213 
11107: loss=0.051, reward_mean=0.530, reward_bound=0.229, batch=212 
11108: loss=0.050, reward_mean=0.500, reward_bound=0.254, batch=211 
11109: loss=0.050, reward_mean=0.480, reward_bound=0.282, batch=205 
11110: loss=0.053, reward_mean=0.500, reward_bound=0.210, batch=213 
11111: loss=0.053, reward_mean=0.490, reward_bound=0.314, batch=215 
11112: loss=0.053, reward_mean=0.440, reward_bound=0.282, batch=217 
11113: loss=0.052, reward_mean=0.520, reward_bound=0.282, batch=220 
11114: loss=0.052, reward_mean=0.430, reward_bound=0.329, batch=224 
11115: loss=0.051, reward_mean=0.390, reward_bound=0.349, batch=215 
11116: loss=0.050, reward_mean=0.550, reward_bound=0.254, batch=219 
11117: loss=0.050, reward_mean=0.580, reward_bound=0.343, batch=223 
11118: loss=0.053, reward_mean=0.430, reward_bound=0.387, batch=209 
11119: loss=0.053, reward_mean=0.510, reward_bound=0.265, batch=216 
11120: loss=0.058, reward_mean=0.460, reward_bound=0.254, batch=220 
11121: loss=0.056, reward_mean=0.400, reward_bound=0.314, batch=223 
11122: loss=0.055, reward_mean=0.520, reward_bound=0.335, batch=226 
11123: loss=0.053, reward_mean=0.500, reward_bound=0.349, batch=222 
11124: loss=0.053, reward_mean=0.600, reward_bound=0.387, batch=218 
11125: loss=0.052, reward_mean=0.450, reward_bound=0.257, batch=222 
11126: loss=0.052, reward_mean=0.450, reward_bound=0.292, batch=225 
11127: loss=0.051, reward_mean=0.530, reward_bound=0.356, batch=227 
11128: loss=0.051, reward_mean=0.470, reward_bound=0.380, batch=229 
11129: loss=0.052, reward_mean=0.430, reward_bound=0.387, batch=227 
11130: loss=0.053, reward_mean=0.470, reward_bound=0.342, batch=229 
11131: loss=0.047, reward_mean=0.480, reward_bound=0.430, batch=169 
11132: loss=0.045, reward_mean=0.490, reward_bound=0.067, batch=188 
11133: loss=0.051, reward_mean=0.410, reward_bound=0.081, batch=201 
11134: loss=0.048, reward_mean=0.550, reward_bound=0.167, batch=209 
11135: loss=0.046, reward_mean=0.430, reward_bound=0.185, batch=215 
11136: loss=0.049, reward_mean=0.520, reward_bound=0.210, batch=220 
11137: loss=0.048, reward_mean=0.540, reward_bound=0.229, batch=222 
11138: loss=0.047, reward_mean=0.560, reward_bound=0.254, batch=221 
11139: loss=0.045, reward_mean=0.490, reward_bound=0.282, batch=213 
11140: loss=0.043, reward_mean=0.550, reward_bound=0.314, batch=210 
11141: loss=0.041, reward_mean=0.570, reward_bound=0.274, batch=217 
11142: loss=0.040, reward_mean=0.530, reward_bound=0.342, batch=222 
11143: loss=0.039, reward_mean=0.560, reward_bound=0.349, batch=211 
11144: loss=0.037, reward_mean=0.480, reward_bound=0.206, batch=217 
11145: loss=0.037, reward_mean=0.510, reward_bound=0.277, batch=222 
11146: loss=0.036, reward_mean=0.520, reward_bound=0.292, batch=225 
11147: loss=0.037, reward_mean=0.450, reward_bound=0.314, batch=219 
11148: loss=0.037, reward_mean=0.370, reward_bound=0.328, batch=223 
11149: loss=0.036, reward_mean=0.490, reward_bound=0.349, batch=225 
11150: loss=0.040, reward_mean=0.520, reward_bound=0.387, batch=208 
11151: loss=0.043, reward_mean=0.460, reward_bound=0.282, batch=214 
11152: loss=0.044, reward_mean=0.510, reward_bound=0.280, batch=220 
11153: loss=0.043, reward_mean=0.530, reward_bound=0.304, batch=224 
11154: loss=0.037, reward_mean=0.560, reward_bound=0.349, batch=221 
11155: loss=0.037, reward_mean=0.460, reward_bound=0.282, batch=222 
11156: loss=0.039, reward_mean=0.410, reward_bound=0.360, batch=225 
11157: loss=0.038, reward_mean=0.490, reward_bound=0.356, batch=227 
11158: loss=0.038, reward_mean=0.580, reward_bound=0.387, batch=219 
11159: loss=0.037, reward_mean=0.500, reward_bound=0.364, batch=223 
11160: loss=0.037, reward_mean=0.460, reward_bound=0.372, batch=226 
11161: loss=0.037, reward_mean=0.580, reward_bound=0.349, batch=227 
11162: loss=0.037, reward_mean=0.490, reward_bound=0.422, batch=229 
11163: loss=0.042, reward_mean=0.540, reward_bound=0.430, batch=197 
11164: loss=0.041, reward_mean=0.550, reward_bound=0.224, batch=208 
11165: loss=0.040, reward_mean=0.510, reward_bound=0.208, batch=215 
11166: loss=0.041, reward_mean=0.520, reward_bound=0.234, batch=220 
11167: loss=0.042, reward_mean=0.540, reward_bound=0.282, batch=219 
11168: loss=0.045, reward_mean=0.570, reward_bound=0.314, batch=221 
11169: loss=0.045, reward_mean=0.510, reward_bound=0.349, batch=222 
11170: loss=0.044, reward_mean=0.500, reward_bound=0.336, batch=225 
11171: loss=0.041, reward_mean=0.570, reward_bound=0.387, batch=215 
11172: loss=0.040, reward_mean=0.500, reward_bound=0.260, batch=220 
11173: loss=0.039, reward_mean=0.520, reward_bound=0.338, batch=224 
11174: loss=0.039, reward_mean=0.480, reward_bound=0.345, batch=227 
11175: loss=0.038, reward_mean=0.450, reward_bound=0.342, batch=229 
11176: loss=0.041, reward_mean=0.570, reward_bound=0.387, batch=225 
11177: loss=0.042, reward_mean=0.570, reward_bound=0.430, batch=211 
11178: loss=0.040, reward_mean=0.530, reward_bound=0.314, batch=217 
11179: loss=0.039, reward_mean=0.510, reward_bound=0.272, batch=222 
11180: loss=0.039, reward_mean=0.550, reward_bound=0.282, batch=224 
11181: loss=0.039, reward_mean=0.560, reward_bound=0.314, batch=226 
11182: loss=0.040, reward_mean=0.520, reward_bound=0.349, batch=223 
11183: loss=0.042, reward_mean=0.550, reward_bound=0.387, batch=222 
11184: loss=0.042, reward_mean=0.470, reward_bound=0.282, batch=224 
11185: loss=0.041, reward_mean=0.460, reward_bound=0.345, batch=227 
11186: loss=0.041, reward_mean=0.510, reward_bound=0.308, batch=229 
11187: loss=0.041, reward_mean=0.470, reward_bound=0.349, batch=229 
11188: loss=0.041, reward_mean=0.510, reward_bound=0.387, batch=227 
11189: loss=0.041, reward_mean=0.460, reward_bound=0.349, batch=228 
11190: loss=0.043, reward_mean=0.490, reward_bound=0.353, batch=229 
11191: loss=0.043, reward_mean=0.530, reward_bound=0.349, batch=229 
11192: loss=0.042, reward_mean=0.580, reward_bound=0.430, batch=221 
11193: loss=0.042, reward_mean=0.510, reward_bound=0.314, batch=223 
11194: loss=0.042, reward_mean=0.380, reward_bound=0.349, batch=224 
11195: loss=0.041, reward_mean=0.520, reward_bound=0.254, batch=226 
11196: loss=0.043, reward_mean=0.500, reward_bound=0.368, batch=228 
11197: loss=0.043, reward_mean=0.560, reward_bound=0.387, batch=228 
11198: loss=0.043, reward_mean=0.540, reward_bound=0.392, batch=229 
11199: loss=0.043, reward_mean=0.480, reward_bound=0.405, batch=230 
11200: loss=0.043, reward_mean=0.480, reward_bound=0.282, batch=230 
11201: loss=0.043, reward_mean=0.550, reward_bound=0.418, batch=231 
11202: loss=0.041, reward_mean=0.490, reward_bound=0.430, batch=230 
11203: loss=0.043, reward_mean=0.540, reward_bound=0.478, batch=141 
11204: loss=0.042, reward_mean=0.460, reward_bound=0.058, batch=168 
11205: loss=0.040, reward_mean=0.490, reward_bound=0.065, batch=186 
11206: loss=0.041, reward_mean=0.480, reward_bound=0.084, batch=200 
11207: loss=0.040, reward_mean=0.550, reward_bound=0.122, batch=207 
11208: loss=0.041, reward_mean=0.450, reward_bound=0.150, batch=211 
11209: loss=0.041, reward_mean=0.490, reward_bound=0.167, batch=215 
11210: loss=0.042, reward_mean=0.500, reward_bound=0.189, batch=220 
11211: loss=0.043, reward_mean=0.510, reward_bound=0.206, batch=231 
11212: loss=0.044, reward_mean=0.550, reward_bound=0.206, batch=231 
11213: loss=0.043, reward_mean=0.570, reward_bound=0.229, batch=231 
11214: loss=0.044, reward_mean=0.590, reward_bound=0.254, batch=231 
11215: loss=0.044, reward_mean=0.570, reward_bound=0.282, batch=220 
11216: loss=0.043, reward_mean=0.480, reward_bound=0.304, batch=224 
11217: loss=0.038, reward_mean=0.560, reward_bound=0.314, batch=209 
11218: loss=0.037, reward_mean=0.480, reward_bound=0.239, batch=216 
11219: loss=0.039, reward_mean=0.450, reward_bound=0.176, batch=221 
11220: loss=0.036, reward_mean=0.540, reward_bound=0.254, batch=219 
11221: loss=0.036, reward_mean=0.550, reward_bound=0.295, batch=223 
11222: loss=0.037, reward_mean=0.480, reward_bound=0.314, batch=225 
11223: loss=0.039, reward_mean=0.470, reward_bound=0.349, batch=203 
11224: loss=0.040, reward_mean=0.450, reward_bound=0.206, batch=210 
11225: loss=0.039, reward_mean=0.490, reward_bound=0.254, batch=216 
11226: loss=0.038, reward_mean=0.460, reward_bound=0.268, batch=221 
11227: loss=0.039, reward_mean=0.560, reward_bound=0.314, batch=222 
11228: loss=0.038, reward_mean=0.510, reward_bound=0.302, batch=225 
11229: loss=0.038, reward_mean=0.460, reward_bound=0.356, batch=227 
11230: loss=0.040, reward_mean=0.550, reward_bound=0.380, batch=229 
11231: loss=0.040, reward_mean=0.470, reward_bound=0.364, batch=230 
11232: loss=0.039, reward_mean=0.500, reward_bound=0.387, batch=202 
11233: loss=0.043, reward_mean=0.470, reward_bound=0.206, batch=212 
11234: loss=0.042, reward_mean=0.450, reward_bound=0.206, batch=222 
11235: loss=0.041, reward_mean=0.470, reward_bound=0.206, batch=226 
11236: loss=0.038, reward_mean=0.570, reward_bound=0.254, batch=226 
11237: loss=0.039, reward_mean=0.470, reward_bound=0.282, batch=226 
11238: loss=0.041, reward_mean=0.560, reward_bound=0.314, batch=227 
11239: loss=0.040, reward_mean=0.500, reward_bound=0.349, batch=223 
11240: loss=0.041, reward_mean=0.400, reward_bound=0.271, batch=226 
11241: loss=0.041, reward_mean=0.490, reward_bound=0.351, batch=228 
11242: loss=0.040, reward_mean=0.460, reward_bound=0.387, batch=225 
11243: loss=0.039, reward_mean=0.540, reward_bound=0.396, batch=227 
11244: loss=0.042, reward_mean=0.450, reward_bound=0.430, batch=199 
11245: loss=0.039, reward_mean=0.490, reward_bound=0.194, batch=209 
11246: loss=0.045, reward_mean=0.490, reward_bound=0.229, batch=213 
11247: loss=0.046, reward_mean=0.450, reward_bound=0.229, batch=216 
11248: loss=0.048, reward_mean=0.490, reward_bound=0.254, batch=220 
11249: loss=0.048, reward_mean=0.520, reward_bound=0.282, batch=218 
11250: loss=0.048, reward_mean=0.490, reward_bound=0.314, batch=220 
11251: loss=0.047, reward_mean=0.560, reward_bound=0.296, batch=224 
11252: loss=0.049, reward_mean=0.560, reward_bound=0.349, batch=225 
11253: loss=0.049, reward_mean=0.530, reward_bound=0.349, batch=226 
11254: loss=0.049, reward_mean=0.480, reward_bound=0.387, batch=217 
11255: loss=0.048, reward_mean=0.610, reward_bound=0.308, batch=222 
11256: loss=0.049, reward_mean=0.550, reward_bound=0.314, batch=224 
11257: loss=0.048, reward_mean=0.530, reward_bound=0.226, batch=227 
11258: loss=0.055, reward_mean=0.470, reward_bound=0.308, batch=229 
11259: loss=0.049, reward_mean=0.510, reward_bound=0.349, batch=227 
11260: loss=0.049, reward_mean=0.520, reward_bound=0.342, batch=229 
11261: loss=0.050, reward_mean=0.570, reward_bound=0.364, batch=230 
11262: loss=0.049, reward_mean=0.570, reward_bound=0.387, batch=229 
11263: loss=0.049, reward_mean=0.440, reward_bound=0.381, batch=230 
11264: loss=0.048, reward_mean=0.460, reward_bound=0.418, batch=231 
11265: loss=0.048, reward_mean=0.450, reward_bound=0.430, batch=214 
11266: loss=0.047, reward_mean=0.450, reward_bound=0.204, batch=220 
11267: loss=0.048, reward_mean=0.500, reward_bound=0.274, batch=224 
11268: loss=0.048, reward_mean=0.470, reward_bound=0.314, batch=226 
11269: loss=0.047, reward_mean=0.570, reward_bound=0.368, batch=228 
11270: loss=0.046, reward_mean=0.470, reward_bound=0.387, batch=228 
11271: loss=0.047, reward_mean=0.430, reward_bound=0.430, batch=222 
11272: loss=0.046, reward_mean=0.530, reward_bound=0.400, batch=225 
11273: loss=0.046, reward_mean=0.550, reward_bound=0.260, batch=227 
11274: loss=0.045, reward_mean=0.590, reward_bound=0.342, batch=229 
11275: loss=0.046, reward_mean=0.510, reward_bound=0.349, batch=229 
11276: loss=0.046, reward_mean=0.490, reward_bound=0.405, batch=230 
11277: loss=0.046, reward_mean=0.460, reward_bound=0.430, batch=228 
11278: loss=0.046, reward_mean=0.610, reward_bound=0.478, batch=230 
11279: loss=0.046, reward_mean=0.410, reward_bound=0.464, batch=231 
11280: loss=0.049, reward_mean=0.500, reward_bound=0.478, batch=188 
11281: loss=0.049, reward_mean=0.430, reward_bound=0.123, batch=201 
11282: loss=0.049, reward_mean=0.560, reward_bound=0.185, batch=208 
11283: loss=0.053, reward_mean=0.560, reward_bound=0.208, batch=215 
11284: loss=0.053, reward_mean=0.560, reward_bound=0.229, batch=216 
11285: loss=0.053, reward_mean=0.420, reward_bound=0.254, batch=218 
11286: loss=0.051, reward_mean=0.500, reward_bound=0.282, batch=221 
11287: loss=0.052, reward_mean=0.480, reward_bound=0.314, batch=216 
11288: loss=0.051, reward_mean=0.590, reward_bound=0.254, batch=220 
11289: loss=0.050, reward_mean=0.460, reward_bound=0.338, batch=224 
11290: loss=0.050, reward_mean=0.460, reward_bound=0.314, batch=225 
11291: loss=0.050, reward_mean=0.550, reward_bound=0.349, batch=212 
11292: loss=0.049, reward_mean=0.480, reward_bound=0.324, batch=218 
11293: loss=0.050, reward_mean=0.490, reward_bound=0.286, batch=222 
11294: loss=0.048, reward_mean=0.560, reward_bound=0.349, batch=222 
11295: loss=0.047, reward_mean=0.460, reward_bound=0.349, batch=224 
11296: loss=0.051, reward_mean=0.560, reward_bound=0.387, batch=211 
11297: loss=0.049, reward_mean=0.510, reward_bound=0.314, batch=216 
11298: loss=0.051, reward_mean=0.560, reward_bound=0.349, batch=218 
11299: loss=0.051, reward_mean=0.530, reward_bound=0.314, batch=220 
11300: loss=0.049, reward_mean=0.480, reward_bound=0.304, batch=224 
11301: loss=0.049, reward_mean=0.420, reward_bound=0.314, batch=225 
11302: loss=0.050, reward_mean=0.560, reward_bound=0.349, batch=225 
11303: loss=0.050, reward_mean=0.480, reward_bound=0.387, batch=224 
11304: loss=0.050, reward_mean=0.510, reward_bound=0.387, batch=226 
11305: loss=0.051, reward_mean=0.520, reward_bound=0.430, batch=210 
11306: loss=0.049, reward_mean=0.430, reward_bound=0.206, batch=218 
11307: loss=0.049, reward_mean=0.450, reward_bound=0.260, batch=222 
11308: loss=0.051, reward_mean=0.510, reward_bound=0.349, batch=222 
11309: loss=0.051, reward_mean=0.500, reward_bound=0.387, batch=219 
11310: loss=0.053, reward_mean=0.500, reward_bound=0.405, batch=223 
11311: loss=0.052, reward_mean=0.600, reward_bound=0.413, batch=226 
11312: loss=0.050, reward_mean=0.530, reward_bound=0.430, batch=219 
11313: loss=0.049, reward_mean=0.520, reward_bound=0.295, batch=223 
11314: loss=0.050, reward_mean=0.520, reward_bound=0.335, batch=226 
11315: loss=0.050, reward_mean=0.480, reward_bound=0.349, batch=226 
11316: loss=0.050, reward_mean=0.420, reward_bound=0.321, batch=228 
11317: loss=0.050, reward_mean=0.480, reward_bound=0.387, batch=226 
11318: loss=0.050, reward_mean=0.510, reward_bound=0.409, batch=228 
11319: loss=0.049, reward_mean=0.550, reward_bound=0.430, batch=227 
11320: loss=0.048, reward_mean=0.530, reward_bound=0.349, batch=228 
11321: loss=0.048, reward_mean=0.470, reward_bound=0.430, batch=228 
11322: loss=0.048, reward_mean=0.510, reward_bound=0.478, batch=230 
11323: loss=0.048, reward_mean=0.550, reward_bound=0.464, batch=231 
11324: loss=0.048, reward_mean=0.460, reward_bound=0.387, batch=231 
11325: loss=0.048, reward_mean=0.480, reward_bound=0.478, batch=209 
11326: loss=0.046, reward_mean=0.510, reward_bound=0.174, batch=216 
11327: loss=0.044, reward_mean=0.480, reward_bound=0.229, batch=220 
11328: loss=0.045, reward_mean=0.530, reward_bound=0.274, batch=224 
11329: loss=0.047, reward_mean=0.490, reward_bound=0.282, batch=226 
11330: loss=0.048, reward_mean=0.470, reward_bound=0.314, batch=225 
11331: loss=0.048, reward_mean=0.430, reward_bound=0.349, batch=226 
11332: loss=0.048, reward_mean=0.460, reward_bound=0.387, batch=220 
11333: loss=0.047, reward_mean=0.530, reward_bound=0.338, batch=224 
11334: loss=0.050, reward_mean=0.530, reward_bound=0.384, batch=227 
11335: loss=0.050, reward_mean=0.480, reward_bound=0.380, batch=229 
11336: loss=0.049, reward_mean=0.480, reward_bound=0.364, batch=230 
11337: loss=0.049, reward_mean=0.510, reward_bound=0.376, batch=231 
11338: loss=0.049, reward_mean=0.490, reward_bound=0.349, batch=231 
11339: loss=0.051, reward_mean=0.480, reward_bound=0.387, batch=231 
11340: loss=0.049, reward_mean=0.520, reward_bound=0.430, batch=226 
11341: loss=0.048, reward_mean=0.540, reward_bound=0.454, batch=228 
11342: loss=0.048, reward_mean=0.490, reward_bound=0.478, batch=230 
11343: loss=0.048, reward_mean=0.560, reward_bound=0.464, batch=231 
11344: loss=0.048, reward_mean=0.470, reward_bound=0.430, batch=231 
11345: loss=0.048, reward_mean=0.460, reward_bound=0.387, batch=231 
11346: loss=0.048, reward_mean=0.500, reward_bound=0.478, batch=217 
11347: loss=0.050, reward_mean=0.520, reward_bound=0.349, batch=221 
11348: loss=0.051, reward_mean=0.460, reward_bound=0.349, batch=223 
11349: loss=0.050, reward_mean=0.500, reward_bound=0.322, batch=226 
11350: loss=0.050, reward_mean=0.560, reward_bound=0.282, batch=227 
11351: loss=0.053, reward_mean=0.540, reward_bound=0.380, batch=229 
11352: loss=0.051, reward_mean=0.460, reward_bound=0.387, batch=226 
11353: loss=0.050, reward_mean=0.450, reward_bound=0.387, batch=227 
11354: loss=0.050, reward_mean=0.540, reward_bound=0.414, batch=229 
11355: loss=0.050, reward_mean=0.440, reward_bound=0.381, batch=230 
11356: loss=0.051, reward_mean=0.420, reward_bound=0.430, batch=224 
11357: loss=0.051, reward_mean=0.510, reward_bound=0.430, batch=225 
11358: loss=0.051, reward_mean=0.490, reward_bound=0.440, batch=227 
11359: loss=0.050, reward_mean=0.420, reward_bound=0.342, batch=229 
11360: loss=0.050, reward_mean=0.470, reward_bound=0.328, batch=230 
11361: loss=0.050, reward_mean=0.530, reward_bound=0.349, batch=230 
11362: loss=0.050, reward_mean=0.580, reward_bound=0.418, batch=231 
11363: loss=0.049, reward_mean=0.450, reward_bound=0.478, batch=226 
11364: loss=0.049, reward_mean=0.440, reward_bound=0.505, batch=228 
11365: loss=0.049, reward_mean=0.420, reward_bound=0.484, batch=229 
11366: loss=0.049, reward_mean=0.520, reward_bound=0.387, batch=229 
11367: loss=0.048, reward_mean=0.520, reward_bound=0.500, batch=230 
11368: loss=0.048, reward_mean=0.460, reward_bound=0.501, batch=231 
11369: loss=0.048, reward_mean=0.590, reward_bound=0.478, batch=231 
11371: loss=0.029, reward_mean=0.510, reward_bound=0.000, batch=51 
11372: loss=0.028, reward_mean=0.460, reward_bound=0.000, batch=97 
11373: loss=0.033, reward_mean=0.510, reward_bound=0.000, batch=138 
11374: loss=0.036, reward_mean=0.510, reward_bound=0.003, batch=166 
11375: loss=0.037, reward_mean=0.520, reward_bound=0.009, batch=186 
11376: loss=0.036, reward_mean=0.490, reward_bound=0.016, batch=199 
11377: loss=0.039, reward_mean=0.510, reward_bound=0.025, batch=206 
11378: loss=0.038, reward_mean=0.500, reward_bound=0.038, batch=210 
11379: loss=0.042, reward_mean=0.520, reward_bound=0.052, batch=208 
11380: loss=0.044, reward_mean=0.520, reward_bound=0.072, batch=207 
11381: loss=0.046, reward_mean=0.520, reward_bound=0.089, batch=221 
11382: loss=0.046, reward_mean=0.440, reward_bound=0.098, batch=212 
11383: loss=0.045, reward_mean=0.480, reward_bound=0.109, batch=210 
11384: loss=0.046, reward_mean=0.520, reward_bound=0.122, batch=211 
11385: loss=0.050, reward_mean=0.510, reward_bound=0.135, batch=202 
11386: loss=0.051, reward_mean=0.560, reward_bound=0.150, batch=199 
11387: loss=0.051, reward_mean=0.580, reward_bound=0.167, batch=191 
11388: loss=0.051, reward_mean=0.530, reward_bound=0.135, batch=202 
11389: loss=0.051, reward_mean=0.490, reward_bound=0.140, batch=211 
11390: loss=0.050, reward_mean=0.550, reward_bound=0.185, batch=195 
11391: loss=0.049, reward_mean=0.530, reward_bound=0.170, batch=206 
11392: loss=0.051, reward_mean=0.480, reward_bound=0.206, batch=192 
11393: loss=0.049, reward_mean=0.450, reward_bound=0.185, batch=201 
11394: loss=0.053, reward_mean=0.450, reward_bound=0.206, batch=206 
11395: loss=0.052, reward_mean=0.490, reward_bound=0.217, batch=214 
11396: loss=0.052, reward_mean=0.570, reward_bound=0.229, batch=189 
11397: loss=0.053, reward_mean=0.450, reward_bound=0.174, batch=202 
11398: loss=0.053, reward_mean=0.520, reward_bound=0.167, batch=210 
11399: loss=0.055, reward_mean=0.430, reward_bound=0.206, batch=218 
11400: loss=0.056, reward_mean=0.510, reward_bound=0.206, batch=221 
11401: loss=0.055, reward_mean=0.510, reward_bound=0.229, batch=224 
11402: loss=0.060, reward_mean=0.440, reward_bound=0.254, batch=191 
11403: loss=0.069, reward_mean=0.530, reward_bound=0.282, batch=164 
11404: loss=0.061, reward_mean=0.440, reward_bound=0.038, batch=185 
11405: loss=0.066, reward_mean=0.470, reward_bound=0.122, batch=197 
11406: loss=0.067, reward_mean=0.530, reward_bound=0.119, batch=208 
11407: loss=0.068, reward_mean=0.560, reward_bound=0.167, batch=213 
11408: loss=0.066, reward_mean=0.470, reward_bound=0.206, batch=215 
11409: loss=0.067, reward_mean=0.540, reward_bound=0.229, batch=215 
11410: loss=0.066, reward_mean=0.450, reward_bound=0.254, batch=217 
11411: loss=0.069, reward_mean=0.490, reward_bound=0.282, batch=213 
11412: loss=0.069, reward_mean=0.470, reward_bound=0.206, batch=218 
11413: loss=0.075, reward_mean=0.520, reward_bound=0.314, batch=169 
11414: loss=0.074, reward_mean=0.480, reward_bound=0.089, batch=187 
11415: loss=0.070, reward_mean=0.480, reward_bound=0.150, batch=199 
11416: loss=0.067, reward_mean=0.540, reward_bound=0.185, batch=207 
11417: loss=0.065, reward_mean=0.410, reward_bound=0.206, batch=213 
11418: loss=0.066, reward_mean=0.540, reward_bound=0.229, batch=215 
11419: loss=0.069, reward_mean=0.480, reward_bound=0.254, batch=212 
11420: loss=0.069, reward_mean=0.480, reward_bound=0.282, batch=214 
11421: loss=0.071, reward_mean=0.450, reward_bound=0.314, batch=213 
11422: loss=0.070, reward_mean=0.530, reward_bound=0.244, batch=219 
11423: loss=0.068, reward_mean=0.570, reward_bound=0.295, batch=223 
11424: loss=0.075, reward_mean=0.510, reward_bound=0.349, batch=170 
11425: loss=0.073, reward_mean=0.550, reward_bound=0.098, batch=188 
11426: loss=0.071, reward_mean=0.460, reward_bound=0.122, batch=198 
11427: loss=0.068, reward_mean=0.510, reward_bound=0.167, batch=204 
11428: loss=0.069, reward_mean=0.470, reward_bound=0.206, batch=210 
11429: loss=0.069, reward_mean=0.570, reward_bound=0.229, batch=212 
11430: loss=0.065, reward_mean=0.550, reward_bound=0.254, batch=215 
11431: loss=0.067, reward_mean=0.450, reward_bound=0.282, batch=205 
11432: loss=0.067, reward_mean=0.590, reward_bound=0.254, batch=212 
11433: loss=0.067, reward_mean=0.490, reward_bound=0.236, batch=218 
11434: loss=0.066, reward_mean=0.580, reward_bound=0.229, batch=221 
11435: loss=0.068, reward_mean=0.500, reward_bound=0.314, batch=214 
11436: loss=0.067, reward_mean=0.500, reward_bound=0.349, batch=205 
11437: loss=0.065, reward_mean=0.470, reward_bound=0.289, batch=213 
11438: loss=0.065, reward_mean=0.460, reward_bound=0.314, batch=217 
11439: loss=0.065, reward_mean=0.410, reward_bound=0.282, batch=220 
11440: loss=0.064, reward_mean=0.460, reward_bound=0.304, batch=224 
11441: loss=0.063, reward_mean=0.430, reward_bound=0.345, batch=227 
11442: loss=0.064, reward_mean=0.530, reward_bound=0.335, batch=229 
11443: loss=0.063, reward_mean=0.510, reward_bound=0.349, batch=223 
11444: loss=0.063, reward_mean=0.550, reward_bound=0.372, batch=226 
11445: loss=0.064, reward_mean=0.460, reward_bound=0.349, batch=227 
11446: loss=0.065, reward_mean=0.490, reward_bound=0.380, batch=229 
11447: loss=0.063, reward_mean=0.540, reward_bound=0.387, batch=142 
11448: loss=0.053, reward_mean=0.480, reward_bound=0.080, batch=165 
11449: loss=0.051, reward_mean=0.440, reward_bound=0.091, batch=185 
11450: loss=0.049, reward_mean=0.550, reward_bound=0.112, batch=199 
11451: loss=0.053, reward_mean=0.470, reward_bound=0.135, batch=204 
11452: loss=0.054, reward_mean=0.580, reward_bound=0.167, batch=208 
11453: loss=0.051, reward_mean=0.490, reward_bound=0.206, batch=212 
11454: loss=0.051, reward_mean=0.510, reward_bound=0.229, batch=205 
11455: loss=0.052, reward_mean=0.550, reward_bound=0.229, batch=212 
11456: loss=0.055, reward_mean=0.450, reward_bound=0.254, batch=205 
11457: loss=0.054, reward_mean=0.540, reward_bound=0.229, batch=211 
11458: loss=0.052, reward_mean=0.500, reward_bound=0.282, batch=202 
11459: loss=0.052, reward_mean=0.540, reward_bound=0.282, batch=210 
11460: loss=0.058, reward_mean=0.500, reward_bound=0.314, batch=207 
11461: loss=0.056, reward_mean=0.490, reward_bound=0.302, batch=215 
11462: loss=0.057, reward_mean=0.490, reward_bound=0.314, batch=216 
11463: loss=0.057, reward_mean=0.450, reward_bound=0.314, batch=219 
11464: loss=0.062, reward_mean=0.580, reward_bound=0.349, batch=196 
11465: loss=0.067, reward_mean=0.480, reward_bound=0.150, batch=206 
11466: loss=0.065, reward_mean=0.420, reward_bound=0.217, batch=214 
11467: loss=0.065, reward_mean=0.530, reward_bound=0.229, batch=217 
11468: loss=0.066, reward_mean=0.450, reward_bound=0.282, batch=221 
11469: loss=0.060, reward_mean=0.540, reward_bound=0.314, batch=217 
11470: loss=0.059, reward_mean=0.550, reward_bound=0.308, batch=222 
11471: loss=0.059, reward_mean=0.410, reward_bound=0.314, batch=224 
11472: loss=0.058, reward_mean=0.570, reward_bound=0.349, batch=223 
11473: loss=0.058, reward_mean=0.500, reward_bound=0.324, batch=226 
11474: loss=0.060, reward_mean=0.540, reward_bound=0.387, batch=205 
11475: loss=0.061, reward_mean=0.500, reward_bound=0.289, batch=213 
11476: loss=0.060, reward_mean=0.500, reward_bound=0.254, batch=218 
11477: loss=0.059, reward_mean=0.540, reward_bound=0.257, batch=222 
11478: loss=0.060, reward_mean=0.540, reward_bound=0.324, batch=225 
11479: loss=0.058, reward_mean=0.490, reward_bound=0.349, batch=223 
11480: loss=0.057, reward_mean=0.500, reward_bound=0.290, batch=226 
11481: loss=0.057, reward_mean=0.540, reward_bound=0.349, batch=225 
11482: loss=0.059, reward_mean=0.490, reward_bound=0.356, batch=227 
11483: loss=0.058, reward_mean=0.580, reward_bound=0.349, batch=228 
11484: loss=0.060, reward_mean=0.510, reward_bound=0.387, batch=222 
11485: loss=0.059, reward_mean=0.430, reward_bound=0.336, batch=225 
11486: loss=0.059, reward_mean=0.450, reward_bound=0.303, batch=227 
11487: loss=0.058, reward_mean=0.470, reward_bound=0.373, batch=229 
11488: loss=0.059, reward_mean=0.530, reward_bound=0.387, batch=228 
11489: loss=0.059, reward_mean=0.510, reward_bound=0.387, batch=228 
11490: loss=0.055, reward_mean=0.540, reward_bound=0.430, batch=123 
11491: loss=0.046, reward_mean=0.460, reward_bound=0.027, batch=156 
11492: loss=0.043, reward_mean=0.480, reward_bound=0.072, batch=178 
11493: loss=0.044, reward_mean=0.510, reward_bound=0.098, batch=192 
11494: loss=0.044, reward_mean=0.500, reward_bound=0.122, batch=197 
11495: loss=0.042, reward_mean=0.460, reward_bound=0.150, batch=203 
11496: loss=0.042, reward_mean=0.590, reward_bound=0.167, batch=204 
11497: loss=0.044, reward_mean=0.570, reward_bound=0.185, batch=204 
11498: loss=0.048, reward_mean=0.490, reward_bound=0.206, batch=207 
11499: loss=0.052, reward_mean=0.500, reward_bound=0.229, batch=206 
11500: loss=0.053, reward_mean=0.520, reward_bound=0.254, batch=207 
11501: loss=0.055, reward_mean=0.400, reward_bound=0.282, batch=202 
11502: loss=0.059, reward_mean=0.540, reward_bound=0.314, batch=192 
11503: loss=0.059, reward_mean=0.530, reward_bound=0.145, batch=204 
11504: loss=0.059, reward_mean=0.580, reward_bound=0.226, batch=213 
11505: loss=0.057, reward_mean=0.520, reward_bound=0.254, batch=218 
11506: loss=0.060, reward_mean=0.510, reward_bound=0.282, batch=219 
11507: loss=0.060, reward_mean=0.520, reward_bound=0.263, batch=223 
11508: loss=0.062, reward_mean=0.530, reward_bound=0.314, batch=218 
11509: loss=0.056, reward_mean=0.470, reward_bound=0.349, batch=201 
11510: loss=0.056, reward_mean=0.530, reward_bound=0.314, batch=208 
11511: loss=0.054, reward_mean=0.390, reward_bound=0.171, batch=215 
11512: loss=0.058, reward_mean=0.580, reward_bound=0.282, batch=219 
11513: loss=0.058, reward_mean=0.450, reward_bound=0.349, batch=217 
11514: loss=0.057, reward_mean=0.580, reward_bound=0.282, batch=221 
11515: loss=0.056, reward_mean=0.510, reward_bound=0.229, batch=223 
11516: loss=0.056, reward_mean=0.500, reward_bound=0.349, batch=224 
11517: loss=0.056, reward_mean=0.430, reward_bound=0.314, batch=226 
11518: loss=0.056, reward_mean=0.510, reward_bound=0.387, batch=192 
11519: loss=0.054, reward_mean=0.540, reward_bound=0.191, batch=204 
11520: loss=0.053, reward_mean=0.430, reward_bound=0.167, batch=212 
11521: loss=0.057, reward_mean=0.580, reward_bound=0.229, batch=217 
11522: loss=0.055, reward_mean=0.510, reward_bound=0.254, batch=218 
11523: loss=0.055, reward_mean=0.530, reward_bound=0.282, batch=219 
11524: loss=0.054, reward_mean=0.440, reward_bound=0.314, batch=218 
11525: loss=0.056, reward_mean=0.470, reward_bound=0.349, batch=217 
11526: loss=0.055, reward_mean=0.520, reward_bound=0.380, batch=222 
11527: loss=0.054, reward_mean=0.490, reward_bound=0.387, batch=219 
11528: loss=0.054, reward_mean=0.520, reward_bound=0.314, batch=222 
11529: loss=0.054, reward_mean=0.480, reward_bound=0.349, batch=222 
11530: loss=0.053, reward_mean=0.490, reward_bound=0.400, batch=225 
11531: loss=0.053, reward_mean=0.560, reward_bound=0.387, batch=226 
11532: loss=0.048, reward_mean=0.550, reward_bound=0.430, batch=177 
11533: loss=0.046, reward_mean=0.550, reward_bound=0.098, batch=192 
11534: loss=0.046, reward_mean=0.440, reward_bound=0.092, batch=204 
11535: loss=0.047, reward_mean=0.470, reward_bound=0.150, batch=212 
11536: loss=0.045, reward_mean=0.390, reward_bound=0.172, batch=218 
11537: loss=0.042, reward_mean=0.430, reward_bound=0.206, batch=218 
11538: loss=0.044, reward_mean=0.500, reward_bound=0.231, batch=222 
11539: loss=0.045, reward_mean=0.500, reward_bound=0.254, batch=219 
11540: loss=0.045, reward_mean=0.500, reward_bound=0.282, batch=212 
11541: loss=0.048, reward_mean=0.540, reward_bound=0.314, batch=210 
11542: loss=0.047, reward_mean=0.510, reward_bound=0.314, batch=216 
11543: loss=0.045, reward_mean=0.500, reward_bound=0.349, batch=206 
11544: loss=0.043, reward_mean=0.490, reward_bound=0.241, batch=214 
11545: loss=0.042, reward_mean=0.520, reward_bound=0.254, batch=218 
11546: loss=0.042, reward_mean=0.460, reward_bound=0.286, batch=222 
11547: loss=0.041, reward_mean=0.470, reward_bound=0.292, batch=225 
11548: loss=0.042, reward_mean=0.520, reward_bound=0.314, batch=221 
11549: loss=0.042, reward_mean=0.580, reward_bound=0.349, batch=222 
11550: loss=0.042, reward_mean=0.560, reward_bound=0.349, batch=224 
11551: loss=0.041, reward_mean=0.550, reward_bound=0.311, batch=227 
11552: loss=0.041, reward_mean=0.520, reward_bound=0.308, batch=229 
11553: loss=0.041, reward_mean=0.480, reward_bound=0.349, batch=228 
11554: loss=0.042, reward_mean=0.420, reward_bound=0.387, batch=210 
11555: loss=0.041, reward_mean=0.470, reward_bound=0.254, batch=216 
11556: loss=0.040, reward_mean=0.530, reward_bound=0.298, batch=221 
11557: loss=0.044, reward_mean=0.530, reward_bound=0.314, batch=222 
11558: loss=0.040, reward_mean=0.580, reward_bound=0.387, batch=222 
11559: loss=0.042, reward_mean=0.510, reward_bound=0.349, batch=224 
11560: loss=0.041, reward_mean=0.450, reward_bound=0.384, batch=227 
11561: loss=0.044, reward_mean=0.600, reward_bound=0.430, batch=203 
11562: loss=0.042, reward_mean=0.550, reward_bound=0.271, batch=212 
11563: loss=0.040, reward_mean=0.390, reward_bound=0.213, batch=218 
11564: loss=0.042, reward_mean=0.450, reward_bound=0.254, batch=221 
11565: loss=0.045, reward_mean=0.500, reward_bound=0.282, batch=224 
11566: loss=0.046, reward_mean=0.470, reward_bound=0.314, batch=221 
11567: loss=0.045, reward_mean=0.390, reward_bound=0.229, batch=224 
11568: loss=0.045, reward_mean=0.440, reward_bound=0.254, batch=225 
11569: loss=0.044, reward_mean=0.460, reward_bound=0.349, batch=223 
11570: loss=0.044, reward_mean=0.580, reward_bound=0.314, batch=225 
11571: loss=0.043, reward_mean=0.430, reward_bound=0.303, batch=227 
11572: loss=0.044, reward_mean=0.410, reward_bound=0.387, batch=225 
11573: loss=0.044, reward_mean=0.540, reward_bound=0.396, batch=227 
11574: loss=0.043, reward_mean=0.590, reward_bound=0.430, batch=219 
11575: loss=0.043, reward_mean=0.520, reward_bound=0.478, batch=224 
11576: loss=0.042, reward_mean=0.460, reward_bound=0.314, batch=225 
11577: loss=0.042, reward_mean=0.490, reward_bound=0.356, batch=227 
11578: loss=0.042, reward_mean=0.480, reward_bound=0.387, batch=227 
11579: loss=0.042, reward_mean=0.560, reward_bound=0.380, batch=229 
11580: loss=0.042, reward_mean=0.490, reward_bound=0.364, batch=230 
11581: loss=0.042, reward_mean=0.490, reward_bound=0.387, batch=230 
11582: loss=0.042, reward_mean=0.480, reward_bound=0.430, batch=228 
11583: loss=0.042, reward_mean=0.460, reward_bound=0.435, batch=229 
11584: loss=0.042, reward_mean=0.530, reward_bound=0.424, batch=230 
11585: loss=0.042, reward_mean=0.530, reward_bound=0.429, batch=231 
11586: loss=0.035, reward_mean=0.460, reward_bound=0.478, batch=89 
11587: loss=0.029, reward_mean=0.470, reward_bound=0.001, batch=132 
11588: loss=0.026, reward_mean=0.450, reward_bound=0.010, batch=160 
11589: loss=0.028, reward_mean=0.460, reward_bound=0.018, batch=180 
11590: loss=0.034, reward_mean=0.540, reward_bound=0.047, batch=194 
11591: loss=0.037, reward_mean=0.430, reward_bound=0.065, batch=205 
11592: loss=0.035, reward_mean=0.450, reward_bound=0.089, batch=215 
11593: loss=0.033, reward_mean=0.600, reward_bound=0.109, batch=224 
11594: loss=0.030, reward_mean=0.490, reward_bound=0.122, batch=223 
11595: loss=0.035, reward_mean=0.500, reward_bound=0.150, batch=214 
11596: loss=0.041, reward_mean=0.540, reward_bound=0.167, batch=213 
11597: loss=0.038, reward_mean=0.540, reward_bound=0.185, batch=210 
11598: loss=0.038, reward_mean=0.580, reward_bound=0.206, batch=219 
11599: loss=0.041, reward_mean=0.500, reward_bound=0.206, batch=214 
11600: loss=0.042, reward_mean=0.530, reward_bound=0.226, batch=220 
11601: loss=0.037, reward_mean=0.520, reward_bound=0.229, batch=210 
11602: loss=0.039, reward_mean=0.520, reward_bound=0.254, batch=189 
11603: loss=0.040, reward_mean=0.420, reward_bound=0.127, batch=202 
11604: loss=0.041, reward_mean=0.570, reward_bound=0.172, batch=211 
11605: loss=0.041, reward_mean=0.450, reward_bound=0.229, batch=212 
11606: loss=0.043, reward_mean=0.500, reward_bound=0.254, batch=214 
11607: loss=0.042, reward_mean=0.500, reward_bound=0.226, batch=220 
11608: loss=0.041, reward_mean=0.570, reward_bound=0.282, batch=201 
11609: loss=0.044, reward_mean=0.530, reward_bound=0.282, batch=208 
11610: loss=0.042, reward_mean=0.430, reward_bound=0.123, batch=215 
11611: loss=0.041, reward_mean=0.420, reward_bound=0.150, batch=219 
11612: loss=0.043, reward_mean=0.350, reward_bound=0.254, batch=221 
11613: loss=0.044, reward_mean=0.550, reward_bound=0.314, batch=193 
11614: loss=0.043, reward_mean=0.490, reward_bound=0.178, batch=205 
11615: loss=0.043, reward_mean=0.400, reward_bound=0.185, batch=210 
11616: loss=0.045, reward_mean=0.490, reward_bound=0.206, batch=220 
11617: loss=0.046, reward_mean=0.450, reward_bound=0.222, batch=224 
11618: loss=0.046, reward_mean=0.520, reward_bound=0.229, batch=226 
11619: loss=0.049, reward_mean=0.510, reward_bound=0.254, batch=223 
11620: loss=0.047, reward_mean=0.490, reward_bound=0.301, batch=226 
11621: loss=0.046, reward_mean=0.500, reward_bound=0.331, batch=228 
11622: loss=0.042, reward_mean=0.430, reward_bound=0.349, batch=189 
11623: loss=0.041, reward_mean=0.450, reward_bound=0.185, batch=200 
11624: loss=0.039, reward_mean=0.520, reward_bound=0.206, batch=211 
11625: loss=0.040, reward_mean=0.550, reward_bound=0.206, batch=213 
11626: loss=0.041, reward_mean=0.560, reward_bound=0.244, batch=219 
11627: loss=0.043, reward_mean=0.490, reward_bound=0.254, batch=222 
11628: loss=0.044, reward_mean=0.590, reward_bound=0.282, batch=217 
11629: loss=0.048, reward_mean=0.440, reward_bound=0.314, batch=217 
11630: loss=0.047, reward_mean=0.450, reward_bound=0.229, batch=221 
11631: loss=0.047, reward_mean=0.460, reward_bound=0.282, batch=223 
11632: loss=0.049, reward_mean=0.430, reward_bound=0.314, batch=225 
11633: loss=0.045, reward_mean=0.560, reward_bound=0.349, batch=223 
11634: loss=0.047, reward_mean=0.570, reward_bound=0.372, batch=226 
11635: loss=0.036, reward_mean=0.500, reward_bound=0.387, batch=182 
11636: loss=0.035, reward_mean=0.490, reward_bound=0.155, batch=197 
11637: loss=0.033, reward_mean=0.510, reward_bound=0.185, batch=206 
11638: loss=0.030, reward_mean=0.480, reward_bound=0.206, batch=211 
11639: loss=0.032, reward_mean=0.500, reward_bound=0.229, batch=210 
11640: loss=0.032, reward_mean=0.420, reward_bound=0.254, batch=214 
11641: loss=0.035, reward_mean=0.480, reward_bound=0.252, batch=220 
11642: loss=0.034, reward_mean=0.610, reward_bound=0.282, batch=218 
11643: loss=0.030, reward_mean=0.590, reward_bound=0.314, batch=214 
11644: loss=0.030, reward_mean=0.490, reward_bound=0.282, batch=219 
11645: loss=0.031, reward_mean=0.540, reward_bound=0.328, batch=223 
11646: loss=0.035, reward_mean=0.510, reward_bound=0.349, batch=216 
11647: loss=0.036, reward_mean=0.530, reward_bound=0.331, batch=221 
11648: loss=0.035, reward_mean=0.500, reward_bound=0.206, batch=224 
11649: loss=0.034, reward_mean=0.640, reward_bound=0.349, batch=223 
11650: loss=0.033, reward_mean=0.460, reward_bound=0.311, batch=226 
11651: loss=0.033, reward_mean=0.480, reward_bound=0.349, batch=224 
11652: loss=0.033, reward_mean=0.490, reward_bound=0.349, batch=225 
11653: loss=0.036, reward_mean=0.600, reward_bound=0.387, batch=210 
11654: loss=0.034, reward_mean=0.580, reward_bound=0.304, batch=217 
11655: loss=0.034, reward_mean=0.510, reward_bound=0.314, batch=220 
11656: loss=0.034, reward_mean=0.520, reward_bound=0.349, batch=222 
11657: loss=0.035, reward_mean=0.520, reward_bound=0.324, batch=225 
11658: loss=0.035, reward_mean=0.410, reward_bound=0.321, batch=227 
11659: loss=0.035, reward_mean=0.540, reward_bound=0.349, batch=226 
11660: loss=0.034, reward_mean=0.410, reward_bound=0.387, batch=222 
11661: loss=0.034, reward_mean=0.590, reward_bound=0.400, batch=225 
11662: loss=0.032, reward_mean=0.540, reward_bound=0.430, batch=161 
11663: loss=0.036, reward_mean=0.540, reward_bound=0.122, batch=182 
11664: loss=0.035, reward_mean=0.540, reward_bound=0.135, batch=195 
11665: loss=0.033, reward_mean=0.460, reward_bound=0.150, batch=205 
11666: loss=0.032, reward_mean=0.530, reward_bound=0.167, batch=212 
11667: loss=0.029, reward_mean=0.550, reward_bound=0.185, batch=217 
11668: loss=0.028, reward_mean=0.480, reward_bound=0.206, batch=219 
11669: loss=0.027, reward_mean=0.530, reward_bound=0.254, batch=216 
11670: loss=0.028, reward_mean=0.520, reward_bound=0.282, batch=209 
11671: loss=0.030, reward_mean=0.490, reward_bound=0.254, batch=215 
11672: loss=0.029, reward_mean=0.420, reward_bound=0.260, batch=220 
11673: loss=0.029, reward_mean=0.530, reward_bound=0.282, batch=223 
11674: loss=0.029, reward_mean=0.480, reward_bound=0.314, batch=210 
11675: loss=0.028, reward_mean=0.540, reward_bound=0.274, batch=217 
11676: loss=0.027, reward_mean=0.430, reward_bound=0.182, batch=222 
11677: loss=0.027, reward_mean=0.550, reward_bound=0.292, batch=225 
11678: loss=0.026, reward_mean=0.550, reward_bound=0.349, batch=215 
11679: loss=0.026, reward_mean=0.540, reward_bound=0.329, batch=220 
11680: loss=0.029, reward_mean=0.420, reward_bound=0.387, batch=201 
11681: loss=0.030, reward_mean=0.490, reward_bound=0.314, batch=208 
11682: loss=0.032, reward_mean=0.550, reward_bound=0.282, batch=214 
11683: loss=0.034, reward_mean=0.530, reward_bound=0.204, batch=220 
11684: loss=0.030, reward_mean=0.400, reward_bound=0.304, batch=224 
11685: loss=0.030, reward_mean=0.460, reward_bound=0.282, batch=226 
11686: loss=0.030, reward_mean=0.520, reward_bound=0.314, batch=227 
11687: loss=0.028, reward_mean=0.520, reward_bound=0.349, batch=224 
11688: loss=0.028, reward_mean=0.550, reward_bound=0.311, batch=227 
11689: loss=0.029, reward_mean=0.420, reward_bound=0.387, batch=216 
11690: loss=0.029, reward_mean=0.510, reward_bound=0.314, batch=218 
11691: loss=0.031, reward_mean=0.470, reward_bound=0.349, batch=221 
11692: loss=0.031, reward_mean=0.500, reward_bound=0.349, batch=222 
11693: loss=0.031, reward_mean=0.440, reward_bound=0.349, batch=224 
11694: loss=0.030, reward_mean=0.480, reward_bound=0.349, batch=226 
11695: loss=0.030, reward_mean=0.470, reward_bound=0.282, batch=227 
11696: loss=0.028, reward_mean=0.460, reward_bound=0.387, batch=225 
11697: loss=0.028, reward_mean=0.550, reward_bound=0.356, batch=227 
11698: loss=0.028, reward_mean=0.510, reward_bound=0.387, batch=227 
11699: loss=0.028, reward_mean=0.490, reward_bound=0.335, batch=229 
11700: loss=0.028, reward_mean=0.510, reward_bound=0.387, batch=228 
11701: loss=0.031, reward_mean=0.520, reward_bound=0.430, batch=206 
11702: loss=0.032, reward_mean=0.470, reward_bound=0.150, batch=213 
11703: loss=0.031, reward_mean=0.470, reward_bound=0.185, batch=218 
11704: loss=0.031, reward_mean=0.520, reward_bound=0.229, batch=221 
11705: loss=0.029, reward_mean=0.450, reward_bound=0.254, batch=221 
11706: loss=0.028, reward_mean=0.590, reward_bound=0.282, batch=222 
11707: loss=0.028, reward_mean=0.500, reward_bound=0.263, batch=225 
11708: loss=0.028, reward_mean=0.480, reward_bound=0.314, batch=226 
11709: loss=0.028, reward_mean=0.500, reward_bound=0.331, batch=228 
11710: loss=0.028, reward_mean=0.570, reward_bound=0.349, batch=226 
11711: loss=0.028, reward_mean=0.480, reward_bound=0.368, batch=228 
11712: loss=0.029, reward_mean=0.600, reward_bound=0.387, batch=218 
11713: loss=0.029, reward_mean=0.490, reward_bound=0.289, batch=222 
11714: loss=0.029, reward_mean=0.450, reward_bound=0.360, batch=225 
11715: loss=0.028, reward_mean=0.480, reward_bound=0.387, batch=226 
11716: loss=0.028, reward_mean=0.530, reward_bound=0.387, batch=227 
11717: loss=0.028, reward_mean=0.560, reward_bound=0.349, batch=228 
11718: loss=0.029, reward_mean=0.510, reward_bound=0.430, batch=222 
11719: loss=0.029, reward_mean=0.520, reward_bound=0.400, batch=225 
11720: loss=0.029, reward_mean=0.570, reward_bound=0.349, batch=226 
11721: loss=0.029, reward_mean=0.460, reward_bound=0.430, batch=225 
11722: loss=0.029, reward_mean=0.520, reward_bound=0.349, batch=226 
11723: loss=0.031, reward_mean=0.510, reward_bound=0.331, batch=228 
11724: loss=0.028, reward_mean=0.490, reward_bound=0.357, batch=229 
11725: loss=0.028, reward_mean=0.600, reward_bound=0.381, batch=230 
11726: loss=0.028, reward_mean=0.430, reward_bound=0.418, batch=231 
11727: loss=0.028, reward_mean=0.510, reward_bound=0.430, batch=230 
11728: loss=0.028, reward_mean=0.500, reward_bound=0.406, batch=231 
11729: loss=0.028, reward_mean=0.480, reward_bound=0.430, batch=231 
11730: loss=0.028, reward_mean=0.440, reward_bound=0.349, batch=231 
11731: loss=0.028, reward_mean=0.590, reward_bound=0.430, batch=231 
11732: loss=0.028, reward_mean=0.490, reward_bound=0.282, batch=231 
11733: loss=0.028, reward_mean=0.480, reward_bound=0.430, batch=231 
11734: loss=0.035, reward_mean=0.500, reward_bound=0.478, batch=149 
11735: loss=0.034, reward_mean=0.530, reward_bound=0.044, batch=174 
11736: loss=0.027, reward_mean=0.510, reward_bound=0.089, batch=191 
11737: loss=0.027, reward_mean=0.490, reward_bound=0.109, batch=201 
11738: loss=0.028, reward_mean=0.460, reward_bound=0.150, batch=203 
11739: loss=0.028, reward_mean=0.490, reward_bound=0.167, batch=209 
11740: loss=0.029, reward_mean=0.510, reward_bound=0.206, batch=208 
11741: loss=0.029, reward_mean=0.420, reward_bound=0.229, batch=213 
11742: loss=0.030, reward_mean=0.540, reward_bound=0.254, batch=208 
11743: loss=0.034, reward_mean=0.570, reward_bound=0.282, batch=206 
11744: loss=0.034, reward_mean=0.480, reward_bound=0.229, batch=213 
11745: loss=0.034, reward_mean=0.470, reward_bound=0.254, batch=216 
11746: loss=0.031, reward_mean=0.510, reward_bound=0.298, batch=221 
11747: loss=0.029, reward_mean=0.450, reward_bound=0.314, batch=213 
11748: loss=0.030, reward_mean=0.520, reward_bound=0.254, batch=218 
11749: loss=0.030, reward_mean=0.520, reward_bound=0.317, batch=222 
11750: loss=0.029, reward_mean=0.510, reward_bound=0.324, batch=225 
11751: loss=0.027, reward_mean=0.540, reward_bound=0.349, batch=210 
11752: loss=0.026, reward_mean=0.460, reward_bound=0.185, batch=216 
11753: loss=0.028, reward_mean=0.480, reward_bound=0.268, batch=221 
11754: loss=0.028, reward_mean=0.530, reward_bound=0.282, batch=223 
11755: loss=0.028, reward_mean=0.610, reward_bound=0.314, batch=222 
11756: loss=0.028, reward_mean=0.490, reward_bound=0.324, batch=225 
11757: loss=0.028, reward_mean=0.460, reward_bound=0.349, batch=224 
11758: loss=0.027, reward_mean=0.470, reward_bound=0.380, batch=227 
11759: loss=0.027, reward_mean=0.480, reward_bound=0.342, batch=229 
11760: loss=0.027, reward_mean=0.560, reward_bound=0.364, batch=230 
11761: loss=0.032, reward_mean=0.480, reward_bound=0.387, batch=198 
11762: loss=0.030, reward_mean=0.460, reward_bound=0.173, batch=208 
11763: loss=0.029, reward_mean=0.490, reward_bound=0.229, batch=214 
11764: loss=0.028, reward_mean=0.430, reward_bound=0.280, batch=220 
11765: loss=0.028, reward_mean=0.590, reward_bound=0.282, batch=223 
11766: loss=0.029, reward_mean=0.470, reward_bound=0.314, batch=220 
11767: loss=0.028, reward_mean=0.510, reward_bound=0.282, batch=223 
11768: loss=0.028, reward_mean=0.510, reward_bound=0.335, batch=226 
11769: loss=0.029, reward_mean=0.570, reward_bound=0.349, batch=220 
11770: loss=0.028, reward_mean=0.380, reward_bound=0.338, batch=224 
11771: loss=0.028, reward_mean=0.510, reward_bound=0.277, batch=227 
11772: loss=0.028, reward_mean=0.560, reward_bound=0.342, batch=229 
11773: loss=0.028, reward_mean=0.590, reward_bound=0.349, batch=227 
11774: loss=0.030, reward_mean=0.450, reward_bound=0.387, batch=216 
11775: loss=0.029, reward_mean=0.450, reward_bound=0.176, batch=221 
11776: loss=0.031, reward_mean=0.570, reward_bound=0.282, batch=224 
11777: loss=0.028, reward_mean=0.510, reward_bound=0.384, batch=227 
11778: loss=0.028, reward_mean=0.510, reward_bound=0.380, batch=229 
11779: loss=0.028, reward_mean=0.450, reward_bound=0.349, batch=229 
11780: loss=0.029, reward_mean=0.540, reward_bound=0.387, batch=224 
11781: loss=0.031, reward_mean=0.450, reward_bound=0.280, batch=227 
11782: loss=0.030, reward_mean=0.470, reward_bound=0.314, batch=228 
11783: loss=0.031, reward_mean=0.510, reward_bound=0.349, batch=226 
11784: loss=0.030, reward_mean=0.480, reward_bound=0.298, batch=228 
11785: loss=0.028, reward_mean=0.540, reward_bound=0.387, batch=228 
11786: loss=0.029, reward_mean=0.470, reward_bound=0.430, batch=201 
11787: loss=0.030, reward_mean=0.440, reward_bound=0.206, batch=210 
11788: loss=0.029, reward_mean=0.520, reward_bound=0.247, batch=217 
11789: loss=0.029, reward_mean=0.560, reward_bound=0.254, batch=217 
11790: loss=0.031, reward_mean=0.550, reward_bound=0.282, batch=221 
11791: loss=0.032, reward_mean=0.500, reward_bound=0.314, batch=219 
11792: loss=0.034, reward_mean=0.600, reward_bound=0.349, batch=217 
11793: loss=0.034, reward_mean=0.510, reward_bound=0.229, batch=220 
11794: loss=0.033, reward_mean=0.490, reward_bound=0.259, batch=224 
11795: loss=0.035, reward_mean=0.490, reward_bound=0.282, batch=225 
11796: loss=0.036, reward_mean=0.510, reward_bound=0.349, batch=224 
11797: loss=0.035, reward_mean=0.510, reward_bound=0.280, batch=227 
11798: loss=0.035, reward_mean=0.520, reward_bound=0.349, batch=228 
11799: loss=0.034, reward_mean=0.520, reward_bound=0.387, batch=221 
11800: loss=0.034, reward_mean=0.560, reward_bound=0.314, batch=223 
11801: loss=0.033, reward_mean=0.540, reward_bound=0.301, batch=226 
11802: loss=0.035, reward_mean=0.510, reward_bound=0.331, batch=228 
11803: loss=0.035, reward_mean=0.590, reward_bound=0.392, batch=229 
11804: loss=0.035, reward_mean=0.430, reward_bound=0.405, batch=230 
11805: loss=0.035, reward_mean=0.460, reward_bound=0.418, batch=231 
11806: loss=0.030, reward_mean=0.500, reward_bound=0.430, batch=220 
11807: loss=0.030, reward_mean=0.390, reward_bound=0.304, batch=224 
11808: loss=0.029, reward_mean=0.500, reward_bound=0.384, batch=227 
11809: loss=0.029, reward_mean=0.490, reward_bound=0.387, batch=227 
11810: loss=0.032, reward_mean=0.520, reward_bound=0.430, batch=226 
11811: loss=0.032, reward_mean=0.510, reward_bound=0.314, batch=226 
11812: loss=0.031, reward_mean=0.560, reward_bound=0.409, batch=228 
11813: loss=0.031, reward_mean=0.580, reward_bound=0.387, batch=228 
11814: loss=0.031, reward_mean=0.520, reward_bound=0.430, batch=227 
11815: loss=0.031, reward_mean=0.460, reward_bound=0.387, batch=228 
11816: loss=0.031, reward_mean=0.510, reward_bound=0.397, batch=229 
11817: loss=0.031, reward_mean=0.430, reward_bound=0.478, batch=231 
11818: loss=0.031, reward_mean=0.470, reward_bound=0.349, batch=231 
11819: loss=0.038, reward_mean=0.590, reward_bound=0.478, batch=186 
11820: loss=0.034, reward_mean=0.600, reward_bound=0.150, batch=199 
11821: loss=0.032, reward_mean=0.450, reward_bound=0.150, batch=208 
11822: loss=0.032, reward_mean=0.550, reward_bound=0.206, batch=210 
11823: loss=0.031, reward_mean=0.510, reward_bound=0.180, batch=217 
11824: loss=0.033, reward_mean=0.570, reward_bound=0.229, batch=221 
11825: loss=0.032, reward_mean=0.520, reward_bound=0.282, batch=217 
11826: loss=0.032, reward_mean=0.460, reward_bound=0.314, batch=218 
11827: loss=0.032, reward_mean=0.610, reward_bound=0.349, batch=216 
11828: loss=0.032, reward_mean=0.660, reward_bound=0.349, batch=217 
11829: loss=0.034, reward_mean=0.450, reward_bound=0.308, batch=222 
11830: loss=0.033, reward_mean=0.450, reward_bound=0.324, batch=225 
11831: loss=0.033, reward_mean=0.450, reward_bound=0.349, batch=225 
11832: loss=0.033, reward_mean=0.460, reward_bound=0.349, batch=225 
11833: loss=0.034, reward_mean=0.490, reward_bound=0.387, batch=220 
11834: loss=0.034, reward_mean=0.550, reward_bound=0.338, batch=224 
11835: loss=0.033, reward_mean=0.530, reward_bound=0.314, batch=226 
11836: loss=0.033, reward_mean=0.510, reward_bound=0.331, batch=228 
11837: loss=0.036, reward_mean=0.530, reward_bound=0.387, batch=226 
11838: loss=0.036, reward_mean=0.490, reward_bound=0.349, batch=227 
11839: loss=0.035, reward_mean=0.520, reward_bound=0.380, batch=229 
11840: loss=0.034, reward_mean=0.500, reward_bound=0.430, batch=207 
11841: loss=0.035, reward_mean=0.580, reward_bound=0.202, batch=215 
11842: loss=0.034, reward_mean=0.490, reward_bound=0.229, batch=219 
11843: loss=0.034, reward_mean=0.490, reward_bound=0.314, batch=221 
11844: loss=0.034, reward_mean=0.510, reward_bound=0.314, batch=224 
11845: loss=0.034, reward_mean=0.550, reward_bound=0.349, batch=225 
11846: loss=0.034, reward_mean=0.560, reward_bound=0.356, batch=227 
11847: loss=0.035, reward_mean=0.590, reward_bound=0.387, batch=220 
11848: loss=0.037, reward_mean=0.570, reward_bound=0.418, batch=224 
11849: loss=0.036, reward_mean=0.500, reward_bound=0.422, batch=227 
11850: loss=0.035, reward_mean=0.540, reward_bound=0.430, batch=222 
11851: loss=0.034, reward_mean=0.430, reward_bound=0.254, batch=225 
11852: loss=0.036, reward_mean=0.560, reward_bound=0.321, batch=227 
11853: loss=0.034, reward_mean=0.430, reward_bound=0.349, batch=227 
11854: loss=0.034, reward_mean=0.520, reward_bound=0.373, batch=229 
11855: loss=0.034, reward_mean=0.570, reward_bound=0.430, batch=227 
11856: loss=0.034, reward_mean=0.530, reward_bound=0.430, batch=228 
11857: loss=0.034, reward_mean=0.580, reward_bound=0.430, batch=228 
11858: loss=0.034, reward_mean=0.590, reward_bound=0.392, batch=229 
11859: loss=0.034, reward_mean=0.470, reward_bound=0.364, batch=230 
11860: loss=0.034, reward_mean=0.600, reward_bound=0.430, batch=230 
11861: loss=0.034, reward_mean=0.520, reward_bound=0.395, batch=231 
11862: loss=0.036, reward_mean=0.540, reward_bound=0.478, batch=198 
11863: loss=0.033, reward_mean=0.560, reward_bound=0.167, batch=207 
11864: loss=0.033, reward_mean=0.490, reward_bound=0.254, batch=210 
11865: loss=0.035, reward_mean=0.470, reward_bound=0.282, batch=215 
11866: loss=0.035, reward_mean=0.510, reward_bound=0.314, batch=215 
11867: loss=0.035, reward_mean=0.620, reward_bound=0.349, batch=214 
11868: loss=0.035, reward_mean=0.570, reward_bound=0.282, batch=219 
11869: loss=0.034, reward_mean=0.430, reward_bound=0.314, batch=222 
11870: loss=0.034, reward_mean=0.520, reward_bound=0.360, batch=225 
11871: loss=0.036, reward_mean=0.490, reward_bound=0.260, batch=227 
11872: loss=0.037, reward_mean=0.490, reward_bound=0.387, batch=220 
11873: loss=0.036, reward_mean=0.540, reward_bound=0.338, batch=224 
11874: loss=0.036, reward_mean=0.490, reward_bound=0.349, batch=225 
11875: loss=0.036, reward_mean=0.430, reward_bound=0.321, batch=227 
11876: loss=0.036, reward_mean=0.530, reward_bound=0.430, batch=215 
11877: loss=0.035, reward_mean=0.430, reward_bound=0.282, batch=219 
11878: loss=0.034, reward_mean=0.540, reward_bound=0.328, batch=223 
11879: loss=0.035, reward_mean=0.480, reward_bound=0.349, batch=222 
11880: loss=0.035, reward_mean=0.490, reward_bound=0.387, batch=223 
11881: loss=0.034, reward_mean=0.500, reward_bound=0.372, batch=226 
11882: loss=0.034, reward_mean=0.510, reward_bound=0.368, batch=228 
11883: loss=0.034, reward_mean=0.480, reward_bound=0.387, batch=228 
11884: loss=0.035, reward_mean=0.530, reward_bound=0.430, batch=222 
11885: loss=0.034, reward_mean=0.450, reward_bound=0.292, batch=225 
11886: loss=0.034, reward_mean=0.570, reward_bound=0.321, batch=227 
11887: loss=0.034, reward_mean=0.550, reward_bound=0.342, batch=229 
11888: loss=0.034, reward_mean=0.510, reward_bound=0.387, batch=227 
11889: loss=0.034, reward_mean=0.470, reward_bound=0.422, batch=229 
11890: loss=0.034, reward_mean=0.550, reward_bound=0.381, batch=230 
11891: loss=0.034, reward_mean=0.450, reward_bound=0.430, batch=228 
11892: loss=0.034, reward_mean=0.600, reward_bound=0.430, batch=228 
11893: loss=0.034, reward_mean=0.450, reward_bound=0.392, batch=229 
11894: loss=0.034, reward_mean=0.570, reward_bound=0.478, batch=231 
11895: loss=0.034, reward_mean=0.410, reward_bound=0.430, batch=231 
11896: loss=0.034, reward_mean=0.440, reward_bound=0.430, batch=231 
11897: loss=0.034, reward_mean=0.430, reward_bound=0.430, batch=231 
11898: loss=0.037, reward_mean=0.540, reward_bound=0.478, batch=210 
11899: loss=0.038, reward_mean=0.440, reward_bound=0.282, batch=216 
11900: loss=0.039, reward_mean=0.450, reward_bound=0.298, batch=221 
11901: loss=0.039, reward_mean=0.470, reward_bound=0.314, batch=221 
11902: loss=0.039, reward_mean=0.490, reward_bound=0.349, batch=221 
11903: loss=0.039, reward_mean=0.540, reward_bound=0.349, batch=224 
11904: loss=0.039, reward_mean=0.530, reward_bound=0.387, batch=222 
11905: loss=0.035, reward_mean=0.530, reward_bound=0.430, batch=220 
11906: loss=0.035, reward_mean=0.580, reward_bound=0.418, batch=224 
11907: loss=0.034, reward_mean=0.540, reward_bound=0.311, batch=227 
11908: loss=0.037, reward_mean=0.570, reward_bound=0.349, batch=228 
11909: loss=0.037, reward_mean=0.620, reward_bound=0.430, batch=227 
11910: loss=0.036, reward_mean=0.500, reward_bound=0.380, batch=229 
11911: loss=0.038, reward_mean=0.560, reward_bound=0.387, batch=229 
11912: loss=0.036, reward_mean=0.460, reward_bound=0.430, batch=229 
11913: loss=0.036, reward_mean=0.390, reward_bound=0.424, batch=230 
11914: loss=0.036, reward_mean=0.530, reward_bound=0.329, batch=231 
11915: loss=0.036, reward_mean=0.470, reward_bound=0.387, batch=231 
11916: loss=0.036, reward_mean=0.480, reward_bound=0.430, batch=231 
11917: loss=0.036, reward_mean=0.490, reward_bound=0.430, batch=231 
11918: loss=0.037, reward_mean=0.470, reward_bound=0.478, batch=222 
11919: loss=0.037, reward_mean=0.530, reward_bound=0.387, batch=224 
11920: loss=0.037, reward_mean=0.530, reward_bound=0.387, batch=226 
11921: loss=0.037, reward_mean=0.450, reward_bound=0.282, batch=227 
11922: loss=0.037, reward_mean=0.540, reward_bound=0.430, batch=228 
11923: loss=0.036, reward_mean=0.570, reward_bound=0.478, batch=230 
11924: loss=0.037, reward_mean=0.490, reward_bound=0.478, batch=225 
11925: loss=0.037, reward_mean=0.540, reward_bound=0.387, batch=226 
11926: loss=0.037, reward_mean=0.500, reward_bound=0.387, batch=227 
11927: loss=0.037, reward_mean=0.500, reward_bound=0.430, batch=227 
11928: loss=0.037, reward_mean=0.590, reward_bound=0.430, batch=228 
11929: loss=0.037, reward_mean=0.500, reward_bound=0.435, batch=229 
11930: loss=0.036, reward_mean=0.530, reward_bound=0.478, batch=232 
11931: loss=0.037, reward_mean=0.590, reward_bound=0.478, batch=229 
11932: loss=0.036, reward_mean=0.550, reward_bound=0.478, batch=232 
11933: loss=0.036, reward_mean=0.520, reward_bound=0.478, batch=230 
11934: loss=0.036, reward_mean=0.500, reward_bound=0.488, batch=231 
11935: loss=0.036, reward_mean=0.500, reward_bound=0.430, batch=231 
11936: loss=0.036, reward_mean=0.500, reward_bound=0.430, batch=231 
11938: loss=0.017, reward_mean=0.580, reward_bound=0.000, batch=58 
11939: loss=0.016, reward_mean=0.510, reward_bound=0.000, batch=109 
11940: loss=0.021, reward_mean=0.550, reward_bound=0.002, batch=144 
11941: loss=0.023, reward_mean=0.440, reward_bound=0.007, batch=169 
11942: loss=0.026, reward_mean=0.580, reward_bound=0.020, batch=186 
11943: loss=0.024, reward_mean=0.450, reward_bound=0.031, batch=197 
11944: loss=0.024, reward_mean=0.490, reward_bound=0.042, batch=200 
11945: loss=0.026, reward_mean=0.530, reward_bound=0.052, batch=199 
11946: loss=0.032, reward_mean=0.560, reward_bound=0.065, batch=196 
11947: loss=0.032, reward_mean=0.550, reward_bound=0.089, batch=195 
11948: loss=0.032, reward_mean=0.460, reward_bound=0.082, batch=206 
11949: loss=0.033, reward_mean=0.520, reward_bound=0.109, batch=196 
11950: loss=0.034, reward_mean=0.500, reward_bound=0.122, batch=204 
11951: loss=0.032, reward_mean=0.420, reward_bound=0.135, batch=201 
11952: loss=0.034, reward_mean=0.480, reward_bound=0.150, batch=193 
11953: loss=0.034, reward_mean=0.500, reward_bound=0.160, batch=205 
11954: loss=0.034, reward_mean=0.580, reward_bound=0.167, batch=202 
11955: loss=0.039, reward_mean=0.520, reward_bound=0.185, batch=188 
11956: loss=0.042, reward_mean=0.490, reward_bound=0.135, batch=198 
11957: loss=0.041, reward_mean=0.460, reward_bound=0.109, batch=207 
11958: loss=0.039, reward_mean=0.550, reward_bound=0.202, batch=215 
11959: loss=0.040, reward_mean=0.490, reward_bound=0.206, batch=196 
11960: loss=0.041, reward_mean=0.590, reward_bound=0.229, batch=177 
11961: loss=0.042, reward_mean=0.470, reward_bound=0.109, batch=195 
11962: loss=0.044, reward_mean=0.490, reward_bound=0.112, batch=206 
11963: loss=0.045, reward_mean=0.470, reward_bound=0.122, batch=213 
11964: loss=0.041, reward_mean=0.420, reward_bound=0.150, batch=213 
11965: loss=0.039, reward_mean=0.590, reward_bound=0.206, batch=217 
11966: loss=0.040, reward_mean=0.550, reward_bound=0.229, batch=219 
11967: loss=0.039, reward_mean=0.540, reward_bound=0.254, batch=195 
11968: loss=0.040, reward_mean=0.570, reward_bound=0.185, batch=204 
11969: loss=0.039, reward_mean=0.520, reward_bound=0.206, batch=212 
11970: loss=0.040, reward_mean=0.500, reward_bound=0.185, batch=217 
11971: loss=0.041, reward_mean=0.570, reward_bound=0.254, batch=220 
11972: loss=0.042, reward_mean=0.550, reward_bound=0.282, batch=174 
11973: loss=0.041, reward_mean=0.520, reward_bound=0.183, batch=192 
11974: loss=0.040, reward_mean=0.520, reward_bound=0.185, batch=202 
11975: loss=0.038, reward_mean=0.460, reward_bound=0.155, batch=211 
11976: loss=0.041, reward_mean=0.510, reward_bound=0.229, batch=217 
11977: loss=0.041, reward_mean=0.510, reward_bound=0.254, batch=217 
11978: loss=0.040, reward_mean=0.530, reward_bound=0.314, batch=156 
11979: loss=0.036, reward_mean=0.540, reward_bound=0.080, batch=177 
11980: loss=0.035, reward_mean=0.430, reward_bound=0.122, batch=187 
11981: loss=0.035, reward_mean=0.480, reward_bound=0.147, batch=201 
11982: loss=0.037, reward_mean=0.560, reward_bound=0.150, batch=209 
11983: loss=0.039, reward_mean=0.470, reward_bound=0.194, batch=216 
11984: loss=0.038, reward_mean=0.510, reward_bound=0.229, batch=207 
11985: loss=0.037, reward_mean=0.530, reward_bound=0.249, batch=215 
11986: loss=0.038, reward_mean=0.520, reward_bound=0.254, batch=219 
11987: loss=0.037, reward_mean=0.630, reward_bound=0.282, batch=217 
11988: loss=0.037, reward_mean=0.590, reward_bound=0.314, batch=211 
11989: loss=0.038, reward_mean=0.500, reward_bound=0.314, batch=216 
11990: loss=0.037, reward_mean=0.390, reward_bound=0.268, batch=221 
11991: loss=0.037, reward_mean=0.520, reward_bound=0.282, batch=222 
11992: loss=0.043, reward_mean=0.420, reward_bound=0.349, batch=154 
11993: loss=0.037, reward_mean=0.450, reward_bound=0.022, batch=178 
11994: loss=0.035, reward_mean=0.510, reward_bound=0.065, batch=193 
11995: loss=0.038, reward_mean=0.550, reward_bound=0.122, batch=200 
11996: loss=0.037, reward_mean=0.500, reward_bound=0.106, batch=210 
11997: loss=0.039, reward_mean=0.520, reward_bound=0.185, batch=209 
11998: loss=0.038, reward_mean=0.470, reward_bound=0.206, batch=208 
11999: loss=0.040, reward_mean=0.510, reward_bound=0.208, batch=215 
12000: loss=0.043, reward_mean=0.460, reward_bound=0.234, batch=220 
12001: loss=0.047, reward_mean=0.520, reward_bound=0.254, batch=211 
12002: loss=0.044, reward_mean=0.610, reward_bound=0.282, batch=209 
12003: loss=0.045, reward_mean=0.460, reward_bound=0.282, batch=215 
12004: loss=0.045, reward_mean=0.550, reward_bound=0.314, batch=209 
12005: loss=0.045, reward_mean=0.560, reward_bound=0.282, batch=215 
12006: loss=0.045, reward_mean=0.530, reward_bound=0.314, batch=217 
12007: loss=0.044, reward_mean=0.530, reward_bound=0.349, batch=206 
12008: loss=0.043, reward_mean=0.510, reward_bound=0.176, batch=214 
12009: loss=0.041, reward_mean=0.510, reward_bound=0.226, batch=220 
12010: loss=0.042, reward_mean=0.470, reward_bound=0.274, batch=224 
12011: loss=0.043, reward_mean=0.460, reward_bound=0.280, batch=227 
12012: loss=0.045, reward_mean=0.430, reward_bound=0.282, batch=228 
12013: loss=0.048, reward_mean=0.470, reward_bound=0.314, batch=224 
12014: loss=0.049, reward_mean=0.500, reward_bound=0.349, batch=222 
12015: loss=0.048, reward_mean=0.480, reward_bound=0.324, batch=225 
12016: loss=0.048, reward_mean=0.530, reward_bound=0.356, batch=227 
12017: loss=0.047, reward_mean=0.600, reward_bound=0.308, batch=229 
12018: loss=0.047, reward_mean=0.410, reward_bound=0.328, batch=230 
12019: loss=0.047, reward_mean=0.450, reward_bound=0.376, batch=231 
12020: loss=0.055, reward_mean=0.510, reward_bound=0.387, batch=148 
12021: loss=0.044, reward_mean=0.420, reward_bound=0.023, batch=173 
12022: loss=0.045, reward_mean=0.490, reward_bound=0.050, batch=191 
12023: loss=0.041, reward_mean=0.570, reward_bound=0.089, batch=202 
12024: loss=0.039, reward_mean=0.470, reward_bound=0.109, batch=209 
12025: loss=0.042, reward_mean=0.520, reward_bound=0.157, batch=216 
12026: loss=0.048, reward_mean=0.570, reward_bound=0.185, batch=216 
12027: loss=0.055, reward_mean=0.500, reward_bound=0.206, batch=217 
12028: loss=0.056, reward_mean=0.450, reward_bound=0.229, batch=209 
12029: loss=0.055, reward_mean=0.450, reward_bound=0.174, batch=216 
12030: loss=0.052, reward_mean=0.550, reward_bound=0.254, batch=212 
12031: loss=0.053, reward_mean=0.460, reward_bound=0.282, batch=206 
12032: loss=0.057, reward_mean=0.460, reward_bound=0.314, batch=200 
12033: loss=0.058, reward_mean=0.580, reward_bound=0.229, batch=209 
12034: loss=0.062, reward_mean=0.520, reward_bound=0.254, batch=212 
12035: loss=0.058, reward_mean=0.470, reward_bound=0.282, batch=217 
12036: loss=0.057, reward_mean=0.570, reward_bound=0.254, batch=220 
12037: loss=0.057, reward_mean=0.490, reward_bound=0.282, batch=221 
12038: loss=0.056, reward_mean=0.540, reward_bound=0.254, batch=224 
12039: loss=0.053, reward_mean=0.480, reward_bound=0.314, batch=224 
12040: loss=0.054, reward_mean=0.520, reward_bound=0.349, batch=209 
12041: loss=0.052, reward_mean=0.550, reward_bound=0.237, batch=216 
12042: loss=0.052, reward_mean=0.490, reward_bound=0.314, batch=218 
12043: loss=0.051, reward_mean=0.470, reward_bound=0.257, batch=222 
12044: loss=0.052, reward_mean=0.520, reward_bound=0.292, batch=225 
12045: loss=0.054, reward_mean=0.520, reward_bound=0.349, batch=224 
12046: loss=0.053, reward_mean=0.460, reward_bound=0.252, batch=227 
12047: loss=0.049, reward_mean=0.530, reward_bound=0.387, batch=197 
12048: loss=0.047, reward_mean=0.410, reward_bound=0.150, batch=207 
12049: loss=0.048, reward_mean=0.480, reward_bound=0.185, batch=211 
12050: loss=0.047, reward_mean=0.590, reward_bound=0.229, batch=213 
12051: loss=0.050, reward_mean=0.520, reward_bound=0.282, batch=215 
12052: loss=0.050, reward_mean=0.530, reward_bound=0.314, batch=216 
12053: loss=0.050, reward_mean=0.480, reward_bound=0.316, batch=221 
12054: loss=0.051, reward_mean=0.550, reward_bound=0.349, batch=219 
12055: loss=0.048, reward_mean=0.500, reward_bound=0.387, batch=213 
12056: loss=0.050, reward_mean=0.520, reward_bound=0.301, batch=219 
12057: loss=0.052, reward_mean=0.440, reward_bound=0.314, batch=219 
12058: loss=0.050, reward_mean=0.480, reward_bound=0.364, batch=223 
12059: loss=0.049, reward_mean=0.460, reward_bound=0.290, batch=226 
12060: loss=0.051, reward_mean=0.560, reward_bound=0.331, batch=228 
12061: loss=0.051, reward_mean=0.530, reward_bound=0.353, batch=229 
12062: loss=0.051, reward_mean=0.460, reward_bound=0.364, batch=230 
12063: loss=0.048, reward_mean=0.560, reward_bound=0.387, batch=224 
12064: loss=0.048, reward_mean=0.590, reward_bound=0.314, batch=226 
12065: loss=0.049, reward_mean=0.510, reward_bound=0.368, batch=228 
12066: loss=0.049, reward_mean=0.530, reward_bound=0.321, batch=229 
12067: loss=0.048, reward_mean=0.510, reward_bound=0.387, batch=226 
12068: loss=0.044, reward_mean=0.470, reward_bound=0.430, batch=125 
12069: loss=0.037, reward_mean=0.600, reward_bound=0.066, batch=157 
12070: loss=0.035, reward_mean=0.460, reward_bound=0.080, batch=178 
12071: loss=0.033, reward_mean=0.510, reward_bound=0.089, batch=192 
12072: loss=0.036, reward_mean=0.530, reward_bound=0.098, batch=201 
12073: loss=0.036, reward_mean=0.460, reward_bound=0.109, batch=205 
12074: loss=0.037, reward_mean=0.530, reward_bound=0.150, batch=204 
12075: loss=0.040, reward_mean=0.560, reward_bound=0.167, batch=208 
12076: loss=0.041, reward_mean=0.580, reward_bound=0.185, batch=209 
12077: loss=0.041, reward_mean=0.420, reward_bound=0.206, batch=207 
12078: loss=0.043, reward_mean=0.420, reward_bound=0.224, batch=215 
12079: loss=0.043, reward_mean=0.460, reward_bound=0.229, batch=216 
12080: loss=0.046, reward_mean=0.450, reward_bound=0.254, batch=207 
12081: loss=0.044, reward_mean=0.590, reward_bound=0.277, batch=215 
12082: loss=0.047, reward_mean=0.590, reward_bound=0.282, batch=201 
12083: loss=0.045, reward_mean=0.510, reward_bound=0.229, batch=209 
12084: loss=0.046, reward_mean=0.540, reward_bound=0.295, batch=216 
12085: loss=0.047, reward_mean=0.540, reward_bound=0.268, batch=221 
12086: loss=0.046, reward_mean=0.520, reward_bound=0.229, batch=224 
12087: loss=0.048, reward_mean=0.480, reward_bound=0.314, batch=204 
12088: loss=0.046, reward_mean=0.460, reward_bound=0.185, batch=212 
12089: loss=0.049, reward_mean=0.540, reward_bound=0.254, batch=215 
12090: loss=0.048, reward_mean=0.590, reward_bound=0.289, batch=220 
12091: loss=0.047, reward_mean=0.480, reward_bound=0.314, batch=218 
12092: loss=0.046, reward_mean=0.520, reward_bound=0.286, batch=222 
12093: loss=0.047, reward_mean=0.550, reward_bound=0.349, batch=206 
12094: loss=0.045, reward_mean=0.370, reward_bound=0.254, batch=213 
12095: loss=0.044, reward_mean=0.480, reward_bound=0.314, batch=217 
12096: loss=0.044, reward_mean=0.440, reward_bound=0.342, batch=222 
12097: loss=0.044, reward_mean=0.450, reward_bound=0.349, batch=220 
12098: loss=0.043, reward_mean=0.470, reward_bound=0.387, batch=188 
12099: loss=0.050, reward_mean=0.460, reward_bound=0.167, batch=200 
12100: loss=0.047, reward_mean=0.440, reward_bound=0.185, batch=209 
12101: loss=0.048, reward_mean=0.510, reward_bound=0.229, batch=214 
12102: loss=0.048, reward_mean=0.430, reward_bound=0.165, batch=220 
12103: loss=0.046, reward_mean=0.470, reward_bound=0.274, batch=224 
12104: loss=0.045, reward_mean=0.520, reward_bound=0.282, batch=218 
12105: loss=0.047, reward_mean=0.530, reward_bound=0.229, batch=221 
12106: loss=0.048, reward_mean=0.570, reward_bound=0.314, batch=217 
12107: loss=0.047, reward_mean=0.480, reward_bound=0.308, batch=222 
12108: loss=0.047, reward_mean=0.510, reward_bound=0.324, batch=225 
12109: loss=0.044, reward_mean=0.510, reward_bound=0.349, batch=218 
12110: loss=0.043, reward_mean=0.530, reward_bound=0.314, batch=220 
12111: loss=0.044, reward_mean=0.410, reward_bound=0.329, batch=224 
12112: loss=0.043, reward_mean=0.510, reward_bound=0.349, batch=224 
12113: loss=0.043, reward_mean=0.540, reward_bound=0.387, batch=213 
12114: loss=0.044, reward_mean=0.550, reward_bound=0.282, batch=218 
12115: loss=0.043, reward_mean=0.460, reward_bound=0.314, batch=221 
12116: loss=0.043, reward_mean=0.440, reward_bound=0.349, batch=223 
12117: loss=0.042, reward_mean=0.540, reward_bound=0.372, batch=226 
12118: loss=0.043, reward_mean=0.520, reward_bound=0.387, batch=226 
12119: loss=0.046, reward_mean=0.500, reward_bound=0.387, batch=227 
12120: loss=0.047, reward_mean=0.500, reward_bound=0.342, batch=229 
12121: loss=0.047, reward_mean=0.500, reward_bound=0.349, batch=229 
12122: loss=0.047, reward_mean=0.550, reward_bound=0.430, batch=182 
12123: loss=0.042, reward_mean=0.490, reward_bound=0.150, batch=196 
12124: loss=0.042, reward_mean=0.560, reward_bound=0.167, batch=205 
12125: loss=0.038, reward_mean=0.500, reward_bound=0.189, batch=213 
12126: loss=0.040, reward_mean=0.540, reward_bound=0.254, batch=212 
12127: loss=0.038, reward_mean=0.370, reward_bound=0.236, batch=218 
12128: loss=0.042, reward_mean=0.550, reward_bound=0.282, batch=216 
12129: loss=0.045, reward_mean=0.590, reward_bound=0.314, batch=214 
12130: loss=0.043, reward_mean=0.450, reward_bound=0.252, batch=220 
12131: loss=0.045, reward_mean=0.430, reward_bound=0.254, batch=221 
12132: loss=0.046, reward_mean=0.610, reward_bound=0.282, batch=220 
12133: loss=0.045, reward_mean=0.440, reward_bound=0.304, batch=224 
12134: loss=0.044, reward_mean=0.490, reward_bound=0.311, batch=227 
12135: loss=0.044, reward_mean=0.480, reward_bound=0.349, batch=219 
12136: loss=0.045, reward_mean=0.490, reward_bound=0.387, batch=212 
12137: loss=0.046, reward_mean=0.600, reward_bound=0.360, batch=218 
12138: loss=0.047, reward_mean=0.570, reward_bound=0.353, batch=222 
12139: loss=0.051, reward_mean=0.540, reward_bound=0.324, batch=225 
12140: loss=0.047, reward_mean=0.570, reward_bound=0.387, batch=223 
12141: loss=0.049, reward_mean=0.480, reward_bound=0.314, batch=225 
12142: loss=0.050, reward_mean=0.590, reward_bound=0.430, batch=214 
12143: loss=0.049, reward_mean=0.500, reward_bound=0.314, batch=219 
12144: loss=0.049, reward_mean=0.510, reward_bound=0.349, batch=222 
12145: loss=0.049, reward_mean=0.560, reward_bound=0.387, batch=220 
12146: loss=0.052, reward_mean=0.580, reward_bound=0.254, batch=223 
12147: loss=0.053, reward_mean=0.530, reward_bound=0.301, batch=226 
12148: loss=0.051, reward_mean=0.500, reward_bound=0.314, batch=227 
12149: loss=0.048, reward_mean=0.550, reward_bound=0.349, batch=227 
12150: loss=0.048, reward_mean=0.560, reward_bound=0.387, batch=226 
12151: loss=0.047, reward_mean=0.510, reward_bound=0.368, batch=228 
12152: loss=0.048, reward_mean=0.390, reward_bound=0.387, batch=226 
12153: loss=0.050, reward_mean=0.490, reward_bound=0.298, batch=228 
12154: loss=0.050, reward_mean=0.440, reward_bound=0.321, batch=229 
12155: loss=0.050, reward_mean=0.550, reward_bound=0.324, batch=230 
12156: loss=0.050, reward_mean=0.480, reward_bound=0.387, batch=229 
12157: loss=0.050, reward_mean=0.520, reward_bound=0.342, batch=230 
12158: loss=0.051, reward_mean=0.530, reward_bound=0.430, batch=224 
12159: loss=0.052, reward_mean=0.430, reward_bound=0.345, batch=227 
12160: loss=0.052, reward_mean=0.510, reward_bound=0.380, batch=229 
12161: loss=0.052, reward_mean=0.460, reward_bound=0.387, batch=229 
12162: loss=0.052, reward_mean=0.590, reward_bound=0.430, batch=229 
12163: loss=0.052, reward_mean=0.510, reward_bound=0.405, batch=230 
12164: loss=0.051, reward_mean=0.500, reward_bound=0.464, batch=231 
12165: loss=0.056, reward_mean=0.540, reward_bound=0.478, batch=100 
12166: loss=0.038, reward_mean=0.490, reward_bound=0.012, batch=140 
12167: loss=0.039, reward_mean=0.510, reward_bound=0.031, batch=167 
12168: loss=0.046, reward_mean=0.530, reward_bound=0.047, batch=185 
12169: loss=0.045, reward_mean=0.370, reward_bound=0.058, batch=201 
12170: loss=0.042, reward_mean=0.570, reward_bound=0.080, batch=209 
12171: loss=0.048, reward_mean=0.530, reward_bound=0.109, batch=215 
12172: loss=0.049, reward_mean=0.390, reward_bound=0.122, batch=218 
12173: loss=0.049, reward_mean=0.490, reward_bound=0.137, batch=222 
12174: loss=0.049, reward_mean=0.450, reward_bound=0.155, batch=225 
12175: loss=0.048, reward_mean=0.520, reward_bound=0.170, batch=227 
12176: loss=0.046, reward_mean=0.500, reward_bound=0.185, batch=214 
12177: loss=0.046, reward_mean=0.420, reward_bound=0.183, batch=220 
12178: loss=0.045, reward_mean=0.500, reward_bound=0.206, batch=226 
12179: loss=0.045, reward_mean=0.530, reward_bound=0.206, batch=227 
12180: loss=0.045, reward_mean=0.470, reward_bound=0.229, batch=223 
12181: loss=0.045, reward_mean=0.410, reward_bound=0.254, batch=219 
12182: loss=0.048, reward_mean=0.530, reward_bound=0.282, batch=204 
12183: loss=0.046, reward_mean=0.530, reward_bound=0.282, batch=211 
12184: loss=0.045, reward_mean=0.470, reward_bound=0.254, batch=216 
12185: loss=0.044, reward_mean=0.580, reward_bound=0.254, batch=220 
12186: loss=0.044, reward_mean=0.470, reward_bound=0.304, batch=224 
12187: loss=0.045, reward_mean=0.490, reward_bound=0.314, batch=196 
12188: loss=0.044, reward_mean=0.560, reward_bound=0.206, batch=206 
12189: loss=0.042, reward_mean=0.500, reward_bound=0.254, batch=211 
12190: loss=0.041, reward_mean=0.450, reward_bound=0.206, batch=217 
12191: loss=0.041, reward_mean=0.550, reward_bound=0.282, batch=218 
12192: loss=0.044, reward_mean=0.490, reward_bound=0.286, batch=222 
12193: loss=0.042, reward_mean=0.420, reward_bound=0.314, batch=223 
12194: loss=0.042, reward_mean=0.530, reward_bound=0.349, batch=189 
12195: loss=0.038, reward_mean=0.450, reward_bound=0.089, batch=201 
12196: loss=0.036, reward_mean=0.400, reward_bound=0.109, batch=210 
12197: loss=0.038, reward_mean=0.500, reward_bound=0.185, batch=214 
12198: loss=0.041, reward_mean=0.500, reward_bound=0.254, batch=214 
12199: loss=0.039, reward_mean=0.490, reward_bound=0.282, batch=214 
12200: loss=0.040, reward_mean=0.460, reward_bound=0.314, batch=212 
12201: loss=0.039, reward_mean=0.460, reward_bound=0.302, batch=218 
12202: loss=0.038, reward_mean=0.450, reward_bound=0.349, batch=213 
12203: loss=0.039, reward_mean=0.340, reward_bound=0.211, batch=219 
12204: loss=0.039, reward_mean=0.570, reward_bound=0.314, batch=221 
12205: loss=0.038, reward_mean=0.520, reward_bound=0.314, batch=224 
12206: loss=0.038, reward_mean=0.530, reward_bound=0.345, batch=227 
12207: loss=0.037, reward_mean=0.540, reward_bound=0.308, batch=229 
12208: loss=0.037, reward_mean=0.440, reward_bound=0.328, batch=230 
12209: loss=0.039, reward_mean=0.490, reward_bound=0.349, batch=230 
12210: loss=0.045, reward_mean=0.490, reward_bound=0.387, batch=176 
12211: loss=0.039, reward_mean=0.560, reward_bound=0.176, batch=193 
12212: loss=0.039, reward_mean=0.520, reward_bound=0.185, batch=203 
12213: loss=0.044, reward_mean=0.430, reward_bound=0.254, batch=205 
12214: loss=0.044, reward_mean=0.480, reward_bound=0.229, batch=212 
12215: loss=0.043, reward_mean=0.530, reward_bound=0.236, batch=218 
12216: loss=0.042, reward_mean=0.460, reward_bound=0.257, batch=222 
12217: loss=0.049, reward_mean=0.490, reward_bound=0.282, batch=217 
12218: loss=0.047, reward_mean=0.630, reward_bound=0.314, batch=211 
12219: loss=0.046, reward_mean=0.480, reward_bound=0.282, batch=217 
12220: loss=0.045, reward_mean=0.510, reward_bound=0.314, batch=221 
12221: loss=0.043, reward_mean=0.540, reward_bound=0.349, batch=206 
12222: loss=0.043, reward_mean=0.550, reward_bound=0.284, batch=214 
12223: loss=0.043, reward_mean=0.460, reward_bound=0.314, batch=218 
12224: loss=0.041, reward_mean=0.500, reward_bound=0.387, batch=207 
12225: loss=0.042, reward_mean=0.540, reward_bound=0.282, batch=213 
12226: loss=0.040, reward_mean=0.500, reward_bound=0.271, batch=219 
12227: loss=0.041, reward_mean=0.540, reward_bound=0.314, batch=218 
12228: loss=0.044, reward_mean=0.510, reward_bound=0.321, batch=222 
12229: loss=0.045, reward_mean=0.480, reward_bound=0.387, batch=222 
12230: loss=0.044, reward_mean=0.490, reward_bound=0.349, batch=224 
12231: loss=0.044, reward_mean=0.600, reward_bound=0.384, batch=227 
12232: loss=0.044, reward_mean=0.480, reward_bound=0.387, batch=227 
12233: loss=0.043, reward_mean=0.360, reward_bound=0.302, batch=229 
12234: loss=0.043, reward_mean=0.550, reward_bound=0.405, batch=230 
12235: loss=0.043, reward_mean=0.500, reward_bound=0.418, batch=231 
12236: loss=0.039, reward_mean=0.450, reward_bound=0.430, batch=173 
12237: loss=0.040, reward_mean=0.510, reward_bound=0.144, batch=191 
12238: loss=0.039, reward_mean=0.470, reward_bound=0.150, batch=203 
12239: loss=0.037, reward_mean=0.490, reward_bound=0.185, batch=208 
12240: loss=0.041, reward_mean=0.520, reward_bound=0.208, batch=215 
12241: loss=0.041, reward_mean=0.590, reward_bound=0.229, batch=219 
12242: loss=0.039, reward_mean=0.410, reward_bound=0.254, batch=222 
12243: loss=0.035, reward_mean=0.480, reward_bound=0.282, batch=212 
12244: loss=0.036, reward_mean=0.390, reward_bound=0.263, batch=218 
12245: loss=0.036, reward_mean=0.500, reward_bound=0.286, batch=222 
12246: loss=0.040, reward_mean=0.430, reward_bound=0.314, batch=214 
12247: loss=0.040, reward_mean=0.490, reward_bound=0.280, batch=220 
12248: loss=0.040, reward_mean=0.510, reward_bound=0.304, batch=224 
12249: loss=0.039, reward_mean=0.460, reward_bound=0.282, batch=226 
12250: loss=0.042, reward_mean=0.500, reward_bound=0.314, batch=224 
12251: loss=0.041, reward_mean=0.560, reward_bound=0.280, batch=227 
12252: loss=0.041, reward_mean=0.450, reward_bound=0.314, batch=228 
12253: loss=0.043, reward_mean=0.430, reward_bound=0.349, batch=219 
12254: loss=0.042, reward_mean=0.560, reward_bound=0.349, batch=222 
12255: loss=0.042, reward_mean=0.450, reward_bound=0.360, batch=225 
12256: loss=0.036, reward_mean=0.470, reward_bound=0.387, batch=205 
12257: loss=0.036, reward_mean=0.510, reward_bound=0.184, batch=213 
12258: loss=0.038, reward_mean=0.480, reward_bound=0.254, batch=218 
12259: loss=0.041, reward_mean=0.530, reward_bound=0.314, batch=219 
12260: loss=0.041, reward_mean=0.440, reward_bound=0.328, batch=223 
12261: loss=0.038, reward_mean=0.530, reward_bound=0.349, batch=219 
12262: loss=0.037, reward_mean=0.550, reward_bound=0.349, batch=221 
12263: loss=0.039, reward_mean=0.500, reward_bound=0.349, batch=223 
12264: loss=0.039, reward_mean=0.530, reward_bound=0.387, batch=223 
12265: loss=0.039, reward_mean=0.450, reward_bound=0.206, batch=225 
12266: loss=0.039, reward_mean=0.530, reward_bound=0.349, batch=225 
12267: loss=0.039, reward_mean=0.510, reward_bound=0.387, batch=224 
12268: loss=0.039, reward_mean=0.450, reward_bound=0.387, batch=226 
12269: loss=0.039, reward_mean=0.510, reward_bound=0.387, batch=227 
12270: loss=0.038, reward_mean=0.490, reward_bound=0.342, batch=229 
12271: loss=0.040, reward_mean=0.550, reward_bound=0.430, batch=207 
12272: loss=0.038, reward_mean=0.460, reward_bound=0.167, batch=214 
12273: loss=0.037, reward_mean=0.470, reward_bound=0.206, batch=219 
12274: loss=0.039, reward_mean=0.460, reward_bound=0.265, batch=223 
12275: loss=0.041, reward_mean=0.490, reward_bound=0.314, batch=225 
12276: loss=0.040, reward_mean=0.550, reward_bound=0.349, batch=223 
12277: loss=0.039, reward_mean=0.470, reward_bound=0.372, batch=226 
12278: loss=0.039, reward_mean=0.540, reward_bound=0.368, batch=228 
12279: loss=0.039, reward_mean=0.460, reward_bound=0.353, batch=229 
12280: loss=0.038, reward_mean=0.560, reward_bound=0.387, batch=225 
12281: loss=0.037, reward_mean=0.510, reward_bound=0.349, batch=226 
12282: loss=0.037, reward_mean=0.540, reward_bound=0.409, batch=228 
12283: loss=0.037, reward_mean=0.480, reward_bound=0.321, batch=229 
12284: loss=0.037, reward_mean=0.550, reward_bound=0.343, batch=230 
12285: loss=0.037, reward_mean=0.540, reward_bound=0.314, batch=230 
12286: loss=0.037, reward_mean=0.490, reward_bound=0.387, batch=230 
12287: loss=0.037, reward_mean=0.500, reward_bound=0.406, batch=231 
12288: loss=0.038, reward_mean=0.550, reward_bound=0.430, batch=224 
12289: loss=0.038, reward_mean=0.510, reward_bound=0.430, batch=225 
12290: loss=0.038, reward_mean=0.520, reward_bound=0.387, batch=226 
12291: loss=0.037, reward_mean=0.570, reward_bound=0.433, batch=228 
12292: loss=0.039, reward_mean=0.660, reward_bound=0.357, batch=229 
12293: loss=0.037, reward_mean=0.500, reward_bound=0.430, batch=228 
12294: loss=0.037, reward_mean=0.540, reward_bound=0.435, batch=229 
12295: loss=0.037, reward_mean=0.480, reward_bound=0.450, batch=230 
12296: loss=0.037, reward_mean=0.420, reward_bound=0.464, batch=231 
12297: loss=0.044, reward_mean=0.540, reward_bound=0.478, batch=149 
12298: loss=0.039, reward_mean=0.570, reward_bound=0.098, batch=173 
12299: loss=0.042, reward_mean=0.520, reward_bound=0.082, batch=191 
12300: loss=0.045, reward_mean=0.490, reward_bound=0.098, batch=201 
12301: loss=0.041, reward_mean=0.380, reward_bound=0.122, batch=209 
12302: loss=0.040, reward_mean=0.520, reward_bound=0.150, batch=212 
12303: loss=0.042, reward_mean=0.580, reward_bound=0.185, batch=214 
12304: loss=0.041, reward_mean=0.510, reward_bound=0.229, batch=209 
12305: loss=0.043, reward_mean=0.520, reward_bound=0.239, batch=216 
12306: loss=0.046, reward_mean=0.500, reward_bound=0.254, batch=208 
12307: loss=0.044, reward_mean=0.530, reward_bound=0.234, batch=215 
12308: loss=0.045, reward_mean=0.480, reward_bound=0.260, batch=220 
12309: loss=0.044, reward_mean=0.470, reward_bound=0.282, batch=212 
12310: loss=0.049, reward_mean=0.540, reward_bound=0.314, batch=202 
12311: loss=0.047, reward_mean=0.510, reward_bound=0.254, batch=210 
12312: loss=0.051, reward_mean=0.460, reward_bound=0.229, batch=216 
12313: loss=0.048, reward_mean=0.560, reward_bound=0.268, batch=221 
12314: loss=0.050, reward_mean=0.510, reward_bound=0.282, batch=221 
12315: loss=0.048, reward_mean=0.440, reward_bound=0.314, batch=224 
12316: loss=0.047, reward_mean=0.510, reward_bound=0.314, batch=226 
12317: loss=0.050, reward_mean=0.560, reward_bound=0.349, batch=202 
12318: loss=0.051, reward_mean=0.500, reward_bound=0.206, batch=212 
12319: loss=0.050, reward_mean=0.500, reward_bound=0.263, batch=218 
12320: loss=0.049, reward_mean=0.400, reward_bound=0.206, batch=221 
12321: loss=0.051, reward_mean=0.470, reward_bound=0.282, batch=222 
12322: loss=0.056, reward_mean=0.470, reward_bound=0.314, batch=224 
12323: loss=0.055, reward_mean=0.530, reward_bound=0.280, batch=227 
12324: loss=0.053, reward_mean=0.540, reward_bound=0.349, batch=225 
12325: loss=0.053, reward_mean=0.520, reward_bound=0.387, batch=203 
12326: loss=0.055, reward_mean=0.500, reward_bound=0.271, batch=212 
12327: loss=0.056, reward_mean=0.480, reward_bound=0.229, batch=218 
12328: loss=0.055, reward_mean=0.360, reward_bound=0.286, batch=222 
12329: loss=0.052, reward_mean=0.530, reward_bound=0.314, batch=223 
12330: loss=0.051, reward_mean=0.470, reward_bound=0.220, batch=226 
12331: loss=0.052, reward_mean=0.560, reward_bound=0.298, batch=228 
12332: loss=0.054, reward_mean=0.450, reward_bound=0.349, batch=224 
12333: loss=0.053, reward_mean=0.460, reward_bound=0.380, batch=227 
12334: loss=0.054, reward_mean=0.490, reward_bound=0.387, batch=222 
12335: loss=0.056, reward_mean=0.560, reward_bound=0.387, batch=224 
12336: loss=0.055, reward_mean=0.520, reward_bound=0.349, batch=226 
12337: loss=0.055, reward_mean=0.530, reward_bound=0.349, batch=227 
12338: loss=0.055, reward_mean=0.570, reward_bound=0.380, batch=229 
12339: loss=0.055, reward_mean=0.520, reward_bound=0.314, batch=229 
12340: loss=0.055, reward_mean=0.530, reward_bound=0.405, batch=230 
12341: loss=0.048, reward_mean=0.520, reward_bound=0.430, batch=193 
12342: loss=0.043, reward_mean=0.540, reward_bound=0.165, batch=205 
12343: loss=0.044, reward_mean=0.530, reward_bound=0.189, batch=213 
12344: loss=0.045, reward_mean=0.470, reward_bound=0.254, batch=218 
12345: loss=0.045, reward_mean=0.550, reward_bound=0.282, batch=219 
12346: loss=0.045, reward_mean=0.500, reward_bound=0.314, batch=212 
12347: loss=0.046, reward_mean=0.480, reward_bound=0.245, batch=218 
12348: loss=0.046, reward_mean=0.590, reward_bound=0.314, batch=221 
12349: loss=0.045, reward_mean=0.450, reward_bound=0.282, batch=222 
12350: loss=0.048, reward_mean=0.450, reward_bound=0.349, batch=215 
12351: loss=0.047, reward_mean=0.540, reward_bound=0.282, batch=219 
12352: loss=0.047, reward_mean=0.500, reward_bound=0.239, batch=223 
12353: loss=0.047, reward_mean=0.510, reward_bound=0.282, batch=224 
12354: loss=0.050, reward_mean=0.560, reward_bound=0.314, batch=222 
12355: loss=0.050, reward_mean=0.490, reward_bound=0.349, batch=223 
12356: loss=0.050, reward_mean=0.500, reward_bound=0.387, batch=216 
12357: loss=0.049, reward_mean=0.510, reward_bound=0.368, batch=221 
12358: loss=0.048, reward_mean=0.490, reward_bound=0.349, batch=223 
12359: loss=0.048, reward_mean=0.520, reward_bound=0.314, batch=225 
12360: loss=0.049, reward_mean=0.520, reward_bound=0.296, batch=227 
12361: loss=0.049, reward_mean=0.460, reward_bound=0.380, batch=229 
12362: loss=0.048, reward_mean=0.540, reward_bound=0.387, batch=224 
12363: loss=0.049, reward_mean=0.510, reward_bound=0.419, batch=227 
12364: loss=0.049, reward_mean=0.470, reward_bound=0.387, batch=227 
12365: loss=0.049, reward_mean=0.460, reward_bound=0.373, batch=229 
12366: loss=0.050, reward_mean=0.560, reward_bound=0.430, batch=215 
12367: loss=0.051, reward_mean=0.470, reward_bound=0.229, batch=219 
12368: loss=0.049, reward_mean=0.540, reward_bound=0.387, batch=221 
12369: loss=0.048, reward_mean=0.480, reward_bound=0.282, batch=223 
12370: loss=0.048, reward_mean=0.560, reward_bound=0.349, batch=225 
12371: loss=0.050, reward_mean=0.490, reward_bound=0.387, batch=226 
12372: loss=0.053, reward_mean=0.440, reward_bound=0.335, batch=228 
12373: loss=0.049, reward_mean=0.490, reward_bound=0.392, batch=229 
12374: loss=0.048, reward_mean=0.440, reward_bound=0.430, batch=225 
12375: loss=0.048, reward_mean=0.480, reward_bound=0.430, batch=226 
12376: loss=0.048, reward_mean=0.510, reward_bound=0.349, batch=227 
12377: loss=0.048, reward_mean=0.450, reward_bound=0.422, batch=229 
12378: loss=0.047, reward_mean=0.500, reward_bound=0.405, batch=230 
12379: loss=0.048, reward_mean=0.460, reward_bound=0.430, batch=228 
12380: loss=0.048, reward_mean=0.550, reward_bound=0.392, batch=229 
12381: loss=0.047, reward_mean=0.490, reward_bound=0.381, batch=230 
12382: loss=0.049, reward_mean=0.500, reward_bound=0.418, batch=231 
12383: loss=0.048, reward_mean=0.480, reward_bound=0.430, batch=228 
12384: loss=0.047, reward_mean=0.620, reward_bound=0.478, batch=230 
12385: loss=0.047, reward_mean=0.520, reward_bound=0.464, batch=231 
12386: loss=0.048, reward_mean=0.640, reward_bound=0.478, batch=183 
12387: loss=0.050, reward_mean=0.460, reward_bound=0.206, batch=197 
12388: loss=0.049, reward_mean=0.550, reward_bound=0.206, batch=205 
12389: loss=0.050, reward_mean=0.480, reward_bound=0.229, batch=211 
12390: loss=0.049, reward_mean=0.610, reward_bound=0.254, batch=216 
12391: loss=0.048, reward_mean=0.500, reward_bound=0.282, batch=214 
12392: loss=0.049, reward_mean=0.570, reward_bound=0.305, batch=220 
12393: loss=0.051, reward_mean=0.470, reward_bound=0.314, batch=218 
12394: loss=0.051, reward_mean=0.500, reward_bound=0.289, batch=222 
12395: loss=0.050, reward_mean=0.510, reward_bound=0.282, batch=224 
12396: loss=0.049, reward_mean=0.460, reward_bound=0.349, batch=214 
12397: loss=0.050, reward_mean=0.500, reward_bound=0.349, batch=219 
12398: loss=0.048, reward_mean=0.590, reward_bound=0.387, batch=208 
12399: loss=0.048, reward_mean=0.560, reward_bound=0.282, batch=213 
12400: loss=0.047, reward_mean=0.510, reward_bound=0.229, batch=217 
12401: loss=0.047, reward_mean=0.560, reward_bound=0.282, batch=219 
12402: loss=0.048, reward_mean=0.520, reward_bound=0.295, batch=223 
12403: loss=0.046, reward_mean=0.540, reward_bound=0.314, batch=223 
12404: loss=0.046, reward_mean=0.570, reward_bound=0.349, batch=223 
12405: loss=0.047, reward_mean=0.570, reward_bound=0.387, batch=222 
12406: loss=0.046, reward_mean=0.520, reward_bound=0.302, batch=225 
12407: loss=0.046, reward_mean=0.470, reward_bound=0.349, batch=225 
12408: loss=0.046, reward_mean=0.530, reward_bound=0.396, batch=227 
12409: loss=0.049, reward_mean=0.560, reward_bound=0.430, batch=210 
12410: loss=0.048, reward_mean=0.550, reward_bound=0.349, batch=215 
12411: loss=0.047, reward_mean=0.510, reward_bound=0.253, batch=220 
12412: loss=0.047, reward_mean=0.390, reward_bound=0.349, batch=221 
12413: loss=0.047, reward_mean=0.390, reward_bound=0.314, batch=222 
12414: loss=0.048, reward_mean=0.510, reward_bound=0.324, batch=225 
12415: loss=0.049, reward_mean=0.530, reward_bound=0.356, batch=227 
12416: loss=0.049, reward_mean=0.530, reward_bound=0.373, batch=229 
12417: loss=0.050, reward_mean=0.550, reward_bound=0.387, batch=225 
12418: loss=0.058, reward_mean=0.540, reward_bound=0.430, batch=220 
12419: loss=0.059, reward_mean=0.430, reward_bound=0.338, batch=224 
12420: loss=0.058, reward_mean=0.500, reward_bound=0.384, batch=227 
12421: loss=0.057, reward_mean=0.610, reward_bound=0.387, batch=226 
12422: loss=0.057, reward_mean=0.580, reward_bound=0.430, batch=223 
12423: loss=0.056, reward_mean=0.570, reward_bound=0.358, batch=226 
12424: loss=0.056, reward_mean=0.470, reward_bound=0.387, batch=227 
12425: loss=0.056, reward_mean=0.530, reward_bound=0.430, batch=228 
12426: loss=0.055, reward_mean=0.510, reward_bound=0.435, batch=229 
12427: loss=0.055, reward_mean=0.520, reward_bound=0.430, batch=229 
12428: loss=0.060, reward_mean=0.540, reward_bound=0.478, batch=231 
12429: loss=0.062, reward_mean=0.570, reward_bound=0.478, batch=200 
12430: loss=0.057, reward_mean=0.480, reward_bound=0.167, batch=209 
12431: loss=0.057, reward_mean=0.550, reward_bound=0.215, batch=216 
12432: loss=0.058, reward_mean=0.450, reward_bound=0.229, batch=218 
12433: loss=0.061, reward_mean=0.550, reward_bound=0.282, batch=218 
12434: loss=0.060, reward_mean=0.560, reward_bound=0.314, batch=220 
12435: loss=0.059, reward_mean=0.520, reward_bound=0.329, batch=224 
12436: loss=0.058, reward_mean=0.560, reward_bound=0.349, batch=215 
12437: loss=0.056, reward_mean=0.520, reward_bound=0.356, batch=220 
12438: loss=0.057, reward_mean=0.480, reward_bound=0.329, batch=224 
12439: loss=0.057, reward_mean=0.530, reward_bound=0.349, batch=226 
12440: loss=0.054, reward_mean=0.490, reward_bound=0.387, batch=220 
12441: loss=0.053, reward_mean=0.450, reward_bound=0.338, batch=224 
12442: loss=0.053, reward_mean=0.480, reward_bound=0.314, batch=226 
12443: loss=0.052, reward_mean=0.520, reward_bound=0.349, batch=227 
12444: loss=0.056, reward_mean=0.520, reward_bound=0.430, batch=214 
12445: loss=0.059, reward_mean=0.460, reward_bound=0.280, batch=220 
12446: loss=0.056, reward_mean=0.430, reward_bound=0.282, batch=223 
12447: loss=0.056, reward_mean=0.490, reward_bound=0.271, batch=226 
12448: loss=0.055, reward_mean=0.520, reward_bound=0.314, batch=225 
12449: loss=0.057, reward_mean=0.570, reward_bound=0.349, batch=225 
12450: loss=0.061, reward_mean=0.450, reward_bound=0.387, batch=223 
12451: loss=0.059, reward_mean=0.470, reward_bound=0.301, batch=226 
12452: loss=0.059, reward_mean=0.530, reward_bound=0.314, batch=226 
12453: loss=0.060, reward_mean=0.570, reward_bound=0.349, batch=225 
12454: loss=0.059, reward_mean=0.440, reward_bound=0.349, batch=226 
12455: loss=0.059, reward_mean=0.610, reward_bound=0.409, batch=228 
12456: loss=0.059, reward_mean=0.450, reward_bound=0.392, batch=229 
12457: loss=0.056, reward_mean=0.480, reward_bound=0.430, batch=220 
12458: loss=0.056, reward_mean=0.420, reward_bound=0.406, batch=224 
12459: loss=0.055, reward_mean=0.480, reward_bound=0.345, batch=227 
12460: loss=0.055, reward_mean=0.570, reward_bound=0.430, batch=228 
12461: loss=0.057, reward_mean=0.560, reward_bound=0.435, batch=229 
12462: loss=0.057, reward_mean=0.460, reward_bound=0.424, batch=230 
12463: loss=0.058, reward_mean=0.470, reward_bound=0.478, batch=215 
12464: loss=0.059, reward_mean=0.500, reward_bound=0.289, batch=220 
12465: loss=0.062, reward_mean=0.510, reward_bound=0.304, batch=224 
12466: loss=0.059, reward_mean=0.500, reward_bound=0.345, batch=227 
12467: loss=0.059, reward_mean=0.540, reward_bound=0.342, batch=229 
12468: loss=0.059, reward_mean=0.490, reward_bound=0.349, batch=228 
12469: loss=0.059, reward_mean=0.440, reward_bound=0.353, batch=229 
12470: loss=0.058, reward_mean=0.460, reward_bound=0.387, batch=227 
12471: loss=0.058, reward_mean=0.640, reward_bound=0.430, batch=223 
12472: loss=0.059, reward_mean=0.460, reward_bound=0.358, batch=226 
12473: loss=0.058, reward_mean=0.380, reward_bound=0.321, batch=228 
12474: loss=0.056, reward_mean=0.480, reward_bound=0.387, batch=228 
12475: loss=0.057, reward_mean=0.510, reward_bound=0.430, batch=225 
12476: loss=0.057, reward_mean=0.520, reward_bound=0.406, batch=227 
12477: loss=0.057, reward_mean=0.550, reward_bound=0.387, batch=228 
12478: loss=0.057, reward_mean=0.570, reward_bound=0.435, batch=229 
12479: loss=0.056, reward_mean=0.470, reward_bound=0.405, batch=230 
12480: loss=0.056, reward_mean=0.560, reward_bound=0.430, batch=230 
12481: loss=0.057, reward_mean=0.480, reward_bound=0.478, batch=220 
12482: loss=0.059, reward_mean=0.520, reward_bound=0.349, batch=222 
12483: loss=0.058, reward_mean=0.550, reward_bound=0.349, batch=225 
12484: loss=0.060, reward_mean=0.460, reward_bound=0.356, batch=227 
12485: loss=0.062, reward_mean=0.460, reward_bound=0.373, batch=229 
12486: loss=0.060, reward_mean=0.550, reward_bound=0.405, batch=230 
12487: loss=0.060, reward_mean=0.510, reward_bound=0.430, batch=226 
12488: loss=0.059, reward_mean=0.530, reward_bound=0.478, batch=223 
12489: loss=0.060, reward_mean=0.460, reward_bound=0.301, batch=226 
12490: loss=0.057, reward_mean=0.490, reward_bound=0.331, batch=228 
12491: loss=0.057, reward_mean=0.480, reward_bound=0.353, batch=229 
12492: loss=0.058, reward_mean=0.480, reward_bound=0.387, batch=228 
12493: loss=0.059, reward_mean=0.520, reward_bound=0.435, batch=229 
12494: loss=0.061, reward_mean=0.490, reward_bound=0.478, batch=232 
12495: loss=0.061, reward_mean=0.460, reward_bound=0.445, batch=232 
12496: loss=0.061, reward_mean=0.460, reward_bound=0.415, batch=232 
12497: loss=0.060, reward_mean=0.530, reward_bound=0.478, batch=227 
12498: loss=0.060, reward_mean=0.420, reward_bound=0.460, batch=229 
12499: loss=0.059, reward_mean=0.500, reward_bound=0.364, batch=230 
12500: loss=0.059, reward_mean=0.400, reward_bound=0.418, batch=231 
12501: loss=0.060, reward_mean=0.460, reward_bound=0.430, batch=229 
12502: loss=0.063, reward_mean=0.500, reward_bound=0.478, batch=232 
12503: loss=0.063, reward_mean=0.520, reward_bound=0.415, batch=232 
12504: loss=0.061, reward_mean=0.420, reward_bound=0.478, batch=229 
12505: loss=0.061, reward_mean=0.510, reward_bound=0.424, batch=230 
12506: loss=0.064, reward_mean=0.570, reward_bound=0.464, batch=231 
12507: loss=0.061, reward_mean=0.490, reward_bound=0.478, batch=229 
12508: loss=0.061, reward_mean=0.440, reward_bound=0.471, batch=230 
12509: loss=0.061, reward_mean=0.430, reward_bound=0.376, batch=231 
12510: loss=0.061, reward_mean=0.440, reward_bound=0.430, batch=231 
12511: loss=0.061, reward_mean=0.450, reward_bound=0.430, batch=231 
12512: loss=0.061, reward_mean=0.540, reward_bound=0.478, batch=230 
12513: loss=0.061, reward_mean=0.540, reward_bound=0.464, batch=231 
12514: loss=0.061, reward_mean=0.480, reward_bound=0.430, batch=231 
12515: loss=0.061, reward_mean=0.490, reward_bound=0.430, batch=231 
12516: loss=0.061, reward_mean=0.490, reward_bound=0.430, batch=231 
12517: loss=0.061, reward_mean=0.490, reward_bound=0.478, batch=230 
12518: loss=0.064, reward_mean=0.480, reward_bound=0.418, batch=231 
12519: loss=0.061, reward_mean=0.540, reward_bound=0.430, batch=231 
12520: loss=0.061, reward_mean=0.470, reward_bound=0.478, batch=230 
12522: loss=0.027, reward_mean=0.470, reward_bound=0.000, batch=47 
12523: loss=0.029, reward_mean=0.540, reward_bound=0.000, batch=101 
12524: loss=0.030, reward_mean=0.460, reward_bound=0.000, batch=140 
12525: loss=0.031, reward_mean=0.480, reward_bound=0.003, batch=168 
12526: loss=0.036, reward_mean=0.490, reward_bound=0.017, batch=187 
12527: loss=0.039, reward_mean=0.620, reward_bound=0.031, batch=200 
12528: loss=0.039, reward_mean=0.560, reward_bound=0.046, batch=210 
12529: loss=0.042, reward_mean=0.480, reward_bound=0.052, batch=216 
12530: loss=0.044, reward_mean=0.530, reward_bound=0.072, batch=219 
12531: loss=0.043, reward_mean=0.560, reward_bound=0.089, batch=221 
12532: loss=0.045, reward_mean=0.540, reward_bound=0.122, batch=203 
12533: loss=0.048, reward_mean=0.540, reward_bound=0.135, batch=200 
12534: loss=0.049, reward_mean=0.510, reward_bound=0.150, batch=197 
12535: loss=0.049, reward_mean=0.480, reward_bound=0.150, batch=207 
12536: loss=0.051, reward_mean=0.510, reward_bound=0.167, batch=200 
12537: loss=0.051, reward_mean=0.440, reward_bound=0.185, batch=188 
12538: loss=0.048, reward_mean=0.500, reward_bound=0.152, batch=201 
12539: loss=0.048, reward_mean=0.490, reward_bound=0.167, batch=210 
12540: loss=0.046, reward_mean=0.550, reward_bound=0.206, batch=222 
12541: loss=0.048, reward_mean=0.470, reward_bound=0.206, batch=232 
12542: loss=0.050, reward_mean=0.530, reward_bound=0.206, batch=246 
12543: loss=0.049, reward_mean=0.510, reward_bound=0.206, batch=228 
12544: loss=0.048, reward_mean=0.430, reward_bound=0.229, batch=208 
12545: loss=0.053, reward_mean=0.440, reward_bound=0.254, batch=185 
12546: loss=0.050, reward_mean=0.510, reward_bound=0.089, batch=200 
12547: loss=0.053, reward_mean=0.520, reward_bound=0.150, batch=208 
12548: loss=0.049, reward_mean=0.490, reward_bound=0.167, batch=214 
12549: loss=0.049, reward_mean=0.530, reward_bound=0.206, batch=219 
12550: loss=0.049, reward_mean=0.540, reward_bound=0.254, batch=217 
12551: loss=0.055, reward_mean=0.460, reward_bound=0.282, batch=179 
12552: loss=0.055, reward_mean=0.560, reward_bound=0.167, batch=194 
12553: loss=0.058, reward_mean=0.420, reward_bound=0.135, batch=205 
12554: loss=0.059, reward_mean=0.500, reward_bound=0.127, batch=213 
12555: loss=0.056, reward_mean=0.440, reward_bound=0.178, batch=219 
12556: loss=0.056, reward_mean=0.490, reward_bound=0.206, batch=219 
12557: loss=0.056, reward_mean=0.560, reward_bound=0.282, batch=214 
12558: loss=0.053, reward_mean=0.470, reward_bound=0.314, batch=168 
12559: loss=0.050, reward_mean=0.510, reward_bound=0.090, batch=187 
12560: loss=0.047, reward_mean=0.520, reward_bound=0.135, batch=199 
12561: loss=0.047, reward_mean=0.490, reward_bound=0.150, batch=206 
12562: loss=0.048, reward_mean=0.450, reward_bound=0.167, batch=208 
12563: loss=0.053, reward_mean=0.410, reward_bound=0.185, batch=212 
12564: loss=0.055, reward_mean=0.440, reward_bound=0.206, batch=224 
12565: loss=0.054, reward_mean=0.480, reward_bound=0.206, batch=225 
12566: loss=0.049, reward_mean=0.560, reward_bound=0.254, batch=216 
12567: loss=0.048, reward_mean=0.420, reward_bound=0.254, batch=220 
12568: loss=0.051, reward_mean=0.570, reward_bound=0.282, batch=214 
12569: loss=0.050, reward_mean=0.500, reward_bound=0.282, batch=218 
12570: loss=0.050, reward_mean=0.540, reward_bound=0.314, batch=212 
12571: loss=0.049, reward_mean=0.540, reward_bound=0.292, batch=218 
12572: loss=0.059, reward_mean=0.460, reward_bound=0.349, batch=151 
12573: loss=0.052, reward_mean=0.530, reward_bound=0.042, batch=175 
12574: loss=0.053, reward_mean=0.400, reward_bound=0.066, batch=192 
12575: loss=0.055, reward_mean=0.500, reward_bound=0.109, batch=203 
12576: loss=0.055, reward_mean=0.470, reward_bound=0.135, batch=210 
12577: loss=0.055, reward_mean=0.420, reward_bound=0.167, batch=216 
12578: loss=0.055, reward_mean=0.430, reward_bound=0.176, batch=221 
12579: loss=0.059, reward_mean=0.520, reward_bound=0.185, batch=218 
12580: loss=0.059, reward_mean=0.500, reward_bound=0.206, batch=217 
12581: loss=0.059, reward_mean=0.480, reward_bound=0.224, batch=222 
12582: loss=0.060, reward_mean=0.490, reward_bound=0.229, batch=217 
12583: loss=0.059, reward_mean=0.550, reward_bound=0.254, batch=214 
12584: loss=0.058, reward_mean=0.600, reward_bound=0.282, batch=207 
12585: loss=0.058, reward_mean=0.510, reward_bound=0.277, batch=215 
12586: loss=0.057, reward_mean=0.460, reward_bound=0.254, batch=217 
12587: loss=0.057, reward_mean=0.510, reward_bound=0.308, batch=222 
12588: loss=0.056, reward_mean=0.500, reward_bound=0.292, batch=225 
12589: loss=0.057, reward_mean=0.440, reward_bound=0.314, batch=215 
12590: loss=0.056, reward_mean=0.440, reward_bound=0.254, batch=219 
12591: loss=0.056, reward_mean=0.510, reward_bound=0.254, batch=222 
12592: loss=0.059, reward_mean=0.430, reward_bound=0.292, batch=225 
12593: loss=0.060, reward_mean=0.500, reward_bound=0.321, batch=227 
12594: loss=0.059, reward_mean=0.500, reward_bound=0.349, batch=212 
12595: loss=0.060, reward_mean=0.600, reward_bound=0.360, batch=218 
12596: loss=0.062, reward_mean=0.510, reward_bound=0.254, batch=221 
12597: loss=0.059, reward_mean=0.540, reward_bound=0.349, batch=223 
12598: loss=0.061, reward_mean=0.600, reward_bound=0.314, batch=224 
12599: loss=0.058, reward_mean=0.510, reward_bound=0.387, batch=162 
12600: loss=0.059, reward_mean=0.520, reward_bound=0.085, batch=183 
12601: loss=0.055, reward_mean=0.470, reward_bound=0.117, batch=198 
12602: loss=0.060, reward_mean=0.500, reward_bound=0.185, batch=206 
12603: loss=0.059, reward_mean=0.480, reward_bound=0.150, batch=213 
12604: loss=0.058, reward_mean=0.480, reward_bound=0.185, batch=218 
12605: loss=0.056, reward_mean=0.470, reward_bound=0.206, batch=219 
12606: loss=0.055, reward_mean=0.550, reward_bound=0.254, batch=218 
12607: loss=0.056, reward_mean=0.480, reward_bound=0.282, batch=211 
12608: loss=0.057, reward_mean=0.480, reward_bound=0.229, batch=217 
12609: loss=0.056, reward_mean=0.560, reward_bound=0.282, batch=220 
12610: loss=0.057, reward_mean=0.580, reward_bound=0.314, batch=212 
12611: loss=0.056, reward_mean=0.470, reward_bound=0.254, batch=216 
12612: loss=0.055, reward_mean=0.490, reward_bound=0.282, batch=220 
12613: loss=0.056, reward_mean=0.620, reward_bound=0.314, batch=223 
12614: loss=0.057, reward_mean=0.570, reward_bound=0.335, batch=226 
12615: loss=0.054, reward_mean=0.520, reward_bound=0.349, batch=217 
12616: loss=0.053, reward_mean=0.590, reward_bound=0.254, batch=221 
12617: loss=0.053, reward_mean=0.540, reward_bound=0.282, batch=224 
12618: loss=0.053, reward_mean=0.470, reward_bound=0.314, batch=223 
12619: loss=0.054, reward_mean=0.550, reward_bound=0.349, batch=225 
12620: loss=0.054, reward_mean=0.600, reward_bound=0.314, batch=226 
12621: loss=0.055, reward_mean=0.430, reward_bound=0.387, batch=208 
12622: loss=0.053, reward_mean=0.480, reward_bound=0.234, batch=215 
12623: loss=0.053, reward_mean=0.480, reward_bound=0.282, batch=219 
12624: loss=0.053, reward_mean=0.430, reward_bound=0.314, batch=220 
12625: loss=0.054, reward_mean=0.510, reward_bound=0.349, batch=220 
12626: loss=0.055, reward_mean=0.550, reward_bound=0.349, batch=223 
12627: loss=0.056, reward_mean=0.470, reward_bound=0.349, batch=225 
12628: loss=0.056, reward_mean=0.520, reward_bound=0.387, batch=218 
12629: loss=0.055, reward_mean=0.440, reward_bound=0.254, batch=221 
12630: loss=0.055, reward_mean=0.460, reward_bound=0.430, batch=112 
12631: loss=0.043, reward_mean=0.580, reward_bound=0.027, batch=148 
12632: loss=0.040, reward_mean=0.530, reward_bound=0.042, batch=172 
12633: loss=0.042, reward_mean=0.400, reward_bound=0.049, batch=190 
12634: loss=0.044, reward_mean=0.520, reward_bound=0.072, batch=198 
12635: loss=0.044, reward_mean=0.500, reward_bound=0.109, batch=202 
12636: loss=0.047, reward_mean=0.560, reward_bound=0.135, batch=200 
12637: loss=0.038, reward_mean=0.460, reward_bound=0.150, batch=205 
12638: loss=0.042, reward_mean=0.480, reward_bound=0.167, batch=210 
12639: loss=0.042, reward_mean=0.550, reward_bound=0.185, batch=208 
12640: loss=0.041, reward_mean=0.570, reward_bound=0.206, batch=202 
12641: loss=0.043, reward_mean=0.570, reward_bound=0.229, batch=200 
12642: loss=0.041, reward_mean=0.480, reward_bound=0.185, batch=210 
12643: loss=0.044, reward_mean=0.600, reward_bound=0.254, batch=208 
12644: loss=0.043, reward_mean=0.460, reward_bound=0.282, batch=201 
12645: loss=0.042, reward_mean=0.520, reward_bound=0.206, batch=210 
12646: loss=0.040, reward_mean=0.430, reward_bound=0.127, batch=217 
12647: loss=0.042, reward_mean=0.570, reward_bound=0.254, batch=220 
12648: loss=0.051, reward_mean=0.500, reward_bound=0.314, batch=195 
12649: loss=0.048, reward_mean=0.530, reward_bound=0.179, batch=206 
12650: loss=0.047, reward_mean=0.550, reward_bound=0.254, batch=212 
12651: loss=0.047, reward_mean=0.480, reward_bound=0.245, batch=218 
12652: loss=0.047, reward_mean=0.490, reward_bound=0.282, batch=218 
12653: loss=0.047, reward_mean=0.410, reward_bound=0.314, batch=215 
12654: loss=0.046, reward_mean=0.500, reward_bound=0.314, batch=217 
12655: loss=0.045, reward_mean=0.440, reward_bound=0.224, batch=222 
12656: loss=0.045, reward_mean=0.510, reward_bound=0.292, batch=225 
12657: loss=0.046, reward_mean=0.490, reward_bound=0.314, batch=226 
12658: loss=0.055, reward_mean=0.530, reward_bound=0.349, batch=199 
12659: loss=0.055, reward_mean=0.530, reward_bound=0.215, batch=209 
12660: loss=0.053, reward_mean=0.600, reward_bound=0.229, batch=214 
12661: loss=0.050, reward_mean=0.500, reward_bound=0.254, batch=215 
12662: loss=0.050, reward_mean=0.580, reward_bound=0.282, batch=218 
12663: loss=0.051, reward_mean=0.440, reward_bound=0.317, batch=222 
12664: loss=0.050, reward_mean=0.520, reward_bound=0.314, batch=224 
12665: loss=0.052, reward_mean=0.450, reward_bound=0.202, batch=227 
12666: loss=0.052, reward_mean=0.540, reward_bound=0.254, batch=228 
12667: loss=0.053, reward_mean=0.610, reward_bound=0.349, batch=221 
12668: loss=0.052, reward_mean=0.470, reward_bound=0.206, batch=224 
12669: loss=0.052, reward_mean=0.430, reward_bound=0.345, batch=227 
12670: loss=0.052, reward_mean=0.440, reward_bound=0.380, batch=229 
12671: loss=0.051, reward_mean=0.490, reward_bound=0.328, batch=230 
12672: loss=0.056, reward_mean=0.550, reward_bound=0.387, batch=183 
12673: loss=0.053, reward_mean=0.550, reward_bound=0.160, batch=198 
12674: loss=0.052, reward_mean=0.450, reward_bound=0.185, batch=205 
12675: loss=0.055, reward_mean=0.510, reward_bound=0.175, batch=213 
12676: loss=0.053, reward_mean=0.560, reward_bound=0.206, batch=217 
12677: loss=0.058, reward_mean=0.560, reward_bound=0.254, batch=218 
12678: loss=0.060, reward_mean=0.480, reward_bound=0.282, batch=213 
12679: loss=0.060, reward_mean=0.530, reward_bound=0.254, batch=218 
12680: loss=0.057, reward_mean=0.580, reward_bound=0.314, batch=216 
12681: loss=0.057, reward_mean=0.570, reward_bound=0.298, batch=221 
12682: loss=0.057, reward_mean=0.550, reward_bound=0.314, batch=223 
12683: loss=0.058, reward_mean=0.610, reward_bound=0.349, batch=221 
12684: loss=0.057, reward_mean=0.510, reward_bound=0.349, batch=224 
12685: loss=0.057, reward_mean=0.470, reward_bound=0.314, batch=226 
12686: loss=0.053, reward_mean=0.470, reward_bound=0.387, batch=214 
12687: loss=0.051, reward_mean=0.360, reward_bound=0.202, batch=220 
12688: loss=0.056, reward_mean=0.530, reward_bound=0.274, batch=224 
12689: loss=0.057, reward_mean=0.440, reward_bound=0.282, batch=224 
12690: loss=0.059, reward_mean=0.440, reward_bound=0.280, batch=227 
12691: loss=0.056, reward_mean=0.480, reward_bound=0.282, batch=228 
12692: loss=0.054, reward_mean=0.480, reward_bound=0.349, batch=226 
12693: loss=0.053, reward_mean=0.540, reward_bound=0.387, batch=222 
12694: loss=0.054, reward_mean=0.360, reward_bound=0.400, batch=225 
12695: loss=0.054, reward_mean=0.500, reward_bound=0.387, batch=226 
12696: loss=0.054, reward_mean=0.480, reward_bound=0.409, batch=228 
12697: loss=0.054, reward_mean=0.460, reward_bound=0.430, batch=172 
12698: loss=0.050, reward_mean=0.570, reward_bound=0.155, batch=190 
12699: loss=0.049, reward_mean=0.450, reward_bound=0.167, batch=201 
12700: loss=0.054, reward_mean=0.490, reward_bound=0.206, batch=207 
12701: loss=0.055, reward_mean=0.530, reward_bound=0.229, batch=204 
12702: loss=0.054, reward_mean=0.500, reward_bound=0.254, batch=203 
12703: loss=0.052, reward_mean=0.590, reward_bound=0.220, batch=212 
12704: loss=0.053, reward_mean=0.500, reward_bound=0.254, batch=217 
12705: loss=0.052, reward_mean=0.530, reward_bound=0.245, batch=222 
12706: loss=0.053, reward_mean=0.450, reward_bound=0.282, batch=220 
12707: loss=0.059, reward_mean=0.520, reward_bound=0.314, batch=217 
12708: loss=0.059, reward_mean=0.520, reward_bound=0.349, batch=212 
12709: loss=0.057, reward_mean=0.520, reward_bound=0.292, batch=218 
12710: loss=0.057, reward_mean=0.480, reward_bound=0.349, batch=220 
12711: loss=0.056, reward_mean=0.470, reward_bound=0.387, batch=214 
12712: loss=0.056, reward_mean=0.490, reward_bound=0.280, batch=220 
12713: loss=0.056, reward_mean=0.450, reward_bound=0.247, batch=224 
12714: loss=0.056, reward_mean=0.530, reward_bound=0.254, batch=226 
12715: loss=0.056, reward_mean=0.560, reward_bound=0.331, batch=228 
12716: loss=0.055, reward_mean=0.580, reward_bound=0.387, batch=226 
12717: loss=0.055, reward_mean=0.530, reward_bound=0.430, batch=205 
12718: loss=0.053, reward_mean=0.580, reward_bound=0.254, batch=212 
12719: loss=0.056, reward_mean=0.530, reward_bound=0.282, batch=217 
12720: loss=0.057, reward_mean=0.570, reward_bound=0.249, batch=222 
12721: loss=0.054, reward_mean=0.510, reward_bound=0.282, batch=224 
12722: loss=0.054, reward_mean=0.550, reward_bound=0.345, batch=227 
12723: loss=0.054, reward_mean=0.500, reward_bound=0.349, batch=226 
12724: loss=0.054, reward_mean=0.530, reward_bound=0.387, batch=222 
12725: loss=0.055, reward_mean=0.450, reward_bound=0.373, batch=225 
12726: loss=0.054, reward_mean=0.490, reward_bound=0.349, batch=226 
12727: loss=0.054, reward_mean=0.480, reward_bound=0.314, batch=227 
12728: loss=0.054, reward_mean=0.440, reward_bound=0.387, batch=227 
12729: loss=0.054, reward_mean=0.450, reward_bound=0.422, batch=229 
12730: loss=0.053, reward_mean=0.420, reward_bound=0.430, batch=218 
12731: loss=0.052, reward_mean=0.590, reward_bound=0.317, batch=222 
12732: loss=0.052, reward_mean=0.540, reward_bound=0.387, batch=223 
12733: loss=0.051, reward_mean=0.520, reward_bound=0.301, batch=226 
12734: loss=0.051, reward_mean=0.580, reward_bound=0.409, batch=228 
12735: loss=0.053, reward_mean=0.390, reward_bound=0.430, batch=226 
12736: loss=0.052, reward_mean=0.360, reward_bound=0.478, batch=98 
12737: loss=0.044, reward_mean=0.510, reward_bound=0.008, batch=136 
12738: loss=0.039, reward_mean=0.510, reward_bound=0.021, batch=165 
12739: loss=0.041, reward_mean=0.470, reward_bound=0.047, batch=184 
12740: loss=0.043, reward_mean=0.560, reward_bound=0.080, batch=193 
12741: loss=0.045, reward_mean=0.520, reward_bound=0.089, batch=202 
12742: loss=0.048, reward_mean=0.500, reward_bound=0.109, batch=206 
12743: loss=0.044, reward_mean=0.540, reward_bound=0.128, batch=214 
12744: loss=0.043, reward_mean=0.580, reward_bound=0.135, batch=212 
12745: loss=0.045, reward_mean=0.550, reward_bound=0.150, batch=212 
12746: loss=0.048, reward_mean=0.500, reward_bound=0.167, batch=210 
12747: loss=0.044, reward_mean=0.490, reward_bound=0.185, batch=211 
12748: loss=0.045, reward_mean=0.450, reward_bound=0.206, batch=203 
12749: loss=0.046, reward_mean=0.510, reward_bound=0.150, batch=210 
12750: loss=0.044, reward_mean=0.420, reward_bound=0.185, batch=216 
12751: loss=0.045, reward_mean=0.510, reward_bound=0.196, batch=221 
12752: loss=0.048, reward_mean=0.450, reward_bound=0.229, batch=211 
12753: loss=0.046, reward_mean=0.560, reward_bound=0.206, batch=217 
12754: loss=0.037, reward_mean=0.520, reward_bound=0.254, batch=195 
12755: loss=0.036, reward_mean=0.540, reward_bound=0.206, batch=204 
12756: loss=0.035, reward_mean=0.440, reward_bound=0.282, batch=192 
12757: loss=0.036, reward_mean=0.580, reward_bound=0.167, batch=202 
12758: loss=0.034, reward_mean=0.530, reward_bound=0.236, batch=211 
12759: loss=0.033, reward_mean=0.480, reward_bound=0.229, batch=215 
12760: loss=0.032, reward_mean=0.570, reward_bound=0.260, batch=220 
12761: loss=0.035, reward_mean=0.410, reward_bound=0.282, batch=216 
12762: loss=0.037, reward_mean=0.450, reward_bound=0.268, batch=221 
12763: loss=0.037, reward_mean=0.530, reward_bound=0.229, batch=224 
12764: loss=0.041, reward_mean=0.500, reward_bound=0.314, batch=197 
12765: loss=0.041, reward_mean=0.510, reward_bound=0.229, batch=207 
12766: loss=0.043, reward_mean=0.450, reward_bound=0.206, batch=214 
12767: loss=0.040, reward_mean=0.460, reward_bound=0.280, batch=220 
12768: loss=0.039, reward_mean=0.460, reward_bound=0.282, batch=223 
12769: loss=0.041, reward_mean=0.510, reward_bound=0.314, batch=217 
12770: loss=0.040, reward_mean=0.500, reward_bound=0.314, batch=219 
12771: loss=0.040, reward_mean=0.530, reward_bound=0.295, batch=223 
12772: loss=0.039, reward_mean=0.480, reward_bound=0.349, batch=181 
12773: loss=0.039, reward_mean=0.480, reward_bound=0.150, batch=196 
12774: loss=0.039, reward_mean=0.510, reward_bound=0.196, batch=207 
12775: loss=0.039, reward_mean=0.450, reward_bound=0.206, batch=212 
12776: loss=0.038, reward_mean=0.500, reward_bound=0.229, batch=209 
12777: loss=0.036, reward_mean=0.400, reward_bound=0.239, batch=216 
12778: loss=0.039, reward_mean=0.620, reward_bound=0.268, batch=221 
12779: loss=0.038, reward_mean=0.500, reward_bound=0.282, batch=217 
12780: loss=0.040, reward_mean=0.520, reward_bound=0.314, batch=213 
12781: loss=0.040, reward_mean=0.490, reward_bound=0.235, batch=219 
12782: loss=0.040, reward_mean=0.500, reward_bound=0.254, batch=221 
12783: loss=0.038, reward_mean=0.530, reward_bound=0.314, batch=222 
12784: loss=0.036, reward_mean=0.570, reward_bound=0.349, batch=216 
12785: loss=0.035, reward_mean=0.530, reward_bound=0.351, batch=221 
12786: loss=0.035, reward_mean=0.550, reward_bound=0.349, batch=223 
12787: loss=0.041, reward_mean=0.530, reward_bound=0.387, batch=189 
12788: loss=0.042, reward_mean=0.490, reward_bound=0.150, batch=200 
12789: loss=0.040, reward_mean=0.530, reward_bound=0.222, batch=210 
12790: loss=0.039, reward_mean=0.560, reward_bound=0.216, batch=217 
12791: loss=0.038, reward_mean=0.580, reward_bound=0.249, batch=222 
12792: loss=0.041, reward_mean=0.580, reward_bound=0.282, batch=219 
12793: loss=0.038, reward_mean=0.490, reward_bound=0.314, batch=221 
12794: loss=0.039, reward_mean=0.480, reward_bound=0.349, batch=213 
12795: loss=0.038, reward_mean=0.470, reward_bound=0.271, batch=219 
12796: loss=0.039, reward_mean=0.540, reward_bound=0.295, batch=223 
12797: loss=0.040, reward_mean=0.510, reward_bound=0.349, batch=222 
12798: loss=0.045, reward_mean=0.610, reward_bound=0.387, batch=216 
12799: loss=0.047, reward_mean=0.500, reward_bound=0.268, batch=221 
12800: loss=0.047, reward_mean=0.500, reward_bound=0.349, batch=224 
12801: loss=0.046, reward_mean=0.410, reward_bound=0.384, batch=227 
12802: loss=0.045, reward_mean=0.450, reward_bound=0.302, batch=229 
12803: loss=0.045, reward_mean=0.520, reward_bound=0.387, batch=225 
12804: loss=0.044, reward_mean=0.440, reward_bound=0.321, batch=227 
12805: loss=0.045, reward_mean=0.520, reward_bound=0.349, batch=227 
12806: loss=0.044, reward_mean=0.550, reward_bound=0.349, batch=228 
12807: loss=0.046, reward_mean=0.500, reward_bound=0.387, batch=228 
12808: loss=0.046, reward_mean=0.490, reward_bound=0.353, batch=229 
12809: loss=0.046, reward_mean=0.580, reward_bound=0.405, batch=230 
12810: loss=0.046, reward_mean=0.470, reward_bound=0.314, batch=230 
12811: loss=0.045, reward_mean=0.560, reward_bound=0.430, batch=173 
12812: loss=0.041, reward_mean=0.370, reward_bound=0.085, batch=191 
12813: loss=0.044, reward_mean=0.440, reward_bound=0.135, batch=201 
12814: loss=0.045, reward_mean=0.540, reward_bound=0.167, batch=209 
12815: loss=0.044, reward_mean=0.420, reward_bound=0.185, batch=210 
12816: loss=0.042, reward_mean=0.510, reward_bound=0.229, batch=212 
12817: loss=0.041, reward_mean=0.490, reward_bound=0.236, batch=218 
12818: loss=0.044, reward_mean=0.520, reward_bound=0.282, batch=214 
12819: loss=0.045, reward_mean=0.490, reward_bound=0.314, batch=211 
12820: loss=0.045, reward_mean=0.570, reward_bound=0.349, batch=206 
12821: loss=0.045, reward_mean=0.570, reward_bound=0.229, batch=212 
12822: loss=0.042, reward_mean=0.440, reward_bound=0.254, batch=216 
12823: loss=0.043, reward_mean=0.420, reward_bound=0.268, batch=221 
12824: loss=0.045, reward_mean=0.460, reward_bound=0.282, batch=223 
12825: loss=0.044, reward_mean=0.550, reward_bound=0.314, batch=225 
12826: loss=0.044, reward_mean=0.540, reward_bound=0.349, batch=219 
12827: loss=0.043, reward_mean=0.490, reward_bound=0.277, batch=223 
12828: loss=0.043, reward_mean=0.510, reward_bound=0.349, batch=224 
12829: loss=0.043, reward_mean=0.540, reward_bound=0.314, batch=225 
12830: loss=0.042, reward_mean=0.510, reward_bound=0.289, batch=227 
12831: loss=0.042, reward_mean=0.470, reward_bound=0.380, batch=229 
12832: loss=0.046, reward_mean=0.550, reward_bound=0.387, batch=204 
12833: loss=0.050, reward_mean=0.530, reward_bound=0.380, batch=213 
12834: loss=0.049, reward_mean=0.550, reward_bound=0.282, batch=217 
12835: loss=0.047, reward_mean=0.500, reward_bound=0.308, batch=222 
12836: loss=0.048, reward_mean=0.500, reward_bound=0.349, batch=223 
12837: loss=0.043, reward_mean=0.540, reward_bound=0.387, batch=223 
12838: loss=0.046, reward_mean=0.550, reward_bound=0.387, batch=225 
12839: loss=0.047, reward_mean=0.550, reward_bound=0.396, batch=227 
12840: loss=0.048, reward_mean=0.480, reward_bound=0.422, batch=229 
12841: loss=0.045, reward_mean=0.510, reward_bound=0.430, batch=212 
12842: loss=0.045, reward_mean=0.520, reward_bound=0.292, batch=218 
12843: loss=0.045, reward_mean=0.540, reward_bound=0.349, batch=218 
12844: loss=0.047, reward_mean=0.560, reward_bound=0.387, batch=219 
12845: loss=0.046, reward_mean=0.550, reward_bound=0.405, batch=223 
12846: loss=0.045, reward_mean=0.540, reward_bound=0.430, batch=221 
12847: loss=0.046, reward_mean=0.490, reward_bound=0.314, batch=223 
12848: loss=0.047, reward_mean=0.530, reward_bound=0.372, batch=226 
12849: loss=0.048, reward_mean=0.550, reward_bound=0.387, batch=225 
12850: loss=0.047, reward_mean=0.590, reward_bound=0.356, batch=227 
12851: loss=0.047, reward_mean=0.580, reward_bound=0.387, batch=227 
12852: loss=0.046, reward_mean=0.550, reward_bound=0.430, batch=226 
12853: loss=0.046, reward_mean=0.500, reward_bound=0.387, batch=227 
12854: loss=0.046, reward_mean=0.490, reward_bound=0.387, batch=228 
12855: loss=0.047, reward_mean=0.520, reward_bound=0.435, batch=229 
12856: loss=0.047, reward_mean=0.540, reward_bound=0.478, batch=231 
12857: loss=0.047, reward_mean=0.490, reward_bound=0.430, batch=231 
12858: loss=0.052, reward_mean=0.390, reward_bound=0.478, batch=148 
12859: loss=0.056, reward_mean=0.580, reward_bound=0.122, batch=172 
12860: loss=0.058, reward_mean=0.500, reward_bound=0.105, batch=190 
12861: loss=0.057, reward_mean=0.530, reward_bound=0.135, batch=198 
12862: loss=0.056, reward_mean=0.520, reward_bound=0.137, batch=208 
12863: loss=0.056, reward_mean=0.580, reward_bound=0.167, batch=211 
12864: loss=0.059, reward_mean=0.530, reward_bound=0.185, batch=212 
12865: loss=0.059, reward_mean=0.530, reward_bound=0.206, batch=225 
12866: loss=0.063, reward_mean=0.480, reward_bound=0.206, batch=223 
12867: loss=0.060, reward_mean=0.520, reward_bound=0.229, batch=220 
12868: loss=0.061, reward_mean=0.550, reward_bound=0.254, batch=220 
12869: loss=0.061, reward_mean=0.540, reward_bound=0.282, batch=213 
12870: loss=0.062, reward_mean=0.450, reward_bound=0.314, batch=201 
12871: loss=0.061, reward_mean=0.520, reward_bound=0.254, batch=208 
12872: loss=0.064, reward_mean=0.400, reward_bound=0.282, batch=214 
12873: loss=0.061, reward_mean=0.460, reward_bound=0.314, batch=213 
12874: loss=0.063, reward_mean=0.550, reward_bound=0.282, batch=217 
12875: loss=0.063, reward_mean=0.520, reward_bound=0.302, batch=222 
12876: loss=0.061, reward_mean=0.490, reward_bound=0.314, batch=222 
12877: loss=0.061, reward_mean=0.510, reward_bound=0.254, batch=224 
12878: loss=0.061, reward_mean=0.510, reward_bound=0.345, batch=227 
12879: loss=0.060, reward_mean=0.490, reward_bound=0.349, batch=205 
12880: loss=0.058, reward_mean=0.520, reward_bound=0.175, batch=213 
12881: loss=0.056, reward_mean=0.400, reward_bound=0.244, batch=219 
12882: loss=0.057, reward_mean=0.580, reward_bound=0.254, batch=222 
12883: loss=0.056, reward_mean=0.530, reward_bound=0.282, batch=224 
12884: loss=0.056, reward_mean=0.480, reward_bound=0.314, batch=225 
12885: loss=0.058, reward_mean=0.550, reward_bound=0.349, batch=220 
12886: loss=0.057, reward_mean=0.470, reward_bound=0.376, batch=224 
12887: loss=0.056, reward_mean=0.540, reward_bound=0.384, batch=227 
12888: loss=0.056, reward_mean=0.500, reward_bound=0.314, batch=228 
12889: loss=0.053, reward_mean=0.450, reward_bound=0.387, batch=196 
12890: loss=0.051, reward_mean=0.530, reward_bound=0.217, batch=207 
12891: loss=0.049, reward_mean=0.590, reward_bound=0.249, batch=215 
12892: loss=0.050, reward_mean=0.490, reward_bound=0.254, batch=219 
12893: loss=0.047, reward_mean=0.570, reward_bound=0.282, batch=219 
12894: loss=0.046, reward_mean=0.440, reward_bound=0.265, batch=223 
12895: loss=0.047, reward_mean=0.480, reward_bound=0.301, batch=226 
12896: loss=0.047, reward_mean=0.580, reward_bound=0.298, batch=228 
12897: loss=0.047, reward_mean=0.400, reward_bound=0.314, batch=224 
12898: loss=0.048, reward_mean=0.460, reward_bound=0.349, batch=219 
12899: loss=0.049, reward_mean=0.440, reward_bound=0.292, batch=223 
12900: loss=0.050, reward_mean=0.520, reward_bound=0.322, batch=226 
12901: loss=0.053, reward_mean=0.490, reward_bound=0.349, batch=227 
12902: loss=0.054, reward_mean=0.500, reward_bound=0.387, batch=224 
12903: loss=0.055, reward_mean=0.520, reward_bound=0.430, batch=200 
12904: loss=0.054, reward_mean=0.480, reward_bound=0.247, batch=210 
12905: loss=0.056, reward_mean=0.410, reward_bound=0.229, batch=215 
12906: loss=0.058, reward_mean=0.470, reward_bound=0.282, batch=218 
12907: loss=0.056, reward_mean=0.490, reward_bound=0.314, batch=216 
12908: loss=0.058, reward_mean=0.530, reward_bound=0.282, batch=219 
12909: loss=0.057, reward_mean=0.510, reward_bound=0.265, batch=223 
12910: loss=0.057, reward_mean=0.450, reward_bound=0.314, batch=224 
12911: loss=0.059, reward_mean=0.530, reward_bound=0.349, batch=220 
12912: loss=0.059, reward_mean=0.500, reward_bound=0.387, batch=219 
12913: loss=0.059, reward_mean=0.530, reward_bound=0.328, batch=223 
12914: loss=0.059, reward_mean=0.510, reward_bound=0.254, batch=224 
12915: loss=0.059, reward_mean=0.480, reward_bound=0.314, batch=226 
12916: loss=0.059, reward_mean=0.500, reward_bound=0.331, batch=228 
12917: loss=0.059, reward_mean=0.510, reward_bound=0.349, batch=227 
12918: loss=0.058, reward_mean=0.530, reward_bound=0.380, batch=229 
12919: loss=0.057, reward_mean=0.530, reward_bound=0.387, batch=228 
12920: loss=0.053, reward_mean=0.480, reward_bound=0.430, batch=212 
12921: loss=0.052, reward_mean=0.560, reward_bound=0.292, batch=218 
12922: loss=0.051, reward_mean=0.470, reward_bound=0.349, batch=219 
12923: loss=0.051, reward_mean=0.540, reward_bound=0.364, batch=223 
12924: loss=0.051, reward_mean=0.500, reward_bound=0.372, batch=226 
12925: loss=0.052, reward_mean=0.490, reward_bound=0.387, batch=224 
12926: loss=0.052, reward_mean=0.550, reward_bound=0.349, batch=226 
12927: loss=0.051, reward_mean=0.470, reward_bound=0.409, batch=228 
12928: loss=0.051, reward_mean=0.430, reward_bound=0.392, batch=229 
12929: loss=0.052, reward_mean=0.530, reward_bound=0.430, batch=219 
12930: loss=0.052, reward_mean=0.530, reward_bound=0.328, batch=223 
12931: loss=0.053, reward_mean=0.550, reward_bound=0.301, batch=226 
12932: loss=0.052, reward_mean=0.450, reward_bound=0.314, batch=226 
12933: loss=0.051, reward_mean=0.440, reward_bound=0.196, batch=228 
12934: loss=0.052, reward_mean=0.480, reward_bound=0.349, batch=224 
12935: loss=0.055, reward_mean=0.510, reward_bound=0.384, batch=227 
12936: loss=0.054, reward_mean=0.550, reward_bound=0.387, batch=222 
12937: loss=0.054, reward_mean=0.510, reward_bound=0.327, batch=225 
12938: loss=0.053, reward_mean=0.510, reward_bound=0.321, batch=227 
12939: loss=0.053, reward_mean=0.550, reward_bound=0.314, batch=227 
12940: loss=0.054, reward_mean=0.420, reward_bound=0.342, batch=229 
12941: loss=0.053, reward_mean=0.460, reward_bound=0.349, batch=229 
12942: loss=0.053, reward_mean=0.490, reward_bound=0.387, batch=227 
12943: loss=0.053, reward_mean=0.480, reward_bound=0.422, batch=229 
12944: loss=0.054, reward_mean=0.530, reward_bound=0.430, batch=226 
12945: loss=0.053, reward_mean=0.530, reward_bound=0.368, batch=228 
12946: loss=0.053, reward_mean=0.580, reward_bound=0.353, batch=229 
12947: loss=0.053, reward_mean=0.480, reward_bound=0.450, batch=230 
12948: loss=0.053, reward_mean=0.550, reward_bound=0.418, batch=231 
12949: loss=0.057, reward_mean=0.520, reward_bound=0.478, batch=187 
12950: loss=0.053, reward_mean=0.590, reward_bound=0.198, batch=201 
12951: loss=0.053, reward_mean=0.520, reward_bound=0.185, batch=209 
12952: loss=0.054, reward_mean=0.390, reward_bound=0.215, batch=216 
12953: loss=0.059, reward_mean=0.510, reward_bound=0.254, batch=216 
12954: loss=0.055, reward_mean=0.480, reward_bound=0.282, batch=216 
12955: loss=0.058, reward_mean=0.530, reward_bound=0.314, batch=212 
12956: loss=0.060, reward_mean=0.560, reward_bound=0.292, batch=218 
12957: loss=0.056, reward_mean=0.570, reward_bound=0.314, batch=219 
12958: loss=0.057, reward_mean=0.560, reward_bound=0.349, batch=209 
12959: loss=0.056, reward_mean=0.480, reward_bound=0.250, batch=216 
12960: loss=0.056, reward_mean=0.550, reward_bound=0.241, batch=221 
12961: loss=0.055, reward_mean=0.550, reward_bound=0.282, batch=222 
12962: loss=0.056, reward_mean=0.560, reward_bound=0.314, batch=224 
12963: loss=0.055, reward_mean=0.480, reward_bound=0.349, batch=224 
12964: loss=0.054, reward_mean=0.570, reward_bound=0.387, batch=209 
12965: loss=0.054, reward_mean=0.540, reward_bound=0.167, batch=214 
12966: loss=0.053, reward_mean=0.480, reward_bound=0.308, batch=220 
12967: loss=0.053, reward_mean=0.470, reward_bound=0.349, batch=221 
12968: loss=0.053, reward_mean=0.450, reward_bound=0.387, batch=220 
12969: loss=0.053, reward_mean=0.410, reward_bound=0.229, batch=223 
12970: loss=0.054, reward_mean=0.540, reward_bound=0.387, batch=223 
12971: loss=0.055, reward_mean=0.640, reward_bound=0.413, batch=226 
12972: loss=0.055, reward_mean=0.470, reward_bound=0.368, batch=228 
12973: loss=0.055, reward_mean=0.410, reward_bound=0.353, batch=229 
12974: loss=0.054, reward_mean=0.500, reward_bound=0.292, batch=230 
12975: loss=0.055, reward_mean=0.520, reward_bound=0.387, batch=230 
12976: loss=0.054, reward_mean=0.480, reward_bound=0.418, batch=231 
12977: loss=0.055, reward_mean=0.470, reward_bound=0.430, batch=212 
12978: loss=0.055, reward_mean=0.570, reward_bound=0.229, batch=217 
12979: loss=0.054, reward_mean=0.570, reward_bound=0.314, batch=219 
12980: loss=0.053, reward_mean=0.580, reward_bound=0.328, batch=223 
12981: loss=0.054, reward_mean=0.540, reward_bound=0.349, batch=223 
12982: loss=0.056, reward_mean=0.500, reward_bound=0.387, batch=218 
12983: loss=0.057, reward_mean=0.410, reward_bound=0.392, batch=222 
12984: loss=0.056, reward_mean=0.530, reward_bound=0.387, batch=224 
12985: loss=0.059, reward_mean=0.570, reward_bound=0.430, batch=218 
12986: loss=0.059, reward_mean=0.480, reward_bound=0.187, batch=222 
12987: loss=0.057, reward_mean=0.480, reward_bound=0.254, batch=224 
12988: loss=0.058, reward_mean=0.560, reward_bound=0.314, batch=223 
12989: loss=0.058, reward_mean=0.490, reward_bound=0.387, batch=225 
12990: loss=0.058, reward_mean=0.390, reward_bound=0.387, batch=226 
12991: loss=0.058, reward_mean=0.540, reward_bound=0.430, batch=224 
12992: loss=0.058, reward_mean=0.420, reward_bound=0.387, batch=226 
12993: loss=0.058, reward_mean=0.460, reward_bound=0.387, batch=227 
12994: loss=0.057, reward_mean=0.500, reward_bound=0.422, batch=229 
12995: loss=0.057, reward_mean=0.540, reward_bound=0.430, batch=229 
12996: loss=0.057, reward_mean=0.500, reward_bound=0.424, batch=230 
12997: loss=0.057, reward_mean=0.570, reward_bound=0.464, batch=231 
12998: loss=0.054, reward_mean=0.460, reward_bound=0.478, batch=210 
12999: loss=0.052, reward_mean=0.500, reward_bound=0.240, batch=217 
13000: loss=0.054, reward_mean=0.530, reward_bound=0.282, batch=217 
13001: loss=0.053, reward_mean=0.570, reward_bound=0.314, batch=216 
13002: loss=0.054, reward_mean=0.520, reward_bound=0.331, batch=221 
13003: loss=0.055, reward_mean=0.430, reward_bound=0.387, batch=223 
13004: loss=0.055, reward_mean=0.470, reward_bound=0.314, batch=225 
13005: loss=0.059, reward_mean=0.520, reward_bound=0.430, batch=224 
13006: loss=0.058, reward_mean=0.580, reward_bound=0.426, batch=227 
13007: loss=0.057, reward_mean=0.510, reward_bound=0.414, batch=229 
13008: loss=0.057, reward_mean=0.440, reward_bound=0.387, batch=229 
13009: loss=0.057, reward_mean=0.520, reward_bound=0.405, batch=230 
13010: loss=0.059, reward_mean=0.490, reward_bound=0.478, batch=223 
13011: loss=0.058, reward_mean=0.460, reward_bound=0.254, batch=225 
13012: loss=0.059, reward_mean=0.450, reward_bound=0.356, batch=227 
13013: loss=0.059, reward_mean=0.510, reward_bound=0.349, batch=228 
13014: loss=0.059, reward_mean=0.510, reward_bound=0.392, batch=229 
13015: loss=0.059, reward_mean=0.560, reward_bound=0.430, batch=228 
13016: loss=0.060, reward_mean=0.530, reward_bound=0.478, batch=231 
13017: loss=0.059, reward_mean=0.570, reward_bound=0.478, batch=227 
13018: loss=0.059, reward_mean=0.530, reward_bound=0.422, batch=229 
13019: loss=0.059, reward_mean=0.580, reward_bound=0.430, batch=229 
13020: loss=0.059, reward_mean=0.520, reward_bound=0.405, batch=230 
13021: loss=0.058, reward_mean=0.500, reward_bound=0.386, batch=231 
13022: loss=0.059, reward_mean=0.690, reward_bound=0.478, batch=229 
13023: loss=0.059, reward_mean=0.460, reward_bound=0.309, batch=230 
13024: loss=0.059, reward_mean=0.530, reward_bound=0.387, batch=230 
13025: loss=0.059, reward_mean=0.490, reward_bound=0.430, batch=230 
13026: loss=0.059, reward_mean=0.530, reward_bound=0.430, batch=230 
13027: loss=0.059, reward_mean=0.580, reward_bound=0.464, batch=231 
13028: loss=0.059, reward_mean=0.450, reward_bound=0.478, batch=230 
13029: loss=0.059, reward_mean=0.480, reward_bound=0.418, batch=231 
13030: loss=0.059, reward_mean=0.450, reward_bound=0.478, batch=230 
13031: loss=0.059, reward_mean=0.520, reward_bound=0.430, batch=230 
13032: loss=0.059, reward_mean=0.420, reward_bound=0.376, batch=231 
13033: loss=0.059, reward_mean=0.450, reward_bound=0.387, batch=231 
13035: loss=0.033, reward_mean=0.450, reward_bound=0.000, batch=45 
13036: loss=0.035, reward_mean=0.500, reward_bound=0.000, batch=95 
13037: loss=0.034, reward_mean=0.530, reward_bound=0.001, batch=136 
13038: loss=0.037, reward_mean=0.570, reward_bound=0.010, batch=163 
13039: loss=0.043, reward_mean=0.500, reward_bound=0.020, batch=183 
13040: loss=0.039, reward_mean=0.470, reward_bound=0.034, batch=195 
13041: loss=0.040, reward_mean=0.560, reward_bound=0.047, batch=202 
13042: loss=0.041, reward_mean=0.570, reward_bound=0.065, batch=202 
13043: loss=0.044, reward_mean=0.500, reward_bound=0.080, batch=209 
13044: loss=0.045, reward_mean=0.510, reward_bound=0.098, batch=211 
13045: loss=0.047, reward_mean=0.530, reward_bound=0.109, batch=215 
13046: loss=0.049, reward_mean=0.530, reward_bound=0.122, batch=215 
13047: loss=0.051, reward_mean=0.490, reward_bound=0.135, batch=204 
13048: loss=0.054, reward_mean=0.480, reward_bound=0.150, batch=194 
13049: loss=0.054, reward_mean=0.510, reward_bound=0.167, batch=197 
13050: loss=0.056, reward_mean=0.570, reward_bound=0.185, batch=183 
13051: loss=0.062, reward_mean=0.510, reward_bound=0.206, batch=168 
13052: loss=0.060, reward_mean=0.460, reward_bound=0.083, batch=187 
13053: loss=0.064, reward_mean=0.490, reward_bound=0.109, batch=205 
13054: loss=0.062, reward_mean=0.480, reward_bound=0.122, batch=209 
13055: loss=0.057, reward_mean=0.510, reward_bound=0.150, batch=215 
13056: loss=0.057, reward_mean=0.550, reward_bound=0.206, batch=219 
13057: loss=0.056, reward_mean=0.450, reward_bound=0.229, batch=191 
13058: loss=0.056, reward_mean=0.450, reward_bound=0.122, batch=200 
13059: loss=0.058, reward_mean=0.510, reward_bound=0.167, batch=209 
13060: loss=0.055, reward_mean=0.490, reward_bound=0.185, batch=215 
13061: loss=0.054, reward_mean=0.530, reward_bound=0.229, batch=219 
13062: loss=0.055, reward_mean=0.510, reward_bound=0.254, batch=192 
13063: loss=0.057, reward_mean=0.480, reward_bound=0.213, batch=204 
13064: loss=0.058, reward_mean=0.530, reward_bound=0.204, batch=213 
13065: loss=0.058, reward_mean=0.420, reward_bound=0.206, batch=218 
13066: loss=0.060, reward_mean=0.450, reward_bound=0.229, batch=220 
13067: loss=0.059, reward_mean=0.470, reward_bound=0.254, batch=222 
13068: loss=0.061, reward_mean=0.430, reward_bound=0.282, batch=182 
13069: loss=0.058, reward_mean=0.510, reward_bound=0.098, batch=196 
13070: loss=0.060, reward_mean=0.510, reward_bound=0.167, batch=202 
13071: loss=0.063, reward_mean=0.540, reward_bound=0.155, batch=211 
13072: loss=0.063, reward_mean=0.540, reward_bound=0.206, batch=213 
13073: loss=0.061, reward_mean=0.460, reward_bound=0.206, batch=218 
13074: loss=0.062, reward_mean=0.450, reward_bound=0.231, batch=222 
13075: loss=0.062, reward_mean=0.530, reward_bound=0.254, batch=224 
13076: loss=0.060, reward_mean=0.540, reward_bound=0.314, batch=179 
13077: loss=0.058, reward_mean=0.520, reward_bound=0.157, batch=195 
13078: loss=0.057, reward_mean=0.450, reward_bound=0.150, batch=204 
13079: loss=0.057, reward_mean=0.570, reward_bound=0.204, batch=213 
13080: loss=0.055, reward_mean=0.570, reward_bound=0.206, batch=218 
13081: loss=0.055, reward_mean=0.420, reward_bound=0.229, batch=217 
13082: loss=0.055, reward_mean=0.510, reward_bound=0.254, batch=220 
13083: loss=0.056, reward_mean=0.530, reward_bound=0.254, batch=223 
13084: loss=0.057, reward_mean=0.480, reward_bound=0.282, batch=222 
13085: loss=0.058, reward_mean=0.450, reward_bound=0.314, batch=217 
13086: loss=0.059, reward_mean=0.640, reward_bound=0.349, batch=155 
13087: loss=0.054, reward_mean=0.480, reward_bound=0.082, batch=178 
13088: loss=0.053, reward_mean=0.430, reward_bound=0.073, batch=194 
13089: loss=0.049, reward_mean=0.480, reward_bound=0.089, batch=204 
13090: loss=0.047, reward_mean=0.390, reward_bound=0.109, batch=211 
13091: loss=0.050, reward_mean=0.500, reward_bound=0.135, batch=208 
13092: loss=0.051, reward_mean=0.450, reward_bound=0.150, batch=212 
13093: loss=0.054, reward_mean=0.530, reward_bound=0.185, batch=211 
13094: loss=0.055, reward_mean=0.400, reward_bound=0.206, batch=210 
13095: loss=0.053, reward_mean=0.450, reward_bound=0.206, batch=218 
13096: loss=0.055, reward_mean=0.490, reward_bound=0.229, batch=214 
13097: loss=0.057, reward_mean=0.490, reward_bound=0.254, batch=210 
13098: loss=0.056, reward_mean=0.510, reward_bound=0.266, batch=217 
13099: loss=0.055, reward_mean=0.430, reward_bound=0.206, batch=221 
13100: loss=0.054, reward_mean=0.560, reward_bound=0.282, batch=219 
13101: loss=0.053, reward_mean=0.490, reward_bound=0.295, batch=223 
13102: loss=0.054, reward_mean=0.500, reward_bound=0.314, batch=210 
13103: loss=0.052, reward_mean=0.450, reward_bound=0.185, batch=216 
13104: loss=0.054, reward_mean=0.580, reward_bound=0.282, batch=218 
13105: loss=0.055, reward_mean=0.470, reward_bound=0.314, batch=218 
13106: loss=0.056, reward_mean=0.550, reward_bound=0.314, batch=221 
13107: loss=0.055, reward_mean=0.450, reward_bound=0.314, batch=224 
13108: loss=0.058, reward_mean=0.450, reward_bound=0.349, batch=208 
13109: loss=0.060, reward_mean=0.530, reward_bound=0.317, batch=215 
13110: loss=0.059, reward_mean=0.510, reward_bound=0.321, batch=220 
13111: loss=0.060, reward_mean=0.490, reward_bound=0.254, batch=223 
13112: loss=0.060, reward_mean=0.590, reward_bound=0.349, batch=223 
13113: loss=0.059, reward_mean=0.490, reward_bound=0.372, batch=226 
13114: loss=0.060, reward_mean=0.480, reward_bound=0.368, batch=228 
13115: loss=0.060, reward_mean=0.420, reward_bound=0.353, batch=229 
13116: loss=0.062, reward_mean=0.470, reward_bound=0.387, batch=152 
13117: loss=0.056, reward_mean=0.460, reward_bound=0.067, batch=176 
13118: loss=0.057, reward_mean=0.500, reward_bound=0.076, batch=193 
13119: loss=0.054, reward_mean=0.500, reward_bound=0.109, batch=204 
13120: loss=0.054, reward_mean=0.440, reward_bound=0.167, batch=210 
13121: loss=0.053, reward_mean=0.470, reward_bound=0.167, batch=215 
13122: loss=0.052, reward_mean=0.500, reward_bound=0.189, batch=220 
13123: loss=0.052, reward_mean=0.580, reward_bound=0.206, batch=228 
13124: loss=0.056, reward_mean=0.430, reward_bound=0.206, batch=222 
13125: loss=0.060, reward_mean=0.480, reward_bound=0.229, batch=218 
13126: loss=0.061, reward_mean=0.490, reward_bound=0.254, batch=209 
13127: loss=0.060, reward_mean=0.490, reward_bound=0.206, batch=215 
13128: loss=0.062, reward_mean=0.550, reward_bound=0.229, batch=218 
13129: loss=0.061, reward_mean=0.550, reward_bound=0.282, batch=217 
13130: loss=0.062, reward_mean=0.570, reward_bound=0.282, batch=221 
13131: loss=0.065, reward_mean=0.450, reward_bound=0.314, batch=210 
13132: loss=0.065, reward_mean=0.520, reward_bound=0.222, batch=217 
13133: loss=0.063, reward_mean=0.510, reward_bound=0.254, batch=219 
13134: loss=0.064, reward_mean=0.590, reward_bound=0.282, batch=221 
13135: loss=0.065, reward_mean=0.540, reward_bound=0.314, batch=224 
13136: loss=0.062, reward_mean=0.460, reward_bound=0.349, batch=209 
13137: loss=0.067, reward_mean=0.490, reward_bound=0.250, batch=216 
13138: loss=0.065, reward_mean=0.520, reward_bound=0.282, batch=219 
13139: loss=0.063, reward_mean=0.560, reward_bound=0.328, batch=223 
13140: loss=0.064, reward_mean=0.480, reward_bound=0.311, batch=226 
13141: loss=0.063, reward_mean=0.600, reward_bound=0.349, batch=223 
13142: loss=0.062, reward_mean=0.460, reward_bound=0.335, batch=226 
13143: loss=0.061, reward_mean=0.530, reward_bound=0.387, batch=208 
13144: loss=0.061, reward_mean=0.560, reward_bound=0.254, batch=213 
13145: loss=0.061, reward_mean=0.420, reward_bound=0.204, batch=219 
13146: loss=0.064, reward_mean=0.460, reward_bound=0.239, batch=223 
13147: loss=0.060, reward_mean=0.530, reward_bound=0.254, batch=223 
13148: loss=0.061, reward_mean=0.590, reward_bound=0.282, batch=223 
13149: loss=0.062, reward_mean=0.560, reward_bound=0.335, batch=226 
13150: loss=0.061, reward_mean=0.430, reward_bound=0.349, batch=227 
13151: loss=0.061, reward_mean=0.580, reward_bound=0.387, batch=223 
13152: loss=0.059, reward_mean=0.570, reward_bound=0.430, batch=123 
13153: loss=0.047, reward_mean=0.480, reward_bound=0.019, batch=156 
13154: loss=0.049, reward_mean=0.520, reward_bound=0.052, batch=178 
13155: loss=0.044, reward_mean=0.480, reward_bound=0.089, batch=190 
13156: loss=0.046, reward_mean=0.590, reward_bound=0.122, batch=198 
13157: loss=0.047, reward_mean=0.460, reward_bound=0.150, batch=202 
13158: loss=0.051, reward_mean=0.510, reward_bound=0.167, batch=204 
13159: loss=0.051, reward_mean=0.440, reward_bound=0.185, batch=208 
13160: loss=0.055, reward_mean=0.510, reward_bound=0.206, batch=203 
13161: loss=0.054, reward_mean=0.470, reward_bound=0.211, batch=212 
13162: loss=0.054, reward_mean=0.520, reward_bound=0.229, batch=208 
13163: loss=0.048, reward_mean=0.530, reward_bound=0.254, batch=196 
13164: loss=0.045, reward_mean=0.520, reward_bound=0.217, batch=207 
13165: loss=0.047, reward_mean=0.530, reward_bound=0.229, batch=213 
13166: loss=0.046, reward_mean=0.510, reward_bound=0.244, batch=219 
13167: loss=0.046, reward_mean=0.620, reward_bound=0.282, batch=215 
13168: loss=0.047, reward_mean=0.450, reward_bound=0.216, batch=220 
13169: loss=0.047, reward_mean=0.460, reward_bound=0.304, batch=224 
13170: loss=0.050, reward_mean=0.540, reward_bound=0.314, batch=203 
13171: loss=0.050, reward_mean=0.550, reward_bound=0.314, batch=210 
13172: loss=0.050, reward_mean=0.510, reward_bound=0.274, batch=217 
13173: loss=0.049, reward_mean=0.580, reward_bound=0.308, batch=222 
13174: loss=0.049, reward_mean=0.580, reward_bound=0.314, batch=224 
13175: loss=0.048, reward_mean=0.530, reward_bound=0.342, batch=227 
13176: loss=0.050, reward_mean=0.570, reward_bound=0.349, batch=206 
13177: loss=0.048, reward_mean=0.450, reward_bound=0.186, batch=214 
13178: loss=0.049, reward_mean=0.490, reward_bound=0.254, batch=219 
13179: loss=0.049, reward_mean=0.500, reward_bound=0.314, batch=221 
13180: loss=0.050, reward_mean=0.470, reward_bound=0.254, batch=224 
13181: loss=0.049, reward_mean=0.440, reward_bound=0.387, batch=186 
13182: loss=0.044, reward_mean=0.540, reward_bound=0.136, batch=200 
13183: loss=0.042, reward_mean=0.460, reward_bound=0.167, batch=208 
13184: loss=0.042, reward_mean=0.450, reward_bound=0.206, batch=212 
13185: loss=0.044, reward_mean=0.440, reward_bound=0.236, batch=218 
13186: loss=0.044, reward_mean=0.550, reward_bound=0.254, batch=220 
13187: loss=0.047, reward_mean=0.540, reward_bound=0.282, batch=220 
13188: loss=0.047, reward_mean=0.460, reward_bound=0.304, batch=224 
13189: loss=0.047, reward_mean=0.500, reward_bound=0.314, batch=218 
13190: loss=0.048, reward_mean=0.440, reward_bound=0.286, batch=222 
13191: loss=0.047, reward_mean=0.450, reward_bound=0.349, batch=214 
13192: loss=0.047, reward_mean=0.510, reward_bound=0.280, batch=220 
13193: loss=0.046, reward_mean=0.490, reward_bound=0.274, batch=224 
13194: loss=0.048, reward_mean=0.460, reward_bound=0.314, batch=222 
13195: loss=0.048, reward_mean=0.440, reward_bound=0.314, batch=224 
13196: loss=0.049, reward_mean=0.490, reward_bound=0.349, batch=225 
13197: loss=0.051, reward_mean=0.480, reward_bound=0.356, batch=227 
13198: loss=0.047, reward_mean=0.540, reward_bound=0.387, batch=215 
13199: loss=0.047, reward_mean=0.510, reward_bound=0.314, batch=217 
13200: loss=0.046, reward_mean=0.540, reward_bound=0.342, batch=222 
13201: loss=0.045, reward_mean=0.520, reward_bound=0.400, batch=225 
13202: loss=0.048, reward_mean=0.570, reward_bound=0.303, batch=227 
13203: loss=0.048, reward_mean=0.500, reward_bound=0.373, batch=229 
13204: loss=0.045, reward_mean=0.500, reward_bound=0.405, batch=230 
13205: loss=0.051, reward_mean=0.530, reward_bound=0.430, batch=173 
13206: loss=0.051, reward_mean=0.580, reward_bound=0.154, batch=191 
13207: loss=0.054, reward_mean=0.520, reward_bound=0.150, batch=202 
13208: loss=0.054, reward_mean=0.480, reward_bound=0.206, batch=215 
13209: loss=0.047, reward_mean=0.490, reward_bound=0.206, batch=219 
13210: loss=0.051, reward_mean=0.520, reward_bound=0.229, batch=217 
13211: loss=0.049, reward_mean=0.520, reward_bound=0.254, batch=219 
13212: loss=0.049, reward_mean=0.560, reward_bound=0.282, batch=214 
13213: loss=0.048, reward_mean=0.520, reward_bound=0.204, batch=220 
13214: loss=0.048, reward_mean=0.390, reward_bound=0.282, batch=222 
13215: loss=0.051, reward_mean=0.500, reward_bound=0.314, batch=209 
13216: loss=0.051, reward_mean=0.560, reward_bound=0.314, batch=213 
13217: loss=0.050, reward_mean=0.570, reward_bound=0.254, batch=218 
13218: loss=0.051, reward_mean=0.430, reward_bound=0.317, batch=222 
13219: loss=0.051, reward_mean=0.440, reward_bound=0.263, batch=225 
13220: loss=0.054, reward_mean=0.470, reward_bound=0.349, batch=213 
13221: loss=0.056, reward_mean=0.510, reward_bound=0.204, batch=219 
13222: loss=0.056, reward_mean=0.530, reward_bound=0.314, batch=221 
13223: loss=0.055, reward_mean=0.450, reward_bound=0.349, batch=222 
13224: loss=0.055, reward_mean=0.360, reward_bound=0.349, batch=224 
13225: loss=0.054, reward_mean=0.480, reward_bound=0.342, batch=227 
13226: loss=0.056, reward_mean=0.470, reward_bound=0.387, batch=208 
13227: loss=0.054, reward_mean=0.570, reward_bound=0.171, batch=215 
13228: loss=0.055, reward_mean=0.500, reward_bound=0.260, batch=220 
13229: loss=0.053, reward_mean=0.570, reward_bound=0.314, batch=222 
13230: loss=0.055, reward_mean=0.550, reward_bound=0.349, batch=221 
13231: loss=0.056, reward_mean=0.430, reward_bound=0.387, batch=218 
13232: loss=0.055, reward_mean=0.530, reward_bound=0.282, batch=219 
13233: loss=0.055, reward_mean=0.480, reward_bound=0.282, batch=222 
