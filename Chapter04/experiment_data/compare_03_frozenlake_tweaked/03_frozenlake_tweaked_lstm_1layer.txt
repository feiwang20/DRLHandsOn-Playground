



2020-05-07 02-59-21

0: loss=1.406, reward_mean=0.010, reward_bound=0.000, batch=1 
1: loss=1.401, reward_mean=0.000, reward_bound=0.000, batch=1 
2: loss=1.383, reward_mean=0.030, reward_bound=0.000, batch=4 
3: loss=1.384, reward_mean=0.020, reward_bound=0.000, batch=6 
4: loss=1.384, reward_mean=0.010, reward_bound=0.000, batch=7 
5: loss=1.385, reward_mean=0.010, reward_bound=0.000, batch=8 
6: loss=1.385, reward_mean=0.000, reward_bound=0.000, batch=8 
7: loss=1.385, reward_mean=0.020, reward_bound=0.000, batch=10 
8: loss=1.385, reward_mean=0.020, reward_bound=0.000, batch=12 
9: loss=1.385, reward_mean=0.050, reward_bound=0.000, batch=17 
10: loss=1.384, reward_mean=0.020, reward_bound=0.000, batch=19 
11: loss=1.384, reward_mean=0.000, reward_bound=0.000, batch=19 
12: loss=1.384, reward_mean=0.000, reward_bound=0.000, batch=19 
13: loss=1.384, reward_mean=0.000, reward_bound=0.000, batch=19 
14: loss=1.383, reward_mean=0.020, reward_bound=0.000, batch=21 
15: loss=1.383, reward_mean=0.010, reward_bound=0.000, batch=22 
16: loss=1.383, reward_mean=0.040, reward_bound=0.000, batch=26 
17: loss=1.383, reward_mean=0.020, reward_bound=0.000, batch=28 
18: loss=1.383, reward_mean=0.010, reward_bound=0.000, batch=29 
19: loss=1.383, reward_mean=0.020, reward_bound=0.000, batch=31 
20: loss=1.383, reward_mean=0.030, reward_bound=0.000, batch=34 
21: loss=1.383, reward_mean=0.000, reward_bound=0.000, batch=34 
22: loss=1.383, reward_mean=0.030, reward_bound=0.000, batch=37 
23: loss=1.383, reward_mean=0.010, reward_bound=0.000, batch=38 
24: loss=1.383, reward_mean=0.010, reward_bound=0.000, batch=39 
25: loss=1.383, reward_mean=0.010, reward_bound=0.000, batch=40 
26: loss=1.382, reward_mean=0.020, reward_bound=0.000, batch=42 
27: loss=1.382, reward_mean=0.020, reward_bound=0.000, batch=44 
28: loss=1.382, reward_mean=0.020, reward_bound=0.000, batch=46 
29: loss=1.382, reward_mean=0.010, reward_bound=0.000, batch=47 
30: loss=1.382, reward_mean=0.010, reward_bound=0.000, batch=48 
31: loss=1.381, reward_mean=0.010, reward_bound=0.000, batch=49 
32: loss=1.381, reward_mean=0.010, reward_bound=0.000, batch=50 
33: loss=1.381, reward_mean=0.040, reward_bound=0.000, batch=54 
34: loss=1.381, reward_mean=0.030, reward_bound=0.000, batch=57 
35: loss=1.380, reward_mean=0.010, reward_bound=0.000, batch=58 
36: loss=1.380, reward_mean=0.010, reward_bound=0.000, batch=59 
37: loss=1.380, reward_mean=0.020, reward_bound=0.000, batch=61 
38: loss=1.380, reward_mean=0.020, reward_bound=0.000, batch=63 
39: loss=1.380, reward_mean=0.010, reward_bound=0.000, batch=64 
40: loss=1.380, reward_mean=0.020, reward_bound=0.000, batch=66 
41: loss=1.380, reward_mean=0.010, reward_bound=0.000, batch=67 
42: loss=1.379, reward_mean=0.000, reward_bound=0.000, batch=67 
43: loss=1.379, reward_mean=0.040, reward_bound=0.000, batch=71 
44: loss=1.379, reward_mean=0.000, reward_bound=0.000, batch=71 
45: loss=1.379, reward_mean=0.020, reward_bound=0.000, batch=73 
46: loss=1.379, reward_mean=0.020, reward_bound=0.000, batch=75 
47: loss=1.379, reward_mean=0.000, reward_bound=0.000, batch=75 
48: loss=1.378, reward_mean=0.020, reward_bound=0.000, batch=77 
49: loss=1.378, reward_mean=0.010, reward_bound=0.000, batch=78 
50: loss=1.378, reward_mean=0.050, reward_bound=0.000, batch=83 
51: loss=1.378, reward_mean=0.050, reward_bound=0.000, batch=88 
52: loss=1.377, reward_mean=0.040, reward_bound=0.000, batch=92 
53: loss=1.377, reward_mean=0.030, reward_bound=0.000, batch=95 
54: loss=1.377, reward_mean=0.000, reward_bound=0.000, batch=95 
55: loss=1.376, reward_mean=0.000, reward_bound=0.000, batch=95 
56: loss=1.376, reward_mean=0.000, reward_bound=0.000, batch=95 
57: loss=1.376, reward_mean=0.000, reward_bound=0.000, batch=95 
58: loss=1.375, reward_mean=0.000, reward_bound=0.000, batch=95 
59: loss=1.375, reward_mean=0.030, reward_bound=0.000, batch=98 
60: loss=1.374, reward_mean=0.000, reward_bound=0.000, batch=98 
61: loss=1.374, reward_mean=0.010, reward_bound=0.000, batch=99 
62: loss=1.373, reward_mean=0.020, reward_bound=0.000, batch=101 
63: loss=1.373, reward_mean=0.020, reward_bound=0.000, batch=103 
64: loss=1.372, reward_mean=0.010, reward_bound=0.000, batch=104 
65: loss=1.372, reward_mean=0.010, reward_bound=0.000, batch=105 
66: loss=1.372, reward_mean=0.030, reward_bound=0.000, batch=108 
67: loss=1.371, reward_mean=0.030, reward_bound=0.000, batch=111 
68: loss=1.371, reward_mean=0.030, reward_bound=0.000, batch=114 
69: loss=1.371, reward_mean=0.030, reward_bound=0.000, batch=117 
70: loss=1.371, reward_mean=0.000, reward_bound=0.000, batch=117 
71: loss=1.370, reward_mean=0.000, reward_bound=0.000, batch=117 
72: loss=1.370, reward_mean=0.030, reward_bound=0.000, batch=120 
73: loss=1.369, reward_mean=0.030, reward_bound=0.000, batch=123 
74: loss=1.369, reward_mean=0.020, reward_bound=0.000, batch=125 
75: loss=1.368, reward_mean=0.010, reward_bound=0.000, batch=126 
76: loss=1.368, reward_mean=0.050, reward_bound=0.000, batch=131 
77: loss=1.367, reward_mean=0.020, reward_bound=0.000, batch=133 
78: loss=1.367, reward_mean=0.020, reward_bound=0.000, batch=135 
79: loss=1.366, reward_mean=0.010, reward_bound=0.000, batch=136 
80: loss=1.366, reward_mean=0.040, reward_bound=0.000, batch=140 
81: loss=1.366, reward_mean=0.020, reward_bound=0.000, batch=142 
82: loss=1.365, reward_mean=0.030, reward_bound=0.000, batch=145 
83: loss=1.364, reward_mean=0.000, reward_bound=0.000, batch=145 
84: loss=1.364, reward_mean=0.020, reward_bound=0.000, batch=147 
85: loss=1.363, reward_mean=0.050, reward_bound=0.000, batch=152 
86: loss=1.363, reward_mean=0.010, reward_bound=0.000, batch=153 
87: loss=1.362, reward_mean=0.030, reward_bound=0.000, batch=156 
88: loss=1.361, reward_mean=0.010, reward_bound=0.000, batch=157 
89: loss=1.360, reward_mean=0.010, reward_bound=0.000, batch=158 
90: loss=1.360, reward_mean=0.010, reward_bound=0.000, batch=159 
91: loss=1.359, reward_mean=0.030, reward_bound=0.000, batch=162 
92: loss=1.359, reward_mean=0.000, reward_bound=0.000, batch=162 
93: loss=1.358, reward_mean=0.020, reward_bound=0.000, batch=164 
94: loss=1.357, reward_mean=0.010, reward_bound=0.000, batch=165 
95: loss=1.356, reward_mean=0.020, reward_bound=0.000, batch=167 
96: loss=1.355, reward_mean=0.030, reward_bound=0.000, batch=170 
97: loss=1.355, reward_mean=0.000, reward_bound=0.000, batch=170 
98: loss=1.354, reward_mean=0.030, reward_bound=0.000, batch=173 
99: loss=1.354, reward_mean=0.040, reward_bound=0.000, batch=177 
100: loss=1.353, reward_mean=0.020, reward_bound=0.000, batch=179 
101: loss=1.352, reward_mean=0.010, reward_bound=0.000, batch=180 
102: loss=1.351, reward_mean=0.030, reward_bound=0.000, batch=183 
103: loss=1.350, reward_mean=0.040, reward_bound=0.000, batch=187 
104: loss=1.349, reward_mean=0.020, reward_bound=0.000, batch=189 
105: loss=1.349, reward_mean=0.020, reward_bound=0.000, batch=191 
106: loss=1.348, reward_mean=0.020, reward_bound=0.000, batch=193 
107: loss=1.347, reward_mean=0.020, reward_bound=0.000, batch=195 
108: loss=1.346, reward_mean=0.000, reward_bound=0.000, batch=195 
109: loss=1.345, reward_mean=0.030, reward_bound=0.000, batch=198 
110: loss=1.345, reward_mean=0.000, reward_bound=0.000, batch=198 
111: loss=1.344, reward_mean=0.010, reward_bound=0.000, batch=199 
112: loss=1.343, reward_mean=0.040, reward_bound=0.000, batch=203 
113: loss=1.342, reward_mean=0.020, reward_bound=0.000, batch=205 
114: loss=1.341, reward_mean=0.030, reward_bound=0.000, batch=208 
115: loss=1.340, reward_mean=0.020, reward_bound=0.000, batch=210 
116: loss=1.340, reward_mean=0.010, reward_bound=0.000, batch=211 
117: loss=1.339, reward_mean=0.020, reward_bound=0.000, batch=213 
118: loss=1.338, reward_mean=0.040, reward_bound=0.000, batch=217 
119: loss=1.338, reward_mean=0.030, reward_bound=0.000, batch=220 
120: loss=1.337, reward_mean=0.010, reward_bound=0.000, batch=221 
121: loss=1.336, reward_mean=0.010, reward_bound=0.000, batch=222 
122: loss=1.336, reward_mean=0.030, reward_bound=0.004, batch=225 
123: loss=1.335, reward_mean=0.020, reward_bound=0.003, batch=227 
124: loss=1.334, reward_mean=0.030, reward_bound=0.016, batch=229 
125: loss=1.332, reward_mean=0.040, reward_bound=0.042, batch=228 
126: loss=1.331, reward_mean=0.050, reward_bound=0.066, batch=229 
127: loss=1.330, reward_mean=0.030, reward_bound=0.083, batch=230 
128: loss=1.329, reward_mean=0.020, reward_bound=0.089, batch=229 
129: loss=1.327, reward_mean=0.040, reward_bound=0.098, batch=226 
130: loss=1.326, reward_mean=0.010, reward_bound=0.000, batch=227 
131: loss=1.325, reward_mean=0.020, reward_bound=0.088, batch=229 
132: loss=1.325, reward_mean=0.000, reward_bound=0.000, batch=229 
133: loss=1.322, reward_mean=0.020, reward_bound=0.109, batch=223 
134: loss=1.322, reward_mean=0.000, reward_bound=0.000, batch=223 
135: loss=1.322, reward_mean=0.000, reward_bound=0.000, batch=223 
136: loss=1.321, reward_mean=0.020, reward_bound=0.000, batch=225 
137: loss=1.319, reward_mean=0.070, reward_bound=0.122, batch=226 
138: loss=1.316, reward_mean=0.050, reward_bound=0.135, batch=218 
139: loss=1.316, reward_mean=0.030, reward_bound=0.000, batch=221 
140: loss=1.313, reward_mean=0.060, reward_bound=0.150, batch=214 
141: loss=1.312, reward_mean=0.070, reward_bound=0.162, batch=220 
142: loss=1.310, reward_mean=0.050, reward_bound=0.150, batch=224 
143: loss=1.310, reward_mean=0.040, reward_bound=0.164, batch=227 
144: loss=1.308, reward_mean=0.040, reward_bound=0.167, batch=224 
145: loss=1.304, reward_mean=0.040, reward_bound=0.185, batch=215 
146: loss=1.304, reward_mean=0.050, reward_bound=0.007, batch=220 
147: loss=1.303, reward_mean=0.070, reward_bound=0.118, batch=224 
148: loss=1.301, reward_mean=0.060, reward_bound=0.204, batch=227 
149: loss=1.299, reward_mean=0.020, reward_bound=0.148, batch=229 
150: loss=1.299, reward_mean=0.020, reward_bound=0.174, batch=230 
151: loss=1.297, reward_mean=0.020, reward_bound=0.200, batch=231 
152: loss=1.298, reward_mean=0.030, reward_bound=0.206, batch=220 
153: loss=1.296, reward_mean=0.030, reward_bound=0.000, batch=223 
154: loss=1.295, reward_mean=0.030, reward_bound=0.073, batch=226 
155: loss=1.294, reward_mean=0.020, reward_bound=0.061, batch=228 
156: loss=1.293, reward_mean=0.020, reward_bound=0.077, batch=229 
157: loss=1.291, reward_mean=0.070, reward_bound=0.229, batch=209 
158: loss=1.291, reward_mean=0.010, reward_bound=0.000, batch=210 
159: loss=1.288, reward_mean=0.030, reward_bound=0.000, batch=213 
160: loss=1.289, reward_mean=0.090, reward_bound=0.171, batch=219 
161: loss=1.288, reward_mean=0.020, reward_bound=0.000, batch=221 
162: loss=1.288, reward_mean=0.020, reward_bound=0.000, batch=223 
163: loss=1.286, reward_mean=0.020, reward_bound=0.000, batch=225 
164: loss=1.286, reward_mean=0.030, reward_bound=0.054, batch=227 
165: loss=1.285, reward_mean=0.050, reward_bound=0.160, batch=229 
166: loss=1.285, reward_mean=0.020, reward_bound=0.167, batch=229 
167: loss=1.285, reward_mean=0.040, reward_bound=0.185, batch=229 
168: loss=1.286, reward_mean=0.060, reward_bound=0.215, batch=230 
169: loss=1.279, reward_mean=0.080, reward_bound=0.254, batch=208 
170: loss=1.277, reward_mean=0.020, reward_bound=0.000, batch=210 
171: loss=1.277, reward_mean=0.040, reward_bound=0.000, batch=214 
172: loss=1.277, reward_mean=0.000, reward_bound=0.000, batch=214 
173: loss=1.276, reward_mean=0.050, reward_bound=0.000, batch=219 
174: loss=1.273, reward_mean=0.050, reward_bound=0.120, batch=223 
175: loss=1.273, reward_mean=0.040, reward_bound=0.144, batch=226 
176: loss=1.275, reward_mean=0.040, reward_bound=0.158, batch=228 
177: loss=1.273, reward_mean=0.040, reward_bound=0.229, batch=228 
178: loss=1.271, reward_mean=0.050, reward_bound=0.282, batch=196 
179: loss=1.268, reward_mean=0.060, reward_bound=0.000, batch=202 
180: loss=1.266, reward_mean=0.100, reward_bound=0.058, batch=211 
181: loss=1.265, reward_mean=0.040, reward_bound=0.000, batch=215 
182: loss=1.264, reward_mean=0.030, reward_bound=0.000, batch=218 
183: loss=1.265, reward_mean=0.050, reward_bound=0.124, batch=222 
184: loss=1.264, reward_mean=0.010, reward_bound=0.000, batch=223 
185: loss=1.266, reward_mean=0.040, reward_bound=0.150, batch=224 
186: loss=1.264, reward_mean=0.040, reward_bound=0.097, batch=227 
187: loss=1.265, reward_mean=0.040, reward_bound=0.182, batch=229 
188: loss=1.264, reward_mean=0.050, reward_bound=0.206, batch=227 
189: loss=1.267, reward_mean=0.030, reward_bound=0.229, batch=224 
190: loss=1.266, reward_mean=0.040, reward_bound=0.245, batch=227 
191: loss=1.266, reward_mean=0.050, reward_bound=0.249, batch=229 
192: loss=1.262, reward_mean=0.070, reward_bound=0.282, batch=229 
193: loss=1.253, reward_mean=0.060, reward_bound=0.314, batch=183 
194: loss=1.251, reward_mean=0.020, reward_bound=0.000, batch=185 
195: loss=1.252, reward_mean=0.050, reward_bound=0.000, batch=190 
196: loss=1.250, reward_mean=0.030, reward_bound=0.000, batch=193 
197: loss=1.247, reward_mean=0.030, reward_bound=0.000, batch=196 
198: loss=1.247, reward_mean=0.020, reward_bound=0.000, batch=198 
199: loss=1.246, reward_mean=0.000, reward_bound=0.000, batch=198 
200: loss=1.244, reward_mean=0.040, reward_bound=0.000, batch=202 
201: loss=1.244, reward_mean=0.030, reward_bound=0.000, batch=205 
202: loss=1.242, reward_mean=0.030, reward_bound=0.000, batch=208 
203: loss=1.244, reward_mean=0.120, reward_bound=0.138, batch=215 
204: loss=1.243, reward_mean=0.010, reward_bound=0.000, batch=216 
205: loss=1.243, reward_mean=0.030, reward_bound=0.000, batch=219 
206: loss=1.243, reward_mean=0.040, reward_bound=0.039, batch=223 
207: loss=1.242, reward_mean=0.030, reward_bound=0.059, batch=226 
208: loss=1.241, reward_mean=0.080, reward_bound=0.185, batch=225 
209: loss=1.241, reward_mean=0.010, reward_bound=0.000, batch=226 
210: loss=1.240, reward_mean=0.050, reward_bound=0.206, batch=226 
211: loss=1.239, reward_mean=0.070, reward_bound=0.241, batch=228 
212: loss=1.238, reward_mean=0.020, reward_bound=0.176, batch=229 
213: loss=1.236, reward_mean=0.040, reward_bound=0.254, batch=222 
214: loss=1.234, reward_mean=0.070, reward_bound=0.245, batch=225 
215: loss=1.232, reward_mean=0.020, reward_bound=0.033, batch=227 
216: loss=1.231, reward_mean=0.020, reward_bound=0.108, batch=229 
217: loss=1.234, reward_mean=0.050, reward_bound=0.224, batch=230 
218: loss=1.236, reward_mean=0.040, reward_bound=0.282, batch=228 
219: loss=1.235, reward_mean=0.050, reward_bound=0.217, batch=229 
220: loss=1.235, reward_mean=0.010, reward_bound=0.126, batch=230 
221: loss=1.237, reward_mean=0.040, reward_bound=0.314, batch=228 
222: loss=1.219, reward_mean=0.050, reward_bound=0.349, batch=182 
223: loss=1.214, reward_mean=0.070, reward_bound=0.000, batch=189 
224: loss=1.212, reward_mean=0.040, reward_bound=0.000, batch=193 
225: loss=1.204, reward_mean=0.090, reward_bound=0.000, batch=202 
226: loss=1.202, reward_mean=0.050, reward_bound=0.000, batch=207 
227: loss=1.199, reward_mean=0.040, reward_bound=0.000, batch=211 
228: loss=1.196, reward_mean=0.040, reward_bound=0.000, batch=215 
229: loss=1.200, reward_mean=0.080, reward_bound=0.065, batch=219 
230: loss=1.198, reward_mean=0.030, reward_bound=0.000, batch=222 
231: loss=1.195, reward_mean=0.070, reward_bound=0.089, batch=225 
232: loss=1.199, reward_mean=0.050, reward_bound=0.167, batch=226 
233: loss=1.198, reward_mean=0.030, reward_bound=0.087, batch=228 
234: loss=1.201, reward_mean=0.070, reward_bound=0.206, batch=225 
235: loss=1.202, reward_mean=0.040, reward_bound=0.127, batch=227 
236: loss=1.201, reward_mean=0.080, reward_bound=0.229, batch=228 
237: loss=1.198, reward_mean=0.080, reward_bound=0.254, batch=226 
238: loss=1.198, reward_mean=0.060, reward_bound=0.229, batch=227 
239: loss=1.198, reward_mean=0.060, reward_bound=0.282, batch=223 
240: loss=1.197, reward_mean=0.050, reward_bound=0.252, batch=226 
241: loss=1.199, reward_mean=0.050, reward_bound=0.282, batch=227 
242: loss=1.201, reward_mean=0.050, reward_bound=0.314, batch=225 
243: loss=1.200, reward_mean=0.090, reward_bound=0.314, batch=226 
244: loss=1.200, reward_mean=0.030, reward_bound=0.235, batch=228 
245: loss=1.199, reward_mean=0.040, reward_bound=0.208, batch=229 
246: loss=1.203, reward_mean=0.080, reward_bound=0.349, batch=215 
247: loss=1.206, reward_mean=0.030, reward_bound=0.000, batch=218 
248: loss=1.201, reward_mean=0.070, reward_bound=0.171, batch=222 
249: loss=1.201, reward_mean=0.010, reward_bound=0.000, batch=223 
250: loss=1.198, reward_mean=0.070, reward_bound=0.229, batch=225 
251: loss=1.199, reward_mean=0.060, reward_bound=0.254, batch=225 
252: loss=1.197, reward_mean=0.040, reward_bound=0.190, batch=227 
253: loss=1.196, reward_mean=0.110, reward_bound=0.277, batch=229 
254: loss=1.197, reward_mean=0.050, reward_bound=0.314, batch=227 
255: loss=1.196, reward_mean=0.050, reward_bound=0.335, batch=229 
256: loss=1.195, reward_mean=0.070, reward_bound=0.292, batch=230 
257: loss=1.196, reward_mean=0.070, reward_bound=0.349, batch=228 
258: loss=1.195, reward_mean=0.110, reward_bound=0.286, batch=229 
259: loss=1.195, reward_mean=0.030, reward_bound=0.314, batch=229 
260: loss=1.179, reward_mean=0.090, reward_bound=0.387, batch=161 
261: loss=1.173, reward_mean=0.050, reward_bound=0.000, batch=166 
262: loss=1.172, reward_mean=0.060, reward_bound=0.000, batch=172 
263: loss=1.173, reward_mean=0.020, reward_bound=0.000, batch=174 
264: loss=1.166, reward_mean=0.060, reward_bound=0.000, batch=180 
265: loss=1.162, reward_mean=0.040, reward_bound=0.000, batch=184 
266: loss=1.164, reward_mean=0.050, reward_bound=0.000, batch=189 
267: loss=1.162, reward_mean=0.040, reward_bound=0.000, batch=193 
268: loss=1.160, reward_mean=0.060, reward_bound=0.000, batch=199 
269: loss=1.157, reward_mean=0.030, reward_bound=0.000, batch=202 
270: loss=1.155, reward_mean=0.030, reward_bound=0.000, batch=205 
271: loss=1.155, reward_mean=0.050, reward_bound=0.000, batch=210 
272: loss=1.157, reward_mean=0.090, reward_bound=0.020, batch=217 
273: loss=1.158, reward_mean=0.060, reward_bound=0.020, batch=221 
274: loss=1.163, reward_mean=0.090, reward_bound=0.109, batch=223 
275: loss=1.163, reward_mean=0.030, reward_bound=0.066, batch=226 
276: loss=1.167, reward_mean=0.070, reward_bound=0.122, batch=227 
277: loss=1.161, reward_mean=0.040, reward_bound=0.150, batch=227 
278: loss=1.160, reward_mean=0.040, reward_bound=0.142, batch=229 
279: loss=1.159, reward_mean=0.050, reward_bound=0.167, batch=226 
280: loss=1.160, reward_mean=0.040, reward_bound=0.185, batch=227 
281: loss=1.163, reward_mean=0.060, reward_bound=0.206, batch=220 
282: loss=1.165, reward_mean=0.090, reward_bound=0.229, batch=217 
283: loss=1.165, reward_mean=0.080, reward_bound=0.254, batch=217 
284: loss=1.169, reward_mean=0.060, reward_bound=0.201, batch=222 
285: loss=1.164, reward_mean=0.070, reward_bound=0.263, batch=225 
286: loss=1.162, reward_mean=0.080, reward_bound=0.282, batch=222 
287: loss=1.160, reward_mean=0.050, reward_bound=0.181, batch=225 
288: loss=1.161, reward_mean=0.080, reward_bound=0.314, batch=221 
289: loss=1.164, reward_mean=0.090, reward_bound=0.349, batch=207 
290: loss=1.162, reward_mean=0.080, reward_bound=0.057, batch=215 
291: loss=1.164, reward_mean=0.040, reward_bound=0.000, batch=219 
292: loss=1.157, reward_mean=0.080, reward_bound=0.102, batch=223 
293: loss=1.162, reward_mean=0.080, reward_bound=0.229, batch=225 
294: loss=1.161, reward_mean=0.060, reward_bound=0.254, batch=224 
295: loss=1.158, reward_mean=0.060, reward_bound=0.311, batch=227 
296: loss=1.160, reward_mean=0.130, reward_bound=0.314, batch=227 
297: loss=1.159, reward_mean=0.100, reward_bound=0.349, batch=224 
298: loss=1.158, reward_mean=0.080, reward_bound=0.280, batch=227 
299: loss=1.159, reward_mean=0.060, reward_bound=0.366, batch=229 
300: loss=1.156, reward_mean=0.030, reward_bound=0.174, batch=230 
301: loss=1.159, reward_mean=0.080, reward_bound=0.274, batch=231 
302: loss=1.165, reward_mean=0.130, reward_bound=0.387, batch=209 
303: loss=1.164, reward_mean=0.060, reward_bound=0.000, batch=215 
304: loss=1.163, reward_mean=0.110, reward_bound=0.175, batch=220 
305: loss=1.162, reward_mean=0.030, reward_bound=0.000, batch=223 
306: loss=1.158, reward_mean=0.090, reward_bound=0.244, batch=226 
307: loss=1.159, reward_mean=0.070, reward_bound=0.254, batch=226 
308: loss=1.161, reward_mean=0.050, reward_bound=0.282, batch=226 
309: loss=1.161, reward_mean=0.030, reward_bound=0.268, batch=228 
310: loss=1.160, reward_mean=0.050, reward_bound=0.286, batch=229 
311: loss=1.160, reward_mean=0.020, reward_bound=0.148, batch=230 
312: loss=1.158, reward_mean=0.070, reward_bound=0.314, batch=229 
313: loss=1.158, reward_mean=0.100, reward_bound=0.349, batch=229 
314: loss=1.158, reward_mean=0.070, reward_bound=0.387, batch=222 
315: loss=1.157, reward_mean=0.070, reward_bound=0.307, batch=225 
316: loss=1.156, reward_mean=0.040, reward_bound=0.157, batch=227 
317: loss=1.155, reward_mean=0.060, reward_bound=0.401, batch=229 
318: loss=1.155, reward_mean=0.040, reward_bound=0.405, batch=230 
319: loss=1.154, reward_mean=0.060, reward_bound=0.406, batch=231 
320: loss=1.154, reward_mean=0.070, reward_bound=0.387, batch=231 
321: loss=1.148, reward_mean=0.070, reward_bound=0.430, batch=131 
322: loss=1.140, reward_mean=0.040, reward_bound=0.000, batch=135 
323: loss=1.142, reward_mean=0.100, reward_bound=0.000, batch=145 
324: loss=1.144, reward_mean=0.060, reward_bound=0.000, batch=151 
325: loss=1.142, reward_mean=0.050, reward_bound=0.000, batch=156 
326: loss=1.137, reward_mean=0.090, reward_bound=0.000, batch=165 
327: loss=1.131, reward_mean=0.040, reward_bound=0.000, batch=169 
328: loss=1.129, reward_mean=0.060, reward_bound=0.000, batch=175 
329: loss=1.126, reward_mean=0.090, reward_bound=0.000, batch=184 
330: loss=1.118, reward_mean=0.100, reward_bound=0.000, batch=194 
331: loss=1.114, reward_mean=0.080, reward_bound=0.000, batch=202 
332: loss=1.113, reward_mean=0.090, reward_bound=0.022, batch=211 
333: loss=1.109, reward_mean=0.030, reward_bound=0.000, batch=214 
334: loss=1.110, reward_mean=0.040, reward_bound=0.000, batch=218 
335: loss=1.112, reward_mean=0.050, reward_bound=0.040, batch=222 
336: loss=1.110, reward_mean=0.060, reward_bound=0.080, batch=224 
337: loss=1.108, reward_mean=0.060, reward_bound=0.098, batch=226 
338: loss=1.108, reward_mean=0.070, reward_bound=0.143, batch=228 
339: loss=1.105, reward_mean=0.070, reward_bound=0.167, batch=224 
340: loss=1.101, reward_mean=0.030, reward_bound=0.109, batch=227 
341: loss=1.099, reward_mean=0.020, reward_bound=0.097, batch=229 
342: loss=1.102, reward_mean=0.090, reward_bound=0.185, batch=223 
343: loss=1.100, reward_mean=0.060, reward_bound=0.206, batch=225 
344: loss=1.099, reward_mean=0.030, reward_bound=0.042, batch=227 
345: loss=1.098, reward_mean=0.040, reward_bound=0.216, batch=229 
346: loss=1.100, reward_mean=0.080, reward_bound=0.229, batch=226 
347: loss=1.106, reward_mean=0.070, reward_bound=0.254, batch=217 
348: loss=1.104, reward_mean=0.040, reward_bound=0.000, batch=221 
349: loss=1.106, reward_mean=0.120, reward_bound=0.282, batch=207 
350: loss=1.102, reward_mean=0.070, reward_bound=0.000, batch=214 
351: loss=1.100, reward_mean=0.050, reward_bound=0.000, batch=219 
352: loss=1.097, reward_mean=0.090, reward_bound=0.206, batch=222 
353: loss=1.098, reward_mean=0.040, reward_bound=0.131, batch=225 
354: loss=1.093, reward_mean=0.070, reward_bound=0.229, batch=226 
355: loss=1.095, reward_mean=0.120, reward_bound=0.254, batch=226 
356: loss=1.093, reward_mean=0.020, reward_bound=0.141, batch=228 
357: loss=1.099, reward_mean=0.070, reward_bound=0.282, batch=228 
358: loss=1.111, reward_mean=0.070, reward_bound=0.314, batch=200 
359: loss=1.109, reward_mean=0.060, reward_bound=0.000, batch=206 
360: loss=1.108, reward_mean=0.070, reward_bound=0.000, batch=213 
361: loss=1.105, reward_mean=0.050, reward_bound=0.000, batch=218 
362: loss=1.107, reward_mean=0.070, reward_bound=0.092, batch=222 
363: loss=1.105, reward_mean=0.090, reward_bound=0.179, batch=225 
364: loss=1.106, reward_mean=0.070, reward_bound=0.210, batch=227 
365: loss=1.107, reward_mean=0.060, reward_bound=0.229, batch=226 
366: loss=1.106, reward_mean=0.090, reward_bound=0.254, batch=227 
367: loss=1.107, reward_mean=0.110, reward_bound=0.282, batch=226 
368: loss=1.108, reward_mean=0.090, reward_bound=0.314, batch=222 
369: loss=1.106, reward_mean=0.050, reward_bound=0.156, batch=225 
370: loss=1.107, reward_mean=0.040, reward_bound=0.205, batch=227 
371: loss=1.105, reward_mean=0.060, reward_bound=0.277, batch=229 
372: loss=1.103, reward_mean=0.060, reward_bound=0.314, batch=229 
373: loss=1.101, reward_mean=0.080, reward_bound=0.328, batch=230 
374: loss=1.108, reward_mean=0.050, reward_bound=0.349, batch=207 
375: loss=1.106, reward_mean=0.060, reward_bound=0.000, batch=213 
376: loss=1.104, reward_mean=0.050, reward_bound=0.000, batch=218 
377: loss=1.102, reward_mean=0.100, reward_bound=0.254, batch=220 
378: loss=1.102, reward_mean=0.030, reward_bound=0.000, batch=223 
379: loss=1.101, reward_mean=0.060, reward_bound=0.271, batch=226 
380: loss=1.101, reward_mean=0.070, reward_bound=0.282, batch=226 
381: loss=1.105, reward_mean=0.050, reward_bound=0.314, batch=226 
382: loss=1.104, reward_mean=0.060, reward_bound=0.314, batch=227 
383: loss=1.106, reward_mean=0.060, reward_bound=0.349, batch=228 
384: loss=1.106, reward_mean=0.040, reward_bound=0.353, batch=229 
385: loss=1.106, reward_mean=0.050, reward_bound=0.278, batch=230 
386: loss=1.112, reward_mean=0.050, reward_bound=0.387, batch=202 
387: loss=1.104, reward_mean=0.110, reward_bound=0.155, batch=211 
388: loss=1.104, reward_mean=0.060, reward_bound=0.000, batch=217 
389: loss=1.104, reward_mean=0.100, reward_bound=0.229, batch=220 
390: loss=1.100, reward_mean=0.080, reward_bound=0.247, batch=224 
391: loss=1.100, reward_mean=0.060, reward_bound=0.183, batch=227 
392: loss=1.100, reward_mean=0.040, reward_bound=0.220, batch=229 
393: loss=1.100, reward_mean=0.070, reward_bound=0.254, batch=228 
394: loss=1.099, reward_mean=0.020, reward_bound=0.150, batch=229 
395: loss=1.095, reward_mean=0.050, reward_bound=0.282, batch=226 
396: loss=1.096, reward_mean=0.060, reward_bound=0.210, batch=228 
397: loss=1.097, reward_mean=0.060, reward_bound=0.314, batch=221 
398: loss=1.098, reward_mean=0.060, reward_bound=0.206, batch=224 
399: loss=1.097, reward_mean=0.030, reward_bound=0.098, batch=227 
400: loss=1.096, reward_mean=0.100, reward_bound=0.254, batch=227 
401: loss=1.096, reward_mean=0.110, reward_bound=0.349, batch=227 
402: loss=1.097, reward_mean=0.060, reward_bound=0.254, batch=228 
403: loss=1.099, reward_mean=0.060, reward_bound=0.387, batch=225 
404: loss=1.098, reward_mean=0.070, reward_bound=0.289, batch=227 
405: loss=1.098, reward_mean=0.090, reward_bound=0.387, batch=226 
406: loss=1.096, reward_mean=0.050, reward_bound=0.390, batch=228 
407: loss=1.095, reward_mean=0.030, reward_bound=0.268, batch=229 
408: loss=1.095, reward_mean=0.050, reward_bound=0.349, batch=229 
409: loss=1.094, reward_mean=0.020, reward_bound=0.187, batch=230 
410: loss=1.095, reward_mean=0.040, reward_bound=0.376, batch=231 
411: loss=1.095, reward_mean=0.010, reward_bound=0.282, batch=231 
412: loss=1.095, reward_mean=0.020, reward_bound=0.349, batch=231 
413: loss=1.094, reward_mean=0.130, reward_bound=0.387, batch=231 
414: loss=1.121, reward_mean=0.050, reward_bound=0.430, batch=182 
415: loss=1.116, reward_mean=0.040, reward_bound=0.000, batch=186 
416: loss=1.111, reward_mean=0.070, reward_bound=0.000, batch=193 
417: loss=1.104, reward_mean=0.070, reward_bound=0.000, batch=200 
418: loss=1.095, reward_mean=0.100, reward_bound=0.041, batch=210 
419: loss=1.087, reward_mean=0.100, reward_bound=0.063, batch=217 
420: loss=1.095, reward_mean=0.100, reward_bound=0.087, batch=222 
421: loss=1.091, reward_mean=0.060, reward_bound=0.102, batch=225 
422: loss=1.090, reward_mean=0.060, reward_bound=0.167, batch=225 
423: loss=1.096, reward_mean=0.070, reward_bound=0.206, batch=222 
424: loss=1.096, reward_mean=0.050, reward_bound=0.213, batch=225 
425: loss=1.097, reward_mean=0.090, reward_bound=0.229, batch=225 
426: loss=1.097, reward_mean=0.110, reward_bound=0.254, batch=224 
427: loss=1.095, reward_mean=0.040, reward_bound=0.244, batch=227 
428: loss=1.096, reward_mean=0.050, reward_bound=0.277, batch=229 
429: loss=1.098, reward_mean=0.050, reward_bound=0.282, batch=228 
430: loss=1.097, reward_mean=0.010, reward_bound=0.031, batch=229 
431: loss=1.106, reward_mean=0.040, reward_bound=0.314, batch=220 
432: loss=1.106, reward_mean=0.050, reward_bound=0.170, batch=224 
433: loss=1.101, reward_mean=0.060, reward_bound=0.247, batch=227 
434: loss=1.101, reward_mean=0.080, reward_bound=0.342, batch=229 
435: loss=1.103, reward_mean=0.060, reward_bound=0.349, batch=222 
436: loss=1.102, reward_mean=0.080, reward_bound=0.263, batch=225 
437: loss=1.103, reward_mean=0.060, reward_bound=0.289, batch=227 
438: loss=1.100, reward_mean=0.050, reward_bound=0.314, batch=228 
439: loss=1.098, reward_mean=0.100, reward_bound=0.349, batch=228 
440: loss=1.103, reward_mean=0.070, reward_bound=0.387, batch=220 
441: loss=1.101, reward_mean=0.040, reward_bound=0.069, batch=224 
442: loss=1.097, reward_mean=0.050, reward_bound=0.160, batch=227 
443: loss=1.101, reward_mean=0.070, reward_bound=0.229, batch=228 
444: loss=1.099, reward_mean=0.050, reward_bound=0.349, batch=228 
445: loss=1.099, reward_mean=0.040, reward_bound=0.317, batch=229 
446: loss=1.098, reward_mean=0.090, reward_bound=0.387, batch=229 
447: loss=1.107, reward_mean=0.080, reward_bound=0.430, batch=211 
448: loss=1.107, reward_mean=0.080, reward_bound=0.282, batch=214 
449: loss=1.105, reward_mean=0.090, reward_bound=0.280, batch=220 
450: loss=1.106, reward_mean=0.040, reward_bound=0.062, batch=224 
451: loss=1.107, reward_mean=0.080, reward_bound=0.282, batch=225 
452: loss=1.108, reward_mean=0.080, reward_bound=0.314, batch=226 
453: loss=1.106, reward_mean=0.040, reward_bound=0.349, batch=227 
454: loss=1.104, reward_mean=0.090, reward_bound=0.380, batch=229 
455: loss=1.104, reward_mean=0.100, reward_bound=0.387, batch=224 
456: loss=1.100, reward_mean=0.070, reward_bound=0.252, batch=227 
457: loss=1.100, reward_mean=0.050, reward_bound=0.277, batch=229 
458: loss=1.102, reward_mean=0.060, reward_bound=0.295, batch=230 
459: loss=1.102, reward_mean=0.050, reward_bound=0.349, batch=229 
460: loss=1.102, reward_mean=0.100, reward_bound=0.387, batch=229 
461: loss=1.101, reward_mean=0.030, reward_bound=0.381, batch=230 
462: loss=1.103, reward_mean=0.030, reward_bound=0.430, batch=224 
463: loss=1.102, reward_mean=0.090, reward_bound=0.308, batch=227 
464: loss=1.104, reward_mean=0.060, reward_bound=0.349, batch=228 
465: loss=1.104, reward_mean=0.040, reward_bound=0.229, batch=228 
466: loss=1.103, reward_mean=0.040, reward_bound=0.392, batch=229 
467: loss=1.104, reward_mean=0.050, reward_bound=0.309, batch=230 
468: loss=1.102, reward_mean=0.080, reward_bound=0.406, batch=231 
469: loss=1.075, reward_mean=0.070, reward_bound=0.478, batch=95 
470: loss=1.069, reward_mean=0.050, reward_bound=0.000, batch=100 
471: loss=1.070, reward_mean=0.030, reward_bound=0.000, batch=103 
472: loss=1.071, reward_mean=0.050, reward_bound=0.000, batch=108 
473: loss=1.068, reward_mean=0.040, reward_bound=0.000, batch=112 
474: loss=1.062, reward_mean=0.070, reward_bound=0.000, batch=119 
475: loss=1.057, reward_mean=0.040, reward_bound=0.000, batch=123 
476: loss=1.055, reward_mean=0.060, reward_bound=0.000, batch=129 
477: loss=1.059, reward_mean=0.090, reward_bound=0.000, batch=138 
478: loss=1.051, reward_mean=0.090, reward_bound=0.000, batch=147 
479: loss=1.050, reward_mean=0.030, reward_bound=0.000, batch=150 
480: loss=1.054, reward_mean=0.040, reward_bound=0.000, batch=154 
481: loss=1.052, reward_mean=0.070, reward_bound=0.000, batch=161 
482: loss=1.052, reward_mean=0.070, reward_bound=0.000, batch=168 
483: loss=1.053, reward_mean=0.060, reward_bound=0.000, batch=174 
484: loss=1.052, reward_mean=0.060, reward_bound=0.000, batch=180 
485: loss=1.051, reward_mean=0.040, reward_bound=0.000, batch=184 
486: loss=1.049, reward_mean=0.040, reward_bound=0.000, batch=188 
487: loss=1.050, reward_mean=0.030, reward_bound=0.000, batch=191 
488: loss=1.045, reward_mean=0.100, reward_bound=0.000, batch=201 
489: loss=1.044, reward_mean=0.010, reward_bound=0.000, batch=202 
490: loss=1.041, reward_mean=0.060, reward_bound=0.000, batch=208 
491: loss=1.044, reward_mean=0.080, reward_bound=0.033, batch=215 
492: loss=1.044, reward_mean=0.040, reward_bound=0.000, batch=219 
493: loss=1.053, reward_mean=0.110, reward_bound=0.080, batch=221 
494: loss=1.046, reward_mean=0.070, reward_bound=0.098, batch=224 
495: loss=1.049, reward_mean=0.060, reward_bound=0.134, batch=227 
496: loss=1.055, reward_mean=0.100, reward_bound=0.163, batch=229 
497: loss=1.057, reward_mean=0.040, reward_bound=0.167, batch=229 
498: loss=1.053, reward_mean=0.070, reward_bound=0.185, batch=225 
499: loss=1.058, reward_mean=0.060, reward_bound=0.206, batch=219 
500: loss=1.052, reward_mean=0.110, reward_bound=0.229, batch=215 
501: loss=1.048, reward_mean=0.070, reward_bound=0.098, batch=219 
502: loss=1.053, reward_mean=0.060, reward_bound=0.172, batch=223 
503: loss=1.045, reward_mean=0.050, reward_bound=0.229, batch=225 
504: loss=1.046, reward_mean=0.090, reward_bound=0.234, batch=227 
505: loss=1.048, reward_mean=0.110, reward_bound=0.254, batch=216 
506: loss=1.048, reward_mean=0.070, reward_bound=0.206, batch=220 
507: loss=1.048, reward_mean=0.030, reward_bound=0.000, batch=223 
508: loss=1.045, reward_mean=0.070, reward_bound=0.181, batch=226 
509: loss=1.048, reward_mean=0.040, reward_bound=0.229, batch=227 
510: loss=1.057, reward_mean=0.100, reward_bound=0.282, batch=208 
511: loss=1.051, reward_mean=0.100, reward_bound=0.231, batch=215 
512: loss=1.053, reward_mean=0.070, reward_bound=0.254, batch=219 
513: loss=1.056, reward_mean=0.100, reward_bound=0.314, batch=202 
514: loss=1.055, reward_mean=0.050, reward_bound=0.000, batch=207 
515: loss=1.058, reward_mean=0.050, reward_bound=0.000, batch=212 
516: loss=1.060, reward_mean=0.070, reward_bound=0.081, batch=218 
517: loss=1.060, reward_mean=0.050, reward_bound=0.015, batch=222 
518: loss=1.058, reward_mean=0.060, reward_bound=0.155, batch=225 
519: loss=1.051, reward_mean=0.070, reward_bound=0.167, batch=226 
520: loss=1.053, reward_mean=0.040, reward_bound=0.196, batch=228 
521: loss=1.051, reward_mean=0.070, reward_bound=0.257, batch=229 
522: loss=1.046, reward_mean=0.040, reward_bound=0.282, batch=224 
523: loss=1.049, reward_mean=0.080, reward_bound=0.305, batch=227 
524: loss=1.047, reward_mean=0.040, reward_bound=0.163, batch=229 
525: loss=1.052, reward_mean=0.060, reward_bound=0.314, batch=228 
526: loss=1.051, reward_mean=0.070, reward_bound=0.317, batch=229 
527: loss=1.055, reward_mean=0.060, reward_bound=0.349, batch=200 
528: loss=1.061, reward_mean=0.100, reward_bound=0.033, batch=210 
529: loss=1.056, reward_mean=0.090, reward_bound=0.200, batch=217 
530: loss=1.064, reward_mean=0.070, reward_bound=0.206, batch=221 
531: loss=1.066, reward_mean=0.030, reward_bound=0.000, batch=224 
532: loss=1.062, reward_mean=0.080, reward_bound=0.229, batch=226 
533: loss=1.064, reward_mean=0.050, reward_bound=0.254, batch=226 
534: loss=1.059, reward_mean=0.040, reward_bound=0.282, batch=225 
535: loss=1.055, reward_mean=0.120, reward_bound=0.314, batch=224 
536: loss=1.053, reward_mean=0.040, reward_bound=0.303, batch=227 
537: loss=1.052, reward_mean=0.030, reward_bound=0.308, batch=229 
538: loss=1.053, reward_mean=0.040, reward_bound=0.216, batch=230 
539: loss=1.055, reward_mean=0.060, reward_bound=0.314, batch=230 
540: loss=1.053, reward_mean=0.110, reward_bound=0.349, batch=225 
541: loss=1.053, reward_mean=0.070, reward_bound=0.321, batch=227 
542: loss=1.052, reward_mean=0.050, reward_bound=0.342, batch=229 
543: loss=1.050, reward_mean=0.030, reward_bound=0.364, batch=230 
544: loss=1.053, reward_mean=0.060, reward_bound=0.387, batch=195 
545: loss=1.055, reward_mean=0.030, reward_bound=0.000, batch=198 
546: loss=1.058, reward_mean=0.050, reward_bound=0.000, batch=203 
547: loss=1.056, reward_mean=0.050, reward_bound=0.000, batch=208 
548: loss=1.057, reward_mean=0.060, reward_bound=0.000, batch=214 
549: loss=1.057, reward_mean=0.050, reward_bound=0.000, batch=219 
550: loss=1.053, reward_mean=0.060, reward_bound=0.072, batch=221 
551: loss=1.057, reward_mean=0.070, reward_bound=0.109, batch=224 
552: loss=1.057, reward_mean=0.080, reward_bound=0.183, batch=227 
553: loss=1.056, reward_mean=0.040, reward_bound=0.178, batch=229 
554: loss=1.051, reward_mean=0.040, reward_bound=0.206, batch=227 
555: loss=1.052, reward_mean=0.070, reward_bound=0.254, batch=227 
556: loss=1.049, reward_mean=0.050, reward_bound=0.282, batch=226 
557: loss=1.047, reward_mean=0.100, reward_bound=0.314, batch=223 
558: loss=1.048, reward_mean=0.070, reward_bound=0.349, batch=222 
559: loss=1.048, reward_mean=0.050, reward_bound=0.254, batch=225 
560: loss=1.049, reward_mean=0.100, reward_bound=0.314, batch=225 
561: loss=1.047, reward_mean=0.060, reward_bound=0.282, batch=226 
562: loss=1.049, reward_mean=0.080, reward_bound=0.349, batch=227 
563: loss=1.052, reward_mean=0.050, reward_bound=0.387, batch=219 
564: loss=1.048, reward_mean=0.100, reward_bound=0.278, batch=223 
565: loss=1.047, reward_mean=0.090, reward_bound=0.290, batch=226 
566: loss=1.046, reward_mean=0.030, reward_bound=0.260, batch=228 
567: loss=1.046, reward_mean=0.050, reward_bound=0.234, batch=229 
568: loss=1.048, reward_mean=0.090, reward_bound=0.328, batch=230 
569: loss=1.049, reward_mean=0.050, reward_bound=0.376, batch=231 
570: loss=1.051, reward_mean=0.080, reward_bound=0.387, batch=231 
571: loss=1.040, reward_mean=0.060, reward_bound=0.430, batch=177 
572: loss=1.039, reward_mean=0.050, reward_bound=0.000, batch=182 
573: loss=1.038, reward_mean=0.060, reward_bound=0.000, batch=188 
574: loss=1.045, reward_mean=0.050, reward_bound=0.000, batch=193 
575: loss=1.045, reward_mean=0.080, reward_bound=0.000, batch=201 
576: loss=1.045, reward_mean=0.100, reward_bound=0.009, batch=210 
577: loss=1.044, reward_mean=0.030, reward_bound=0.000, batch=213 
578: loss=1.044, reward_mean=0.060, reward_bound=0.039, batch=219 
579: loss=1.040, reward_mean=0.060, reward_bound=0.067, batch=223 
580: loss=1.041, reward_mean=0.080, reward_bound=0.134, batch=226 
581: loss=1.042, reward_mean=0.040, reward_bound=0.158, batch=228 
582: loss=1.033, reward_mean=0.140, reward_bound=0.206, batch=226 
583: loss=1.033, reward_mean=0.070, reward_bound=0.229, batch=227 
584: loss=1.030, reward_mean=0.110, reward_bound=0.277, batch=229 
585: loss=1.034, reward_mean=0.120, reward_bound=0.282, batch=225 
586: loss=1.033, reward_mean=0.120, reward_bound=0.314, batch=224 
587: loss=1.035, reward_mean=0.050, reward_bound=0.216, batch=227 
588: loss=1.033, reward_mean=0.040, reward_bound=0.224, batch=229 
589: loss=1.030, reward_mean=0.080, reward_bound=0.282, batch=228 
590: loss=1.030, reward_mean=0.090, reward_bound=0.317, batch=229 
591: loss=1.035, reward_mean=0.040, reward_bound=0.349, batch=215 
592: loss=1.032, reward_mean=0.030, reward_bound=0.000, batch=218 
593: loss=1.033, reward_mean=0.090, reward_bound=0.286, batch=222 
594: loss=1.030, reward_mean=0.070, reward_bound=0.349, batch=223 
595: loss=1.026, reward_mean=0.030, reward_bound=0.100, batch=226 
596: loss=1.029, reward_mean=0.080, reward_bound=0.185, batch=227 
597: loss=1.028, reward_mean=0.060, reward_bound=0.342, batch=229 
598: loss=1.030, reward_mean=0.080, reward_bound=0.387, batch=214 
599: loss=1.031, reward_mean=0.080, reward_bound=0.206, batch=219 
600: loss=1.028, reward_mean=0.030, reward_bound=0.000, batch=222 
601: loss=1.026, reward_mean=0.020, reward_bound=0.000, batch=224 
602: loss=1.030, reward_mean=0.070, reward_bound=0.224, batch=227 
603: loss=1.029, reward_mean=0.090, reward_bound=0.282, batch=228 
604: loss=1.031, reward_mean=0.040, reward_bound=0.234, batch=229 
605: loss=1.031, reward_mean=0.010, reward_bound=0.113, batch=230 
606: loss=1.027, reward_mean=0.050, reward_bound=0.314, batch=229 
607: loss=1.027, reward_mean=0.050, reward_bound=0.328, batch=230 
608: loss=1.026, reward_mean=0.050, reward_bound=0.349, batch=230 
609: loss=1.027, reward_mean=0.110, reward_bound=0.387, batch=228 
610: loss=1.026, reward_mean=0.120, reward_bound=0.297, batch=229 
611: loss=1.026, reward_mean=0.060, reward_bound=0.405, batch=230 
612: loss=1.025, reward_mean=0.060, reward_bound=0.418, batch=231 
613: loss=1.025, reward_mean=0.040, reward_bound=0.254, batch=231 
614: loss=1.032, reward_mean=0.080, reward_bound=0.430, batch=208 
615: loss=1.030, reward_mean=0.080, reward_bound=0.043, batch=215 
616: loss=1.024, reward_mean=0.060, reward_bound=0.095, batch=220 
617: loss=1.022, reward_mean=0.080, reward_bound=0.194, batch=224 
618: loss=1.024, reward_mean=0.100, reward_bound=0.280, batch=227 
619: loss=1.022, reward_mean=0.060, reward_bound=0.282, batch=227 
620: loss=1.021, reward_mean=0.050, reward_bound=0.256, batch=229 
621: loss=1.021, reward_mean=0.080, reward_bound=0.314, batch=228 
622: loss=1.022, reward_mean=0.090, reward_bound=0.349, batch=222 
623: loss=1.024, reward_mean=0.110, reward_bound=0.387, batch=223 
624: loss=1.023, reward_mean=0.060, reward_bound=0.229, batch=225 
625: loss=1.024, reward_mean=0.080, reward_bound=0.321, batch=227 
626: loss=1.023, reward_mean=0.070, reward_bound=0.349, batch=227 
627: loss=1.022, reward_mean=0.100, reward_bound=0.387, batch=227 
628: loss=1.021, reward_mean=0.100, reward_bound=0.422, batch=229 
629: loss=1.029, reward_mean=0.090, reward_bound=0.430, batch=222 
630: loss=1.027, reward_mean=0.080, reward_bound=0.387, batch=224 
631: loss=1.027, reward_mean=0.070, reward_bound=0.342, batch=227 
632: loss=1.025, reward_mean=0.050, reward_bound=0.206, batch=228 
633: loss=1.025, reward_mean=0.050, reward_bound=0.349, batch=228 
634: loss=1.025, reward_mean=0.040, reward_bound=0.353, batch=229 
635: loss=1.026, reward_mean=0.110, reward_bound=0.387, batch=228 
636: loss=1.025, reward_mean=0.070, reward_bound=0.392, batch=229 
637: loss=1.026, reward_mean=0.060, reward_bound=0.450, batch=230 
638: loss=1.025, reward_mean=0.040, reward_bound=0.406, batch=231 
639: loss=1.027, reward_mean=0.070, reward_bound=0.430, batch=231 
640: loss=1.027, reward_mean=0.110, reward_bound=0.430, batch=231 
641: loss=1.027, reward_mean=0.090, reward_bound=0.387, batch=231 
642: loss=1.037, reward_mean=0.070, reward_bound=0.478, batch=158 
643: loss=1.030, reward_mean=0.090, reward_bound=0.000, batch=167 
644: loss=1.028, reward_mean=0.010, reward_bound=0.000, batch=168 
645: loss=1.023, reward_mean=0.070, reward_bound=0.000, batch=175 
646: loss=1.019, reward_mean=0.080, reward_bound=0.000, batch=183 
647: loss=1.014, reward_mean=0.050, reward_bound=0.000, batch=188 
648: loss=1.018, reward_mean=0.110, reward_bound=0.000, batch=199 
649: loss=1.016, reward_mean=0.090, reward_bound=0.000, batch=208 
650: loss=1.009, reward_mean=0.050, reward_bound=0.000, batch=213 
651: loss=1.009, reward_mean=0.080, reward_bound=0.077, batch=219 
652: loss=1.011, reward_mean=0.110, reward_bound=0.122, batch=222 
653: loss=1.010, reward_mean=0.130, reward_bound=0.206, batch=226 
654: loss=1.009, reward_mean=0.020, reward_bound=0.083, batch=228 
655: loss=1.009, reward_mean=0.040, reward_bound=0.171, batch=229 
656: loss=1.008, reward_mean=0.110, reward_bound=0.229, batch=224 
657: loss=1.012, reward_mean=0.060, reward_bound=0.252, batch=227 
658: loss=1.012, reward_mean=0.020, reward_bound=0.088, batch=229 
659: loss=1.007, reward_mean=0.070, reward_bound=0.254, batch=227 
660: loss=1.009, reward_mean=0.070, reward_bound=0.282, batch=221 
661: loss=1.010, reward_mean=0.060, reward_bound=0.150, batch=224 
662: loss=1.015, reward_mean=0.100, reward_bound=0.314, batch=209 
663: loss=1.016, reward_mean=0.100, reward_bound=0.194, batch=216 
664: loss=1.015, reward_mean=0.050, reward_bound=0.040, batch=221 
665: loss=1.017, reward_mean=0.060, reward_bound=0.185, batch=224 
666: loss=1.013, reward_mean=0.090, reward_bound=0.282, batch=226 
667: loss=1.013, reward_mean=0.010, reward_bound=0.000, batch=227 
668: loss=1.015, reward_mean=0.040, reward_bound=0.220, batch=229 
669: loss=1.015, reward_mean=0.050, reward_bound=0.215, batch=230 
670: loss=1.018, reward_mean=0.120, reward_bound=0.349, batch=221 
671: loss=1.025, reward_mean=0.100, reward_bound=0.387, batch=200 
672: loss=1.023, reward_mean=0.090, reward_bound=0.000, batch=209 
673: loss=1.019, reward_mean=0.080, reward_bound=0.127, batch=216 
674: loss=1.020, reward_mean=0.020, reward_bound=0.000, batch=218 
675: loss=1.021, reward_mean=0.040, reward_bound=0.014, batch=222 
676: loss=1.023, reward_mean=0.050, reward_bound=0.140, batch=225 
677: loss=1.019, reward_mean=0.070, reward_bound=0.189, batch=227 
678: loss=1.017, reward_mean=0.090, reward_bound=0.254, batch=227 
679: loss=1.014, reward_mean=0.110, reward_bound=0.282, batch=228 
680: loss=1.018, reward_mean=0.060, reward_bound=0.314, batch=226 
681: loss=1.016, reward_mean=0.030, reward_bound=0.138, batch=228 
682: loss=1.013, reward_mean=0.070, reward_bound=0.349, batch=225 
683: loss=1.011, reward_mean=0.060, reward_bound=0.281, batch=227 
684: loss=1.016, reward_mean=0.060, reward_bound=0.387, batch=221 
685: loss=1.017, reward_mean=0.100, reward_bound=0.349, batch=223 
686: loss=1.018, reward_mean=0.060, reward_bound=0.244, batch=226 
687: loss=1.019, reward_mean=0.040, reward_bound=0.335, batch=228 
688: loss=1.015, reward_mean=0.070, reward_bound=0.387, batch=228 
689: loss=1.022, reward_mean=0.110, reward_bound=0.430, batch=201 
690: loss=1.022, reward_mean=0.060, reward_bound=0.000, batch=207 
691: loss=1.014, reward_mean=0.040, reward_bound=0.000, batch=211 
692: loss=1.007, reward_mean=0.050, reward_bound=0.000, batch=216 
693: loss=1.009, reward_mean=0.050, reward_bound=0.026, batch=221 
694: loss=1.012, reward_mean=0.040, reward_bound=0.052, batch=224 
695: loss=1.017, reward_mean=0.060, reward_bound=0.135, batch=226 
696: loss=1.015, reward_mean=0.070, reward_bound=0.217, batch=228 
697: loss=1.013, reward_mean=0.080, reward_bound=0.231, batch=229 
698: loss=1.017, reward_mean=0.060, reward_bound=0.282, batch=229 
699: loss=1.017, reward_mean=0.050, reward_bound=0.278, batch=230 
700: loss=1.017, reward_mean=0.040, reward_bound=0.314, batch=230 
701: loss=1.020, reward_mean=0.060, reward_bound=0.349, batch=225 
702: loss=1.018, reward_mean=0.070, reward_bound=0.349, batch=226 
703: loss=1.021, reward_mean=0.060, reward_bound=0.331, batch=228 
704: loss=1.021, reward_mean=0.030, reward_bound=0.349, batch=228 
705: loss=1.020, reward_mean=0.080, reward_bound=0.387, batch=224 
706: loss=1.016, reward_mean=0.060, reward_bound=0.345, batch=227 
707: loss=1.018, reward_mean=0.110, reward_bound=0.422, batch=229 
708: loss=1.013, reward_mean=0.100, reward_bound=0.430, batch=216 
709: loss=1.014, reward_mean=0.010, reward_bound=0.000, batch=217 
710: loss=1.012, reward_mean=0.100, reward_bound=0.245, batch=222 
711: loss=1.013, reward_mean=0.080, reward_bound=0.282, batch=224 
712: loss=1.010, reward_mean=0.060, reward_bound=0.349, batch=226 
713: loss=1.012, reward_mean=0.040, reward_bound=0.298, batch=228 
714: loss=1.011, reward_mean=0.070, reward_bound=0.314, batch=228 
715: loss=1.012, reward_mean=0.060, reward_bound=0.387, batch=224 
716: loss=1.012, reward_mean=0.080, reward_bound=0.387, batch=226 
717: loss=1.013, reward_mean=0.030, reward_bound=0.130, batch=228 
718: loss=1.013, reward_mean=0.090, reward_bound=0.349, batch=228 
719: loss=1.013, reward_mean=0.070, reward_bound=0.430, batch=225 
720: loss=1.017, reward_mean=0.040, reward_bound=0.254, batch=226 
721: loss=1.019, reward_mean=0.060, reward_bound=0.301, batch=228 
722: loss=1.017, reward_mean=0.080, reward_bound=0.357, batch=229 
723: loss=1.015, reward_mean=0.070, reward_bound=0.405, batch=230 
724: loss=1.016, reward_mean=0.030, reward_bound=0.266, batch=231 
725: loss=1.016, reward_mean=0.100, reward_bound=0.430, batch=229 
726: loss=1.017, reward_mean=0.100, reward_bound=0.478, batch=231 
727: loss=1.017, reward_mean=0.080, reward_bound=0.387, batch=231 
728: loss=1.021, reward_mean=0.090, reward_bound=0.478, batch=188 
729: loss=1.024, reward_mean=0.060, reward_bound=0.000, batch=194 
730: loss=1.025, reward_mean=0.060, reward_bound=0.000, batch=200 
731: loss=1.020, reward_mean=0.070, reward_bound=0.000, batch=207 
732: loss=1.028, reward_mean=0.120, reward_bound=0.150, batch=213 
733: loss=1.022, reward_mean=0.080, reward_bound=0.178, batch=219 
734: loss=1.021, reward_mean=0.050, reward_bound=0.140, batch=223 
735: loss=1.016, reward_mean=0.060, reward_bound=0.206, batch=222 
736: loss=1.018, reward_mean=0.040, reward_bound=0.179, batch=225 
737: loss=1.016, reward_mean=0.090, reward_bound=0.229, batch=226 
738: loss=1.013, reward_mean=0.100, reward_bound=0.282, batch=222 
739: loss=1.018, reward_mean=0.120, reward_bound=0.314, batch=222 
740: loss=1.015, reward_mean=0.050, reward_bound=0.283, batch=225 
741: loss=1.012, reward_mean=0.110, reward_bound=0.349, batch=221 
742: loss=1.010, reward_mean=0.070, reward_bound=0.167, batch=224 
743: loss=1.012, reward_mean=0.070, reward_bound=0.377, batch=227 
744: loss=1.011, reward_mean=0.040, reward_bound=0.206, batch=228 
745: loss=1.011, reward_mean=0.020, reward_bound=0.317, batch=229 
746: loss=1.011, reward_mean=0.030, reward_bound=0.309, batch=230 
747: loss=1.011, reward_mean=0.080, reward_bound=0.376, batch=231 
748: loss=1.018, reward_mean=0.090, reward_bound=0.387, batch=226 
749: loss=1.018, reward_mean=0.070, reward_bound=0.372, batch=228 
750: loss=1.017, reward_mean=0.030, reward_bound=0.325, batch=229 
751: loss=1.017, reward_mean=0.060, reward_bound=0.405, batch=230 
752: loss=1.019, reward_mean=0.050, reward_bound=0.430, batch=211 
753: loss=1.013, reward_mean=0.070, reward_bound=0.229, batch=217 
754: loss=1.011, reward_mean=0.070, reward_bound=0.342, batch=222 
755: loss=1.011, reward_mean=0.050, reward_bound=0.292, batch=225 
756: loss=1.009, reward_mean=0.090, reward_bound=0.314, batch=226 
757: loss=1.010, reward_mean=0.080, reward_bound=0.349, batch=225 
758: loss=1.008, reward_mean=0.060, reward_bound=0.321, batch=227 
759: loss=1.010, reward_mean=0.060, reward_bound=0.249, batch=229 
760: loss=1.015, reward_mean=0.090, reward_bound=0.387, batch=222 
761: loss=1.014, reward_mean=0.060, reward_bound=0.220, batch=225 
762: loss=1.014, reward_mean=0.070, reward_bound=0.260, batch=227 
763: loss=1.014, reward_mean=0.050, reward_bound=0.308, batch=229 
764: loss=1.017, reward_mean=0.120, reward_bound=0.349, batch=228 
765: loss=1.016, reward_mean=0.060, reward_bound=0.387, batch=227 
766: loss=1.017, reward_mean=0.030, reward_bound=0.166, batch=229 
767: loss=1.015, reward_mean=0.040, reward_bound=0.324, batch=230 
768: loss=1.015, reward_mean=0.090, reward_bound=0.376, batch=231 
769: loss=1.015, reward_mean=0.060, reward_bound=0.387, batch=231 
770: loss=1.015, reward_mean=0.030, reward_bound=0.430, batch=223 
771: loss=1.014, reward_mean=0.060, reward_bound=0.430, batch=225 
772: loss=1.013, reward_mean=0.060, reward_bound=0.440, batch=227 
773: loss=1.012, reward_mean=0.050, reward_bound=0.314, batch=228 
774: loss=1.013, reward_mean=0.050, reward_bound=0.349, batch=228 
775: loss=1.013, reward_mean=0.100, reward_bound=0.392, batch=229 
776: loss=1.014, reward_mean=0.040, reward_bound=0.360, batch=230 
777: loss=1.015, reward_mean=0.070, reward_bound=0.430, batch=229 
778: loss=1.014, reward_mean=0.040, reward_bound=0.364, batch=230 
779: loss=1.016, reward_mean=0.030, reward_bound=0.308, batch=231 
780: loss=1.017, reward_mean=0.080, reward_bound=0.387, batch=230 
781: loss=1.018, reward_mean=0.070, reward_bound=0.464, batch=231 
782: loss=1.018, reward_mean=0.030, reward_bound=0.430, batch=231 
783: loss=1.018, reward_mean=0.070, reward_bound=0.430, batch=231 
784: loss=1.018, reward_mean=0.060, reward_bound=0.478, batch=206 
785: loss=1.014, reward_mean=0.050, reward_bound=0.000, batch=211 
786: loss=1.013, reward_mean=0.090, reward_bound=0.109, batch=216 
787: loss=1.010, reward_mean=0.070, reward_bound=0.143, batch=221 
788: loss=1.007, reward_mean=0.050, reward_bound=0.167, batch=224 
789: loss=1.009, reward_mean=0.090, reward_bound=0.229, batch=226 
790: loss=1.011, reward_mean=0.070, reward_bound=0.282, batch=226 
791: loss=1.013, reward_mean=0.070, reward_bound=0.314, batch=227 
792: loss=1.014, reward_mean=0.110, reward_bound=0.380, batch=229 
793: loss=1.012, reward_mean=0.060, reward_bound=0.387, batch=225 
794: loss=1.009, reward_mean=0.070, reward_bound=0.356, batch=227 
795: loss=1.007, reward_mean=0.070, reward_bound=0.380, batch=229 
796: loss=1.011, reward_mean=0.080, reward_bound=0.387, batch=227 
797: loss=1.012, reward_mean=0.060, reward_bound=0.380, batch=229 
798: loss=1.010, reward_mean=0.060, reward_bound=0.387, batch=228 
799: loss=1.010, reward_mean=0.070, reward_bound=0.392, batch=229 
800: loss=1.010, reward_mean=0.060, reward_bound=0.381, batch=230 
801: loss=1.010, reward_mean=0.030, reward_bound=0.363, batch=231 
802: loss=1.016, reward_mean=0.100, reward_bound=0.430, batch=219 
803: loss=1.017, reward_mean=0.070, reward_bound=0.364, batch=223 
804: loss=1.016, reward_mean=0.030, reward_bound=0.169, batch=226 
805: loss=1.014, reward_mean=0.080, reward_bound=0.282, batch=227 
806: loss=1.015, reward_mean=0.080, reward_bound=0.387, batch=227 
807: loss=1.013, reward_mean=0.070, reward_bound=0.414, batch=229 
808: loss=1.013, reward_mean=0.080, reward_bound=0.430, batch=226 
809: loss=1.013, reward_mean=0.070, reward_bound=0.390, batch=228 
810: loss=1.012, reward_mean=0.070, reward_bound=0.392, batch=229 
811: loss=1.011, reward_mean=0.120, reward_bound=0.430, batch=229 
812: loss=1.011, reward_mean=0.060, reward_bound=0.478, batch=231 
813: loss=1.013, reward_mean=0.070, reward_bound=0.478, batch=221 
814: loss=1.013, reward_mean=0.100, reward_bound=0.254, batch=224 
815: loss=1.010, reward_mean=0.030, reward_bound=0.167, batch=227 
816: loss=1.010, reward_mean=0.080, reward_bound=0.314, batch=227 
817: loss=1.010, reward_mean=0.090, reward_bound=0.314, batch=228 
818: loss=1.011, reward_mean=0.060, reward_bound=0.349, batch=226 
819: loss=1.010, reward_mean=0.090, reward_bound=0.409, batch=228 
820: loss=1.010, reward_mean=0.050, reward_bound=0.325, batch=229 
821: loss=1.009, reward_mean=0.060, reward_bound=0.360, batch=230 
822: loss=1.011, reward_mean=0.090, reward_bound=0.430, batch=228 
823: loss=1.012, reward_mean=0.060, reward_bound=0.478, batch=231 
824: loss=1.014, reward_mean=0.130, reward_bound=0.478, batch=228 
825: loss=1.014, reward_mean=0.060, reward_bound=0.353, batch=229 
826: loss=1.013, reward_mean=0.030, reward_bound=0.364, batch=230 
827: loss=1.014, reward_mean=0.070, reward_bound=0.304, batch=231 
828: loss=1.016, reward_mean=0.080, reward_bound=0.387, batch=230 
829: loss=1.013, reward_mean=0.060, reward_bound=0.478, batch=229 
830: loss=1.014, reward_mean=0.020, reward_bound=0.211, batch=230 
831: loss=1.013, reward_mean=0.100, reward_bound=0.430, batch=229 
832: loss=1.012, reward_mean=0.020, reward_bound=0.169, batch=230 
833: loss=1.013, reward_mean=0.030, reward_bound=0.314, batch=229 
834: loss=1.013, reward_mean=0.090, reward_bound=0.387, batch=229 
835: loss=1.014, reward_mean=0.020, reward_bound=0.283, batch=230 
836: loss=1.014, reward_mean=0.030, reward_bound=0.365, batch=231 
837: loss=1.014, reward_mean=0.100, reward_bound=0.349, batch=231 
838: loss=1.012, reward_mean=0.040, reward_bound=0.387, batch=231 
839: loss=1.012, reward_mean=0.080, reward_bound=0.430, batch=230 
840: loss=1.012, reward_mean=0.040, reward_bound=0.296, batch=231 
841: loss=1.012, reward_mean=0.100, reward_bound=0.430, batch=231 
842: loss=1.012, reward_mean=0.040, reward_bound=0.349, batch=231 
843: loss=1.012, reward_mean=0.060, reward_bound=0.430, batch=231 
844: loss=1.013, reward_mean=0.050, reward_bound=0.478, batch=230 
845: loss=1.013, reward_mean=0.100, reward_bound=0.464, batch=231 
846: loss=1.013, reward_mean=0.050, reward_bound=0.349, batch=231 
847: loss=1.013, reward_mean=0.080, reward_bound=0.478, batch=230 
848: loss=1.012, reward_mean=0.010, reward_bound=0.271, batch=231 
849: loss=1.015, reward_mean=0.050, reward_bound=0.387, batch=231 
850: loss=1.011, reward_mean=0.070, reward_bound=0.430, batch=231 
851: loss=1.013, reward_mean=0.040, reward_bound=0.478, batch=231 
852: loss=1.013, reward_mean=0.020, reward_bound=0.229, batch=231 
853: loss=1.013, reward_mean=0.010, reward_bound=0.282, batch=231 
855: loss=0.990, reward_mean=0.060, reward_bound=0.000, batch=6 
856: loss=1.027, reward_mean=0.080, reward_bound=0.000, batch=14 
857: loss=0.997, reward_mean=0.040, reward_bound=0.000, batch=18 
858: loss=0.994, reward_mean=0.070, reward_bound=0.000, batch=25 
859: loss=0.983, reward_mean=0.050, reward_bound=0.000, batch=30 
860: loss=0.978, reward_mean=0.070, reward_bound=0.000, batch=37 
861: loss=0.971, reward_mean=0.050, reward_bound=0.000, batch=42 
862: loss=0.977, reward_mean=0.040, reward_bound=0.000, batch=46 
863: loss=0.955, reward_mean=0.110, reward_bound=0.000, batch=57 
864: loss=0.945, reward_mean=0.090, reward_bound=0.000, batch=66 
865: loss=0.938, reward_mean=0.070, reward_bound=0.000, batch=73 
866: loss=0.945, reward_mean=0.090, reward_bound=0.000, batch=82 
867: loss=0.944, reward_mean=0.120, reward_bound=0.000, batch=94 
868: loss=0.942, reward_mean=0.100, reward_bound=0.000, batch=104 
869: loss=0.940, reward_mean=0.150, reward_bound=0.000, batch=119 
870: loss=0.934, reward_mean=0.140, reward_bound=0.000, batch=133 
871: loss=0.931, reward_mean=0.100, reward_bound=0.000, batch=143 
872: loss=0.928, reward_mean=0.110, reward_bound=0.000, batch=154 
873: loss=0.924, reward_mean=0.060, reward_bound=0.000, batch=160 
874: loss=0.926, reward_mean=0.090, reward_bound=0.000, batch=169 
875: loss=0.921, reward_mean=0.150, reward_bound=0.000, batch=184 
876: loss=0.921, reward_mean=0.060, reward_bound=0.000, batch=190 
877: loss=0.918, reward_mean=0.090, reward_bound=0.000, batch=199 
878: loss=0.915, reward_mean=0.120, reward_bound=0.034, batch=208 
879: loss=0.915, reward_mean=0.060, reward_bound=0.000, batch=214 
880: loss=0.914, reward_mean=0.080, reward_bound=0.042, batch=219 
881: loss=0.911, reward_mean=0.110, reward_bound=0.067, batch=223 
882: loss=0.910, reward_mean=0.070, reward_bound=0.089, batch=225 
883: loss=0.908, reward_mean=0.080, reward_bound=0.098, batch=226 
884: loss=0.909, reward_mean=0.110, reward_bound=0.115, batch=228 
885: loss=0.909, reward_mean=0.110, reward_bound=0.135, batch=221 
886: loss=0.904, reward_mean=0.110, reward_bound=0.150, batch=217 
887: loss=0.907, reward_mean=0.090, reward_bound=0.167, batch=216 
888: loss=0.911, reward_mean=0.110, reward_bound=0.185, batch=210 
889: loss=0.912, reward_mean=0.100, reward_bound=0.131, batch=217 
890: loss=0.917, reward_mean=0.110, reward_bound=0.206, batch=202 
891: loss=0.916, reward_mean=0.130, reward_bound=0.179, batch=211 
892: loss=0.913, reward_mean=0.060, reward_bound=0.000, batch=217 
893: loss=0.908, reward_mean=0.140, reward_bound=0.229, batch=208 
894: loss=0.906, reward_mean=0.090, reward_bound=0.112, batch=215 
895: loss=0.910, reward_mean=0.090, reward_bound=0.153, batch=220 
896: loss=0.910, reward_mean=0.070, reward_bound=0.150, batch=224 
897: loss=0.905, reward_mean=0.120, reward_bound=0.167, batch=226 
898: loss=0.912, reward_mean=0.100, reward_bound=0.229, batch=227 
899: loss=0.910, reward_mean=0.100, reward_bound=0.254, batch=207 
900: loss=0.905, reward_mean=0.090, reward_bound=0.181, batch=215 
901: loss=0.905, reward_mean=0.110, reward_bound=0.234, batch=220 
902: loss=0.905, reward_mean=0.110, reward_bound=0.274, batch=224 
903: loss=0.905, reward_mean=0.090, reward_bound=0.280, batch=227 
904: loss=0.911, reward_mean=0.080, reward_bound=0.282, batch=191 
905: loss=0.913, reward_mean=0.060, reward_bound=0.000, batch=197 
906: loss=0.914, reward_mean=0.080, reward_bound=0.000, batch=205 
907: loss=0.910, reward_mean=0.070, reward_bound=0.000, batch=212 
908: loss=0.913, reward_mean=0.140, reward_bound=0.126, batch=218 
909: loss=0.914, reward_mean=0.100, reward_bound=0.138, batch=222 
910: loss=0.913, reward_mean=0.060, reward_bound=0.155, batch=225 
911: loss=0.909, reward_mean=0.090, reward_bound=0.185, batch=226 
912: loss=0.903, reward_mean=0.150, reward_bound=0.217, batch=228 
913: loss=0.902, reward_mean=0.120, reward_bound=0.229, batch=228 
914: loss=0.904, reward_mean=0.070, reward_bound=0.254, batch=224 
915: loss=0.905, reward_mean=0.100, reward_bound=0.311, batch=227 
916: loss=0.901, reward_mean=0.080, reward_bound=0.314, batch=183 
917: loss=0.897, reward_mean=0.110, reward_bound=0.000, batch=194 
918: loss=0.899, reward_mean=0.100, reward_bound=0.000, batch=204 
919: loss=0.900, reward_mean=0.070, reward_bound=0.000, batch=211 
920: loss=0.900, reward_mean=0.090, reward_bound=0.065, batch=217 
921: loss=0.900, reward_mean=0.110, reward_bound=0.132, batch=222 
922: loss=0.896, reward_mean=0.060, reward_bound=0.135, batch=224 
923: loss=0.895, reward_mean=0.100, reward_bound=0.183, batch=227 
924: loss=0.890, reward_mean=0.110, reward_bound=0.254, batch=225 
925: loss=0.894, reward_mean=0.080, reward_bound=0.282, batch=218 
926: loss=0.895, reward_mean=0.100, reward_bound=0.237, batch=222 
927: loss=0.892, reward_mean=0.070, reward_bound=0.172, batch=225 
928: loss=0.901, reward_mean=0.090, reward_bound=0.314, batch=217 
929: loss=0.900, reward_mean=0.130, reward_bound=0.220, batch=222 
930: loss=0.898, reward_mean=0.120, reward_bound=0.263, batch=225 
931: loss=0.895, reward_mean=0.090, reward_bound=0.289, batch=227 
932: loss=0.895, reward_mean=0.100, reward_bound=0.308, batch=229 
933: loss=0.883, reward_mean=0.140, reward_bound=0.349, batch=174 
934: loss=0.881, reward_mean=0.080, reward_bound=0.000, batch=182 
935: loss=0.888, reward_mean=0.090, reward_bound=0.000, batch=191 
936: loss=0.883, reward_mean=0.060, reward_bound=0.000, batch=197 
937: loss=0.881, reward_mean=0.140, reward_bound=0.102, batch=208 
938: loss=0.883, reward_mean=0.120, reward_bound=0.150, batch=212 
939: loss=0.880, reward_mean=0.110, reward_bound=0.167, batch=216 
940: loss=0.880, reward_mean=0.090, reward_bound=0.176, batch=221 
941: loss=0.878, reward_mean=0.080, reward_bound=0.167, batch=224 
942: loss=0.879, reward_mean=0.140, reward_bound=0.206, batch=224 
943: loss=0.883, reward_mean=0.110, reward_bound=0.229, batch=226 
944: loss=0.886, reward_mean=0.100, reward_bound=0.254, batch=227 
945: loss=0.882, reward_mean=0.120, reward_bound=0.282, batch=225 
946: loss=0.880, reward_mean=0.060, reward_bound=0.289, batch=227 
947: loss=0.880, reward_mean=0.070, reward_bound=0.249, batch=229 
948: loss=0.876, reward_mean=0.090, reward_bound=0.314, batch=220 
949: loss=0.877, reward_mean=0.100, reward_bound=0.296, batch=224 
950: loss=0.877, reward_mean=0.080, reward_bound=0.314, batch=224 
951: loss=0.878, reward_mean=0.080, reward_bound=0.254, batch=226 
952: loss=0.878, reward_mean=0.160, reward_bound=0.349, batch=217 
953: loss=0.878, reward_mean=0.100, reward_bound=0.282, batch=221 
954: loss=0.885, reward_mean=0.170, reward_bound=0.387, batch=150 
955: loss=0.875, reward_mean=0.110, reward_bound=0.000, batch=161 
956: loss=0.868, reward_mean=0.050, reward_bound=0.000, batch=166 
957: loss=0.862, reward_mean=0.110, reward_bound=0.000, batch=177 
958: loss=0.846, reward_mean=0.110, reward_bound=0.000, batch=188 
959: loss=0.837, reward_mean=0.140, reward_bound=0.006, batch=201 
960: loss=0.836, reward_mean=0.140, reward_bound=0.080, batch=208 
961: loss=0.842, reward_mean=0.160, reward_bound=0.111, batch=215 
962: loss=0.846, reward_mean=0.100, reward_bound=0.122, batch=218 
963: loss=0.851, reward_mean=0.120, reward_bound=0.150, batch=220 
964: loss=0.847, reward_mean=0.190, reward_bound=0.185, batch=222 
965: loss=0.847, reward_mean=0.140, reward_bound=0.206, batch=231 
966: loss=0.852, reward_mean=0.070, reward_bound=0.206, batch=226 
967: loss=0.852, reward_mean=0.050, reward_bound=0.217, batch=228 
968: loss=0.854, reward_mean=0.160, reward_bound=0.231, batch=229 
969: loss=0.851, reward_mean=0.110, reward_bound=0.254, batch=225 
970: loss=0.850, reward_mean=0.070, reward_bound=0.210, batch=227 
971: loss=0.853, reward_mean=0.100, reward_bound=0.282, batch=220 
972: loss=0.853, reward_mean=0.090, reward_bound=0.162, batch=224 
973: loss=0.854, reward_mean=0.130, reward_bound=0.280, batch=227 
974: loss=0.856, reward_mean=0.120, reward_bound=0.282, batch=228 
975: loss=0.858, reward_mean=0.120, reward_bound=0.314, batch=210 
976: loss=0.858, reward_mean=0.080, reward_bound=0.034, batch=217 
977: loss=0.857, reward_mean=0.100, reward_bound=0.150, batch=220 
978: loss=0.858, reward_mean=0.080, reward_bound=0.222, batch=224 
979: loss=0.859, reward_mean=0.050, reward_bound=0.229, batch=223 
980: loss=0.858, reward_mean=0.110, reward_bound=0.282, batch=225 
981: loss=0.859, reward_mean=0.060, reward_bound=0.185, batch=226 
982: loss=0.859, reward_mean=0.080, reward_bound=0.314, batch=225 
983: loss=0.855, reward_mean=0.090, reward_bound=0.349, batch=210 
984: loss=0.849, reward_mean=0.060, reward_bound=0.000, batch=216 
985: loss=0.855, reward_mean=0.100, reward_bound=0.241, batch=221 
986: loss=0.855, reward_mean=0.110, reward_bound=0.282, batch=222 
987: loss=0.855, reward_mean=0.070, reward_bound=0.193, batch=225 
988: loss=0.854, reward_mean=0.050, reward_bound=0.260, batch=227 
989: loss=0.858, reward_mean=0.120, reward_bound=0.314, batch=228 
990: loss=0.861, reward_mean=0.110, reward_bound=0.349, batch=222 
991: loss=0.862, reward_mean=0.080, reward_bound=0.272, batch=225 
992: loss=0.860, reward_mean=0.140, reward_bound=0.356, batch=227 
993: loss=0.863, reward_mean=0.020, reward_bound=0.015, batch=229 
994: loss=0.862, reward_mean=0.150, reward_bound=0.349, batch=229 
995: loss=0.861, reward_mean=0.090, reward_bound=0.364, batch=230 
996: loss=0.853, reward_mean=0.100, reward_bound=0.387, batch=205 
997: loss=0.852, reward_mean=0.080, reward_bound=0.020, batch=213 
998: loss=0.847, reward_mean=0.070, reward_bound=0.071, batch=219 
999: loss=0.847, reward_mean=0.100, reward_bound=0.135, batch=221 
1000: loss=0.848, reward_mean=0.080, reward_bound=0.167, batch=223 
1001: loss=0.847, reward_mean=0.070, reward_bound=0.220, batch=226 
1002: loss=0.852, reward_mean=0.100, reward_bound=0.229, batch=226 
1003: loss=0.853, reward_mean=0.100, reward_bound=0.254, batch=226 
1004: loss=0.854, reward_mean=0.080, reward_bound=0.282, batch=227 
1005: loss=0.854, reward_mean=0.090, reward_bound=0.314, batch=226 
1006: loss=0.852, reward_mean=0.080, reward_bound=0.349, batch=220 
1007: loss=0.851, reward_mean=0.130, reward_bound=0.376, batch=224 
1008: loss=0.850, reward_mean=0.050, reward_bound=0.280, batch=227 
1009: loss=0.852, reward_mean=0.120, reward_bound=0.380, batch=229 
1010: loss=0.851, reward_mean=0.090, reward_bound=0.364, batch=230 
1011: loss=0.851, reward_mean=0.100, reward_bound=0.356, batch=231 
1012: loss=0.856, reward_mean=0.150, reward_bound=0.387, batch=222 
1013: loss=0.857, reward_mean=0.080, reward_bound=0.254, batch=225 
1014: loss=0.852, reward_mean=0.110, reward_bound=0.329, batch=227 
1015: loss=0.849, reward_mean=0.150, reward_bound=0.387, batch=228 
1016: loss=0.848, reward_mean=0.080, reward_bound=0.297, batch=229 
1017: loss=0.881, reward_mean=0.070, reward_bound=0.430, batch=134 
1018: loss=0.867, reward_mean=0.080, reward_bound=0.000, batch=142 
1019: loss=0.874, reward_mean=0.090, reward_bound=0.000, batch=151 
1020: loss=0.867, reward_mean=0.130, reward_bound=0.000, batch=164 
1021: loss=0.862, reward_mean=0.110, reward_bound=0.000, batch=175 
1022: loss=0.857, reward_mean=0.060, reward_bound=0.000, batch=181 
1023: loss=0.857, reward_mean=0.090, reward_bound=0.000, batch=190 
1024: loss=0.854, reward_mean=0.080, reward_bound=0.000, batch=198 
1025: loss=0.854, reward_mean=0.070, reward_bound=0.000, batch=205 
1026: loss=0.853, reward_mean=0.070, reward_bound=0.000, batch=212 
1027: loss=0.857, reward_mean=0.090, reward_bound=0.072, batch=215 
1028: loss=0.857, reward_mean=0.080, reward_bound=0.089, batch=221 
1029: loss=0.857, reward_mean=0.130, reward_bound=0.122, batch=221 
1030: loss=0.860, reward_mean=0.170, reward_bound=0.185, batch=219 
1031: loss=0.860, reward_mean=0.130, reward_bound=0.206, batch=222 
1032: loss=0.860, reward_mean=0.070, reward_bound=0.229, batch=217 
1033: loss=0.876, reward_mean=0.120, reward_bound=0.254, batch=213 
1034: loss=0.868, reward_mean=0.080, reward_bound=0.058, batch=219 
1035: loss=0.869, reward_mean=0.130, reward_bound=0.225, batch=223 
1036: loss=0.867, reward_mean=0.140, reward_bound=0.282, batch=211 
1037: loss=0.869, reward_mean=0.110, reward_bound=0.185, batch=217 
1038: loss=0.872, reward_mean=0.130, reward_bound=0.314, batch=211 
1039: loss=0.872, reward_mean=0.130, reward_bound=0.254, batch=217 
1040: loss=0.881, reward_mean=0.170, reward_bound=0.349, batch=203 
1041: loss=0.884, reward_mean=0.040, reward_bound=0.000, batch=207 
1042: loss=0.879, reward_mean=0.060, reward_bound=0.000, batch=213 
1043: loss=0.874, reward_mean=0.130, reward_bound=0.122, batch=218 
1044: loss=0.872, reward_mean=0.110, reward_bound=0.152, batch=222 
1045: loss=0.875, reward_mean=0.080, reward_bound=0.198, batch=225 
1046: loss=0.871, reward_mean=0.060, reward_bound=0.229, batch=225 
1047: loss=0.872, reward_mean=0.090, reward_bound=0.254, batch=226 
1048: loss=0.873, reward_mean=0.100, reward_bound=0.282, batch=225 
1049: loss=0.875, reward_mean=0.110, reward_bound=0.314, batch=225 
1050: loss=0.874, reward_mean=0.100, reward_bound=0.349, batch=222 
1051: loss=0.879, reward_mean=0.100, reward_bound=0.387, batch=197 
1052: loss=0.875, reward_mean=0.150, reward_bound=0.245, batch=208 
1053: loss=0.867, reward_mean=0.090, reward_bound=0.138, batch=215 
1054: loss=0.866, reward_mean=0.100, reward_bound=0.189, batch=220 
1055: loss=0.866, reward_mean=0.170, reward_bound=0.274, batch=224 
1056: loss=0.864, reward_mean=0.080, reward_bound=0.269, batch=227 
1057: loss=0.862, reward_mean=0.070, reward_bound=0.282, batch=224 
1058: loss=0.868, reward_mean=0.090, reward_bound=0.314, batch=223 
1059: loss=0.866, reward_mean=0.100, reward_bound=0.349, batch=220 
1060: loss=0.868, reward_mean=0.080, reward_bound=0.175, batch=224 
1061: loss=0.874, reward_mean=0.080, reward_bound=0.224, batch=227 
1062: loss=0.870, reward_mean=0.070, reward_bound=0.229, batch=227 
1063: loss=0.868, reward_mean=0.050, reward_bound=0.282, batch=228 
1064: loss=0.872, reward_mean=0.110, reward_bound=0.387, batch=221 
1065: loss=0.882, reward_mean=0.120, reward_bound=0.430, batch=198 
1066: loss=0.875, reward_mean=0.080, reward_bound=0.000, batch=206 
1067: loss=0.874, reward_mean=0.120, reward_bound=0.136, batch=214 
1068: loss=0.872, reward_mean=0.070, reward_bound=0.138, batch=220 
1069: loss=0.872, reward_mean=0.090, reward_bound=0.200, batch=224 
1070: loss=0.877, reward_mean=0.110, reward_bound=0.206, batch=225 
1071: loss=0.872, reward_mean=0.100, reward_bound=0.254, batch=224 
1072: loss=0.875, reward_mean=0.080, reward_bound=0.282, batch=222 
1073: loss=0.876, reward_mean=0.070, reward_bound=0.292, batch=225 
1074: loss=0.877, reward_mean=0.120, reward_bound=0.314, batch=226 
1075: loss=0.879, reward_mean=0.110, reward_bound=0.349, batch=218 
1076: loss=0.876, reward_mean=0.120, reward_bound=0.293, batch=222 
1077: loss=0.875, reward_mean=0.080, reward_bound=0.314, batch=225 
1078: loss=0.874, reward_mean=0.070, reward_bound=0.321, batch=227 
1079: loss=0.875, reward_mean=0.100, reward_bound=0.387, batch=216 
1080: loss=0.871, reward_mean=0.100, reward_bound=0.268, batch=221 
1081: loss=0.868, reward_mean=0.050, reward_bound=0.282, batch=223 
1082: loss=0.872, reward_mean=0.090, reward_bound=0.372, batch=226 
1083: loss=0.871, reward_mean=0.150, reward_bound=0.368, batch=228 
1084: loss=0.873, reward_mean=0.150, reward_bound=0.387, batch=228 
1085: loss=0.879, reward_mean=0.110, reward_bound=0.430, batch=215 
1086: loss=0.880, reward_mean=0.120, reward_bound=0.321, batch=220 
1087: loss=0.879, reward_mean=0.140, reward_bound=0.387, batch=222 
1088: loss=0.878, reward_mean=0.100, reward_bound=0.349, batch=225 
1089: loss=0.880, reward_mean=0.090, reward_bound=0.337, batch=227 
1090: loss=0.882, reward_mean=0.070, reward_bound=0.342, batch=229 
1091: loss=0.880, reward_mean=0.090, reward_bound=0.364, batch=230 
1092: loss=0.882, reward_mean=0.130, reward_bound=0.430, batch=225 
1093: loss=0.883, reward_mean=0.090, reward_bound=0.266, batch=227 
1094: loss=0.883, reward_mean=0.090, reward_bound=0.342, batch=229 
1095: loss=0.890, reward_mean=0.150, reward_bound=0.405, batch=230 
1096: loss=0.878, reward_mean=0.110, reward_bound=0.464, batch=231 
1097: loss=0.870, reward_mean=0.120, reward_bound=0.478, batch=93 
1098: loss=0.869, reward_mean=0.100, reward_bound=0.000, batch=103 
1099: loss=0.868, reward_mean=0.110, reward_bound=0.000, batch=114 
1100: loss=0.860, reward_mean=0.090, reward_bound=0.000, batch=123 
1101: loss=0.849, reward_mean=0.100, reward_bound=0.000, batch=133 
1102: loss=0.848, reward_mean=0.030, reward_bound=0.000, batch=136 
1103: loss=0.858, reward_mean=0.080, reward_bound=0.000, batch=144 
1104: loss=0.855, reward_mean=0.050, reward_bound=0.000, batch=149 
1105: loss=0.854, reward_mean=0.100, reward_bound=0.000, batch=159 
1106: loss=0.851, reward_mean=0.070, reward_bound=0.000, batch=166 
1107: loss=0.852, reward_mean=0.080, reward_bound=0.000, batch=174 
1108: loss=0.837, reward_mean=0.130, reward_bound=0.000, batch=187 
1109: loss=0.826, reward_mean=0.150, reward_bound=0.014, batch=201 
1110: loss=0.817, reward_mean=0.170, reward_bound=0.065, batch=208 
1111: loss=0.816, reward_mean=0.090, reward_bound=0.073, batch=215 
1112: loss=0.814, reward_mean=0.090, reward_bound=0.089, batch=221 
1113: loss=0.823, reward_mean=0.130, reward_bound=0.098, batch=224 
1114: loss=0.827, reward_mean=0.130, reward_bound=0.109, batch=224 
1115: loss=0.823, reward_mean=0.100, reward_bound=0.135, batch=222 
1116: loss=0.823, reward_mean=0.120, reward_bound=0.167, batch=221 
1117: loss=0.820, reward_mean=0.060, reward_bound=0.185, batch=215 
1118: loss=0.822, reward_mean=0.070, reward_bound=0.206, batch=217 
1119: loss=0.823, reward_mean=0.060, reward_bound=0.160, batch=222 
1120: loss=0.821, reward_mean=0.120, reward_bound=0.229, batch=216 
1121: loss=0.820, reward_mean=0.130, reward_bound=0.217, batch=221 
1122: loss=0.819, reward_mean=0.070, reward_bound=0.229, batch=224 
1123: loss=0.820, reward_mean=0.070, reward_bound=0.254, batch=214 
1124: loss=0.816, reward_mean=0.070, reward_bound=0.182, batch=220 
1125: loss=0.818, reward_mean=0.070, reward_bound=0.185, batch=223 
1126: loss=0.822, reward_mean=0.110, reward_bound=0.254, batch=225 
1127: loss=0.815, reward_mean=0.070, reward_bound=0.282, batch=210 
1128: loss=0.815, reward_mean=0.050, reward_bound=0.000, batch=215 
1129: loss=0.817, reward_mean=0.050, reward_bound=0.016, batch=220 
1130: loss=0.815, reward_mean=0.080, reward_bound=0.122, batch=223 
1131: loss=0.812, reward_mean=0.100, reward_bound=0.160, batch=226 
1132: loss=0.807, reward_mean=0.090, reward_bound=0.196, batch=228 
1133: loss=0.808, reward_mean=0.060, reward_bound=0.206, batch=228 
1134: loss=0.815, reward_mean=0.100, reward_bound=0.254, batch=226 
1135: loss=0.814, reward_mean=0.030, reward_bound=0.209, batch=228 
1136: loss=0.815, reward_mean=0.090, reward_bound=0.282, batch=228 
1137: loss=0.817, reward_mean=0.130, reward_bound=0.314, batch=202 
1138: loss=0.812, reward_mean=0.070, reward_bound=0.000, batch=209 
1139: loss=0.806, reward_mean=0.060, reward_bound=0.000, batch=215 
1140: loss=0.805, reward_mean=0.050, reward_bound=0.022, batch=220 
1141: loss=0.805, reward_mean=0.060, reward_bound=0.163, batch=224 
1142: loss=0.807, reward_mean=0.100, reward_bound=0.254, batch=224 
1143: loss=0.804, reward_mean=0.070, reward_bound=0.269, batch=227 
1144: loss=0.803, reward_mean=0.130, reward_bound=0.282, batch=227 
1145: loss=0.811, reward_mean=0.110, reward_bound=0.349, batch=192 
1146: loss=0.814, reward_mean=0.060, reward_bound=0.000, batch=198 
1147: loss=0.806, reward_mean=0.090, reward_bound=0.000, batch=207 
1148: loss=0.807, reward_mean=0.140, reward_bound=0.206, batch=212 
1149: loss=0.805, reward_mean=0.090, reward_bound=0.220, batch=218 
1150: loss=0.808, reward_mean=0.130, reward_bound=0.314, batch=220 
1151: loss=0.802, reward_mean=0.150, reward_bound=0.349, batch=214 
1152: loss=0.799, reward_mean=0.110, reward_bound=0.206, batch=218 
1153: loss=0.799, reward_mean=0.080, reward_bound=0.166, batch=222 
1154: loss=0.792, reward_mean=0.050, reward_bound=0.132, batch=225 
1155: loss=0.798, reward_mean=0.070, reward_bound=0.266, batch=227 
1156: loss=0.794, reward_mean=0.100, reward_bound=0.349, batch=227 
1157: loss=0.812, reward_mean=0.080, reward_bound=0.387, batch=179 
1158: loss=0.820, reward_mean=0.070, reward_bound=0.000, batch=186 
1159: loss=0.821, reward_mean=0.120, reward_bound=0.000, batch=198 
1160: loss=0.815, reward_mean=0.080, reward_bound=0.000, batch=206 
1161: loss=0.811, reward_mean=0.070, reward_bound=0.000, batch=213 
1162: loss=0.806, reward_mean=0.100, reward_bound=0.117, batch=219 
1163: loss=0.802, reward_mean=0.130, reward_bound=0.167, batch=222 
1164: loss=0.795, reward_mean=0.090, reward_bound=0.206, batch=227 
1165: loss=0.798, reward_mean=0.080, reward_bound=0.206, batch=228 
1166: loss=0.801, reward_mean=0.070, reward_bound=0.229, batch=226 
1167: loss=0.797, reward_mean=0.140, reward_bound=0.254, batch=223 
1168: loss=0.795, reward_mean=0.050, reward_bound=0.160, batch=226 
1169: loss=0.801, reward_mean=0.060, reward_bound=0.196, batch=228 
1170: loss=0.798, reward_mean=0.100, reward_bound=0.282, batch=220 
1171: loss=0.796, reward_mean=0.100, reward_bound=0.254, batch=222 
1172: loss=0.795, reward_mean=0.150, reward_bound=0.314, batch=218 
1173: loss=0.791, reward_mean=0.050, reward_bound=0.169, batch=222 
1174: loss=0.794, reward_mean=0.090, reward_bound=0.213, batch=225 
1175: loss=0.795, reward_mean=0.080, reward_bound=0.254, batch=225 
1176: loss=0.796, reward_mean=0.100, reward_bound=0.296, batch=227 
1177: loss=0.795, reward_mean=0.080, reward_bound=0.335, batch=229 
1178: loss=0.801, reward_mean=0.080, reward_bound=0.349, batch=217 
1179: loss=0.804, reward_mean=0.050, reward_bound=0.226, batch=222 
1180: loss=0.801, reward_mean=0.130, reward_bound=0.349, batch=224 
1181: loss=0.798, reward_mean=0.100, reward_bound=0.384, batch=227 
1182: loss=0.798, reward_mean=0.120, reward_bound=0.380, batch=229 
1183: loss=0.800, reward_mean=0.100, reward_bound=0.387, batch=216 
1184: loss=0.803, reward_mean=0.080, reward_bound=0.301, batch=221 
1185: loss=0.803, reward_mean=0.080, reward_bound=0.349, batch=221 
1186: loss=0.804, reward_mean=0.110, reward_bound=0.314, batch=224 
1187: loss=0.803, reward_mean=0.080, reward_bound=0.345, batch=227 
1188: loss=0.802, reward_mean=0.080, reward_bound=0.342, batch=229 
1189: loss=0.800, reward_mean=0.070, reward_bound=0.349, batch=229 
1190: loss=0.798, reward_mean=0.090, reward_bound=0.387, batch=225 
1191: loss=0.796, reward_mean=0.080, reward_bound=0.349, batch=226 
1192: loss=0.825, reward_mean=0.140, reward_bound=0.430, batch=173 
1193: loss=0.823, reward_mean=0.090, reward_bound=0.000, batch=182 
1194: loss=0.819, reward_mean=0.050, reward_bound=0.000, batch=187 
1195: loss=0.813, reward_mean=0.130, reward_bound=0.000, batch=200 
1196: loss=0.812, reward_mean=0.100, reward_bound=0.030, batch=210 
1197: loss=0.817, reward_mean=0.060, reward_bound=0.000, batch=216 
1198: loss=0.809, reward_mean=0.110, reward_bound=0.104, batch=221 
1199: loss=0.814, reward_mean=0.110, reward_bound=0.135, batch=224 
1200: loss=0.815, reward_mean=0.070, reward_bound=0.167, batch=224 
1201: loss=0.813, reward_mean=0.070, reward_bound=0.174, batch=227 
1202: loss=0.809, reward_mean=0.170, reward_bound=0.224, batch=229 
1203: loss=0.812, reward_mean=0.120, reward_bound=0.254, batch=225 
1204: loss=0.813, reward_mean=0.110, reward_bound=0.282, batch=223 
1205: loss=0.812, reward_mean=0.080, reward_bound=0.314, batch=223 
1206: loss=0.808, reward_mean=0.070, reward_bound=0.311, batch=226 
1207: loss=0.807, reward_mean=0.070, reward_bound=0.349, batch=220 
1208: loss=0.809, reward_mean=0.070, reward_bound=0.248, batch=224 
1209: loss=0.802, reward_mean=0.130, reward_bound=0.314, batch=226 
1210: loss=0.804, reward_mean=0.090, reward_bound=0.368, batch=228 
1211: loss=0.804, reward_mean=0.180, reward_bound=0.387, batch=223 
1212: loss=0.804, reward_mean=0.140, reward_bound=0.398, batch=226 
1213: loss=0.803, reward_mean=0.100, reward_bound=0.387, batch=227 
1214: loss=0.804, reward_mean=0.150, reward_bound=0.373, batch=229 
1215: loss=0.802, reward_mean=0.080, reward_bound=0.387, batch=229 
1216: loss=0.804, reward_mean=0.070, reward_bound=0.405, batch=230 
1217: loss=0.807, reward_mean=0.060, reward_bound=0.406, batch=231 
1218: loss=0.813, reward_mean=0.150, reward_bound=0.430, batch=206 
1219: loss=0.816, reward_mean=0.070, reward_bound=0.000, batch=213 
1220: loss=0.814, reward_mean=0.110, reward_bound=0.112, batch=219 
1221: loss=0.814, reward_mean=0.070, reward_bound=0.215, batch=223 
1222: loss=0.811, reward_mean=0.060, reward_bound=0.190, batch=226 
1223: loss=0.819, reward_mean=0.100, reward_bound=0.254, batch=227 
1224: loss=0.817, reward_mean=0.060, reward_bound=0.277, batch=229 
1225: loss=0.820, reward_mean=0.090, reward_bound=0.282, batch=226 
1226: loss=0.822, reward_mean=0.140, reward_bound=0.298, batch=228 
1227: loss=0.815, reward_mean=0.100, reward_bound=0.349, batch=226 
1228: loss=0.813, reward_mean=0.110, reward_bound=0.387, batch=223 
1229: loss=0.817, reward_mean=0.110, reward_bound=0.349, batch=225 
1230: loss=0.817, reward_mean=0.080, reward_bound=0.303, batch=227 
1231: loss=0.811, reward_mean=0.110, reward_bound=0.387, batch=228 
1232: loss=0.811, reward_mean=0.090, reward_bound=0.387, batch=228 
1233: loss=0.812, reward_mean=0.140, reward_bound=0.430, batch=224 
1234: loss=0.812, reward_mean=0.080, reward_bound=0.224, batch=227 
1235: loss=0.815, reward_mean=0.060, reward_bound=0.297, batch=229 
1236: loss=0.815, reward_mean=0.070, reward_bound=0.278, batch=230 
1237: loss=0.812, reward_mean=0.120, reward_bound=0.349, batch=229 
1238: loss=0.813, reward_mean=0.110, reward_bound=0.405, batch=230 
1239: loss=0.811, reward_mean=0.070, reward_bound=0.329, batch=231 
1240: loss=0.815, reward_mean=0.080, reward_bound=0.430, batch=231 
1241: loss=0.829, reward_mean=0.080, reward_bound=0.478, batch=158 
1242: loss=0.817, reward_mean=0.070, reward_bound=0.000, batch=165 
1243: loss=0.823, reward_mean=0.090, reward_bound=0.000, batch=174 
1244: loss=0.833, reward_mean=0.140, reward_bound=0.000, batch=188 
1245: loss=0.833, reward_mean=0.060, reward_bound=0.000, batch=194 
1246: loss=0.829, reward_mean=0.100, reward_bound=0.000, batch=204 
1247: loss=0.840, reward_mean=0.060, reward_bound=0.000, batch=210 
1248: loss=0.829, reward_mean=0.120, reward_bound=0.077, batch=217 
1249: loss=0.834, reward_mean=0.110, reward_bound=0.117, batch=222 
1250: loss=0.842, reward_mean=0.170, reward_bound=0.172, batch=225 
1251: loss=0.842, reward_mean=0.110, reward_bound=0.189, batch=227 
1252: loss=0.833, reward_mean=0.160, reward_bound=0.206, batch=227 
1253: loss=0.833, reward_mean=0.080, reward_bound=0.229, batch=225 
1254: loss=0.834, reward_mean=0.040, reward_bound=0.171, batch=227 
1255: loss=0.827, reward_mean=0.070, reward_bound=0.254, batch=217 
1256: loss=0.829, reward_mean=0.070, reward_bound=0.185, batch=221 
1257: loss=0.828, reward_mean=0.050, reward_bound=0.167, batch=224 
1258: loss=0.832, reward_mean=0.140, reward_bound=0.282, batch=220 
1259: loss=0.837, reward_mean=0.070, reward_bound=0.167, batch=223 
1260: loss=0.829, reward_mean=0.050, reward_bound=0.206, batch=225 
1261: loss=0.830, reward_mean=0.140, reward_bound=0.314, batch=218 
1262: loss=0.826, reward_mean=0.160, reward_bound=0.349, batch=213 
1263: loss=0.828, reward_mean=0.100, reward_bound=0.154, batch=219 
1264: loss=0.827, reward_mean=0.060, reward_bound=0.148, batch=223 
1265: loss=0.822, reward_mean=0.100, reward_bound=0.220, batch=226 
1266: loss=0.829, reward_mean=0.130, reward_bound=0.331, batch=228 
1267: loss=0.829, reward_mean=0.100, reward_bound=0.317, batch=229 
1268: loss=0.827, reward_mean=0.170, reward_bound=0.349, batch=229 
1269: loss=0.819, reward_mean=0.100, reward_bound=0.387, batch=209 
1270: loss=0.815, reward_mean=0.070, reward_bound=0.023, batch=216 
1271: loss=0.810, reward_mean=0.070, reward_bound=0.119, batch=221 
1272: loss=0.815, reward_mean=0.110, reward_bound=0.206, batch=222 
1273: loss=0.816, reward_mean=0.140, reward_bound=0.272, batch=225 
1274: loss=0.815, reward_mean=0.090, reward_bound=0.227, batch=227 
1275: loss=0.814, reward_mean=0.080, reward_bound=0.314, batch=225 
1276: loss=0.813, reward_mean=0.090, reward_bound=0.349, batch=222 
1277: loss=0.811, reward_mean=0.110, reward_bound=0.185, batch=225 
1278: loss=0.811, reward_mean=0.090, reward_bound=0.349, batch=226 
1279: loss=0.810, reward_mean=0.080, reward_bound=0.335, batch=228 
1280: loss=0.814, reward_mean=0.090, reward_bound=0.387, batch=222 
1281: loss=0.813, reward_mean=0.110, reward_bound=0.302, batch=225 
1282: loss=0.809, reward_mean=0.050, reward_bound=0.356, batch=227 
1283: loss=0.808, reward_mean=0.080, reward_bound=0.342, batch=229 
1284: loss=0.808, reward_mean=0.060, reward_bound=0.309, batch=230 
1285: loss=0.809, reward_mean=0.060, reward_bound=0.376, batch=231 
1286: loss=0.811, reward_mean=0.050, reward_bound=0.387, batch=230 
1287: loss=0.811, reward_mean=0.100, reward_bound=0.349, batch=230 
1288: loss=0.813, reward_mean=0.130, reward_bound=0.418, batch=231 
1289: loss=0.813, reward_mean=0.090, reward_bound=0.387, batch=231 
1290: loss=0.813, reward_mean=0.080, reward_bound=0.349, batch=231 
1291: loss=0.813, reward_mean=0.050, reward_bound=0.314, batch=231 
1292: loss=0.818, reward_mean=0.080, reward_bound=0.430, batch=200 
1293: loss=0.823, reward_mean=0.060, reward_bound=0.000, batch=206 
1294: loss=0.818, reward_mean=0.080, reward_bound=0.075, batch=214 
1295: loss=0.819, reward_mean=0.080, reward_bound=0.130, batch=220 
1296: loss=0.816, reward_mean=0.100, reward_bound=0.162, batch=224 
1297: loss=0.828, reward_mean=0.110, reward_bound=0.229, batch=225 
1298: loss=0.830, reward_mean=0.050, reward_bound=0.282, batch=226 
1299: loss=0.824, reward_mean=0.080, reward_bound=0.314, batch=221 
1300: loss=0.824, reward_mean=0.080, reward_bound=0.349, batch=218 
1301: loss=0.822, reward_mean=0.080, reward_bound=0.268, batch=222 
1302: loss=0.831, reward_mean=0.150, reward_bound=0.387, batch=218 
1303: loss=0.832, reward_mean=0.090, reward_bound=0.231, batch=222 
1304: loss=0.833, reward_mean=0.080, reward_bound=0.254, batch=224 
1305: loss=0.840, reward_mean=0.100, reward_bound=0.314, batch=226 
1306: loss=0.836, reward_mean=0.090, reward_bound=0.349, batch=227 
1307: loss=0.835, reward_mean=0.080, reward_bound=0.387, batch=226 
1308: loss=0.834, reward_mean=0.100, reward_bound=0.372, batch=228 
1309: loss=0.830, reward_mean=0.080, reward_bound=0.430, batch=218 
1310: loss=0.829, reward_mean=0.150, reward_bound=0.317, batch=222 
1311: loss=0.829, reward_mean=0.070, reward_bound=0.349, batch=223 
1312: loss=0.832, reward_mean=0.090, reward_bound=0.413, batch=226 
1313: loss=0.829, reward_mean=0.090, reward_bound=0.368, batch=228 
1314: loss=0.829, reward_mean=0.050, reward_bound=0.430, batch=225 
1315: loss=0.831, reward_mean=0.070, reward_bound=0.296, batch=227 
1316: loss=0.829, reward_mean=0.100, reward_bound=0.335, batch=229 
1317: loss=0.828, reward_mean=0.100, reward_bound=0.405, batch=230 
1318: loss=0.828, reward_mean=0.080, reward_bound=0.430, batch=229 
1319: loss=0.830, reward_mean=0.090, reward_bound=0.405, batch=230 
1320: loss=0.827, reward_mean=0.080, reward_bound=0.464, batch=231 
1321: loss=0.819, reward_mean=0.090, reward_bound=0.478, batch=184 
1322: loss=0.816, reward_mean=0.090, reward_bound=0.000, batch=193 
1323: loss=0.810, reward_mean=0.060, reward_bound=0.000, batch=199 
1324: loss=0.810, reward_mean=0.110, reward_bound=0.067, batch=209 
1325: loss=0.806, reward_mean=0.050, reward_bound=0.000, batch=214 
1326: loss=0.815, reward_mean=0.080, reward_bound=0.079, batch=220 
1327: loss=0.813, reward_mean=0.080, reward_bound=0.106, batch=224 
1328: loss=0.808, reward_mean=0.090, reward_bound=0.165, batch=227 
1329: loss=0.809, reward_mean=0.100, reward_bound=0.229, batch=226 
1330: loss=0.808, reward_mean=0.100, reward_bound=0.254, batch=224 
1331: loss=0.806, reward_mean=0.120, reward_bound=0.282, batch=224 
1332: loss=0.806, reward_mean=0.090, reward_bound=0.311, batch=227 
1333: loss=0.807, reward_mean=0.090, reward_bound=0.314, batch=222 
1334: loss=0.805, reward_mean=0.070, reward_bound=0.324, batch=225 
1335: loss=0.804, reward_mean=0.080, reward_bound=0.321, batch=227 
1336: loss=0.808, reward_mean=0.080, reward_bound=0.349, batch=218 
1337: loss=0.808, reward_mean=0.130, reward_bound=0.349, batch=219 
1338: loss=0.808, reward_mean=0.130, reward_bound=0.328, batch=223 
1339: loss=0.810, reward_mean=0.100, reward_bound=0.335, batch=226 
1340: loss=0.808, reward_mean=0.100, reward_bound=0.349, batch=227 
1341: loss=0.810, reward_mean=0.150, reward_bound=0.342, batch=229 
1342: loss=0.809, reward_mean=0.070, reward_bound=0.265, batch=230 
1343: loss=0.806, reward_mean=0.130, reward_bound=0.376, batch=231 
1344: loss=0.809, reward_mean=0.090, reward_bound=0.387, batch=221 
1345: loss=0.812, reward_mean=0.090, reward_bound=0.229, batch=223 
1346: loss=0.809, reward_mean=0.110, reward_bound=0.358, batch=226 
1347: loss=0.812, reward_mean=0.110, reward_bound=0.241, batch=228 
1348: loss=0.810, reward_mean=0.110, reward_bound=0.254, batch=228 
1349: loss=0.811, reward_mean=0.090, reward_bound=0.286, batch=229 
1350: loss=0.809, reward_mean=0.070, reward_bound=0.349, batch=229 
1351: loss=0.812, reward_mean=0.120, reward_bound=0.405, batch=230 
1352: loss=0.808, reward_mean=0.130, reward_bound=0.430, batch=213 
1353: loss=0.803, reward_mean=0.060, reward_bound=0.025, batch=219 
1354: loss=0.803, reward_mean=0.090, reward_bound=0.282, batch=221 
1355: loss=0.803, reward_mean=0.060, reward_bound=0.229, batch=224 
1356: loss=0.804, reward_mean=0.080, reward_bound=0.314, batch=223 
1357: loss=0.800, reward_mean=0.090, reward_bound=0.314, batch=225 
1358: loss=0.802, reward_mean=0.150, reward_bound=0.349, batch=223 
1359: loss=0.801, reward_mean=0.100, reward_bound=0.271, batch=226 
1360: loss=0.800, reward_mean=0.070, reward_bound=0.196, batch=228 
1361: loss=0.802, reward_mean=0.110, reward_bound=0.282, batch=227 
1362: loss=0.806, reward_mean=0.070, reward_bound=0.387, batch=222 
1363: loss=0.803, reward_mean=0.110, reward_bound=0.360, batch=225 
1364: loss=0.800, reward_mean=0.090, reward_bound=0.321, batch=227 
1365: loss=0.805, reward_mean=0.130, reward_bound=0.387, batch=225 
1366: loss=0.802, reward_mean=0.060, reward_bound=0.253, batch=227 
1367: loss=0.801, reward_mean=0.130, reward_bound=0.414, batch=229 
1368: loss=0.801, reward_mean=0.070, reward_bound=0.349, batch=229 
1369: loss=0.804, reward_mean=0.160, reward_bound=0.430, batch=223 
1370: loss=0.805, reward_mean=0.050, reward_bound=0.235, batch=226 
1371: loss=0.803, reward_mean=0.110, reward_bound=0.282, batch=227 
1372: loss=0.802, reward_mean=0.080, reward_bound=0.380, batch=229 
1373: loss=0.804, reward_mean=0.090, reward_bound=0.387, batch=228 
1374: loss=0.802, reward_mean=0.090, reward_bound=0.297, batch=229 
1375: loss=0.803, reward_mean=0.120, reward_bound=0.430, batch=226 
1376: loss=0.802, reward_mean=0.070, reward_bound=0.390, batch=228 
1377: loss=0.802, reward_mean=0.070, reward_bound=0.317, batch=229 
1378: loss=0.800, reward_mean=0.120, reward_bound=0.349, batch=229 
1379: loss=0.800, reward_mean=0.030, reward_bound=0.279, batch=230 
1380: loss=0.797, reward_mean=0.070, reward_bound=0.418, batch=231 
1381: loss=0.802, reward_mean=0.110, reward_bound=0.430, batch=231 
1382: loss=0.815, reward_mean=0.130, reward_bound=0.478, batch=204 
1383: loss=0.810, reward_mean=0.090, reward_bound=0.098, batch=213 
1384: loss=0.804, reward_mean=0.060, reward_bound=0.039, batch=219 
1385: loss=0.801, reward_mean=0.090, reward_bound=0.157, batch=223 
1386: loss=0.799, reward_mean=0.150, reward_bound=0.206, batch=225 
1387: loss=0.805, reward_mean=0.060, reward_bound=0.229, batch=226 
1388: loss=0.803, reward_mean=0.090, reward_bound=0.256, batch=228 
1389: loss=0.805, reward_mean=0.070, reward_bound=0.314, batch=228 
1390: loss=0.809, reward_mean=0.100, reward_bound=0.349, batch=226 
1391: loss=0.808, reward_mean=0.150, reward_bound=0.387, batch=223 
1392: loss=0.810, reward_mean=0.110, reward_bound=0.372, batch=226 
1393: loss=0.806, reward_mean=0.070, reward_bound=0.387, batch=226 
1394: loss=0.803, reward_mean=0.110, reward_bound=0.390, batch=228 
1395: loss=0.804, reward_mean=0.120, reward_bound=0.392, batch=229 
1396: loss=0.809, reward_mean=0.110, reward_bound=0.430, batch=223 
1397: loss=0.810, reward_mean=0.070, reward_bound=0.235, batch=226 
1398: loss=0.812, reward_mean=0.090, reward_bound=0.282, batch=227 
1399: loss=0.808, reward_mean=0.090, reward_bound=0.342, batch=229 
1400: loss=0.809, reward_mean=0.120, reward_bound=0.364, batch=230 
1401: loss=0.809, reward_mean=0.100, reward_bound=0.387, batch=228 
1402: loss=0.810, reward_mean=0.060, reward_bound=0.241, batch=229 
1403: loss=0.810, reward_mean=0.110, reward_bound=0.328, batch=230 
1404: loss=0.809, reward_mean=0.090, reward_bound=0.430, batch=224 
1405: loss=0.810, reward_mean=0.090, reward_bound=0.422, batch=227 
1406: loss=0.811, reward_mean=0.030, reward_bound=0.223, batch=229 
1407: loss=0.809, reward_mean=0.070, reward_bound=0.360, batch=230 
1408: loss=0.809, reward_mean=0.060, reward_bound=0.387, batch=230 
1409: loss=0.808, reward_mean=0.100, reward_bound=0.347, batch=231 
1410: loss=0.808, reward_mean=0.120, reward_bound=0.314, batch=231 
1411: loss=0.808, reward_mean=0.080, reward_bound=0.314, batch=231 
1412: loss=0.809, reward_mean=0.080, reward_bound=0.387, batch=230 
1413: loss=0.807, reward_mean=0.100, reward_bound=0.365, batch=231 
1414: loss=0.809, reward_mean=0.090, reward_bound=0.387, batch=230 
1415: loss=0.809, reward_mean=0.060, reward_bound=0.247, batch=231 
1416: loss=0.806, reward_mean=0.080, reward_bound=0.430, batch=229 
1417: loss=0.807, reward_mean=0.090, reward_bound=0.450, batch=230 
1418: loss=0.808, reward_mean=0.120, reward_bound=0.464, batch=231 
1419: loss=0.808, reward_mean=0.110, reward_bound=0.387, batch=231 
1420: loss=0.808, reward_mean=0.080, reward_bound=0.430, batch=231 
1421: loss=0.814, reward_mean=0.060, reward_bound=0.478, batch=219 
1422: loss=0.814, reward_mean=0.030, reward_bound=0.000, batch=222 
1423: loss=0.813, reward_mean=0.120, reward_bound=0.349, batch=225 
1424: loss=0.812, reward_mean=0.060, reward_bound=0.199, batch=227 
1425: loss=0.811, reward_mean=0.130, reward_bound=0.282, batch=228 
1426: loss=0.812, reward_mean=0.160, reward_bound=0.392, batch=229 
1427: loss=0.814, reward_mean=0.120, reward_bound=0.430, batch=224 
1428: loss=0.810, reward_mean=0.120, reward_bound=0.308, batch=227 
1429: loss=0.807, reward_mean=0.090, reward_bound=0.314, batch=228 
1430: loss=0.811, reward_mean=0.140, reward_bound=0.387, batch=227 
1431: loss=0.809, reward_mean=0.070, reward_bound=0.414, batch=229 
1432: loss=0.809, reward_mean=0.100, reward_bound=0.405, batch=230 
1433: loss=0.808, reward_mean=0.080, reward_bound=0.376, batch=231 
1434: loss=0.814, reward_mean=0.080, reward_bound=0.430, batch=228 
1435: loss=0.816, reward_mean=0.080, reward_bound=0.478, batch=230 
1436: loss=0.815, reward_mean=0.090, reward_bound=0.478, batch=225 
1437: loss=0.814, reward_mean=0.100, reward_bound=0.356, batch=227 
1438: loss=0.817, reward_mean=0.160, reward_bound=0.430, batch=227 
1439: loss=0.816, reward_mean=0.090, reward_bound=0.373, batch=229 
1440: loss=0.813, reward_mean=0.080, reward_bound=0.405, batch=230 
1441: loss=0.814, reward_mean=0.100, reward_bound=0.430, batch=229 
1442: loss=0.813, reward_mean=0.090, reward_bound=0.424, batch=230 
1443: loss=0.813, reward_mean=0.060, reward_bound=0.439, batch=231 
1444: loss=0.817, reward_mean=0.140, reward_bound=0.478, batch=228 
1445: loss=0.817, reward_mean=0.080, reward_bound=0.387, batch=228 
1446: loss=0.816, reward_mean=0.100, reward_bound=0.484, batch=229 
1447: loss=0.815, reward_mean=0.020, reward_bound=0.105, batch=230 
1448: loss=0.815, reward_mean=0.050, reward_bound=0.240, batch=231 
1449: loss=0.814, reward_mean=0.080, reward_bound=0.430, batch=231 
1451: loss=0.701, reward_mean=0.110, reward_bound=0.000, batch=11 
1452: loss=0.732, reward_mean=0.140, reward_bound=0.000, batch=25 
1453: loss=0.738, reward_mean=0.110, reward_bound=0.000, batch=36 
1454: loss=0.719, reward_mean=0.050, reward_bound=0.000, batch=41 
1455: loss=0.733, reward_mean=0.110, reward_bound=0.000, batch=52 
1456: loss=0.744, reward_mean=0.070, reward_bound=0.000, batch=59 
1457: loss=0.740, reward_mean=0.090, reward_bound=0.000, batch=68 
1458: loss=0.738, reward_mean=0.100, reward_bound=0.000, batch=78 
1459: loss=0.735, reward_mean=0.100, reward_bound=0.000, batch=88 
1460: loss=0.720, reward_mean=0.120, reward_bound=0.000, batch=100 
1461: loss=0.715, reward_mean=0.100, reward_bound=0.000, batch=110 
1462: loss=0.712, reward_mean=0.090, reward_bound=0.000, batch=119 
1463: loss=0.708, reward_mean=0.050, reward_bound=0.000, batch=124 
1464: loss=0.702, reward_mean=0.100, reward_bound=0.000, batch=134 
1465: loss=0.694, reward_mean=0.090, reward_bound=0.000, batch=143 
1466: loss=0.697, reward_mean=0.070, reward_bound=0.000, batch=150 
1467: loss=0.694, reward_mean=0.090, reward_bound=0.000, batch=159 
1468: loss=0.693, reward_mean=0.170, reward_bound=0.000, batch=176 
1469: loss=0.693, reward_mean=0.090, reward_bound=0.000, batch=185 
1470: loss=0.689, reward_mean=0.110, reward_bound=0.000, batch=196 
1471: loss=0.688, reward_mean=0.090, reward_bound=0.000, batch=205 
1472: loss=0.685, reward_mean=0.170, reward_bound=0.052, batch=212 
1473: loss=0.680, reward_mean=0.130, reward_bound=0.082, batch=218 
1474: loss=0.680, reward_mean=0.120, reward_bound=0.090, batch=222 
1475: loss=0.680, reward_mean=0.100, reward_bound=0.098, batch=223 
1476: loss=0.677, reward_mean=0.130, reward_bound=0.122, batch=219 
1477: loss=0.682, reward_mean=0.150, reward_bound=0.141, batch=223 
1478: loss=0.684, reward_mean=0.070, reward_bound=0.150, batch=210 
1479: loss=0.686, reward_mean=0.050, reward_bound=0.000, batch=215 
1480: loss=0.681, reward_mean=0.120, reward_bound=0.167, batch=208 
1481: loss=0.683, reward_mean=0.130, reward_bound=0.169, batch=215 
1482: loss=0.679, reward_mean=0.190, reward_bound=0.185, batch=214 
1483: loss=0.673, reward_mean=0.080, reward_bound=0.109, batch=219 
1484: loss=0.672, reward_mean=0.080, reward_bound=0.185, batch=222 
1485: loss=0.671, reward_mean=0.080, reward_bound=0.206, batch=228 
1486: loss=0.667, reward_mean=0.150, reward_bound=0.206, batch=217 
1487: loss=0.665, reward_mean=0.090, reward_bound=0.210, batch=222 
1488: loss=0.662, reward_mean=0.190, reward_bound=0.229, batch=213 
1489: loss=0.657, reward_mean=0.080, reward_bound=0.155, batch=219 
1490: loss=0.658, reward_mean=0.120, reward_bound=0.239, batch=223 
1491: loss=0.647, reward_mean=0.110, reward_bound=0.254, batch=204 
1492: loss=0.641, reward_mean=0.090, reward_bound=0.058, batch=213 
1493: loss=0.648, reward_mean=0.170, reward_bound=0.271, batch=219 
1494: loss=0.638, reward_mean=0.110, reward_bound=0.282, batch=201 
1495: loss=0.642, reward_mean=0.090, reward_bound=0.000, batch=210 
1496: loss=0.640, reward_mean=0.120, reward_bound=0.098, batch=216 
1497: loss=0.636, reward_mean=0.080, reward_bound=0.217, batch=221 
1498: loss=0.632, reward_mean=0.070, reward_bound=0.206, batch=224 
1499: loss=0.635, reward_mean=0.140, reward_bound=0.229, batch=226 
1500: loss=0.635, reward_mean=0.090, reward_bound=0.254, batch=225 
1501: loss=0.635, reward_mean=0.080, reward_bound=0.289, batch=227 
1502: loss=0.635, reward_mean=0.150, reward_bound=0.314, batch=184 
1503: loss=0.632, reward_mean=0.120, reward_bound=0.000, batch=196 
1504: loss=0.628, reward_mean=0.070, reward_bound=0.000, batch=203 
1505: loss=0.627, reward_mean=0.080, reward_bound=0.000, batch=211 
1506: loss=0.620, reward_mean=0.130, reward_bound=0.052, batch=216 
1507: loss=0.619, reward_mean=0.090, reward_bound=0.068, batch=221 
1508: loss=0.615, reward_mean=0.100, reward_bound=0.098, batch=223 
1509: loss=0.611, reward_mean=0.130, reward_bound=0.167, batch=225 
1510: loss=0.610, reward_mean=0.120, reward_bound=0.206, batch=226 
1511: loss=0.616, reward_mean=0.110, reward_bound=0.241, batch=228 
1512: loss=0.620, reward_mean=0.090, reward_bound=0.257, batch=229 
1513: loss=0.615, reward_mean=0.090, reward_bound=0.282, batch=222 
1514: loss=0.618, reward_mean=0.070, reward_bound=0.236, batch=225 
1515: loss=0.616, reward_mean=0.140, reward_bound=0.314, batch=217 
1516: loss=0.614, reward_mean=0.160, reward_bound=0.308, batch=222 
1517: loss=0.616, reward_mean=0.110, reward_bound=0.349, batch=173 
1518: loss=0.611, reward_mean=0.100, reward_bound=0.000, batch=183 
1519: loss=0.613, reward_mean=0.090, reward_bound=0.000, batch=192 
1520: loss=0.611, reward_mean=0.090, reward_bound=0.000, batch=201 
1521: loss=0.607, reward_mean=0.120, reward_bound=0.058, batch=210 
1522: loss=0.605, reward_mean=0.090, reward_bound=0.089, batch=216 
1523: loss=0.601, reward_mean=0.120, reward_bound=0.122, batch=220 
1524: loss=0.603, reward_mean=0.170, reward_bound=0.162, batch=224 
1525: loss=0.607, reward_mean=0.100, reward_bound=0.185, batch=225 
1526: loss=0.609, reward_mean=0.110, reward_bound=0.206, batch=226 
1527: loss=0.609, reward_mean=0.170, reward_bound=0.282, batch=222 
1528: loss=0.604, reward_mean=0.130, reward_bound=0.314, batch=220 
1529: loss=0.603, reward_mean=0.110, reward_bound=0.240, batch=224 
1530: loss=0.600, reward_mean=0.090, reward_bound=0.282, batch=226 
1531: loss=0.606, reward_mean=0.130, reward_bound=0.349, batch=217 
1532: loss=0.605, reward_mean=0.110, reward_bound=0.282, batch=221 
1533: loss=0.608, reward_mean=0.130, reward_bound=0.282, batch=224 
1534: loss=0.607, reward_mean=0.120, reward_bound=0.314, batch=226 
1535: loss=0.601, reward_mean=0.110, reward_bound=0.349, batch=224 
1536: loss=0.600, reward_mean=0.080, reward_bound=0.314, batch=226 
1537: loss=0.602, reward_mean=0.140, reward_bound=0.368, batch=228 
1538: loss=0.603, reward_mean=0.120, reward_bound=0.245, batch=229 
1539: loss=0.602, reward_mean=0.050, reward_bound=0.307, batch=230 
1540: loss=0.607, reward_mean=0.060, reward_bound=0.387, batch=161 
1541: loss=0.613, reward_mean=0.130, reward_bound=0.000, batch=174 
1542: loss=0.614, reward_mean=0.130, reward_bound=0.000, batch=187 
1543: loss=0.611, reward_mean=0.120, reward_bound=0.000, batch=199 
1544: loss=0.613, reward_mean=0.130, reward_bound=0.061, batch=209 
1545: loss=0.615, reward_mean=0.120, reward_bound=0.098, batch=215 
1546: loss=0.611, reward_mean=0.130, reward_bound=0.138, batch=220 
1547: loss=0.613, reward_mean=0.130, reward_bound=0.167, batch=221 
1548: loss=0.605, reward_mean=0.130, reward_bound=0.206, batch=220 
1549: loss=0.606, reward_mean=0.140, reward_bound=0.229, batch=222 
1550: loss=0.607, reward_mean=0.060, reward_bound=0.254, batch=212 
1551: loss=0.608, reward_mean=0.150, reward_bound=0.185, batch=218 
1552: loss=0.612, reward_mean=0.140, reward_bound=0.229, batch=221 
1553: loss=0.608, reward_mean=0.080, reward_bound=0.185, batch=224 
1554: loss=0.611, reward_mean=0.140, reward_bound=0.229, batch=226 
1555: loss=0.608, reward_mean=0.120, reward_bound=0.268, batch=228 
1556: loss=0.606, reward_mean=0.080, reward_bound=0.234, batch=229 
1557: loss=0.612, reward_mean=0.150, reward_bound=0.282, batch=214 
1558: loss=0.619, reward_mean=0.190, reward_bound=0.314, batch=217 
1559: loss=0.614, reward_mean=0.140, reward_bound=0.297, batch=222 
1560: loss=0.621, reward_mean=0.140, reward_bound=0.349, batch=208 
1561: loss=0.627, reward_mean=0.070, reward_bound=0.005, batch=215 
1562: loss=0.624, reward_mean=0.110, reward_bound=0.124, batch=220 
1563: loss=0.623, reward_mean=0.080, reward_bound=0.150, batch=223 
1564: loss=0.624, reward_mean=0.100, reward_bound=0.229, batch=225 
1565: loss=0.622, reward_mean=0.130, reward_bound=0.321, batch=227 
1566: loss=0.622, reward_mean=0.160, reward_bound=0.308, batch=229 
1567: loss=0.617, reward_mean=0.160, reward_bound=0.349, batch=224 
1568: loss=0.616, reward_mean=0.140, reward_bound=0.342, batch=227 
1569: loss=0.624, reward_mean=0.090, reward_bound=0.387, batch=206 
1570: loss=0.607, reward_mean=0.090, reward_bound=0.034, batch=214 
1571: loss=0.607, reward_mean=0.140, reward_bound=0.165, batch=220 
1572: loss=0.614, reward_mean=0.120, reward_bound=0.200, batch=224 
1573: loss=0.621, reward_mean=0.160, reward_bound=0.282, batch=224 
1574: loss=0.611, reward_mean=0.170, reward_bound=0.314, batch=224 
1575: loss=0.619, reward_mean=0.140, reward_bound=0.349, batch=225 
1576: loss=0.618, reward_mean=0.170, reward_bound=0.387, batch=219 
1577: loss=0.616, reward_mean=0.140, reward_bound=0.314, batch=222 
1578: loss=0.619, reward_mean=0.080, reward_bound=0.349, batch=224 
1579: loss=0.619, reward_mean=0.100, reward_bound=0.349, batch=226 
1580: loss=0.620, reward_mean=0.150, reward_bound=0.349, batch=227 
1581: loss=0.616, reward_mean=0.090, reward_bound=0.387, batch=225 
1582: loss=0.617, reward_mean=0.100, reward_bound=0.430, batch=131 
1583: loss=0.610, reward_mean=0.070, reward_bound=0.000, batch=138 
1584: loss=0.612, reward_mean=0.150, reward_bound=0.000, batch=153 
1585: loss=0.614, reward_mean=0.180, reward_bound=0.000, batch=171 
1586: loss=0.618, reward_mean=0.120, reward_bound=0.000, batch=183 
1587: loss=0.617, reward_mean=0.090, reward_bound=0.000, batch=192 
1588: loss=0.614, reward_mean=0.110, reward_bound=0.000, batch=203 
1589: loss=0.618, reward_mean=0.120, reward_bound=0.041, batch=212 
1590: loss=0.613, reward_mean=0.140, reward_bound=0.072, batch=217 
1591: loss=0.610, reward_mean=0.070, reward_bound=0.073, batch=222 
1592: loss=0.612, reward_mean=0.110, reward_bound=0.109, batch=224 
1593: loss=0.612, reward_mean=0.100, reward_bound=0.149, batch=227 
1594: loss=0.610, reward_mean=0.150, reward_bound=0.167, batch=227 
1595: loss=0.610, reward_mean=0.070, reward_bound=0.185, batch=225 
1596: loss=0.617, reward_mean=0.130, reward_bound=0.206, batch=222 
1597: loss=0.609, reward_mean=0.110, reward_bound=0.229, batch=219 
1598: loss=0.608, reward_mean=0.190, reward_bound=0.254, batch=212 
1599: loss=0.606, reward_mean=0.130, reward_bound=0.201, batch=218 
1600: loss=0.617, reward_mean=0.120, reward_bound=0.282, batch=215 
1601: loss=0.616, reward_mean=0.170, reward_bound=0.314, batch=201 
1602: loss=0.612, reward_mean=0.090, reward_bound=0.000, batch=210 
1603: loss=0.614, reward_mean=0.120, reward_bound=0.109, batch=217 
1604: loss=0.605, reward_mean=0.200, reward_bound=0.224, batch=222 
1605: loss=0.606, reward_mean=0.130, reward_bound=0.254, batch=223 
1606: loss=0.605, reward_mean=0.080, reward_bound=0.282, batch=225 
1607: loss=0.605, reward_mean=0.060, reward_bound=0.289, batch=227 
1608: loss=0.603, reward_mean=0.060, reward_bound=0.272, batch=229 
1609: loss=0.607, reward_mean=0.130, reward_bound=0.314, batch=229 
1610: loss=0.617, reward_mean=0.070, reward_bound=0.349, batch=203 
1611: loss=0.612, reward_mean=0.080, reward_bound=0.000, batch=211 
1612: loss=0.615, reward_mean=0.140, reward_bound=0.135, batch=217 
1613: loss=0.617, reward_mean=0.070, reward_bound=0.163, batch=222 
1614: loss=0.601, reward_mean=0.150, reward_bound=0.236, batch=225 
1615: loss=0.606, reward_mean=0.110, reward_bound=0.282, batch=223 
1616: loss=0.605, reward_mean=0.140, reward_bound=0.314, batch=224 
1617: loss=0.606, reward_mean=0.110, reward_bound=0.254, batch=226 
1618: loss=0.610, reward_mean=0.090, reward_bound=0.349, batch=222 
1619: loss=0.609, reward_mean=0.090, reward_bound=0.229, batch=224 
1620: loss=0.608, reward_mean=0.150, reward_bound=0.273, batch=227 
1621: loss=0.603, reward_mean=0.120, reward_bound=0.282, batch=227 
1622: loss=0.603, reward_mean=0.090, reward_bound=0.387, batch=200 
1623: loss=0.605, reward_mean=0.080, reward_bound=0.000, batch=208 
1624: loss=0.602, reward_mean=0.100, reward_bound=0.069, batch=215 
1625: loss=0.606, reward_mean=0.060, reward_bound=0.030, batch=220 
1626: loss=0.607, reward_mean=0.060, reward_bound=0.103, batch=224 
1627: loss=0.605, reward_mean=0.070, reward_bound=0.134, batch=227 
1628: loss=0.611, reward_mean=0.160, reward_bound=0.206, batch=228 
1629: loss=0.616, reward_mean=0.120, reward_bound=0.282, batch=222 
1630: loss=0.616, reward_mean=0.100, reward_bound=0.263, batch=225 
1631: loss=0.612, reward_mean=0.070, reward_bound=0.282, batch=226 
1632: loss=0.615, reward_mean=0.100, reward_bound=0.314, batch=222 
1633: loss=0.615, reward_mean=0.100, reward_bound=0.272, batch=225 
1634: loss=0.612, reward_mean=0.090, reward_bound=0.321, batch=227 
1635: loss=0.613, reward_mean=0.070, reward_bound=0.308, batch=229 
1636: loss=0.606, reward_mean=0.140, reward_bound=0.349, batch=226 
1637: loss=0.605, reward_mean=0.090, reward_bound=0.314, batch=227 
1638: loss=0.604, reward_mean=0.150, reward_bound=0.349, batch=228 
1639: loss=0.601, reward_mean=0.110, reward_bound=0.387, batch=222 
1640: loss=0.601, reward_mean=0.060, reward_bound=0.167, batch=225 
1641: loss=0.603, reward_mean=0.100, reward_bound=0.289, batch=227 
1642: loss=0.600, reward_mean=0.120, reward_bound=0.349, batch=228 
1643: loss=0.599, reward_mean=0.200, reward_bound=0.387, batch=226 
1644: loss=0.600, reward_mean=0.150, reward_bound=0.390, batch=228 
1645: loss=0.612, reward_mean=0.130, reward_bound=0.430, batch=186 
1646: loss=0.603, reward_mean=0.100, reward_bound=0.000, batch=196 
1647: loss=0.594, reward_mean=0.140, reward_bound=0.122, batch=207 
1648: loss=0.596, reward_mean=0.080, reward_bound=0.010, batch=215 
1649: loss=0.592, reward_mean=0.140, reward_bound=0.138, batch=220 
1650: loss=0.592, reward_mean=0.120, reward_bound=0.167, batch=223 
1651: loss=0.596, reward_mean=0.100, reward_bound=0.185, batch=222 
1652: loss=0.597, reward_mean=0.130, reward_bound=0.206, batch=229 
1653: loss=0.592, reward_mean=0.120, reward_bound=0.206, batch=227 
1654: loss=0.594, reward_mean=0.180, reward_bound=0.254, batch=225 
1655: loss=0.604, reward_mean=0.120, reward_bound=0.282, batch=225 
1656: loss=0.601, reward_mean=0.140, reward_bound=0.314, batch=220 
1657: loss=0.606, reward_mean=0.100, reward_bound=0.282, batch=223 
1658: loss=0.604, reward_mean=0.100, reward_bound=0.178, batch=226 
1659: loss=0.597, reward_mean=0.150, reward_bound=0.349, batch=215 
1660: loss=0.593, reward_mean=0.130, reward_bound=0.254, batch=219 
1661: loss=0.589, reward_mean=0.130, reward_bound=0.314, batch=222 
1662: loss=0.591, reward_mean=0.120, reward_bound=0.349, batch=224 
1663: loss=0.591, reward_mean=0.070, reward_bound=0.282, batch=226 
1664: loss=0.592, reward_mean=0.090, reward_bound=0.331, batch=228 
1665: loss=0.591, reward_mean=0.070, reward_bound=0.317, batch=229 
1666: loss=0.591, reward_mean=0.080, reward_bound=0.349, batch=229 
1667: loss=0.588, reward_mean=0.100, reward_bound=0.328, batch=230 
1668: loss=0.595, reward_mean=0.090, reward_bound=0.387, batch=219 
1669: loss=0.598, reward_mean=0.100, reward_bound=0.309, batch=223 
1670: loss=0.597, reward_mean=0.100, reward_bound=0.261, batch=226 
1671: loss=0.594, reward_mean=0.090, reward_bound=0.387, batch=225 
1672: loss=0.594, reward_mean=0.070, reward_bound=0.396, batch=227 
1673: loss=0.603, reward_mean=0.160, reward_bound=0.366, batch=229 
1674: loss=0.602, reward_mean=0.100, reward_bound=0.430, batch=213 
1675: loss=0.597, reward_mean=0.080, reward_bound=0.144, batch=219 
1676: loss=0.593, reward_mean=0.120, reward_bound=0.185, batch=221 
1677: loss=0.596, reward_mean=0.140, reward_bound=0.282, batch=223 
1678: loss=0.596, reward_mean=0.130, reward_bound=0.349, batch=225 
1679: loss=0.601, reward_mean=0.100, reward_bound=0.356, batch=227 
1680: loss=0.599, reward_mean=0.140, reward_bound=0.380, batch=229 
1681: loss=0.601, reward_mean=0.120, reward_bound=0.387, batch=224 
1682: loss=0.602, reward_mean=0.070, reward_bound=0.185, batch=226 
1683: loss=0.595, reward_mean=0.110, reward_bound=0.229, batch=227 
1684: loss=0.601, reward_mean=0.130, reward_bound=0.349, batch=228 
1685: loss=0.601, reward_mean=0.140, reward_bound=0.392, batch=229 
1686: loss=0.600, reward_mean=0.150, reward_bound=0.360, batch=230 
1687: loss=0.594, reward_mean=0.130, reward_bound=0.430, batch=224 
1688: loss=0.591, reward_mean=0.080, reward_bound=0.252, batch=227 
1689: loss=0.590, reward_mean=0.090, reward_bound=0.277, batch=229 
1690: loss=0.589, reward_mean=0.140, reward_bound=0.405, batch=230 
1691: loss=0.588, reward_mean=0.130, reward_bound=0.418, batch=231 
1692: loss=0.593, reward_mean=0.110, reward_bound=0.430, batch=229 
1693: loss=0.594, reward_mean=0.130, reward_bound=0.450, batch=230 
1694: loss=0.584, reward_mean=0.130, reward_bound=0.478, batch=101 
1695: loss=0.571, reward_mean=0.110, reward_bound=0.000, batch=112 
1696: loss=0.582, reward_mean=0.160, reward_bound=0.000, batch=128 
1697: loss=0.576, reward_mean=0.070, reward_bound=0.000, batch=135 
1698: loss=0.584, reward_mean=0.130, reward_bound=0.000, batch=148 
1699: loss=0.574, reward_mean=0.110, reward_bound=0.000, batch=159 
1700: loss=0.567, reward_mean=0.140, reward_bound=0.000, batch=173 
1701: loss=0.574, reward_mean=0.100, reward_bound=0.000, batch=183 
1702: loss=0.570, reward_mean=0.080, reward_bound=0.000, batch=191 
1703: loss=0.568, reward_mean=0.090, reward_bound=0.000, batch=200 
1704: loss=0.562, reward_mean=0.110, reward_bound=0.016, batch=210 
1705: loss=0.554, reward_mean=0.130, reward_bound=0.033, batch=217 
1706: loss=0.537, reward_mean=0.110, reward_bound=0.056, batch=222 
1707: loss=0.542, reward_mean=0.180, reward_bound=0.109, batch=224 
1708: loss=0.547, reward_mean=0.120, reward_bound=0.149, batch=227 
1709: loss=0.543, reward_mean=0.200, reward_bound=0.167, batch=227 
1710: loss=0.541, reward_mean=0.160, reward_bound=0.185, batch=226 
1711: loss=0.558, reward_mean=0.200, reward_bound=0.229, batch=219 
1712: loss=0.555, reward_mean=0.150, reward_bound=0.239, batch=223 
1713: loss=0.557, reward_mean=0.100, reward_bound=0.204, batch=226 
1714: loss=0.569, reward_mean=0.150, reward_bound=0.254, batch=211 
1715: loss=0.566, reward_mean=0.100, reward_bound=0.229, batch=217 
1716: loss=0.563, reward_mean=0.100, reward_bound=0.277, batch=222 
1717: loss=0.563, reward_mean=0.090, reward_bound=0.229, batch=223 
1718: loss=0.558, reward_mean=0.160, reward_bound=0.282, batch=202 
1719: loss=0.556, reward_mean=0.080, reward_bound=0.000, batch=210 
1720: loss=0.555, reward_mean=0.120, reward_bound=0.157, batch=217 
1721: loss=0.558, reward_mean=0.060, reward_bound=0.140, batch=222 
1722: loss=0.557, reward_mean=0.120, reward_bound=0.172, batch=225 
1723: loss=0.557, reward_mean=0.140, reward_bound=0.254, batch=226 
1724: loss=0.556, reward_mean=0.150, reward_bound=0.298, batch=228 
1725: loss=0.556, reward_mean=0.140, reward_bound=0.314, batch=211 
1726: loss=0.556, reward_mean=0.100, reward_bound=0.254, batch=217 
1727: loss=0.552, reward_mean=0.150, reward_bound=0.254, batch=220 
1728: loss=0.557, reward_mean=0.120, reward_bound=0.274, batch=224 
1729: loss=0.558, reward_mean=0.140, reward_bound=0.345, batch=227 
1730: loss=0.570, reward_mean=0.110, reward_bound=0.349, batch=198 
1731: loss=0.568, reward_mean=0.060, reward_bound=0.000, batch=204 
1732: loss=0.567, reward_mean=0.130, reward_bound=0.135, batch=212 
1733: loss=0.573, reward_mean=0.150, reward_bound=0.229, batch=216 
1734: loss=0.569, reward_mean=0.060, reward_bound=0.217, batch=221 
1735: loss=0.576, reward_mean=0.140, reward_bound=0.254, batch=224 
1736: loss=0.576, reward_mean=0.080, reward_bound=0.277, batch=227 
1737: loss=0.578, reward_mean=0.080, reward_bound=0.254, batch=228 
1738: loss=0.576, reward_mean=0.130, reward_bound=0.314, batch=225 
1739: loss=0.580, reward_mean=0.170, reward_bound=0.349, batch=223 
1740: loss=0.585, reward_mean=0.100, reward_bound=0.334, batch=226 
1741: loss=0.587, reward_mean=0.100, reward_bound=0.368, batch=228 
1742: loss=0.586, reward_mean=0.140, reward_bound=0.387, batch=189 
1743: loss=0.578, reward_mean=0.080, reward_bound=0.000, batch=197 
1744: loss=0.581, reward_mean=0.150, reward_bound=0.062, batch=208 
1745: loss=0.582, reward_mean=0.150, reward_bound=0.167, batch=214 
1746: loss=0.582, reward_mean=0.080, reward_bound=0.150, batch=219 
1747: loss=0.578, reward_mean=0.150, reward_bound=0.206, batch=217 
1748: loss=0.576, reward_mean=0.150, reward_bound=0.229, batch=221 
1749: loss=0.582, reward_mean=0.090, reward_bound=0.254, batch=219 
1750: loss=0.579, reward_mean=0.150, reward_bound=0.265, batch=223 
1751: loss=0.575, reward_mean=0.140, reward_bound=0.271, batch=226 
1752: loss=0.578, reward_mean=0.170, reward_bound=0.282, batch=224 
1753: loss=0.572, reward_mean=0.180, reward_bound=0.314, batch=222 
1754: loss=0.571, reward_mean=0.100, reward_bound=0.349, batch=219 
1755: loss=0.567, reward_mean=0.060, reward_bound=0.147, batch=223 
1756: loss=0.566, reward_mean=0.200, reward_bound=0.282, batch=224 
1757: loss=0.565, reward_mean=0.150, reward_bound=0.349, batch=225 
1758: loss=0.569, reward_mean=0.090, reward_bound=0.260, batch=227 
1759: loss=0.563, reward_mean=0.120, reward_bound=0.380, batch=229 
1760: loss=0.564, reward_mean=0.120, reward_bound=0.343, batch=230 
1761: loss=0.573, reward_mean=0.190, reward_bound=0.387, batch=223 
1762: loss=0.571, reward_mean=0.150, reward_bound=0.372, batch=226 
1763: loss=0.569, reward_mean=0.150, reward_bound=0.349, batch=227 
1764: loss=0.564, reward_mean=0.120, reward_bound=0.430, batch=172 
1765: loss=0.571, reward_mean=0.100, reward_bound=0.000, batch=182 
1766: loss=0.581, reward_mean=0.120, reward_bound=0.000, batch=194 
1767: loss=0.578, reward_mean=0.090, reward_bound=0.000, batch=203 
1768: loss=0.582, reward_mean=0.100, reward_bound=0.021, batch=212 
1769: loss=0.583, reward_mean=0.140, reward_bound=0.092, batch=218 
1770: loss=0.574, reward_mean=0.210, reward_bound=0.152, batch=222 
1771: loss=0.565, reward_mean=0.100, reward_bound=0.167, batch=224 
1772: loss=0.568, reward_mean=0.180, reward_bound=0.229, batch=224 
1773: loss=0.578, reward_mean=0.100, reward_bound=0.254, batch=222 
1774: loss=0.568, reward_mean=0.090, reward_bound=0.282, batch=214 
1775: loss=0.570, reward_mean=0.080, reward_bound=0.226, batch=220 
1776: loss=0.567, reward_mean=0.130, reward_bound=0.314, batch=214 
1777: loss=0.564, reward_mean=0.120, reward_bound=0.226, batch=220 
1778: loss=0.572, reward_mean=0.160, reward_bound=0.349, batch=210 
1779: loss=0.569, reward_mean=0.090, reward_bound=0.147, batch=217 
1780: loss=0.566, reward_mean=0.060, reward_bound=0.087, batch=222 
1781: loss=0.564, reward_mean=0.090, reward_bound=0.161, batch=225 
1782: loss=0.568, reward_mean=0.150, reward_bound=0.254, batch=226 
1783: loss=0.564, reward_mean=0.150, reward_bound=0.298, batch=228 
1784: loss=0.566, reward_mean=0.090, reward_bound=0.314, batch=226 
1785: loss=0.565, reward_mean=0.140, reward_bound=0.368, batch=228 
1786: loss=0.566, reward_mean=0.100, reward_bound=0.353, batch=229 
1787: loss=0.561, reward_mean=0.140, reward_bound=0.387, batch=217 
1788: loss=0.562, reward_mean=0.190, reward_bound=0.342, batch=222 
1789: loss=0.561, reward_mean=0.110, reward_bound=0.324, batch=225 
1790: loss=0.557, reward_mean=0.150, reward_bound=0.349, batch=225 
1791: loss=0.560, reward_mean=0.140, reward_bound=0.387, batch=223 
1792: loss=0.559, reward_mean=0.110, reward_bound=0.387, batch=225 
1793: loss=0.559, reward_mean=0.150, reward_bound=0.387, batch=225 
1794: loss=0.561, reward_mean=0.110, reward_bound=0.430, batch=208 
1795: loss=0.562, reward_mean=0.130, reward_bound=0.187, batch=215 
1796: loss=0.558, reward_mean=0.060, reward_bound=0.075, batch=220 
1797: loss=0.554, reward_mean=0.080, reward_bound=0.122, batch=223 
1798: loss=0.556, reward_mean=0.170, reward_bound=0.301, batch=226 
1799: loss=0.565, reward_mean=0.100, reward_bound=0.314, batch=225 
1800: loss=0.562, reward_mean=0.090, reward_bound=0.203, batch=227 
1801: loss=0.553, reward_mean=0.170, reward_bound=0.349, batch=227 
1802: loss=0.554, reward_mean=0.070, reward_bound=0.373, batch=229 
1803: loss=0.553, reward_mean=0.080, reward_bound=0.307, batch=230 
1804: loss=0.550, reward_mean=0.130, reward_bound=0.387, batch=229 
1805: loss=0.549, reward_mean=0.130, reward_bound=0.430, batch=220 
1806: loss=0.546, reward_mean=0.090, reward_bound=0.376, batch=224 
1807: loss=0.548, reward_mean=0.160, reward_bound=0.345, batch=227 
1808: loss=0.543, reward_mean=0.130, reward_bound=0.349, batch=228 
1809: loss=0.543, reward_mean=0.110, reward_bound=0.293, batch=229 
1810: loss=0.542, reward_mean=0.160, reward_bound=0.387, batch=228 
1811: loss=0.541, reward_mean=0.060, reward_bound=0.392, batch=229 
1812: loss=0.541, reward_mean=0.130, reward_bound=0.405, batch=230 
1813: loss=0.540, reward_mean=0.080, reward_bound=0.356, batch=231 
1814: loss=0.540, reward_mean=0.140, reward_bound=0.387, batch=231 
1815: loss=0.538, reward_mean=0.150, reward_bound=0.430, batch=229 
1816: loss=0.536, reward_mean=0.110, reward_bound=0.364, batch=230 
1817: loss=0.534, reward_mean=0.100, reward_bound=0.376, batch=231 
1818: loss=0.537, reward_mean=0.130, reward_bound=0.387, batch=230 
1819: loss=0.537, reward_mean=0.090, reward_bound=0.418, batch=231 
1820: loss=0.537, reward_mean=0.170, reward_bound=0.387, batch=231 
1821: loss=0.546, reward_mean=0.170, reward_bound=0.478, batch=161 
1822: loss=0.525, reward_mean=0.120, reward_bound=0.000, batch=173 
1823: loss=0.511, reward_mean=0.150, reward_bound=0.000, batch=188 
1824: loss=0.514, reward_mean=0.160, reward_bound=0.020, batch=201 
1825: loss=0.518, reward_mean=0.150, reward_bound=0.065, batch=210 
1826: loss=0.533, reward_mean=0.170, reward_bound=0.118, batch=217 
1827: loss=0.530, reward_mean=0.190, reward_bound=0.147, batch=222 
1828: loss=0.523, reward_mean=0.100, reward_bound=0.185, batch=221 
1829: loss=0.519, reward_mean=0.150, reward_bound=0.206, batch=223 
1830: loss=0.524, reward_mean=0.170, reward_bound=0.254, batch=217 
1831: loss=0.529, reward_mean=0.130, reward_bound=0.282, batch=215 
1832: loss=0.528, reward_mean=0.150, reward_bound=0.289, batch=220 
1833: loss=0.525, reward_mean=0.090, reward_bound=0.282, batch=223 
1834: loss=0.542, reward_mean=0.150, reward_bound=0.314, batch=213 
1835: loss=0.543, reward_mean=0.100, reward_bound=0.244, batch=219 
1836: loss=0.543, reward_mean=0.170, reward_bound=0.278, batch=223 
1837: loss=0.542, reward_mean=0.080, reward_bound=0.301, batch=226 
1838: loss=0.539, reward_mean=0.120, reward_bound=0.314, batch=226 
1839: loss=0.533, reward_mean=0.100, reward_bound=0.349, batch=207 
1840: loss=0.538, reward_mean=0.110, reward_bound=0.229, batch=214 
1841: loss=0.541, reward_mean=0.140, reward_bound=0.133, batch=220 
1842: loss=0.542, reward_mean=0.110, reward_bound=0.200, batch=224 
1843: loss=0.540, reward_mean=0.080, reward_bound=0.249, batch=227 
1844: loss=0.542, reward_mean=0.110, reward_bound=0.254, batch=226 
1845: loss=0.532, reward_mean=0.220, reward_bound=0.314, batch=225 
1846: loss=0.529, reward_mean=0.140, reward_bound=0.356, batch=227 
1847: loss=0.522, reward_mean=0.180, reward_bound=0.387, batch=208 
1848: loss=0.522, reward_mean=0.170, reward_bound=0.208, batch=215 
1849: loss=0.520, reward_mean=0.130, reward_bound=0.260, batch=220 
1850: loss=0.530, reward_mean=0.120, reward_bound=0.282, batch=222 
1851: loss=0.534, reward_mean=0.150, reward_bound=0.292, batch=225 
1852: loss=0.536, reward_mean=0.100, reward_bound=0.314, batch=224 
1853: loss=0.535, reward_mean=0.100, reward_bound=0.337, batch=227 
1854: loss=0.534, reward_mean=0.110, reward_bound=0.342, batch=229 
1855: loss=0.531, reward_mean=0.100, reward_bound=0.349, batch=223 
1856: loss=0.532, reward_mean=0.120, reward_bound=0.372, batch=226 
1857: loss=0.531, reward_mean=0.100, reward_bound=0.387, batch=222 
1858: loss=0.529, reward_mean=0.120, reward_bound=0.387, batch=224 
1859: loss=0.546, reward_mean=0.150, reward_bound=0.430, batch=188 
1860: loss=0.539, reward_mean=0.070, reward_bound=0.000, batch=195 
1861: loss=0.538, reward_mean=0.110, reward_bound=0.004, batch=206 
1862: loss=0.549, reward_mean=0.100, reward_bound=0.046, batch=214 
1863: loss=0.549, reward_mean=0.060, reward_bound=0.052, batch=220 
1864: loss=0.552, reward_mean=0.130, reward_bound=0.157, batch=224 
1865: loss=0.554, reward_mean=0.100, reward_bound=0.183, batch=227 
1866: loss=0.543, reward_mean=0.100, reward_bound=0.229, batch=223 
1867: loss=0.545, reward_mean=0.080, reward_bound=0.227, batch=226 
1868: loss=0.544, reward_mean=0.110, reward_bound=0.254, batch=222 
1869: loss=0.543, reward_mean=0.120, reward_bound=0.245, batch=225 
1870: loss=0.541, reward_mean=0.170, reward_bound=0.282, batch=226 
1871: loss=0.539, reward_mean=0.160, reward_bound=0.298, batch=228 
1872: loss=0.542, reward_mean=0.030, reward_bound=0.314, batch=228 
1873: loss=0.542, reward_mean=0.090, reward_bound=0.289, batch=229 
1874: loss=0.548, reward_mean=0.110, reward_bound=0.349, batch=219 
1875: loss=0.547, reward_mean=0.140, reward_bound=0.278, batch=223 
1876: loss=0.546, reward_mean=0.100, reward_bound=0.314, batch=225 
1877: loss=0.546, reward_mean=0.140, reward_bound=0.321, batch=227 
1878: loss=0.545, reward_mean=0.160, reward_bound=0.380, batch=229 
1879: loss=0.555, reward_mean=0.120, reward_bound=0.387, batch=219 
1880: loss=0.558, reward_mean=0.140, reward_bound=0.349, batch=222 
1881: loss=0.555, reward_mean=0.160, reward_bound=0.387, batch=222 
1882: loss=0.554, reward_mean=0.160, reward_bound=0.360, batch=225 
1883: loss=0.554, reward_mean=0.150, reward_bound=0.282, batch=225 
1884: loss=0.553, reward_mean=0.060, reward_bound=0.356, batch=227 
1885: loss=0.551, reward_mean=0.110, reward_bound=0.366, batch=229 
1886: loss=0.551, reward_mean=0.120, reward_bound=0.387, batch=227 
1887: loss=0.542, reward_mean=0.110, reward_bound=0.430, batch=207 
1888: loss=0.545, reward_mean=0.100, reward_bound=0.115, batch=215 
1889: loss=0.544, reward_mean=0.110, reward_bound=0.206, batch=219 
1890: loss=0.548, reward_mean=0.130, reward_bound=0.229, batch=222 
1891: loss=0.545, reward_mean=0.060, reward_bound=0.282, batch=221 
1892: loss=0.546, reward_mean=0.100, reward_bound=0.314, batch=221 
1893: loss=0.547, reward_mean=0.130, reward_bound=0.349, batch=222 
1894: loss=0.545, reward_mean=0.090, reward_bound=0.360, batch=225 
1895: loss=0.541, reward_mean=0.130, reward_bound=0.387, batch=221 
1896: loss=0.542, reward_mean=0.150, reward_bound=0.430, batch=218 
1897: loss=0.538, reward_mean=0.140, reward_bound=0.286, batch=222 
1898: loss=0.537, reward_mean=0.120, reward_bound=0.292, batch=225 
1899: loss=0.543, reward_mean=0.180, reward_bound=0.314, batch=226 
1900: loss=0.548, reward_mean=0.140, reward_bound=0.349, batch=227 
1901: loss=0.550, reward_mean=0.160, reward_bound=0.380, batch=229 
1902: loss=0.549, reward_mean=0.120, reward_bound=0.387, batch=226 
1903: loss=0.549, reward_mean=0.040, reward_bound=0.271, batch=228 
1904: loss=0.551, reward_mean=0.090, reward_bound=0.392, batch=229 
1905: loss=0.549, reward_mean=0.110, reward_bound=0.430, batch=222 
1906: loss=0.548, reward_mean=0.160, reward_bound=0.445, batch=225 
1907: loss=0.548, reward_mean=0.080, reward_bound=0.396, batch=227 
1908: loss=0.551, reward_mean=0.120, reward_bound=0.422, batch=229 
1909: loss=0.549, reward_mean=0.140, reward_bound=0.430, batch=227 
1910: loss=0.547, reward_mean=0.100, reward_bound=0.349, batch=228 
1911: loss=0.548, reward_mean=0.140, reward_bound=0.435, batch=229 
1912: loss=0.548, reward_mean=0.070, reward_bound=0.349, batch=229 
1913: loss=0.548, reward_mean=0.190, reward_bound=0.430, batch=229 
1914: loss=0.548, reward_mean=0.150, reward_bound=0.430, batch=229 
1915: loss=0.547, reward_mean=0.120, reward_bound=0.405, batch=230 
1916: loss=0.544, reward_mean=0.100, reward_bound=0.304, batch=231 
1917: loss=0.548, reward_mean=0.120, reward_bound=0.430, batch=230 
1918: loss=0.547, reward_mean=0.160, reward_bound=0.464, batch=231 
1919: loss=0.555, reward_mean=0.080, reward_bound=0.478, batch=187 
1920: loss=0.546, reward_mean=0.080, reward_bound=0.000, batch=195 
1921: loss=0.539, reward_mean=0.130, reward_bound=0.027, batch=206 
1922: loss=0.541, reward_mean=0.100, reward_bound=0.061, batch=214 
1923: loss=0.557, reward_mean=0.180, reward_bound=0.167, batch=219 
1924: loss=0.553, reward_mean=0.150, reward_bound=0.229, batch=218 
1925: loss=0.553, reward_mean=0.080, reward_bound=0.206, batch=221 
1926: loss=0.561, reward_mean=0.100, reward_bound=0.254, batch=224 
1927: loss=0.552, reward_mean=0.120, reward_bound=0.282, batch=225 
1928: loss=0.556, reward_mean=0.180, reward_bound=0.314, batch=218 
1929: loss=0.553, reward_mean=0.160, reward_bound=0.254, batch=220 
1930: loss=0.557, reward_mean=0.080, reward_bound=0.282, batch=223 
1931: loss=0.555, reward_mean=0.080, reward_bound=0.244, batch=226 
1932: loss=0.545, reward_mean=0.120, reward_bound=0.349, batch=218 
1933: loss=0.539, reward_mean=0.100, reward_bound=0.132, batch=222 
1934: loss=0.546, reward_mean=0.160, reward_bound=0.282, batch=224 
1935: loss=0.543, reward_mean=0.150, reward_bound=0.349, batch=226 
1936: loss=0.546, reward_mean=0.140, reward_bound=0.387, batch=214 
1937: loss=0.545, reward_mean=0.150, reward_bound=0.314, batch=218 
1938: loss=0.543, reward_mean=0.160, reward_bound=0.353, batch=222 
1939: loss=0.542, reward_mean=0.140, reward_bound=0.387, batch=223 
1940: loss=0.539, reward_mean=0.150, reward_bound=0.372, batch=226 
1941: loss=0.539, reward_mean=0.110, reward_bound=0.409, batch=228 
1942: loss=0.540, reward_mean=0.110, reward_bound=0.430, batch=218 
1943: loss=0.540, reward_mean=0.130, reward_bound=0.317, batch=222 
1944: loss=0.544, reward_mean=0.130, reward_bound=0.387, batch=224 
1945: loss=0.544, reward_mean=0.120, reward_bound=0.229, batch=226 
1946: loss=0.541, reward_mean=0.080, reward_bound=0.314, batch=227 
1947: loss=0.539, reward_mean=0.140, reward_bound=0.414, batch=229 
1948: loss=0.538, reward_mean=0.170, reward_bound=0.364, batch=230 
1949: loss=0.541, reward_mean=0.110, reward_bound=0.387, batch=230 
1950: loss=0.540, reward_mean=0.110, reward_bound=0.430, batch=226 
1951: loss=0.541, reward_mean=0.150, reward_bound=0.387, batch=227 
1952: loss=0.540, reward_mean=0.090, reward_bound=0.254, batch=228 
1953: loss=0.539, reward_mean=0.050, reward_bound=0.392, batch=229 
1954: loss=0.539, reward_mean=0.110, reward_bound=0.405, batch=230 
1955: loss=0.539, reward_mean=0.200, reward_bound=0.387, batch=230 
1956: loss=0.538, reward_mean=0.120, reward_bound=0.395, batch=231 
1957: loss=0.541, reward_mean=0.090, reward_bound=0.430, batch=229 
1958: loss=0.542, reward_mean=0.120, reward_bound=0.478, batch=231 
1959: loss=0.543, reward_mean=0.100, reward_bound=0.478, batch=207 
1960: loss=0.542, reward_mean=0.110, reward_bound=0.140, batch=215 
1961: loss=0.543, reward_mean=0.130, reward_bound=0.229, batch=218 
1962: loss=0.543, reward_mean=0.140, reward_bound=0.254, batch=221 
1963: loss=0.544, reward_mean=0.150, reward_bound=0.349, batch=220 
1964: loss=0.546, reward_mean=0.130, reward_bound=0.304, batch=224 
1965: loss=0.545, reward_mean=0.160, reward_bound=0.349, batch=225 
1966: loss=0.541, reward_mean=0.190, reward_bound=0.356, batch=227 
1967: loss=0.541, reward_mean=0.150, reward_bound=0.387, batch=221 
1968: loss=0.537, reward_mean=0.100, reward_bound=0.254, batch=224 
1969: loss=0.539, reward_mean=0.110, reward_bound=0.311, batch=227 
1970: loss=0.543, reward_mean=0.150, reward_bound=0.342, batch=229 
1971: loss=0.545, reward_mean=0.110, reward_bound=0.364, batch=230 
1972: loss=0.544, reward_mean=0.160, reward_bound=0.430, batch=218 
1973: loss=0.543, reward_mean=0.140, reward_bound=0.387, batch=220 
1974: loss=0.540, reward_mean=0.100, reward_bound=0.254, batch=223 
1975: loss=0.540, reward_mean=0.070, reward_bound=0.244, batch=226 
1976: loss=0.539, reward_mean=0.090, reward_bound=0.298, batch=228 
1977: loss=0.540, reward_mean=0.110, reward_bound=0.314, batch=227 
1978: loss=0.541, reward_mean=0.150, reward_bound=0.387, batch=227 
1979: loss=0.543, reward_mean=0.130, reward_bound=0.430, batch=223 
1980: loss=0.544, reward_mean=0.150, reward_bound=0.290, batch=226 
1981: loss=0.545, reward_mean=0.110, reward_bound=0.331, batch=228 
1982: loss=0.546, reward_mean=0.170, reward_bound=0.387, batch=226 
1983: loss=0.548, reward_mean=0.080, reward_bound=0.351, batch=228 
1984: loss=0.549, reward_mean=0.160, reward_bound=0.392, batch=229 
1985: loss=0.548, reward_mean=0.100, reward_bound=0.381, batch=230 
1986: loss=0.552, reward_mean=0.090, reward_bound=0.338, batch=231 
1987: loss=0.548, reward_mean=0.160, reward_bound=0.430, batch=228 
1988: loss=0.548, reward_mean=0.140, reward_bound=0.435, batch=229 
1989: loss=0.546, reward_mean=0.170, reward_bound=0.405, batch=230 
1990: loss=0.546, reward_mean=0.120, reward_bound=0.387, batch=230 
1991: loss=0.550, reward_mean=0.110, reward_bound=0.464, batch=231 
1992: loss=0.550, reward_mean=0.110, reward_bound=0.430, batch=231 
1993: loss=0.540, reward_mean=0.110, reward_bound=0.478, batch=216 
1994: loss=0.541, reward_mean=0.160, reward_bound=0.331, batch=221 
1995: loss=0.543, reward_mean=0.110, reward_bound=0.282, batch=224 
1996: loss=0.543, reward_mean=0.100, reward_bound=0.269, batch=227 
1997: loss=0.541, reward_mean=0.060, reward_bound=0.282, batch=227 
1998: loss=0.540, reward_mean=0.140, reward_bound=0.349, batch=227 
1999: loss=0.535, reward_mean=0.170, reward_bound=0.387, batch=224 
2000: loss=0.534, reward_mean=0.090, reward_bound=0.387, batch=225 
2001: loss=0.534, reward_mean=0.090, reward_bound=0.321, batch=227 
2002: loss=0.534, reward_mean=0.190, reward_bound=0.414, batch=229 
2003: loss=0.534, reward_mean=0.120, reward_bound=0.430, batch=227 
2004: loss=0.532, reward_mean=0.120, reward_bound=0.422, batch=229 
2005: loss=0.537, reward_mean=0.140, reward_bound=0.450, batch=230 
2006: loss=0.544, reward_mean=0.150, reward_bound=0.478, batch=220 
2007: loss=0.543, reward_mean=0.110, reward_bound=0.338, batch=224 
2008: loss=0.542, reward_mean=0.090, reward_bound=0.342, batch=227 
2009: loss=0.542, reward_mean=0.090, reward_bound=0.308, batch=229 
2010: loss=0.544, reward_mean=0.090, reward_bound=0.328, batch=230 
2011: loss=0.542, reward_mean=0.080, reward_bound=0.349, batch=229 
2012: loss=0.538, reward_mean=0.100, reward_bound=0.387, batch=227 
2013: loss=0.535, reward_mean=0.120, reward_bound=0.422, batch=229 
2014: loss=0.540, reward_mean=0.130, reward_bound=0.430, batch=225 
2015: loss=0.540, reward_mean=0.080, reward_bound=0.356, batch=227 
2016: loss=0.544, reward_mean=0.150, reward_bound=0.387, batch=228 
2017: loss=0.545, reward_mean=0.120, reward_bound=0.392, batch=229 
2018: loss=0.544, reward_mean=0.070, reward_bound=0.364, batch=230 
2019: loss=0.545, reward_mean=0.110, reward_bound=0.387, batch=230 
2020: loss=0.543, reward_mean=0.120, reward_bound=0.430, batch=228 
2021: loss=0.542, reward_mean=0.110, reward_bound=0.397, batch=229 
2022: loss=0.541, reward_mean=0.090, reward_bound=0.380, batch=230 
2023: loss=0.539, reward_mean=0.090, reward_bound=0.464, batch=231 
2024: loss=0.541, reward_mean=0.140, reward_bound=0.478, batch=224 
2025: loss=0.538, reward_mean=0.090, reward_bound=0.311, batch=227 
2026: loss=0.536, reward_mean=0.150, reward_bound=0.277, batch=229 
2027: loss=0.538, reward_mean=0.130, reward_bound=0.349, batch=227 
2028: loss=0.537, reward_mean=0.120, reward_bound=0.422, batch=229 
2029: loss=0.538, reward_mean=0.120, reward_bound=0.430, batch=229 
2030: loss=0.537, reward_mean=0.110, reward_bound=0.424, batch=230 
2031: loss=0.538, reward_mean=0.170, reward_bound=0.451, batch=231 
2032: loss=0.540, reward_mean=0.090, reward_bound=0.478, batch=228 
2034: loss=0.446, reward_mean=0.130, reward_bound=0.000, batch=13 
2035: loss=0.453, reward_mean=0.120, reward_bound=0.000, batch=25 
2036: loss=0.474, reward_mean=0.090, reward_bound=0.000, batch=34 
2037: loss=0.476, reward_mean=0.190, reward_bound=0.000, batch=53 
2038: loss=0.483, reward_mean=0.140, reward_bound=0.000, batch=67 
2039: loss=0.476, reward_mean=0.170, reward_bound=0.000, batch=84 
2040: loss=0.463, reward_mean=0.110, reward_bound=0.000, batch=95 
2041: loss=0.455, reward_mean=0.200, reward_bound=0.000, batch=115 
2042: loss=0.448, reward_mean=0.120, reward_bound=0.000, batch=127 
2043: loss=0.442, reward_mean=0.160, reward_bound=0.000, batch=143 
2044: loss=0.426, reward_mean=0.190, reward_bound=0.000, batch=162 
2045: loss=0.422, reward_mean=0.170, reward_bound=0.000, batch=179 
2046: loss=0.422, reward_mean=0.230, reward_bound=0.016, batch=195 
2047: loss=0.426, reward_mean=0.260, reward_bound=0.034, batch=205 
2048: loss=0.434, reward_mean=0.170, reward_bound=0.047, batch=212 
2049: loss=0.430, reward_mean=0.220, reward_bound=0.089, batch=217 
2050: loss=0.427, reward_mean=0.170, reward_bound=0.098, batch=217 
2051: loss=0.422, reward_mean=0.180, reward_bound=0.109, batch=230 
2052: loss=0.425, reward_mean=0.150, reward_bound=0.109, batch=226 
2053: loss=0.423, reward_mean=0.110, reward_bound=0.122, batch=217 
2054: loss=0.419, reward_mean=0.220, reward_bound=0.135, batch=209 
2055: loss=0.422, reward_mean=0.190, reward_bound=0.150, batch=208 
2056: loss=0.421, reward_mean=0.250, reward_bound=0.167, batch=206 
2057: loss=0.427, reward_mean=0.170, reward_bound=0.185, batch=197 
2058: loss=0.422, reward_mean=0.250, reward_bound=0.206, batch=190 
2059: loss=0.410, reward_mean=0.180, reward_bound=0.041, batch=203 
2060: loss=0.413, reward_mean=0.210, reward_bound=0.098, batch=211 
2061: loss=0.415, reward_mean=0.180, reward_bound=0.150, batch=217 
2062: loss=0.415, reward_mean=0.180, reward_bound=0.206, batch=220 
2063: loss=0.418, reward_mean=0.210, reward_bound=0.229, batch=202 
2064: loss=0.413, reward_mean=0.140, reward_bound=0.117, batch=211 
2065: loss=0.409, reward_mean=0.240, reward_bound=0.185, batch=216 
2066: loss=0.414, reward_mean=0.210, reward_bound=0.229, batch=220 
2067: loss=0.411, reward_mean=0.240, reward_bound=0.254, batch=199 
2068: loss=0.418, reward_mean=0.180, reward_bound=0.157, batch=209 
2069: loss=0.418, reward_mean=0.160, reward_bound=0.215, batch=216 
2070: loss=0.418, reward_mean=0.230, reward_bound=0.241, batch=221 
2071: loss=0.415, reward_mean=0.220, reward_bound=0.282, batch=188 
2072: loss=0.400, reward_mean=0.150, reward_bound=0.026, batch=201 
2073: loss=0.404, reward_mean=0.210, reward_bound=0.135, batch=209 
2074: loss=0.406, reward_mean=0.150, reward_bound=0.141, batch=216 
2075: loss=0.410, reward_mean=0.210, reward_bound=0.186, batch=221 
2076: loss=0.419, reward_mean=0.210, reward_bound=0.229, batch=224 
2077: loss=0.412, reward_mean=0.210, reward_bound=0.254, batch=224 
2078: loss=0.415, reward_mean=0.160, reward_bound=0.282, batch=222 
2079: loss=0.401, reward_mean=0.250, reward_bound=0.314, batch=178 
2080: loss=0.402, reward_mean=0.130, reward_bound=0.000, batch=191 
2081: loss=0.393, reward_mean=0.220, reward_bound=0.072, batch=203 
2082: loss=0.400, reward_mean=0.230, reward_bound=0.109, batch=211 
2083: loss=0.401, reward_mean=0.230, reward_bound=0.150, batch=216 
2084: loss=0.394, reward_mean=0.220, reward_bound=0.185, batch=218 
2085: loss=0.395, reward_mean=0.170, reward_bound=0.206, batch=220 
2086: loss=0.394, reward_mean=0.160, reward_bound=0.229, batch=219 
2087: loss=0.400, reward_mean=0.270, reward_bound=0.254, batch=217 
2088: loss=0.404, reward_mean=0.180, reward_bound=0.282, batch=216 
2089: loss=0.400, reward_mean=0.190, reward_bound=0.217, batch=221 
2090: loss=0.401, reward_mean=0.170, reward_bound=0.254, batch=223 
2091: loss=0.404, reward_mean=0.180, reward_bound=0.282, batch=225 
2092: loss=0.404, reward_mean=0.220, reward_bound=0.314, batch=215 
2093: loss=0.402, reward_mean=0.170, reward_bound=0.282, batch=219 
2094: loss=0.400, reward_mean=0.200, reward_bound=0.254, batch=222 
2095: loss=0.398, reward_mean=0.240, reward_bound=0.324, batch=225 
2096: loss=0.416, reward_mean=0.190, reward_bound=0.349, batch=175 
2097: loss=0.420, reward_mean=0.160, reward_bound=0.000, batch=191 
2098: loss=0.412, reward_mean=0.140, reward_bound=0.038, batch=203 
2099: loss=0.418, reward_mean=0.110, reward_bound=0.047, batch=211 
2100: loss=0.422, reward_mean=0.230, reward_bound=0.122, batch=217 
2101: loss=0.419, reward_mean=0.220, reward_bound=0.202, batch=222 
2102: loss=0.411, reward_mean=0.150, reward_bound=0.206, batch=229 
2103: loss=0.424, reward_mean=0.220, reward_bound=0.229, batch=226 
2104: loss=0.422, reward_mean=0.130, reward_bound=0.254, batch=222 
2105: loss=0.427, reward_mean=0.190, reward_bound=0.282, batch=219 
2106: loss=0.422, reward_mean=0.230, reward_bound=0.314, batch=215 
2107: loss=0.417, reward_mean=0.200, reward_bound=0.321, batch=220 
2108: loss=0.420, reward_mean=0.110, reward_bound=0.229, batch=223 
2109: loss=0.420, reward_mean=0.200, reward_bound=0.335, batch=226 
2110: loss=0.408, reward_mean=0.150, reward_bound=0.349, batch=217 
2111: loss=0.405, reward_mean=0.160, reward_bound=0.185, batch=221 
2112: loss=0.404, reward_mean=0.190, reward_bound=0.314, batch=222 
2113: loss=0.402, reward_mean=0.170, reward_bound=0.213, batch=225 
2114: loss=0.406, reward_mean=0.210, reward_bound=0.266, batch=227 
2115: loss=0.406, reward_mean=0.190, reward_bound=0.314, batch=227 
2116: loss=0.405, reward_mean=0.190, reward_bound=0.314, batch=228 
2117: loss=0.403, reward_mean=0.190, reward_bound=0.349, batch=224 
2118: loss=0.400, reward_mean=0.180, reward_bound=0.387, batch=154 
2119: loss=0.404, reward_mean=0.200, reward_bound=0.000, batch=174 
2120: loss=0.389, reward_mean=0.180, reward_bound=0.008, batch=192 
2121: loss=0.402, reward_mean=0.180, reward_bound=0.022, batch=204 
2122: loss=0.410, reward_mean=0.170, reward_bound=0.058, batch=213 
2123: loss=0.415, reward_mean=0.210, reward_bound=0.098, batch=218 
2124: loss=0.405, reward_mean=0.160, reward_bound=0.135, batch=221 
2125: loss=0.402, reward_mean=0.140, reward_bound=0.167, batch=222 
2126: loss=0.400, reward_mean=0.170, reward_bound=0.185, batch=219 
2127: loss=0.401, reward_mean=0.130, reward_bound=0.215, batch=223 
2128: loss=0.395, reward_mean=0.160, reward_bound=0.229, batch=222 
2129: loss=0.393, reward_mean=0.220, reward_bound=0.254, batch=221 
2130: loss=0.393, reward_mean=0.220, reward_bound=0.282, batch=219 
2131: loss=0.392, reward_mean=0.130, reward_bound=0.265, batch=223 
2132: loss=0.390, reward_mean=0.200, reward_bound=0.314, batch=216 
2133: loss=0.390, reward_mean=0.150, reward_bound=0.268, batch=221 
2134: loss=0.388, reward_mean=0.230, reward_bound=0.314, batch=224 
2135: loss=0.393, reward_mean=0.190, reward_bound=0.349, batch=208 
2136: loss=0.390, reward_mean=0.180, reward_bound=0.282, batch=213 
2137: loss=0.394, reward_mean=0.230, reward_bound=0.227, batch=219 
2138: loss=0.383, reward_mean=0.190, reward_bound=0.295, batch=223 
2139: loss=0.386, reward_mean=0.200, reward_bound=0.314, batch=224 
2140: loss=0.387, reward_mean=0.210, reward_bound=0.305, batch=227 
2141: loss=0.386, reward_mean=0.190, reward_bound=0.308, batch=229 
2142: loss=0.383, reward_mean=0.140, reward_bound=0.314, batch=228 
2143: loss=0.392, reward_mean=0.180, reward_bound=0.353, batch=229 
2144: loss=0.396, reward_mean=0.150, reward_bound=0.387, batch=207 
2145: loss=0.403, reward_mean=0.230, reward_bound=0.224, batch=215 
2146: loss=0.410, reward_mean=0.170, reward_bound=0.260, batch=220 
2147: loss=0.413, reward_mean=0.230, reward_bound=0.282, batch=223 
2148: loss=0.404, reward_mean=0.210, reward_bound=0.314, batch=217 
2149: loss=0.407, reward_mean=0.140, reward_bound=0.292, batch=222 
2150: loss=0.409, reward_mean=0.190, reward_bound=0.314, batch=224 
2151: loss=0.411, reward_mean=0.160, reward_bound=0.311, batch=227 
2152: loss=0.409, reward_mean=0.250, reward_bound=0.342, batch=229 
2153: loss=0.406, reward_mean=0.240, reward_bound=0.349, batch=224 
2154: loss=0.405, reward_mean=0.150, reward_bound=0.345, batch=227 
2155: loss=0.404, reward_mean=0.150, reward_bound=0.387, batch=223 
2156: loss=0.404, reward_mean=0.180, reward_bound=0.398, batch=226 
2157: loss=0.401, reward_mean=0.160, reward_bound=0.316, batch=228 
2158: loss=0.402, reward_mean=0.150, reward_bound=0.387, batch=227 
2159: loss=0.402, reward_mean=0.180, reward_bound=0.414, batch=229 
2160: loss=0.401, reward_mean=0.120, reward_bound=0.381, batch=230 
2161: loss=0.401, reward_mean=0.140, reward_bound=0.387, batch=230 
2162: loss=0.389, reward_mean=0.170, reward_bound=0.430, batch=126 
2163: loss=0.399, reward_mean=0.180, reward_bound=0.000, batch=144 
2164: loss=0.385, reward_mean=0.200, reward_bound=0.000, batch=164 
2165: loss=0.379, reward_mean=0.170, reward_bound=0.000, batch=181 
2166: loss=0.371, reward_mean=0.210, reward_bound=0.034, batch=195 
2167: loss=0.369, reward_mean=0.170, reward_bound=0.052, batch=204 
2168: loss=0.378, reward_mean=0.170, reward_bound=0.072, batch=211 
2169: loss=0.375, reward_mean=0.180, reward_bound=0.098, batch=215 
2170: loss=0.378, reward_mean=0.170, reward_bound=0.112, batch=220 
2171: loss=0.373, reward_mean=0.180, reward_bound=0.150, batch=215 
2172: loss=0.371, reward_mean=0.160, reward_bound=0.170, batch=220 
2173: loss=0.373, reward_mean=0.150, reward_bound=0.185, batch=221 
2174: loss=0.378, reward_mean=0.150, reward_bound=0.206, batch=218 
2175: loss=0.378, reward_mean=0.250, reward_bound=0.229, batch=212 
2176: loss=0.375, reward_mean=0.210, reward_bound=0.179, batch=218 
2177: loss=0.377, reward_mean=0.170, reward_bound=0.229, batch=221 
2178: loss=0.374, reward_mean=0.230, reward_bound=0.254, batch=221 
2179: loss=0.368, reward_mean=0.190, reward_bound=0.282, batch=209 
2180: loss=0.367, reward_mean=0.180, reward_bound=0.225, batch=216 
2181: loss=0.369, reward_mean=0.220, reward_bound=0.254, batch=220 
2182: loss=0.369, reward_mean=0.200, reward_bound=0.282, batch=222 
2183: loss=0.377, reward_mean=0.190, reward_bound=0.314, batch=206 
2184: loss=0.372, reward_mean=0.200, reward_bound=0.256, batch=214 
2185: loss=0.381, reward_mean=0.230, reward_bound=0.349, batch=194 
2186: loss=0.369, reward_mean=0.140, reward_bound=0.064, batch=206 
2187: loss=0.358, reward_mean=0.200, reward_bound=0.158, batch=214 
2188: loss=0.361, reward_mean=0.200, reward_bound=0.185, batch=219 
2189: loss=0.364, reward_mean=0.140, reward_bound=0.229, batch=221 
2190: loss=0.373, reward_mean=0.180, reward_bound=0.254, batch=224 
2191: loss=0.368, reward_mean=0.210, reward_bound=0.282, batch=226 
2192: loss=0.376, reward_mean=0.240, reward_bound=0.314, batch=223 
2193: loss=0.375, reward_mean=0.140, reward_bound=0.349, batch=223 
2194: loss=0.373, reward_mean=0.210, reward_bound=0.358, batch=226 
2195: loss=0.377, reward_mean=0.200, reward_bound=0.387, batch=203 
2196: loss=0.373, reward_mean=0.200, reward_bound=0.244, batch=212 
2197: loss=0.366, reward_mean=0.180, reward_bound=0.282, batch=215 
2198: loss=0.371, reward_mean=0.220, reward_bound=0.260, batch=220 
2199: loss=0.369, reward_mean=0.140, reward_bound=0.282, batch=222 
2200: loss=0.362, reward_mean=0.210, reward_bound=0.314, batch=222 
2201: loss=0.366, reward_mean=0.180, reward_bound=0.349, batch=219 
2202: loss=0.367, reward_mean=0.190, reward_bound=0.343, batch=223 
2203: loss=0.369, reward_mean=0.240, reward_bound=0.387, batch=223 
2204: loss=0.367, reward_mean=0.170, reward_bound=0.349, batch=225 
2205: loss=0.370, reward_mean=0.110, reward_bound=0.387, batch=226 
2206: loss=0.369, reward_mean=0.150, reward_bound=0.387, batch=227 
2207: loss=0.360, reward_mean=0.140, reward_bound=0.430, batch=174 
2208: loss=0.363, reward_mean=0.190, reward_bound=0.018, batch=191 
2209: loss=0.359, reward_mean=0.160, reward_bound=0.028, batch=203 
2210: loss=0.367, reward_mean=0.160, reward_bound=0.074, batch=212 
2211: loss=0.364, reward_mean=0.220, reward_bound=0.122, batch=217 
2212: loss=0.369, reward_mean=0.200, reward_bound=0.163, batch=222 
2213: loss=0.359, reward_mean=0.100, reward_bound=0.167, batch=222 
2214: loss=0.364, reward_mean=0.190, reward_bound=0.185, batch=221 
2215: loss=0.363, reward_mean=0.140, reward_bound=0.206, batch=221 
2216: loss=0.355, reward_mean=0.210, reward_bound=0.229, batch=220 
2217: loss=0.361, reward_mean=0.200, reward_bound=0.254, batch=222 
2218: loss=0.363, reward_mean=0.160, reward_bound=0.245, batch=225 
2219: loss=0.364, reward_mean=0.210, reward_bound=0.282, batch=218 
2220: loss=0.362, reward_mean=0.150, reward_bound=0.286, batch=222 
2221: loss=0.360, reward_mean=0.240, reward_bound=0.254, batch=224 
2222: loss=0.362, reward_mean=0.140, reward_bound=0.311, batch=227 
2223: loss=0.360, reward_mean=0.190, reward_bound=0.308, batch=229 
2224: loss=0.359, reward_mean=0.170, reward_bound=0.278, batch=230 
2225: loss=0.353, reward_mean=0.280, reward_bound=0.314, batch=226 
2226: loss=0.357, reward_mean=0.160, reward_bound=0.349, batch=211 
2227: loss=0.352, reward_mean=0.130, reward_bound=0.150, batch=217 
2228: loss=0.361, reward_mean=0.250, reward_bound=0.277, batch=222 
2229: loss=0.363, reward_mean=0.150, reward_bound=0.314, batch=220 
2230: loss=0.366, reward_mean=0.150, reward_bound=0.314, batch=223 
2231: loss=0.357, reward_mean=0.200, reward_bound=0.349, batch=224 
2232: loss=0.361, reward_mean=0.110, reward_bound=0.337, batch=227 
2233: loss=0.362, reward_mean=0.170, reward_bound=0.380, batch=229 
2234: loss=0.361, reward_mean=0.210, reward_bound=0.364, batch=230 
2235: loss=0.362, reward_mean=0.110, reward_bound=0.376, batch=231 
2236: loss=0.366, reward_mean=0.190, reward_bound=0.387, batch=217 
2237: loss=0.366, reward_mean=0.170, reward_bound=0.349, batch=221 
2238: loss=0.366, reward_mean=0.140, reward_bound=0.254, batch=224 
2239: loss=0.367, reward_mean=0.220, reward_bound=0.345, batch=227 
2240: loss=0.370, reward_mean=0.160, reward_bound=0.349, batch=225 
2241: loss=0.370, reward_mean=0.140, reward_bound=0.273, batch=227 
2242: loss=0.369, reward_mean=0.160, reward_bound=0.349, batch=228 
2243: loss=0.368, reward_mean=0.190, reward_bound=0.293, batch=229 
2244: loss=0.364, reward_mean=0.170, reward_bound=0.387, batch=225 
2245: loss=0.365, reward_mean=0.200, reward_bound=0.430, batch=203 
2246: loss=0.365, reward_mean=0.240, reward_bound=0.282, batch=211 
2247: loss=0.366, reward_mean=0.150, reward_bound=0.229, batch=217 
2248: loss=0.367, reward_mean=0.210, reward_bound=0.224, batch=222 
2249: loss=0.370, reward_mean=0.180, reward_bound=0.314, batch=217 
2250: loss=0.367, reward_mean=0.230, reward_bound=0.314, batch=220 
2251: loss=0.362, reward_mean=0.260, reward_bound=0.349, batch=217 
2252: loss=0.360, reward_mean=0.200, reward_bound=0.342, batch=222 
2253: loss=0.364, reward_mean=0.180, reward_bound=0.349, batch=224 
2254: loss=0.365, reward_mean=0.130, reward_bound=0.280, batch=227 
2255: loss=0.363, reward_mean=0.180, reward_bound=0.342, batch=229 
2256: loss=0.362, reward_mean=0.180, reward_bound=0.349, batch=229 
2257: loss=0.369, reward_mean=0.190, reward_bound=0.387, batch=220 
2258: loss=0.369, reward_mean=0.150, reward_bound=0.376, batch=224 
2259: loss=0.368, reward_mean=0.170, reward_bound=0.349, batch=226 
2260: loss=0.367, reward_mean=0.190, reward_bound=0.368, batch=228 
2261: loss=0.370, reward_mean=0.170, reward_bound=0.387, batch=226 
2262: loss=0.370, reward_mean=0.240, reward_bound=0.298, batch=228 
2263: loss=0.371, reward_mean=0.210, reward_bound=0.392, batch=229 
2264: loss=0.371, reward_mean=0.200, reward_bound=0.430, batch=219 
2265: loss=0.372, reward_mean=0.130, reward_bound=0.314, batch=222 
2266: loss=0.355, reward_mean=0.270, reward_bound=0.478, batch=86 
2267: loss=0.330, reward_mean=0.130, reward_bound=0.000, batch=99 
2268: loss=0.336, reward_mean=0.190, reward_bound=0.000, batch=118 
2269: loss=0.348, reward_mean=0.240, reward_bound=0.000, batch=142 
2270: loss=0.356, reward_mean=0.180, reward_bound=0.000, batch=160 
2271: loss=0.357, reward_mean=0.110, reward_bound=0.000, batch=171 
2272: loss=0.353, reward_mean=0.160, reward_bound=0.000, batch=187 
2273: loss=0.352, reward_mean=0.170, reward_bound=0.010, batch=201 
2274: loss=0.353, reward_mean=0.220, reward_bound=0.047, batch=208 
2275: loss=0.349, reward_mean=0.130, reward_bound=0.058, batch=213 
2276: loss=0.350, reward_mean=0.150, reward_bound=0.069, batch=219 
2277: loss=0.357, reward_mean=0.150, reward_bound=0.089, batch=220 
2278: loss=0.356, reward_mean=0.230, reward_bound=0.122, batch=222 
2279: loss=0.351, reward_mean=0.220, reward_bound=0.140, batch=225 
2280: loss=0.351, reward_mean=0.220, reward_bound=0.150, batch=224 
2281: loss=0.348, reward_mean=0.180, reward_bound=0.167, batch=224 
2282: loss=0.354, reward_mean=0.180, reward_bound=0.185, batch=222 
2283: loss=0.351, reward_mean=0.180, reward_bound=0.206, batch=231 
2284: loss=0.354, reward_mean=0.130, reward_bound=0.206, batch=222 
2285: loss=0.351, reward_mean=0.180, reward_bound=0.229, batch=216 
2286: loss=0.346, reward_mean=0.190, reward_bound=0.254, batch=202 
2287: loss=0.347, reward_mean=0.200, reward_bound=0.229, batch=210 
2288: loss=0.350, reward_mean=0.170, reward_bound=0.150, batch=216 
2289: loss=0.349, reward_mean=0.240, reward_bound=0.282, batch=204 
2290: loss=0.348, reward_mean=0.210, reward_bound=0.224, batch=213 
2291: loss=0.352, reward_mean=0.210, reward_bound=0.254, batch=218 
2292: loss=0.351, reward_mean=0.170, reward_bound=0.257, batch=222 
2293: loss=0.352, reward_mean=0.230, reward_bound=0.282, batch=220 
2294: loss=0.352, reward_mean=0.140, reward_bound=0.216, batch=224 
2295: loss=0.348, reward_mean=0.230, reward_bound=0.280, batch=227 
2296: loss=0.350, reward_mean=0.150, reward_bound=0.308, batch=229 
2297: loss=0.350, reward_mean=0.190, reward_bound=0.314, batch=200 
2298: loss=0.339, reward_mean=0.150, reward_bound=0.076, batch=210 
2299: loss=0.340, reward_mean=0.250, reward_bound=0.150, batch=216 
2300: loss=0.342, reward_mean=0.210, reward_bound=0.217, batch=221 
2301: loss=0.344, reward_mean=0.120, reward_bound=0.254, batch=223 
2302: loss=0.346, reward_mean=0.180, reward_bound=0.282, batch=224 
2303: loss=0.350, reward_mean=0.190, reward_bound=0.314, batch=220 
2304: loss=0.350, reward_mean=0.190, reward_bound=0.254, batch=223 
2305: loss=0.355, reward_mean=0.150, reward_bound=0.235, batch=226 
2306: loss=0.346, reward_mean=0.160, reward_bound=0.298, batch=228 
2307: loss=0.349, reward_mean=0.150, reward_bound=0.314, batch=228 
2308: loss=0.353, reward_mean=0.190, reward_bound=0.349, batch=190 
2309: loss=0.358, reward_mean=0.190, reward_bound=0.063, batch=203 
2310: loss=0.356, reward_mean=0.180, reward_bound=0.160, batch=212 
2311: loss=0.354, reward_mean=0.200, reward_bound=0.229, batch=215 
2312: loss=0.354, reward_mean=0.110, reward_bound=0.254, batch=216 
2313: loss=0.353, reward_mean=0.230, reward_bound=0.254, batch=220 
2314: loss=0.352, reward_mean=0.190, reward_bound=0.229, batch=223 
2315: loss=0.362, reward_mean=0.130, reward_bound=0.282, batch=220 
2316: loss=0.360, reward_mean=0.130, reward_bound=0.304, batch=224 
2317: loss=0.361, reward_mean=0.150, reward_bound=0.311, batch=227 
2318: loss=0.352, reward_mean=0.230, reward_bound=0.314, batch=226 
2319: loss=0.358, reward_mean=0.090, reward_bound=0.349, batch=220 
2320: loss=0.356, reward_mean=0.220, reward_bound=0.314, batch=223 
2321: loss=0.348, reward_mean=0.210, reward_bound=0.387, batch=180 
2322: loss=0.341, reward_mean=0.090, reward_bound=0.000, batch=189 
2323: loss=0.346, reward_mean=0.130, reward_bound=0.023, batch=202 
2324: loss=0.352, reward_mean=0.120, reward_bound=0.047, batch=211 
2325: loss=0.353, reward_mean=0.210, reward_bound=0.122, batch=216 
2326: loss=0.342, reward_mean=0.170, reward_bound=0.135, batch=219 
2327: loss=0.340, reward_mean=0.120, reward_bound=0.150, batch=220 
2328: loss=0.345, reward_mean=0.140, reward_bound=0.185, batch=222 
2329: loss=0.339, reward_mean=0.200, reward_bound=0.206, batch=229 
2330: loss=0.347, reward_mean=0.200, reward_bound=0.229, batch=222 
2331: loss=0.347, reward_mean=0.280, reward_bound=0.254, batch=221 
2332: loss=0.346, reward_mean=0.130, reward_bound=0.206, batch=224 
2333: loss=0.351, reward_mean=0.120, reward_bound=0.252, batch=227 
2334: loss=0.345, reward_mean=0.120, reward_bound=0.282, batch=225 
2335: loss=0.349, reward_mean=0.140, reward_bound=0.314, batch=213 
2336: loss=0.344, reward_mean=0.140, reward_bound=0.122, batch=218 
2337: loss=0.347, reward_mean=0.190, reward_bound=0.211, batch=222 
2338: loss=0.345, reward_mean=0.180, reward_bound=0.292, batch=225 
2339: loss=0.344, reward_mean=0.130, reward_bound=0.314, batch=226 
2340: loss=0.342, reward_mean=0.190, reward_bound=0.314, batch=227 
2341: loss=0.342, reward_mean=0.150, reward_bound=0.342, batch=229 
2342: loss=0.335, reward_mean=0.230, reward_bound=0.349, batch=212 
2343: loss=0.336, reward_mean=0.190, reward_bound=0.198, batch=218 
2344: loss=0.328, reward_mean=0.220, reward_bound=0.314, batch=219 
2345: loss=0.330, reward_mean=0.090, reward_bound=0.349, batch=220 
2346: loss=0.334, reward_mean=0.180, reward_bound=0.376, batch=224 
2347: loss=0.334, reward_mean=0.210, reward_bound=0.380, batch=227 
2348: loss=0.341, reward_mean=0.250, reward_bound=0.387, batch=219 
2349: loss=0.340, reward_mean=0.220, reward_bound=0.364, batch=223 
2350: loss=0.338, reward_mean=0.170, reward_bound=0.372, batch=226 
2351: loss=0.345, reward_mean=0.160, reward_bound=0.387, batch=223 
2352: loss=0.366, reward_mean=0.260, reward_bound=0.430, batch=161 
2353: loss=0.361, reward_mean=0.170, reward_bound=0.000, batch=178 
2354: loss=0.368, reward_mean=0.170, reward_bound=0.020, batch=194 
2355: loss=0.350, reward_mean=0.280, reward_bound=0.119, batch=206 
2356: loss=0.343, reward_mean=0.120, reward_bound=0.075, batch=214 
2357: loss=0.348, reward_mean=0.210, reward_bound=0.150, batch=218 
2358: loss=0.353, reward_mean=0.120, reward_bound=0.167, batch=221 
2359: loss=0.355, reward_mean=0.260, reward_bound=0.206, batch=217 
2360: loss=0.363, reward_mean=0.170, reward_bound=0.229, batch=218 
2361: loss=0.361, reward_mean=0.150, reward_bound=0.254, batch=219 
2362: loss=0.362, reward_mean=0.200, reward_bound=0.282, batch=215 
2363: loss=0.359, reward_mean=0.130, reward_bound=0.216, batch=220 
2364: loss=0.355, reward_mean=0.190, reward_bound=0.304, batch=224 
2365: loss=0.357, reward_mean=0.190, reward_bound=0.314, batch=211 
2366: loss=0.362, reward_mean=0.130, reward_bound=0.135, batch=217 
2367: loss=0.363, reward_mean=0.100, reward_bound=0.167, batch=221 
2368: loss=0.360, reward_mean=0.140, reward_bound=0.282, batch=224 
2369: loss=0.362, reward_mean=0.210, reward_bound=0.314, batch=226 
2370: loss=0.363, reward_mean=0.120, reward_bound=0.349, batch=214 
2371: loss=0.366, reward_mean=0.190, reward_bound=0.185, batch=219 
2372: loss=0.362, reward_mean=0.130, reward_bound=0.328, batch=223 
2373: loss=0.365, reward_mean=0.170, reward_bound=0.349, batch=224 
2374: loss=0.361, reward_mean=0.130, reward_bound=0.305, batch=227 
2375: loss=0.363, reward_mean=0.220, reward_bound=0.349, batch=228 
2376: loss=0.367, reward_mean=0.170, reward_bound=0.387, batch=211 
2377: loss=0.364, reward_mean=0.100, reward_bound=0.282, batch=215 
2378: loss=0.360, reward_mean=0.160, reward_bound=0.229, batch=219 
2379: loss=0.367, reward_mean=0.180, reward_bound=0.282, batch=221 
2380: loss=0.368, reward_mean=0.150, reward_bound=0.314, batch=224 
2381: loss=0.371, reward_mean=0.120, reward_bound=0.204, batch=227 
2382: loss=0.369, reward_mean=0.100, reward_bound=0.277, batch=229 
2383: loss=0.366, reward_mean=0.150, reward_bound=0.328, batch=230 
2384: loss=0.367, reward_mean=0.230, reward_bound=0.349, batch=226 
2385: loss=0.363, reward_mean=0.190, reward_bound=0.387, batch=224 
2386: loss=0.364, reward_mean=0.140, reward_bound=0.422, batch=227 
2387: loss=0.355, reward_mean=0.130, reward_bound=0.430, batch=193 
2388: loss=0.355, reward_mean=0.200, reward_bound=0.144, batch=205 
2389: loss=0.352, reward_mean=0.140, reward_bound=0.124, batch=213 
2390: loss=0.349, reward_mean=0.190, reward_bound=0.160, batch=219 
2391: loss=0.349, reward_mean=0.140, reward_bound=0.194, batch=223 
2392: loss=0.361, reward_mean=0.190, reward_bound=0.244, batch=226 
2393: loss=0.361, reward_mean=0.220, reward_bound=0.254, batch=223 
2394: loss=0.360, reward_mean=0.170, reward_bound=0.282, batch=224 
2395: loss=0.362, reward_mean=0.210, reward_bound=0.314, batch=221 
2396: loss=0.360, reward_mean=0.220, reward_bound=0.349, batch=220 
2397: loss=0.356, reward_mean=0.160, reward_bound=0.222, batch=224 
2398: loss=0.354, reward_mean=0.200, reward_bound=0.345, batch=227 
2399: loss=0.362, reward_mean=0.210, reward_bound=0.380, batch=229 
2400: loss=0.361, reward_mean=0.190, reward_bound=0.364, batch=230 
2401: loss=0.355, reward_mean=0.140, reward_bound=0.387, batch=221 
2402: loss=0.352, reward_mean=0.190, reward_bound=0.282, batch=224 
2403: loss=0.356, reward_mean=0.150, reward_bound=0.314, batch=226 
2404: loss=0.355, reward_mean=0.190, reward_bound=0.368, batch=228 
2405: loss=0.354, reward_mean=0.190, reward_bound=0.387, batch=228 
2406: loss=0.353, reward_mean=0.170, reward_bound=0.325, batch=229 
2407: loss=0.356, reward_mean=0.140, reward_bound=0.364, batch=230 
2408: loss=0.353, reward_mean=0.120, reward_bound=0.418, batch=231 
2409: loss=0.348, reward_mean=0.180, reward_bound=0.430, batch=216 
2410: loss=0.345, reward_mean=0.090, reward_bound=0.189, batch=221 
2411: loss=0.345, reward_mean=0.160, reward_bound=0.254, batch=224 
2412: loss=0.347, reward_mean=0.200, reward_bound=0.314, batch=225 
2413: loss=0.342, reward_mean=0.120, reward_bound=0.356, batch=227 
2414: loss=0.345, reward_mean=0.190, reward_bound=0.387, batch=226 
2415: loss=0.343, reward_mean=0.210, reward_bound=0.409, batch=228 
2416: loss=0.344, reward_mean=0.220, reward_bound=0.392, batch=229 
2417: loss=0.344, reward_mean=0.110, reward_bound=0.387, batch=229 
2418: loss=0.350, reward_mean=0.160, reward_bound=0.430, batch=224 
2419: loss=0.358, reward_mean=0.160, reward_bound=0.345, batch=227 
2420: loss=0.350, reward_mean=0.170, reward_bound=0.349, batch=228 
2421: loss=0.354, reward_mean=0.160, reward_bound=0.387, batch=228 
2422: loss=0.348, reward_mean=0.240, reward_bound=0.430, batch=226 
2423: loss=0.347, reward_mean=0.140, reward_bound=0.430, batch=227 
2424: loss=0.346, reward_mean=0.170, reward_bound=0.469, batch=229 
2425: loss=0.346, reward_mean=0.170, reward_bound=0.328, batch=230 
2426: loss=0.346, reward_mean=0.160, reward_bound=0.430, batch=230 
2427: loss=0.346, reward_mean=0.160, reward_bound=0.430, batch=230 
2428: loss=0.345, reward_mean=0.160, reward_bound=0.418, batch=231 
2429: loss=0.332, reward_mean=0.120, reward_bound=0.478, batch=143 
2430: loss=0.346, reward_mean=0.170, reward_bound=0.000, batch=160 
2431: loss=0.333, reward_mean=0.210, reward_bound=0.000, batch=181 
2432: loss=0.325, reward_mean=0.130, reward_bound=0.000, batch=194 
2433: loss=0.336, reward_mean=0.180, reward_bound=0.019, batch=206 
2434: loss=0.332, reward_mean=0.150, reward_bound=0.072, batch=214 
2435: loss=0.334, reward_mean=0.230, reward_bound=0.109, batch=218 
2436: loss=0.336, reward_mean=0.130, reward_bound=0.150, batch=216 
2437: loss=0.332, reward_mean=0.300, reward_bound=0.185, batch=219 
2438: loss=0.342, reward_mean=0.210, reward_bound=0.206, batch=220 
2439: loss=0.338, reward_mean=0.110, reward_bound=0.229, batch=215 
2440: loss=0.340, reward_mean=0.130, reward_bound=0.229, batch=219 
2441: loss=0.347, reward_mean=0.150, reward_bound=0.254, batch=210 
2442: loss=0.348, reward_mean=0.150, reward_bound=0.229, batch=215 
2443: loss=0.348, reward_mean=0.150, reward_bound=0.260, batch=220 
2444: loss=0.351, reward_mean=0.150, reward_bound=0.274, batch=224 
2445: loss=0.346, reward_mean=0.130, reward_bound=0.282, batch=213 
2446: loss=0.351, reward_mean=0.180, reward_bound=0.314, batch=206 
2447: loss=0.359, reward_mean=0.110, reward_bound=0.076, batch=214 
2448: loss=0.353, reward_mean=0.170, reward_bound=0.165, batch=220 
2449: loss=0.347, reward_mean=0.180, reward_bound=0.229, batch=222 
2450: loss=0.346, reward_mean=0.180, reward_bound=0.282, batch=220 
2451: loss=0.346, reward_mean=0.110, reward_bound=0.200, batch=224 
2452: loss=0.346, reward_mean=0.160, reward_bound=0.311, batch=227 
2453: loss=0.346, reward_mean=0.250, reward_bound=0.314, batch=224 
2454: loss=0.348, reward_mean=0.240, reward_bound=0.349, batch=203 
2455: loss=0.337, reward_mean=0.160, reward_bound=0.190, batch=212 
2456: loss=0.340, reward_mean=0.110, reward_bound=0.140, batch=218 
2457: loss=0.353, reward_mean=0.160, reward_bound=0.206, batch=220 
2458: loss=0.360, reward_mean=0.190, reward_bound=0.247, batch=224 
2459: loss=0.361, reward_mean=0.200, reward_bound=0.254, batch=225 
2460: loss=0.354, reward_mean=0.210, reward_bound=0.289, batch=227 
2461: loss=0.352, reward_mean=0.170, reward_bound=0.314, batch=223 
2462: loss=0.352, reward_mean=0.150, reward_bound=0.335, batch=226 
2463: loss=0.350, reward_mean=0.120, reward_bound=0.349, batch=223 
2464: loss=0.353, reward_mean=0.100, reward_bound=0.358, batch=226 
2465: loss=0.343, reward_mean=0.150, reward_bound=0.387, batch=206 
2466: loss=0.342, reward_mean=0.190, reward_bound=0.196, batch=214 
2467: loss=0.344, reward_mean=0.160, reward_bound=0.252, batch=220 
2468: loss=0.346, reward_mean=0.200, reward_bound=0.254, batch=222 
2469: loss=0.350, reward_mean=0.150, reward_bound=0.314, batch=222 
2470: loss=0.349, reward_mean=0.110, reward_bound=0.263, batch=225 
2471: loss=0.351, reward_mean=0.170, reward_bound=0.349, batch=224 
2472: loss=0.349, reward_mean=0.140, reward_bound=0.342, batch=227 
2473: loss=0.351, reward_mean=0.150, reward_bound=0.349, batch=228 
2474: loss=0.347, reward_mean=0.190, reward_bound=0.387, batch=225 
2475: loss=0.350, reward_mean=0.210, reward_bound=0.430, batch=189 
2476: loss=0.347, reward_mean=0.170, reward_bound=0.102, batch=202 
2477: loss=0.347, reward_mean=0.180, reward_bound=0.155, batch=211 
2478: loss=0.345, reward_mean=0.170, reward_bound=0.150, batch=217 
2479: loss=0.345, reward_mean=0.220, reward_bound=0.224, batch=222 
2480: loss=0.344, reward_mean=0.150, reward_bound=0.229, batch=222 
2481: loss=0.342, reward_mean=0.140, reward_bound=0.229, batch=224 
2482: loss=0.346, reward_mean=0.150, reward_bound=0.254, batch=221 
2483: loss=0.346, reward_mean=0.160, reward_bound=0.282, batch=222 
2484: loss=0.346, reward_mean=0.200, reward_bound=0.272, batch=225 
2485: loss=0.344, reward_mean=0.150, reward_bound=0.289, batch=227 
2486: loss=0.342, reward_mean=0.160, reward_bound=0.314, batch=225 
2487: loss=0.339, reward_mean=0.140, reward_bound=0.349, batch=219 
2488: loss=0.338, reward_mean=0.170, reward_bound=0.295, batch=223 
2489: loss=0.340, reward_mean=0.170, reward_bound=0.335, batch=226 
2490: loss=0.341, reward_mean=0.160, reward_bound=0.349, batch=226 
2491: loss=0.347, reward_mean=0.190, reward_bound=0.387, batch=212 
2492: loss=0.346, reward_mean=0.130, reward_bound=0.236, batch=218 
2493: loss=0.345, reward_mean=0.160, reward_bound=0.282, batch=220 
2494: loss=0.342, reward_mean=0.190, reward_bound=0.304, batch=224 
2495: loss=0.343, reward_mean=0.200, reward_bound=0.314, batch=225 
2496: loss=0.341, reward_mean=0.190, reward_bound=0.321, batch=227 
2497: loss=0.347, reward_mean=0.190, reward_bound=0.349, batch=224 
2498: loss=0.347, reward_mean=0.230, reward_bound=0.384, batch=227 
2499: loss=0.346, reward_mean=0.100, reward_bound=0.373, batch=229 
2500: loss=0.342, reward_mean=0.120, reward_bound=0.387, batch=228 
2501: loss=0.342, reward_mean=0.130, reward_bound=0.357, batch=229 
2502: loss=0.351, reward_mean=0.160, reward_bound=0.430, batch=212 
2503: loss=0.343, reward_mean=0.210, reward_bound=0.213, batch=218 
2504: loss=0.345, reward_mean=0.100, reward_bound=0.208, batch=222 
2505: loss=0.347, reward_mean=0.160, reward_bound=0.229, batch=224 
2506: loss=0.353, reward_mean=0.140, reward_bound=0.254, batch=225 
2507: loss=0.351, reward_mean=0.250, reward_bound=0.282, batch=225 
2508: loss=0.350, reward_mean=0.220, reward_bound=0.349, batch=226 
2509: loss=0.345, reward_mean=0.170, reward_bound=0.387, batch=223 
2510: loss=0.354, reward_mean=0.130, reward_bound=0.358, batch=226 
2511: loss=0.350, reward_mean=0.120, reward_bound=0.387, batch=226 
2512: loss=0.353, reward_mean=0.190, reward_bound=0.430, batch=225 
2513: loss=0.355, reward_mean=0.160, reward_bound=0.396, batch=227 
2514: loss=0.354, reward_mean=0.200, reward_bound=0.430, batch=228 
2515: loss=0.355, reward_mean=0.120, reward_bound=0.397, batch=229 
2516: loss=0.354, reward_mean=0.210, reward_bound=0.478, batch=232 
2517: loss=0.331, reward_mean=0.190, reward_bound=0.478, batch=182 
2518: loss=0.323, reward_mean=0.170, reward_bound=0.040, batch=197 
2519: loss=0.315, reward_mean=0.130, reward_bound=0.057, batch=208 
2520: loss=0.333, reward_mean=0.220, reward_bound=0.150, batch=212 
2521: loss=0.325, reward_mean=0.170, reward_bound=0.185, batch=217 
2522: loss=0.332, reward_mean=0.170, reward_bound=0.229, batch=217 
2523: loss=0.319, reward_mean=0.210, reward_bound=0.254, batch=218 
2524: loss=0.321, reward_mean=0.110, reward_bound=0.161, batch=222 
2525: loss=0.326, reward_mean=0.220, reward_bound=0.282, batch=221 
2526: loss=0.324, reward_mean=0.130, reward_bound=0.314, batch=215 
2527: loss=0.325, reward_mean=0.160, reward_bound=0.260, batch=220 
2528: loss=0.322, reward_mean=0.150, reward_bound=0.282, batch=222 
2529: loss=0.324, reward_mean=0.210, reward_bound=0.191, batch=225 
2530: loss=0.323, reward_mean=0.150, reward_bound=0.321, batch=227 
2531: loss=0.326, reward_mean=0.120, reward_bound=0.349, batch=216 
2532: loss=0.333, reward_mean=0.160, reward_bound=0.268, batch=221 
2533: loss=0.330, reward_mean=0.220, reward_bound=0.349, batch=224 
2534: loss=0.327, reward_mean=0.170, reward_bound=0.387, batch=211 
2535: loss=0.325, reward_mean=0.160, reward_bound=0.206, batch=216 
2536: loss=0.324, reward_mean=0.160, reward_bound=0.268, batch=221 
2537: loss=0.324, reward_mean=0.160, reward_bound=0.282, batch=223 
2538: loss=0.323, reward_mean=0.190, reward_bound=0.349, batch=221 
2539: loss=0.321, reward_mean=0.160, reward_bound=0.185, batch=224 
2540: loss=0.322, reward_mean=0.180, reward_bound=0.387, batch=220 
2541: loss=0.326, reward_mean=0.120, reward_bound=0.131, batch=224 
2542: loss=0.317, reward_mean=0.130, reward_bound=0.164, batch=227 
2543: loss=0.313, reward_mean=0.190, reward_bound=0.282, batch=228 
2544: loss=0.315, reward_mean=0.170, reward_bound=0.349, batch=227 
2545: loss=0.313, reward_mean=0.220, reward_bound=0.422, batch=229 
2546: loss=0.318, reward_mean=0.180, reward_bound=0.430, batch=212 
2547: loss=0.316, reward_mean=0.170, reward_bound=0.254, batch=217 
2548: loss=0.317, reward_mean=0.220, reward_bound=0.314, batch=219 
2549: loss=0.318, reward_mean=0.140, reward_bound=0.295, batch=223 
2550: loss=0.316, reward_mean=0.120, reward_bound=0.191, batch=226 
2551: loss=0.316, reward_mean=0.210, reward_bound=0.331, batch=228 
2552: loss=0.316, reward_mean=0.120, reward_bound=0.289, batch=229 
2553: loss=0.315, reward_mean=0.220, reward_bound=0.349, batch=226 
2554: loss=0.316, reward_mean=0.090, reward_bound=0.335, batch=228 
2555: loss=0.324, reward_mean=0.220, reward_bound=0.387, batch=226 
2556: loss=0.324, reward_mean=0.160, reward_bound=0.342, batch=228 
2557: loss=0.323, reward_mean=0.180, reward_bound=0.392, batch=229 
2558: loss=0.320, reward_mean=0.190, reward_bound=0.430, batch=220 
2559: loss=0.321, reward_mean=0.170, reward_bound=0.175, batch=224 
2560: loss=0.320, reward_mean=0.190, reward_bound=0.345, batch=227 
2561: loss=0.321, reward_mean=0.130, reward_bound=0.349, batch=227 
2562: loss=0.319, reward_mean=0.180, reward_bound=0.342, batch=229 
2563: loss=0.314, reward_mean=0.180, reward_bound=0.387, batch=227 
2564: loss=0.312, reward_mean=0.160, reward_bound=0.342, batch=229 
2565: loss=0.312, reward_mean=0.190, reward_bound=0.328, batch=230 
2566: loss=0.317, reward_mean=0.200, reward_bound=0.376, batch=231 
2567: loss=0.315, reward_mean=0.110, reward_bound=0.387, batch=230 
2568: loss=0.317, reward_mean=0.200, reward_bound=0.430, batch=229 
2569: loss=0.316, reward_mean=0.180, reward_bound=0.478, batch=231 
2570: loss=0.316, reward_mean=0.150, reward_bound=0.349, batch=231 
2571: loss=0.324, reward_mean=0.200, reward_bound=0.478, batch=204 
2572: loss=0.323, reward_mean=0.160, reward_bound=0.221, batch=213 
2573: loss=0.326, reward_mean=0.200, reward_bound=0.282, batch=217 
2574: loss=0.320, reward_mean=0.160, reward_bound=0.314, batch=221 
2575: loss=0.319, reward_mean=0.240, reward_bound=0.349, batch=222 
2576: loss=0.315, reward_mean=0.160, reward_bound=0.360, batch=225 
2577: loss=0.319, reward_mean=0.100, reward_bound=0.234, batch=227 
2578: loss=0.314, reward_mean=0.140, reward_bound=0.282, batch=227 
2579: loss=0.320, reward_mean=0.200, reward_bound=0.387, batch=222 
2580: loss=0.324, reward_mean=0.200, reward_bound=0.236, batch=225 
2581: loss=0.325, reward_mean=0.210, reward_bound=0.349, batch=226 
2582: loss=0.325, reward_mean=0.160, reward_bound=0.387, batch=227 
2583: loss=0.320, reward_mean=0.190, reward_bound=0.430, batch=223 
2584: loss=0.318, reward_mean=0.160, reward_bound=0.372, batch=226 
2585: loss=0.320, reward_mean=0.230, reward_bound=0.387, batch=227 
2586: loss=0.318, reward_mean=0.130, reward_bound=0.414, batch=229 
2587: loss=0.319, reward_mean=0.180, reward_bound=0.430, batch=229 
2588: loss=0.319, reward_mean=0.170, reward_bound=0.450, batch=230 
2589: loss=0.319, reward_mean=0.190, reward_bound=0.464, batch=231 
2590: loss=0.319, reward_mean=0.110, reward_bound=0.430, batch=231 
2591: loss=0.329, reward_mean=0.170, reward_bound=0.478, batch=217 
2592: loss=0.326, reward_mean=0.120, reward_bound=0.308, batch=222 
2593: loss=0.330, reward_mean=0.150, reward_bound=0.292, batch=225 
2594: loss=0.328, reward_mean=0.090, reward_bound=0.314, batch=225 
2595: loss=0.328, reward_mean=0.160, reward_bound=0.296, batch=227 
2596: loss=0.328, reward_mean=0.120, reward_bound=0.302, batch=229 
2597: loss=0.330, reward_mean=0.210, reward_bound=0.387, batch=228 
2598: loss=0.329, reward_mean=0.150, reward_bound=0.357, batch=229 
2599: loss=0.328, reward_mean=0.180, reward_bound=0.430, batch=224 
2600: loss=0.327, reward_mean=0.220, reward_bound=0.478, batch=221 
2601: loss=0.329, reward_mean=0.130, reward_bound=0.282, batch=224 
2602: loss=0.326, reward_mean=0.180, reward_bound=0.349, batch=225 
2603: loss=0.329, reward_mean=0.240, reward_bound=0.356, batch=227 
2604: loss=0.328, reward_mean=0.180, reward_bound=0.380, batch=229 
2605: loss=0.326, reward_mean=0.140, reward_bound=0.364, batch=230 
2606: loss=0.323, reward_mean=0.210, reward_bound=0.418, batch=231 
2607: loss=0.326, reward_mean=0.150, reward_bound=0.430, batch=226 
2608: loss=0.324, reward_mean=0.180, reward_bound=0.368, batch=228 
2609: loss=0.326, reward_mean=0.190, reward_bound=0.430, batch=226 
2610: loss=0.324, reward_mean=0.150, reward_bound=0.409, batch=228 
2611: loss=0.325, reward_mean=0.190, reward_bound=0.430, batch=227 
2612: loss=0.327, reward_mean=0.150, reward_bound=0.302, batch=229 
2613: loss=0.326, reward_mean=0.170, reward_bound=0.405, batch=230 
2614: loss=0.326, reward_mean=0.190, reward_bound=0.418, batch=231 
2615: loss=0.325, reward_mean=0.150, reward_bound=0.430, batch=230 
2616: loss=0.325, reward_mean=0.160, reward_bound=0.347, batch=231 
2617: loss=0.324, reward_mean=0.210, reward_bound=0.387, batch=231 
2618: loss=0.325, reward_mean=0.220, reward_bound=0.430, batch=230 
2619: loss=0.328, reward_mean=0.190, reward_bound=0.418, batch=231 
2620: loss=0.324, reward_mean=0.130, reward_bound=0.430, batch=231 
2621: loss=0.324, reward_mean=0.160, reward_bound=0.478, batch=225 
2622: loss=0.327, reward_mean=0.200, reward_bound=0.440, batch=227 
2623: loss=0.330, reward_mean=0.170, reward_bound=0.342, batch=229 
2624: loss=0.325, reward_mean=0.130, reward_bound=0.387, batch=229 
2625: loss=0.324, reward_mean=0.070, reward_bound=0.343, batch=230 
2626: loss=0.326, reward_mean=0.250, reward_bound=0.430, batch=230 
2627: loss=0.324, reward_mean=0.230, reward_bound=0.478, batch=225 
2628: loss=0.322, reward_mean=0.130, reward_bound=0.396, batch=227 
2629: loss=0.324, reward_mean=0.190, reward_bound=0.387, batch=228 
2630: loss=0.324, reward_mean=0.110, reward_bound=0.430, batch=226 
2631: loss=0.324, reward_mean=0.140, reward_bound=0.368, batch=228 
2632: loss=0.322, reward_mean=0.180, reward_bound=0.430, batch=228 
2633: loss=0.322, reward_mean=0.150, reward_bound=0.430, batch=228 
2634: loss=0.321, reward_mean=0.170, reward_bound=0.362, batch=229 
2635: loss=0.321, reward_mean=0.200, reward_bound=0.478, batch=231 
2636: loss=0.324, reward_mean=0.140, reward_bound=0.478, batch=228 
2637: loss=0.324, reward_mean=0.240, reward_bound=0.392, batch=229 
2638: loss=0.328, reward_mean=0.140, reward_bound=0.450, batch=230 
2639: loss=0.327, reward_mean=0.180, reward_bound=0.451, batch=231 
2640: loss=0.326, reward_mean=0.140, reward_bound=0.478, batch=230 
2641: loss=0.329, reward_mean=0.240, reward_bound=0.515, batch=231 
2642: loss=0.329, reward_mean=0.190, reward_bound=0.430, batch=231 
2643: loss=0.329, reward_mean=0.170, reward_bound=0.478, batch=231 
2645: loss=0.307, reward_mean=0.190, reward_bound=0.000, batch=19 
2646: loss=0.351, reward_mean=0.190, reward_bound=0.000, batch=38 
2647: loss=0.351, reward_mean=0.180, reward_bound=0.000, batch=56 
2648: loss=0.342, reward_mean=0.170, reward_bound=0.000, batch=73 
2649: loss=0.318, reward_mean=0.150, reward_bound=0.000, batch=88 
2650: loss=0.315, reward_mean=0.140, reward_bound=0.000, batch=102 
2651: loss=0.315, reward_mean=0.200, reward_bound=0.000, batch=122 
2652: loss=0.311, reward_mean=0.190, reward_bound=0.000, batch=141 
2653: loss=0.306, reward_mean=0.180, reward_bound=0.000, batch=159 
2654: loss=0.302, reward_mean=0.170, reward_bound=0.000, batch=176 
2655: loss=0.300, reward_mean=0.170, reward_bound=0.000, batch=193 
2656: loss=0.309, reward_mean=0.270, reward_bound=0.034, batch=204 
2657: loss=0.305, reward_mean=0.090, reward_bound=0.012, batch=213 
2658: loss=0.306, reward_mean=0.170, reward_bound=0.047, batch=217 
2659: loss=0.299, reward_mean=0.190, reward_bound=0.065, batch=220 
2660: loss=0.302, reward_mean=0.110, reward_bound=0.080, batch=215 
2661: loss=0.310, reward_mean=0.200, reward_bound=0.098, batch=213 
2662: loss=0.314, reward_mean=0.200, reward_bound=0.109, batch=217 
2663: loss=0.315, reward_mean=0.190, reward_bound=0.122, batch=221 
2664: loss=0.325, reward_mean=0.220, reward_bound=0.150, batch=205 
2665: loss=0.323, reward_mean=0.200, reward_bound=0.153, batch=213 
2666: loss=0.320, reward_mean=0.180, reward_bound=0.167, batch=203 
2667: loss=0.327, reward_mean=0.160, reward_bound=0.185, batch=196 
2668: loss=0.328, reward_mean=0.250, reward_bound=0.206, batch=187 
2669: loss=0.320, reward_mean=0.190, reward_bound=0.037, batch=201 
2670: loss=0.324, reward_mean=0.170, reward_bound=0.065, batch=210 
2671: loss=0.325, reward_mean=0.160, reward_bound=0.118, batch=217 
2672: loss=0.319, reward_mean=0.170, reward_bound=0.150, batch=221 
2673: loss=0.322, reward_mean=0.240, reward_bound=0.206, batch=223 
2674: loss=0.338, reward_mean=0.300, reward_bound=0.229, batch=204 
2675: loss=0.334, reward_mean=0.280, reward_bound=0.229, batch=211 
2676: loss=0.343, reward_mean=0.250, reward_bound=0.254, batch=176 
2677: loss=0.343, reward_mean=0.260, reward_bound=0.089, batch=193 
2678: loss=0.337, reward_mean=0.300, reward_bound=0.185, batch=203 
2679: loss=0.333, reward_mean=0.250, reward_bound=0.198, batch=212 
2680: loss=0.331, reward_mean=0.240, reward_bound=0.236, batch=218 
2681: loss=0.333, reward_mean=0.250, reward_bound=0.254, batch=220 
2682: loss=0.332, reward_mean=0.150, reward_bound=0.247, batch=224 
2683: loss=0.332, reward_mean=0.200, reward_bound=0.282, batch=195 
2684: loss=0.328, reward_mean=0.220, reward_bound=0.153, batch=206 
2685: loss=0.331, reward_mean=0.260, reward_bound=0.186, batch=214 
2686: loss=0.325, reward_mean=0.180, reward_bound=0.229, batch=215 
2687: loss=0.328, reward_mean=0.190, reward_bound=0.260, batch=220 
2688: loss=0.332, reward_mean=0.210, reward_bound=0.282, batch=222 
2689: loss=0.324, reward_mean=0.250, reward_bound=0.314, batch=171 
2690: loss=0.318, reward_mean=0.180, reward_bound=0.000, batch=189 
2691: loss=0.320, reward_mean=0.180, reward_bound=0.040, batch=202 
2692: loss=0.328, reward_mean=0.130, reward_bound=0.044, batch=211 
2693: loss=0.319, reward_mean=0.230, reward_bound=0.098, batch=217 
2694: loss=0.321, reward_mean=0.220, reward_bound=0.182, batch=222 
2695: loss=0.325, reward_mean=0.190, reward_bound=0.185, batch=223 
2696: loss=0.328, reward_mean=0.140, reward_bound=0.229, batch=224 
2697: loss=0.328, reward_mean=0.170, reward_bound=0.254, batch=226 
2698: loss=0.321, reward_mean=0.210, reward_bound=0.282, batch=220 
2699: loss=0.314, reward_mean=0.290, reward_bound=0.314, batch=218 
2700: loss=0.313, reward_mean=0.200, reward_bound=0.254, batch=221 
2701: loss=0.317, reward_mean=0.200, reward_bound=0.314, batch=224 
2702: loss=0.311, reward_mean=0.290, reward_bound=0.349, batch=175 
2703: loss=0.308, reward_mean=0.240, reward_bound=0.035, batch=192 
2704: loss=0.308, reward_mean=0.170, reward_bound=0.054, batch=204 
2705: loss=0.305, reward_mean=0.220, reward_bound=0.089, batch=212 
2706: loss=0.304, reward_mean=0.220, reward_bound=0.126, batch=218 
2707: loss=0.301, reward_mean=0.150, reward_bound=0.167, batch=220 
2708: loss=0.301, reward_mean=0.200, reward_bound=0.206, batch=226 
2709: loss=0.301, reward_mean=0.210, reward_bound=0.229, batch=225 
2710: loss=0.304, reward_mean=0.190, reward_bound=0.254, batch=224 
2711: loss=0.308, reward_mean=0.230, reward_bound=0.282, batch=218 
2712: loss=0.307, reward_mean=0.180, reward_bound=0.286, batch=222 
2713: loss=0.306, reward_mean=0.210, reward_bound=0.282, batch=224 
2714: loss=0.309, reward_mean=0.190, reward_bound=0.314, batch=216 
2715: loss=0.311, reward_mean=0.210, reward_bound=0.284, batch=221 
2716: loss=0.307, reward_mean=0.160, reward_bound=0.314, batch=224 
2717: loss=0.307, reward_mean=0.250, reward_bound=0.349, batch=219 
2718: loss=0.309, reward_mean=0.230, reward_bound=0.278, batch=223 
2719: loss=0.302, reward_mean=0.190, reward_bound=0.314, batch=224 
2720: loss=0.304, reward_mean=0.200, reward_bound=0.387, batch=151 
2721: loss=0.291, reward_mean=0.120, reward_bound=0.000, batch=163 
2722: loss=0.287, reward_mean=0.160, reward_bound=0.000, batch=179 
2723: loss=0.286, reward_mean=0.180, reward_bound=0.007, batch=195 
2724: loss=0.294, reward_mean=0.220, reward_bound=0.032, batch=206 
2725: loss=0.308, reward_mean=0.280, reward_bound=0.089, batch=211 
2726: loss=0.307, reward_mean=0.240, reward_bound=0.109, batch=216 
2727: loss=0.312, reward_mean=0.190, reward_bound=0.122, batch=219 
2728: loss=0.316, reward_mean=0.190, reward_bound=0.150, batch=220 
2729: loss=0.317, reward_mean=0.220, reward_bound=0.180, batch=224 
2730: loss=0.312, reward_mean=0.250, reward_bound=0.206, batch=224 
2731: loss=0.306, reward_mean=0.240, reward_bound=0.254, batch=223 
2732: loss=0.303, reward_mean=0.160, reward_bound=0.282, batch=214 
2733: loss=0.305, reward_mean=0.190, reward_bound=0.311, batch=220 
2734: loss=0.301, reward_mean=0.220, reward_bound=0.314, batch=209 
2735: loss=0.299, reward_mean=0.210, reward_bound=0.229, batch=215 
2736: loss=0.300, reward_mean=0.340, reward_bound=0.282, batch=219 
2737: loss=0.304, reward_mean=0.210, reward_bound=0.225, batch=223 
2738: loss=0.303, reward_mean=0.310, reward_bound=0.335, batch=226 
2739: loss=0.302, reward_mean=0.180, reward_bound=0.271, batch=228 
2740: loss=0.307, reward_mean=0.230, reward_bound=0.349, batch=207 
2741: loss=0.307, reward_mean=0.230, reward_bound=0.185, batch=214 
2742: loss=0.306, reward_mean=0.160, reward_bound=0.221, batch=220 
2743: loss=0.305, reward_mean=0.180, reward_bound=0.229, batch=221 
2744: loss=0.310, reward_mean=0.210, reward_bound=0.314, batch=224 
2745: loss=0.307, reward_mean=0.210, reward_bound=0.349, batch=222 
2746: loss=0.306, reward_mean=0.280, reward_bound=0.292, batch=225 
2747: loss=0.309, reward_mean=0.210, reward_bound=0.314, batch=226 
2748: loss=0.312, reward_mean=0.290, reward_bound=0.289, batch=228 
2749: loss=0.310, reward_mean=0.170, reward_bound=0.387, batch=201 
2750: loss=0.300, reward_mean=0.220, reward_bound=0.167, batch=210 
2751: loss=0.316, reward_mean=0.270, reward_bound=0.282, batch=215 
2752: loss=0.311, reward_mean=0.220, reward_bound=0.314, batch=218 
2753: loss=0.312, reward_mean=0.240, reward_bound=0.282, batch=221 
2754: loss=0.310, reward_mean=0.280, reward_bound=0.314, batch=224 
2755: loss=0.307, reward_mean=0.230, reward_bound=0.345, batch=227 
2756: loss=0.309, reward_mean=0.220, reward_bound=0.349, batch=220 
2757: loss=0.303, reward_mean=0.230, reward_bound=0.387, batch=218 
2758: loss=0.304, reward_mean=0.230, reward_bound=0.317, batch=222 
2759: loss=0.306, reward_mean=0.190, reward_bound=0.314, batch=223 
2760: loss=0.307, reward_mean=0.160, reward_bound=0.314, batch=225 
2761: loss=0.302, reward_mean=0.220, reward_bound=0.349, batch=225 
2762: loss=0.304, reward_mean=0.190, reward_bound=0.387, batch=225 
2763: loss=0.303, reward_mean=0.220, reward_bound=0.396, batch=227 
2764: loss=0.302, reward_mean=0.280, reward_bound=0.380, batch=229 
2765: loss=0.302, reward_mean=0.220, reward_bound=0.387, batch=229 
2766: loss=0.302, reward_mean=0.260, reward_bound=0.360, batch=230 
2767: loss=0.264, reward_mean=0.260, reward_bound=0.430, batch=134 
2768: loss=0.270, reward_mean=0.180, reward_bound=0.000, batch=152 
2769: loss=0.262, reward_mean=0.190, reward_bound=0.000, batch=171 
2770: loss=0.268, reward_mean=0.320, reward_bound=0.038, batch=186 
2771: loss=0.265, reward_mean=0.230, reward_bound=0.058, batch=197 
2772: loss=0.274, reward_mean=0.250, reward_bound=0.065, batch=205 
2773: loss=0.275, reward_mean=0.230, reward_bound=0.080, batch=212 
2774: loss=0.270, reward_mean=0.300, reward_bound=0.109, batch=214 
2775: loss=0.272, reward_mean=0.280, reward_bound=0.150, batch=216 
2776: loss=0.272, reward_mean=0.220, reward_bound=0.167, batch=218 
2777: loss=0.267, reward_mean=0.230, reward_bound=0.185, batch=217 
2778: loss=0.264, reward_mean=0.280, reward_bound=0.206, batch=218 
2779: loss=0.266, reward_mean=0.210, reward_bound=0.208, batch=222 
2780: loss=0.254, reward_mean=0.260, reward_bound=0.229, batch=222 
2781: loss=0.254, reward_mean=0.250, reward_bound=0.206, batch=226 
2782: loss=0.251, reward_mean=0.250, reward_bound=0.229, batch=227 
2783: loss=0.258, reward_mean=0.190, reward_bound=0.254, batch=217 
2784: loss=0.258, reward_mean=0.250, reward_bound=0.249, batch=222 
2785: loss=0.258, reward_mean=0.200, reward_bound=0.236, batch=225 
2786: loss=0.263, reward_mean=0.280, reward_bound=0.282, batch=212 
2787: loss=0.259, reward_mean=0.210, reward_bound=0.236, batch=218 
2788: loss=0.261, reward_mean=0.250, reward_bound=0.254, batch=221 
2789: loss=0.256, reward_mean=0.200, reward_bound=0.282, batch=221 
2790: loss=0.260, reward_mean=0.240, reward_bound=0.314, batch=204 
2791: loss=0.269, reward_mean=0.180, reward_bound=0.120, batch=213 
2792: loss=0.262, reward_mean=0.110, reward_bound=0.139, batch=219 
2793: loss=0.255, reward_mean=0.290, reward_bound=0.206, batch=220 
2794: loss=0.259, reward_mean=0.270, reward_bound=0.254, batch=222 
2795: loss=0.263, reward_mean=0.270, reward_bound=0.314, batch=223 
2796: loss=0.259, reward_mean=0.300, reward_bound=0.349, batch=204 
2797: loss=0.259, reward_mean=0.220, reward_bound=0.109, batch=212 
2798: loss=0.266, reward_mean=0.210, reward_bound=0.145, batch=218 
2799: loss=0.261, reward_mean=0.260, reward_bound=0.185, batch=220 
2800: loss=0.263, reward_mean=0.320, reward_bound=0.254, batch=222 
2801: loss=0.264, reward_mean=0.230, reward_bound=0.314, batch=223 
2802: loss=0.263, reward_mean=0.230, reward_bound=0.314, batch=224 
2803: loss=0.260, reward_mean=0.300, reward_bound=0.349, batch=224 
2804: loss=0.259, reward_mean=0.230, reward_bound=0.282, batch=225 
2805: loss=0.259, reward_mean=0.260, reward_bound=0.349, batch=225 
2806: loss=0.261, reward_mean=0.280, reward_bound=0.387, batch=200 
2807: loss=0.257, reward_mean=0.320, reward_bound=0.180, batch=210 
2808: loss=0.259, reward_mean=0.330, reward_bound=0.206, batch=220 
2809: loss=0.265, reward_mean=0.220, reward_bound=0.206, batch=228 
2810: loss=0.268, reward_mean=0.260, reward_bound=0.254, batch=227 
2811: loss=0.267, reward_mean=0.210, reward_bound=0.282, batch=222 
2812: loss=0.267, reward_mean=0.340, reward_bound=0.314, batch=222 
2813: loss=0.268, reward_mean=0.220, reward_bound=0.245, batch=225 
2814: loss=0.264, reward_mean=0.300, reward_bound=0.349, batch=224 
2815: loss=0.263, reward_mean=0.150, reward_bound=0.345, batch=227 
2816: loss=0.261, reward_mean=0.260, reward_bound=0.349, batch=228 
2817: loss=0.263, reward_mean=0.270, reward_bound=0.387, batch=217 
2818: loss=0.262, reward_mean=0.240, reward_bound=0.314, batch=221 
2819: loss=0.262, reward_mean=0.260, reward_bound=0.282, batch=224 
2820: loss=0.263, reward_mean=0.150, reward_bound=0.277, batch=227 
2821: loss=0.262, reward_mean=0.190, reward_bound=0.349, batch=228 
2822: loss=0.261, reward_mean=0.210, reward_bound=0.387, batch=227 
2823: loss=0.252, reward_mean=0.250, reward_bound=0.430, batch=184 
2824: loss=0.249, reward_mean=0.310, reward_bound=0.134, batch=199 
2825: loss=0.253, reward_mean=0.190, reward_bound=0.174, batch=209 
2826: loss=0.254, reward_mean=0.250, reward_bound=0.229, batch=212 
2827: loss=0.253, reward_mean=0.160, reward_bound=0.105, batch=218 
2828: loss=0.250, reward_mean=0.240, reward_bound=0.254, batch=215 
2829: loss=0.243, reward_mean=0.220, reward_bound=0.282, batch=216 
2830: loss=0.243, reward_mean=0.210, reward_bound=0.241, batch=221 
2831: loss=0.248, reward_mean=0.290, reward_bound=0.314, batch=219 
2832: loss=0.248, reward_mean=0.290, reward_bound=0.292, batch=223 
2833: loss=0.249, reward_mean=0.240, reward_bound=0.335, batch=226 
2834: loss=0.246, reward_mean=0.200, reward_bound=0.349, batch=222 
2835: loss=0.248, reward_mean=0.310, reward_bound=0.324, batch=225 
2836: loss=0.247, reward_mean=0.190, reward_bound=0.356, batch=227 
2837: loss=0.249, reward_mean=0.230, reward_bound=0.387, batch=208 
2838: loss=0.246, reward_mean=0.280, reward_bound=0.231, batch=215 
2839: loss=0.250, reward_mean=0.230, reward_bound=0.229, batch=219 
2840: loss=0.252, reward_mean=0.250, reward_bound=0.254, batch=222 
2841: loss=0.249, reward_mean=0.330, reward_bound=0.292, batch=225 
2842: loss=0.254, reward_mean=0.200, reward_bound=0.314, batch=225 
2843: loss=0.256, reward_mean=0.250, reward_bound=0.349, batch=220 
2844: loss=0.254, reward_mean=0.240, reward_bound=0.274, batch=224 
2845: loss=0.252, reward_mean=0.210, reward_bound=0.282, batch=225 
2846: loss=0.252, reward_mean=0.260, reward_bound=0.314, batch=226 
2847: loss=0.255, reward_mean=0.250, reward_bound=0.387, batch=224 
2848: loss=0.254, reward_mean=0.290, reward_bound=0.426, batch=227 
2849: loss=0.254, reward_mean=0.200, reward_bound=0.387, batch=228 
2850: loss=0.265, reward_mean=0.270, reward_bound=0.430, batch=216 
2851: loss=0.264, reward_mean=0.250, reward_bound=0.268, batch=221 
2852: loss=0.262, reward_mean=0.250, reward_bound=0.314, batch=223 
2853: loss=0.261, reward_mean=0.230, reward_bound=0.254, batch=225 
2854: loss=0.265, reward_mean=0.260, reward_bound=0.387, batch=223 
2855: loss=0.269, reward_mean=0.190, reward_bound=0.322, batch=226 
2856: loss=0.268, reward_mean=0.240, reward_bound=0.409, batch=228 
2857: loss=0.268, reward_mean=0.180, reward_bound=0.392, batch=229 
2858: loss=0.265, reward_mean=0.300, reward_bound=0.430, batch=223 
2859: loss=0.265, reward_mean=0.160, reward_bound=0.271, batch=226 
2860: loss=0.266, reward_mean=0.220, reward_bound=0.331, batch=228 
2861: loss=0.265, reward_mean=0.230, reward_bound=0.349, batch=227 
2862: loss=0.266, reward_mean=0.220, reward_bound=0.380, batch=229 
2863: loss=0.268, reward_mean=0.180, reward_bound=0.328, batch=230 
2864: loss=0.267, reward_mean=0.310, reward_bound=0.387, batch=228 
2865: loss=0.267, reward_mean=0.160, reward_bound=0.430, batch=228 
2866: loss=0.266, reward_mean=0.200, reward_bound=0.392, batch=229 
2867: loss=0.267, reward_mean=0.250, reward_bound=0.450, batch=230 
2868: loss=0.269, reward_mean=0.210, reward_bound=0.386, batch=231 
2869: loss=0.267, reward_mean=0.280, reward_bound=0.430, batch=231 
2870: loss=0.296, reward_mean=0.300, reward_bound=0.478, batch=92 
2871: loss=0.245, reward_mean=0.310, reward_bound=0.000, batch=123 
2872: loss=0.239, reward_mean=0.200, reward_bound=0.000, batch=143 
2873: loss=0.241, reward_mean=0.230, reward_bound=0.000, batch=166 
2874: loss=0.256, reward_mean=0.290, reward_bound=0.018, batch=184 
2875: loss=0.257, reward_mean=0.270, reward_bound=0.037, batch=199 
2876: loss=0.250, reward_mean=0.230, reward_bound=0.052, batch=208 
2877: loss=0.250, reward_mean=0.270, reward_bound=0.072, batch=214 
2878: loss=0.250, reward_mean=0.200, reward_bound=0.088, batch=220 
2879: loss=0.261, reward_mean=0.270, reward_bound=0.109, batch=222 
2880: loss=0.272, reward_mean=0.230, reward_bound=0.122, batch=217 
2881: loss=0.270, reward_mean=0.210, reward_bound=0.135, batch=221 
2882: loss=0.266, reward_mean=0.240, reward_bound=0.150, batch=219 
2883: loss=0.274, reward_mean=0.280, reward_bound=0.185, batch=207 
2884: loss=0.283, reward_mean=0.390, reward_bound=0.206, batch=212 
2885: loss=0.286, reward_mean=0.250, reward_bound=0.229, batch=209 
2886: loss=0.285, reward_mean=0.310, reward_bound=0.229, batch=215 
2887: loss=0.291, reward_mean=0.310, reward_bound=0.254, batch=202 
2888: loss=0.286, reward_mean=0.270, reward_bound=0.191, batch=211 
2889: loss=0.285, reward_mean=0.280, reward_bound=0.254, batch=216 
2890: loss=0.290, reward_mean=0.280, reward_bound=0.282, batch=200 
2891: loss=0.284, reward_mean=0.320, reward_bound=0.247, batch=210 
2892: loss=0.283, reward_mean=0.270, reward_bound=0.200, batch=217 
2893: loss=0.282, reward_mean=0.270, reward_bound=0.224, batch=222 
2894: loss=0.282, reward_mean=0.260, reward_bound=0.236, batch=225 
2895: loss=0.275, reward_mean=0.290, reward_bound=0.254, batch=225 
2896: loss=0.280, reward_mean=0.290, reward_bound=0.282, batch=225 
2897: loss=0.289, reward_mean=0.350, reward_bound=0.314, batch=196 
2898: loss=0.290, reward_mean=0.240, reward_bound=0.143, batch=207 
2899: loss=0.282, reward_mean=0.360, reward_bound=0.229, batch=212 
2900: loss=0.285, reward_mean=0.350, reward_bound=0.282, batch=215 
2901: loss=0.286, reward_mean=0.330, reward_bound=0.260, batch=220 
2902: loss=0.290, reward_mean=0.300, reward_bound=0.254, batch=223 
2903: loss=0.292, reward_mean=0.190, reward_bound=0.229, batch=225 
2904: loss=0.292, reward_mean=0.180, reward_bound=0.282, batch=226 
2905: loss=0.289, reward_mean=0.270, reward_bound=0.331, batch=228 
2906: loss=0.293, reward_mean=0.290, reward_bound=0.349, batch=203 
2907: loss=0.298, reward_mean=0.300, reward_bound=0.229, batch=211 
2908: loss=0.292, reward_mean=0.260, reward_bound=0.229, batch=217 
2909: loss=0.300, reward_mean=0.260, reward_bound=0.254, batch=220 
2910: loss=0.299, reward_mean=0.240, reward_bound=0.282, batch=220 
2911: loss=0.300, reward_mean=0.230, reward_bound=0.314, batch=221 
2912: loss=0.299, reward_mean=0.300, reward_bound=0.349, batch=217 
2913: loss=0.300, reward_mean=0.270, reward_bound=0.349, batch=220 
2914: loss=0.300, reward_mean=0.260, reward_bound=0.314, batch=223 
2915: loss=0.300, reward_mean=0.310, reward_bound=0.345, batch=226 
2916: loss=0.301, reward_mean=0.190, reward_bound=0.331, batch=228 
2917: loss=0.298, reward_mean=0.250, reward_bound=0.353, batch=229 
2918: loss=0.294, reward_mean=0.280, reward_bound=0.387, batch=184 
2919: loss=0.283, reward_mean=0.240, reward_bound=0.120, batch=199 
2920: loss=0.296, reward_mean=0.250, reward_bound=0.135, batch=207 
2921: loss=0.296, reward_mean=0.300, reward_bound=0.167, batch=207 
2922: loss=0.301, reward_mean=0.270, reward_bound=0.185, batch=213 
2923: loss=0.302, reward_mean=0.320, reward_bound=0.229, batch=213 
2924: loss=0.301, reward_mean=0.220, reward_bound=0.211, batch=219 
2925: loss=0.297, reward_mean=0.210, reward_bound=0.229, batch=222 
2926: loss=0.303, reward_mean=0.280, reward_bound=0.254, batch=224 
2927: loss=0.305, reward_mean=0.250, reward_bound=0.280, batch=227 
2928: loss=0.304, reward_mean=0.260, reward_bound=0.282, batch=228 
2929: loss=0.301, reward_mean=0.270, reward_bound=0.314, batch=221 
2930: loss=0.303, reward_mean=0.290, reward_bound=0.314, batch=224 
2931: loss=0.293, reward_mean=0.250, reward_bound=0.349, batch=215 
2932: loss=0.291, reward_mean=0.270, reward_bound=0.321, batch=220 
2933: loss=0.291, reward_mean=0.240, reward_bound=0.304, batch=224 
2934: loss=0.294, reward_mean=0.240, reward_bound=0.314, batch=226 
2935: loss=0.291, reward_mean=0.270, reward_bound=0.349, batch=225 
2936: loss=0.297, reward_mean=0.280, reward_bound=0.387, batch=200 
2937: loss=0.294, reward_mean=0.290, reward_bound=0.131, batch=210 
2938: loss=0.293, reward_mean=0.300, reward_bound=0.180, batch=217 
2939: loss=0.300, reward_mean=0.240, reward_bound=0.206, batch=218 
2940: loss=0.303, reward_mean=0.260, reward_bound=0.229, batch=218 
2941: loss=0.301, reward_mean=0.240, reward_bound=0.231, batch=222 
2942: loss=0.296, reward_mean=0.300, reward_bound=0.282, batch=222 
2943: loss=0.292, reward_mean=0.300, reward_bound=0.292, batch=225 
2944: loss=0.288, reward_mean=0.320, reward_bound=0.314, batch=226 
2945: loss=0.288, reward_mean=0.150, reward_bound=0.349, batch=223 
2946: loss=0.289, reward_mean=0.320, reward_bound=0.314, batch=224 
2947: loss=0.286, reward_mean=0.280, reward_bound=0.311, batch=227 
2948: loss=0.286, reward_mean=0.220, reward_bound=0.342, batch=229 
2949: loss=0.293, reward_mean=0.280, reward_bound=0.387, batch=220 
2950: loss=0.292, reward_mean=0.300, reward_bound=0.304, batch=224 
2951: loss=0.294, reward_mean=0.290, reward_bound=0.349, batch=226 
2952: loss=0.296, reward_mean=0.230, reward_bound=0.409, batch=228 
2953: loss=0.308, reward_mean=0.280, reward_bound=0.430, batch=162 
2954: loss=0.284, reward_mean=0.200, reward_bound=0.000, batch=182 
2955: loss=0.293, reward_mean=0.300, reward_bound=0.069, batch=197 
2956: loss=0.294, reward_mean=0.280, reward_bound=0.098, batch=205 
2957: loss=0.298, reward_mean=0.300, reward_bound=0.138, batch=213 
2958: loss=0.295, reward_mean=0.270, reward_bound=0.160, batch=219 
2959: loss=0.300, reward_mean=0.250, reward_bound=0.185, batch=215 
2960: loss=0.300, reward_mean=0.190, reward_bound=0.206, batch=213 
2961: loss=0.298, reward_mean=0.220, reward_bound=0.229, batch=213 
2962: loss=0.294, reward_mean=0.260, reward_bound=0.254, batch=214 
2963: loss=0.294, reward_mean=0.210, reward_bound=0.280, batch=220 
2964: loss=0.298, reward_mean=0.210, reward_bound=0.282, batch=213 
2965: loss=0.294, reward_mean=0.230, reward_bound=0.254, batch=218 
2966: loss=0.292, reward_mean=0.240, reward_bound=0.254, batch=221 
2967: loss=0.290, reward_mean=0.240, reward_bound=0.282, batch=223 
2968: loss=0.294, reward_mean=0.280, reward_bound=0.314, batch=214 
2969: loss=0.286, reward_mean=0.280, reward_bound=0.349, batch=209 
2970: loss=0.283, reward_mean=0.290, reward_bound=0.215, batch=216 
2971: loss=0.282, reward_mean=0.260, reward_bound=0.298, batch=221 
2972: loss=0.288, reward_mean=0.180, reward_bound=0.314, batch=222 
2973: loss=0.287, reward_mean=0.280, reward_bound=0.324, batch=225 
2974: loss=0.285, reward_mean=0.280, reward_bound=0.349, batch=226 
2975: loss=0.296, reward_mean=0.270, reward_bound=0.387, batch=202 
2976: loss=0.283, reward_mean=0.210, reward_bound=0.185, batch=210 
2977: loss=0.287, reward_mean=0.220, reward_bound=0.229, batch=216 
2978: loss=0.288, reward_mean=0.200, reward_bound=0.241, batch=221 
2979: loss=0.294, reward_mean=0.290, reward_bound=0.282, batch=223 
2980: loss=0.300, reward_mean=0.170, reward_bound=0.314, batch=218 
2981: loss=0.300, reward_mean=0.260, reward_bound=0.349, batch=218 
2982: loss=0.298, reward_mean=0.250, reward_bound=0.282, batch=220 
2983: loss=0.299, reward_mean=0.220, reward_bound=0.349, batch=222 
2984: loss=0.300, reward_mean=0.260, reward_bound=0.292, batch=225 
2985: loss=0.295, reward_mean=0.220, reward_bound=0.356, batch=227 
2986: loss=0.294, reward_mean=0.290, reward_bound=0.387, batch=218 
2987: loss=0.292, reward_mean=0.280, reward_bound=0.231, batch=222 
2988: loss=0.298, reward_mean=0.220, reward_bound=0.314, batch=224 
2989: loss=0.308, reward_mean=0.260, reward_bound=0.384, batch=227 
2990: loss=0.310, reward_mean=0.240, reward_bound=0.373, batch=229 
2991: loss=0.309, reward_mean=0.290, reward_bound=0.430, batch=199 
2992: loss=0.299, reward_mean=0.230, reward_bound=0.075, batch=209 
2993: loss=0.305, reward_mean=0.220, reward_bound=0.229, batch=215 
2994: loss=0.303, reward_mean=0.190, reward_bound=0.234, batch=220 
2995: loss=0.303, reward_mean=0.270, reward_bound=0.282, batch=222 
2996: loss=0.309, reward_mean=0.190, reward_bound=0.272, batch=225 
2997: loss=0.317, reward_mean=0.310, reward_bound=0.349, batch=217 
2998: loss=0.318, reward_mean=0.300, reward_bound=0.342, batch=222 
2999: loss=0.320, reward_mean=0.240, reward_bound=0.324, batch=225 
3000: loss=0.320, reward_mean=0.190, reward_bound=0.321, batch=227 
3001: loss=0.310, reward_mean=0.270, reward_bound=0.387, batch=216 
3002: loss=0.311, reward_mean=0.200, reward_bound=0.196, batch=221 
3003: loss=0.313, reward_mean=0.220, reward_bound=0.254, batch=224 
3004: loss=0.318, reward_mean=0.270, reward_bound=0.314, batch=225 
3005: loss=0.311, reward_mean=0.250, reward_bound=0.387, batch=223 
3006: loss=0.310, reward_mean=0.120, reward_bound=0.301, batch=226 
3007: loss=0.311, reward_mean=0.300, reward_bound=0.387, batch=226 
3008: loss=0.310, reward_mean=0.250, reward_bound=0.409, batch=228 
3009: loss=0.304, reward_mean=0.280, reward_bound=0.430, batch=222 
3010: loss=0.303, reward_mean=0.190, reward_bound=0.276, batch=225 
3011: loss=0.304, reward_mean=0.180, reward_bound=0.387, batch=226 
3012: loss=0.302, reward_mean=0.230, reward_bound=0.409, batch=228 
3013: loss=0.303, reward_mean=0.270, reward_bound=0.353, batch=229 
3014: loss=0.304, reward_mean=0.190, reward_bound=0.364, batch=230 
3015: loss=0.301, reward_mean=0.220, reward_bound=0.387, batch=230 
3016: loss=0.301, reward_mean=0.270, reward_bound=0.349, batch=230 
3017: loss=0.303, reward_mean=0.320, reward_bound=0.430, batch=228 
3018: loss=0.301, reward_mean=0.240, reward_bound=0.435, batch=229 
3019: loss=0.300, reward_mean=0.240, reward_bound=0.405, batch=230 
3020: loss=0.304, reward_mean=0.200, reward_bound=0.340, batch=231 
3021: loss=0.300, reward_mean=0.270, reward_bound=0.387, batch=231 
3022: loss=0.301, reward_mean=0.300, reward_bound=0.430, batch=231 
3023: loss=0.301, reward_mean=0.190, reward_bound=0.430, batch=231 
3024: loss=0.301, reward_mean=0.230, reward_bound=0.430, batch=231 
3025: loss=0.301, reward_mean=0.260, reward_bound=0.430, batch=231 
3026: loss=0.302, reward_mean=0.230, reward_bound=0.430, batch=231 
3027: loss=0.302, reward_mean=0.230, reward_bound=0.430, batch=231 
3028: loss=0.296, reward_mean=0.330, reward_bound=0.478, batch=151 
3029: loss=0.290, reward_mean=0.300, reward_bound=0.058, batch=175 
3030: loss=0.280, reward_mean=0.150, reward_bound=0.000, batch=190 
3031: loss=0.293, reward_mean=0.210, reward_bound=0.024, batch=203 
3032: loss=0.292, reward_mean=0.300, reward_bound=0.072, batch=211 
3033: loss=0.288, reward_mean=0.310, reward_bound=0.122, batch=217 
3034: loss=0.286, reward_mean=0.210, reward_bound=0.167, batch=217 
3035: loss=0.295, reward_mean=0.230, reward_bound=0.206, batch=215 
3036: loss=0.292, reward_mean=0.230, reward_bound=0.153, batch=220 
3037: loss=0.286, reward_mean=0.280, reward_bound=0.229, batch=216 
3038: loss=0.290, reward_mean=0.240, reward_bound=0.254, batch=215 
3039: loss=0.299, reward_mean=0.220, reward_bound=0.282, batch=204 
3040: loss=0.305, reward_mean=0.190, reward_bound=0.226, batch=213 
3041: loss=0.302, reward_mean=0.260, reward_bound=0.254, batch=216 
3042: loss=0.300, reward_mean=0.230, reward_bound=0.150, batch=219 
3043: loss=0.299, reward_mean=0.200, reward_bound=0.265, batch=223 
3044: loss=0.292, reward_mean=0.260, reward_bound=0.314, batch=214 
3045: loss=0.295, reward_mean=0.220, reward_bound=0.308, batch=220 
3046: loss=0.298, reward_mean=0.290, reward_bound=0.338, batch=224 
3047: loss=0.298, reward_mean=0.190, reward_bound=0.314, batch=226 
3048: loss=0.296, reward_mean=0.310, reward_bound=0.349, batch=207 
3049: loss=0.292, reward_mean=0.350, reward_bound=0.229, batch=214 
3050: loss=0.290, reward_mean=0.240, reward_bound=0.311, batch=220 
3051: loss=0.288, reward_mean=0.230, reward_bound=0.266, batch=224 
3052: loss=0.287, reward_mean=0.240, reward_bound=0.282, batch=226 
3053: loss=0.287, reward_mean=0.230, reward_bound=0.331, batch=228 
3054: loss=0.295, reward_mean=0.230, reward_bound=0.387, batch=203 
3055: loss=0.286, reward_mean=0.240, reward_bound=0.144, batch=212 
3056: loss=0.290, reward_mean=0.220, reward_bound=0.263, batch=218 
3057: loss=0.293, reward_mean=0.210, reward_bound=0.314, batch=218 
3058: loss=0.289, reward_mean=0.250, reward_bound=0.349, batch=217 
3059: loss=0.286, reward_mean=0.210, reward_bound=0.224, batch=222 
3060: loss=0.288, reward_mean=0.280, reward_bound=0.349, batch=223 
3061: loss=0.286, reward_mean=0.240, reward_bound=0.349, batch=225 
3062: loss=0.290, reward_mean=0.250, reward_bound=0.387, batch=225 
3063: loss=0.288, reward_mean=0.180, reward_bound=0.289, batch=227 
3064: loss=0.288, reward_mean=0.240, reward_bound=0.349, batch=227 
3065: loss=0.289, reward_mean=0.310, reward_bound=0.349, batch=228 
3066: loss=0.289, reward_mean=0.210, reward_bound=0.325, batch=229 
3067: loss=0.290, reward_mean=0.260, reward_bound=0.364, batch=230 
3068: loss=0.290, reward_mean=0.220, reward_bound=0.329, batch=231 
3069: loss=0.288, reward_mean=0.270, reward_bound=0.387, batch=230 
3070: loss=0.305, reward_mean=0.260, reward_bound=0.430, batch=192 
3071: loss=0.302, reward_mean=0.220, reward_bound=0.109, batch=203 
3072: loss=0.310, reward_mean=0.250, reward_bound=0.185, batch=211 
3073: loss=0.309, reward_mean=0.260, reward_bound=0.229, batch=216 
3074: loss=0.304, reward_mean=0.230, reward_bound=0.230, batch=221 
3075: loss=0.305, reward_mean=0.230, reward_bound=0.254, batch=224 
3076: loss=0.302, reward_mean=0.300, reward_bound=0.282, batch=223 
3077: loss=0.305, reward_mean=0.280, reward_bound=0.290, batch=226 
3078: loss=0.305, reward_mean=0.200, reward_bound=0.314, batch=220 
3079: loss=0.303, reward_mean=0.180, reward_bound=0.304, batch=224 
3080: loss=0.302, reward_mean=0.230, reward_bound=0.349, batch=219 
3081: loss=0.303, reward_mean=0.230, reward_bound=0.278, batch=223 
3082: loss=0.296, reward_mean=0.280, reward_bound=0.349, batch=225 
3083: loss=0.296, reward_mean=0.300, reward_bound=0.356, batch=227 
3084: loss=0.305, reward_mean=0.250, reward_bound=0.387, batch=215 
3085: loss=0.303, reward_mean=0.290, reward_bound=0.356, batch=220 
3086: loss=0.306, reward_mean=0.230, reward_bound=0.387, batch=218 
3087: loss=0.304, reward_mean=0.290, reward_bound=0.237, batch=222 
3088: loss=0.300, reward_mean=0.310, reward_bound=0.314, batch=224 
3089: loss=0.303, reward_mean=0.290, reward_bound=0.384, batch=227 
3090: loss=0.302, reward_mean=0.220, reward_bound=0.387, batch=226 
3091: loss=0.299, reward_mean=0.190, reward_bound=0.331, batch=228 
3092: loss=0.308, reward_mean=0.270, reward_bound=0.387, batch=228 
3093: loss=0.308, reward_mean=0.280, reward_bound=0.387, batch=228 
3094: loss=0.308, reward_mean=0.240, reward_bound=0.387, batch=228 
3095: loss=0.309, reward_mean=0.210, reward_bound=0.430, batch=220 
3096: loss=0.309, reward_mean=0.180, reward_bound=0.282, batch=222 
3097: loss=0.308, reward_mean=0.190, reward_bound=0.349, batch=223 
3098: loss=0.306, reward_mean=0.180, reward_bound=0.358, batch=226 
3099: loss=0.308, reward_mean=0.170, reward_bound=0.351, batch=228 
3100: loss=0.309, reward_mean=0.180, reward_bound=0.321, batch=229 
3101: loss=0.308, reward_mean=0.250, reward_bound=0.405, batch=230 
3102: loss=0.310, reward_mean=0.200, reward_bound=0.376, batch=231 
3103: loss=0.309, reward_mean=0.250, reward_bound=0.430, batch=225 
3104: loss=0.310, reward_mean=0.220, reward_bound=0.430, batch=226 
3105: loss=0.307, reward_mean=0.170, reward_bound=0.284, batch=228 
3106: loss=0.311, reward_mean=0.160, reward_bound=0.317, batch=229 
3107: loss=0.308, reward_mean=0.280, reward_bound=0.430, batch=228 
3108: loss=0.309, reward_mean=0.190, reward_bound=0.397, batch=229 
3109: loss=0.309, reward_mean=0.210, reward_bound=0.478, batch=231 
3110: loss=0.309, reward_mean=0.270, reward_bound=0.387, batch=231 
3111: loss=0.309, reward_mean=0.260, reward_bound=0.430, batch=231 
3112: loss=0.303, reward_mean=0.290, reward_bound=0.478, batch=195 
3113: loss=0.297, reward_mean=0.220, reward_bound=0.112, batch=206 
3114: loss=0.305, reward_mean=0.250, reward_bound=0.167, batch=211 
3115: loss=0.308, reward_mean=0.250, reward_bound=0.185, batch=216 
3116: loss=0.317, reward_mean=0.240, reward_bound=0.229, batch=217 
3117: loss=0.314, reward_mean=0.260, reward_bound=0.220, batch=222 
3118: loss=0.314, reward_mean=0.220, reward_bound=0.282, batch=220 
3119: loss=0.312, reward_mean=0.200, reward_bound=0.314, batch=217 
3120: loss=0.311, reward_mean=0.240, reward_bound=0.206, batch=221 
3121: loss=0.311, reward_mean=0.240, reward_bound=0.314, batch=223 
3122: loss=0.310, reward_mean=0.190, reward_bound=0.335, batch=226 
3123: loss=0.304, reward_mean=0.180, reward_bound=0.349, batch=221 
3124: loss=0.305, reward_mean=0.280, reward_bound=0.387, batch=215 
3125: loss=0.303, reward_mean=0.260, reward_bound=0.314, batch=219 
3126: loss=0.303, reward_mean=0.270, reward_bound=0.349, batch=220 
3127: loss=0.305, reward_mean=0.260, reward_bound=0.254, batch=223 
3128: loss=0.309, reward_mean=0.180, reward_bound=0.204, batch=226 
3129: loss=0.309, reward_mean=0.250, reward_bound=0.316, batch=228 
3130: loss=0.311, reward_mean=0.260, reward_bound=0.353, batch=229 
3131: loss=0.311, reward_mean=0.210, reward_bound=0.387, batch=226 
3132: loss=0.311, reward_mean=0.250, reward_bound=0.430, batch=212 
3133: loss=0.305, reward_mean=0.240, reward_bound=0.191, batch=218 
3134: loss=0.308, reward_mean=0.210, reward_bound=0.211, batch=222 
3135: loss=0.311, reward_mean=0.200, reward_bound=0.263, batch=225 
3136: loss=0.311, reward_mean=0.270, reward_bound=0.314, batch=224 
3137: loss=0.318, reward_mean=0.260, reward_bound=0.387, batch=225 
3138: loss=0.316, reward_mean=0.140, reward_bound=0.296, batch=227 
3139: loss=0.317, reward_mean=0.280, reward_bound=0.430, batch=224 
3140: loss=0.320, reward_mean=0.230, reward_bound=0.374, batch=227 
3141: loss=0.320, reward_mean=0.320, reward_bound=0.380, batch=229 
3142: loss=0.323, reward_mean=0.220, reward_bound=0.405, batch=230 
3143: loss=0.319, reward_mean=0.290, reward_bound=0.430, batch=228 
3144: loss=0.321, reward_mean=0.230, reward_bound=0.478, batch=230 
3145: loss=0.321, reward_mean=0.240, reward_bound=0.387, batch=230 
3146: loss=0.320, reward_mean=0.260, reward_bound=0.418, batch=231 
3147: loss=0.321, reward_mean=0.230, reward_bound=0.430, batch=230 
3148: loss=0.321, reward_mean=0.190, reward_bound=0.418, batch=231 
3149: loss=0.321, reward_mean=0.230, reward_bound=0.430, batch=230 
3150: loss=0.319, reward_mean=0.240, reward_bound=0.376, batch=231 
3151: loss=0.309, reward_mean=0.340, reward_bound=0.478, batch=209 
3152: loss=0.310, reward_mean=0.250, reward_bound=0.282, batch=214 
3153: loss=0.316, reward_mean=0.260, reward_bound=0.311, batch=220 
3154: loss=0.315, reward_mean=0.260, reward_bound=0.314, batch=222 
3155: loss=0.319, reward_mean=0.220, reward_bound=0.349, batch=223 
3156: loss=0.319, reward_mean=0.140, reward_bound=0.311, batch=226 
3157: loss=0.321, reward_mean=0.230, reward_bound=0.368, batch=228 
3158: loss=0.315, reward_mean=0.280, reward_bound=0.387, batch=222 
3159: loss=0.319, reward_mean=0.170, reward_bound=0.327, batch=225 
3160: loss=0.317, reward_mean=0.280, reward_bound=0.246, batch=227 
3161: loss=0.317, reward_mean=0.240, reward_bound=0.308, batch=229 
3162: loss=0.322, reward_mean=0.190, reward_bound=0.387, batch=229 
3163: loss=0.316, reward_mean=0.230, reward_bound=0.430, batch=217 
3164: loss=0.315, reward_mean=0.240, reward_bound=0.430, batch=219 
3165: loss=0.316, reward_mean=0.270, reward_bound=0.265, batch=223 
3166: loss=0.325, reward_mean=0.210, reward_bound=0.301, batch=226 
3167: loss=0.328, reward_mean=0.290, reward_bound=0.314, batch=227 
3168: loss=0.320, reward_mean=0.220, reward_bound=0.349, batch=228 
3169: loss=0.321, reward_mean=0.200, reward_bound=0.387, batch=228 
3170: loss=0.322, reward_mean=0.260, reward_bound=0.392, batch=229 
3171: loss=0.319, reward_mean=0.240, reward_bound=0.430, batch=226 
3172: loss=0.313, reward_mean=0.240, reward_bound=0.478, batch=217 
3173: loss=0.311, reward_mean=0.320, reward_bound=0.314, batch=221 
3174: loss=0.312, reward_mean=0.200, reward_bound=0.314, batch=223 
3175: loss=0.312, reward_mean=0.290, reward_bound=0.349, batch=225 
3176: loss=0.309, reward_mean=0.250, reward_bound=0.329, batch=227 
3177: loss=0.307, reward_mean=0.280, reward_bound=0.380, batch=229 
3178: loss=0.309, reward_mean=0.250, reward_bound=0.387, batch=226 
3179: loss=0.309, reward_mean=0.190, reward_bound=0.390, batch=228 
3180: loss=0.313, reward_mean=0.270, reward_bound=0.430, batch=223 
3181: loss=0.309, reward_mean=0.270, reward_bound=0.413, batch=226 
3182: loss=0.311, reward_mean=0.230, reward_bound=0.387, batch=227 
3183: loss=0.313, reward_mean=0.290, reward_bound=0.430, batch=227 
3184: loss=0.313, reward_mean=0.250, reward_bound=0.277, batch=229 
3185: loss=0.312, reward_mean=0.230, reward_bound=0.349, batch=229 
3186: loss=0.313, reward_mean=0.240, reward_bound=0.450, batch=230 
3187: loss=0.312, reward_mean=0.270, reward_bound=0.439, batch=231 
3188: loss=0.312, reward_mean=0.170, reward_bound=0.387, batch=231 
3189: loss=0.312, reward_mean=0.260, reward_bound=0.314, batch=231 
3190: loss=0.312, reward_mean=0.220, reward_bound=0.430, batch=231 
3191: loss=0.311, reward_mean=0.250, reward_bound=0.478, batch=224 
3192: loss=0.315, reward_mean=0.160, reward_bound=0.349, batch=226 
3193: loss=0.315, reward_mean=0.250, reward_bound=0.454, batch=228 
3194: loss=0.315, reward_mean=0.260, reward_bound=0.430, batch=228 
3195: loss=0.320, reward_mean=0.210, reward_bound=0.478, batch=230 
3196: loss=0.319, reward_mean=0.250, reward_bound=0.464, batch=231 
3197: loss=0.316, reward_mean=0.270, reward_bound=0.478, batch=226 
3198: loss=0.317, reward_mean=0.240, reward_bound=0.372, batch=228 
3199: loss=0.315, reward_mean=0.260, reward_bound=0.478, batch=230 
3200: loss=0.316, reward_mean=0.200, reward_bound=0.451, batch=231 
3201: loss=0.316, reward_mean=0.160, reward_bound=0.430, batch=231 
3202: loss=0.316, reward_mean=0.240, reward_bound=0.430, batch=231 
3203: loss=0.315, reward_mean=0.220, reward_bound=0.349, batch=231 
3204: loss=0.316, reward_mean=0.270, reward_bound=0.478, batch=226 
3205: loss=0.319, reward_mean=0.250, reward_bound=0.368, batch=228 
3206: loss=0.316, reward_mean=0.250, reward_bound=0.392, batch=229 
3207: loss=0.316, reward_mean=0.280, reward_bound=0.405, batch=230 
3208: loss=0.315, reward_mean=0.260, reward_bound=0.430, batch=229 
3209: loss=0.313, reward_mean=0.220, reward_bound=0.478, batch=232 
3210: loss=0.319, reward_mean=0.190, reward_bound=0.478, batch=228 
3211: loss=0.321, reward_mean=0.200, reward_bound=0.325, batch=229 
3212: loss=0.321, reward_mean=0.210, reward_bound=0.349, batch=229 
3213: loss=0.319, reward_mean=0.250, reward_bound=0.471, batch=230 
3214: loss=0.317, reward_mean=0.280, reward_bound=0.376, batch=231 
3215: loss=0.319, reward_mean=0.170, reward_bound=0.430, batch=230 
3216: loss=0.318, reward_mean=0.300, reward_bound=0.488, batch=231 
3217: loss=0.318, reward_mean=0.200, reward_bound=0.478, batch=231 
3218: loss=0.318, reward_mean=0.310, reward_bound=0.387, batch=231 
3219: loss=0.318, reward_mean=0.230, reward_bound=0.478, batch=231 
3220: loss=0.318, reward_mean=0.230, reward_bound=0.430, batch=231 
3222: loss=0.295, reward_mean=0.250, reward_bound=0.000, batch=25 
3223: loss=0.275, reward_mean=0.240, reward_bound=0.000, batch=49 
3224: loss=0.267, reward_mean=0.290, reward_bound=0.000, batch=78 
3225: loss=0.264, reward_mean=0.220, reward_bound=0.000, batch=100 
3226: loss=0.270, reward_mean=0.270, reward_bound=0.000, batch=127 
3227: loss=0.267, reward_mean=0.190, reward_bound=0.000, batch=146 
3228: loss=0.262, reward_mean=0.280, reward_bound=0.004, batch=172 
3229: loss=0.268, reward_mean=0.200, reward_bound=0.005, batch=190 
3230: loss=0.276, reward_mean=0.320, reward_bound=0.016, batch=201 
3231: loss=0.282, reward_mean=0.250, reward_bound=0.031, batch=207 
3232: loss=0.280, reward_mean=0.360, reward_bound=0.047, batch=213 
3233: loss=0.286, reward_mean=0.270, reward_bound=0.058, batch=212 
3234: loss=0.291, reward_mean=0.270, reward_bound=0.080, batch=215 
3235: loss=0.291, reward_mean=0.290, reward_bound=0.089, batch=230 
3236: loss=0.288, reward_mean=0.290, reward_bound=0.098, batch=227 
3237: loss=0.291, reward_mean=0.290, reward_bound=0.122, batch=214 
3238: loss=0.291, reward_mean=0.320, reward_bound=0.135, batch=209 
3239: loss=0.299, reward_mean=0.290, reward_bound=0.150, batch=206 
3240: loss=0.297, reward_mean=0.270, reward_bound=0.128, batch=214 
3241: loss=0.295, reward_mean=0.330, reward_bound=0.167, batch=211 
3242: loss=0.288, reward_mean=0.370, reward_bound=0.185, batch=200 
3243: loss=0.288, reward_mean=0.260, reward_bound=0.167, batch=209 
3244: loss=0.285, reward_mean=0.290, reward_bound=0.206, batch=194 
3245: loss=0.279, reward_mean=0.330, reward_bound=0.167, batch=205 
3246: loss=0.284, reward_mean=0.360, reward_bound=0.185, batch=212 
3247: loss=0.299, reward_mean=0.280, reward_bound=0.229, batch=187 
3248: loss=0.291, reward_mean=0.270, reward_bound=0.132, batch=201 
3249: loss=0.292, reward_mean=0.280, reward_bound=0.135, batch=210 
3250: loss=0.296, reward_mean=0.270, reward_bound=0.200, batch=217 
3251: loss=0.294, reward_mean=0.320, reward_bound=0.224, batch=222 
3252: loss=0.293, reward_mean=0.290, reward_bound=0.229, batch=220 
3253: loss=0.285, reward_mean=0.310, reward_bound=0.254, batch=203 
3254: loss=0.281, reward_mean=0.260, reward_bound=0.254, batch=211 
3255: loss=0.286, reward_mean=0.360, reward_bound=0.282, batch=183 
3256: loss=0.276, reward_mean=0.230, reward_bound=0.074, batch=198 
3257: loss=0.279, reward_mean=0.290, reward_bound=0.137, batch=208 
3258: loss=0.274, reward_mean=0.240, reward_bound=0.167, batch=214 
3259: loss=0.274, reward_mean=0.210, reward_bound=0.149, batch=220 
3260: loss=0.279, reward_mean=0.280, reward_bound=0.185, batch=220 
3261: loss=0.288, reward_mean=0.360, reward_bound=0.229, batch=222 
3262: loss=0.279, reward_mean=0.280, reward_bound=0.254, batch=221 
3263: loss=0.279, reward_mean=0.300, reward_bound=0.282, batch=222 
3264: loss=0.273, reward_mean=0.360, reward_bound=0.314, batch=175 
3265: loss=0.273, reward_mean=0.270, reward_bound=0.072, batch=191 
3266: loss=0.267, reward_mean=0.260, reward_bound=0.098, batch=203 
3267: loss=0.266, reward_mean=0.350, reward_bound=0.185, batch=208 
3268: loss=0.271, reward_mean=0.380, reward_bound=0.206, batch=214 
3269: loss=0.271, reward_mean=0.280, reward_bound=0.229, batch=214 
3270: loss=0.270, reward_mean=0.250, reward_bound=0.252, batch=220 
3271: loss=0.263, reward_mean=0.340, reward_bound=0.254, batch=222 
3272: loss=0.259, reward_mean=0.270, reward_bound=0.282, batch=220 
3273: loss=0.261, reward_mean=0.240, reward_bound=0.222, batch=224 
3274: loss=0.265, reward_mean=0.360, reward_bound=0.314, batch=213 
3275: loss=0.266, reward_mean=0.380, reward_bound=0.282, batch=217 
3276: loss=0.266, reward_mean=0.330, reward_bound=0.342, batch=222 
3277: loss=0.271, reward_mean=0.300, reward_bound=0.349, batch=168 
3278: loss=0.267, reward_mean=0.260, reward_bound=0.066, batch=187 
3279: loss=0.258, reward_mean=0.220, reward_bound=0.056, batch=201 
3280: loss=0.253, reward_mean=0.250, reward_bound=0.089, batch=210 
3281: loss=0.267, reward_mean=0.330, reward_bound=0.135, batch=215 
3282: loss=0.266, reward_mean=0.280, reward_bound=0.167, batch=217 
3283: loss=0.264, reward_mean=0.310, reward_bound=0.202, batch=222 
3284: loss=0.270, reward_mean=0.250, reward_bound=0.206, batch=228 
3285: loss=0.268, reward_mean=0.270, reward_bound=0.229, batch=224 
3286: loss=0.268, reward_mean=0.350, reward_bound=0.254, batch=225 
3287: loss=0.268, reward_mean=0.260, reward_bound=0.282, batch=218 
3288: loss=0.268, reward_mean=0.320, reward_bound=0.314, batch=212 
3289: loss=0.266, reward_mean=0.220, reward_bound=0.229, batch=215 
3290: loss=0.268, reward_mean=0.320, reward_bound=0.260, batch=220 
3291: loss=0.267, reward_mean=0.280, reward_bound=0.254, batch=223 
3292: loss=0.270, reward_mean=0.280, reward_bound=0.314, batch=221 
3293: loss=0.269, reward_mean=0.240, reward_bound=0.254, batch=224 
3294: loss=0.271, reward_mean=0.240, reward_bound=0.345, batch=227 
3295: loss=0.271, reward_mean=0.340, reward_bound=0.349, batch=216 
3296: loss=0.269, reward_mean=0.280, reward_bound=0.268, batch=221 
3297: loss=0.270, reward_mean=0.240, reward_bound=0.314, batch=224 
3298: loss=0.271, reward_mean=0.340, reward_bound=0.349, batch=226 
3299: loss=0.270, reward_mean=0.210, reward_bound=0.282, batch=227 
3300: loss=0.271, reward_mean=0.270, reward_bound=0.387, batch=151 
3301: loss=0.258, reward_mean=0.310, reward_bound=0.052, batch=175 
3302: loss=0.255, reward_mean=0.360, reward_bound=0.109, batch=195 
3303: loss=0.253, reward_mean=0.260, reward_bound=0.109, batch=210 
3304: loss=0.261, reward_mean=0.250, reward_bound=0.109, batch=214 
3305: loss=0.259, reward_mean=0.260, reward_bound=0.122, batch=219 
3306: loss=0.258, reward_mean=0.350, reward_bound=0.174, batch=223 
3307: loss=0.259, reward_mean=0.270, reward_bound=0.185, batch=224 
3308: loss=0.262, reward_mean=0.280, reward_bound=0.206, batch=220 
3309: loss=0.262, reward_mean=0.380, reward_bound=0.229, batch=223 
3310: loss=0.261, reward_mean=0.290, reward_bound=0.254, batch=222 
3311: loss=0.265, reward_mean=0.290, reward_bound=0.282, batch=221 
3312: loss=0.265, reward_mean=0.310, reward_bound=0.314, batch=214 
3313: loss=0.261, reward_mean=0.350, reward_bound=0.345, batch=220 
3314: loss=0.264, reward_mean=0.250, reward_bound=0.314, batch=223 
3315: loss=0.268, reward_mean=0.340, reward_bound=0.349, batch=206 
3316: loss=0.266, reward_mean=0.280, reward_bound=0.160, batch=214 
3317: loss=0.264, reward_mean=0.230, reward_bound=0.185, batch=219 
3318: loss=0.267, reward_mean=0.280, reward_bound=0.265, batch=223 
3319: loss=0.268, reward_mean=0.340, reward_bound=0.271, batch=226 
3320: loss=0.262, reward_mean=0.280, reward_bound=0.282, batch=225 
3321: loss=0.260, reward_mean=0.270, reward_bound=0.289, batch=227 
3322: loss=0.260, reward_mean=0.300, reward_bound=0.314, batch=228 
3323: loss=0.259, reward_mean=0.360, reward_bound=0.349, batch=227 
3324: loss=0.262, reward_mean=0.230, reward_bound=0.387, batch=203 
3325: loss=0.260, reward_mean=0.260, reward_bound=0.144, batch=212 
3326: loss=0.264, reward_mean=0.340, reward_bound=0.229, batch=215 
3327: loss=0.268, reward_mean=0.230, reward_bound=0.254, batch=218 
3328: loss=0.273, reward_mean=0.360, reward_bound=0.314, batch=218 
3329: loss=0.267, reward_mean=0.220, reward_bound=0.349, batch=221 
3330: loss=0.268, reward_mean=0.230, reward_bound=0.229, batch=223 
3331: loss=0.264, reward_mean=0.370, reward_bound=0.335, batch=226 
3332: loss=0.266, reward_mean=0.270, reward_bound=0.349, batch=227 
3333: loss=0.261, reward_mean=0.400, reward_bound=0.387, batch=216 
3334: loss=0.259, reward_mean=0.220, reward_bound=0.230, batch=221 
3335: loss=0.261, reward_mean=0.330, reward_bound=0.387, batch=224 
3336: loss=0.260, reward_mean=0.260, reward_bound=0.308, batch=227 
3337: loss=0.261, reward_mean=0.260, reward_bound=0.387, batch=228 
3338: loss=0.262, reward_mean=0.300, reward_bound=0.325, batch=229 
3339: loss=0.262, reward_mean=0.350, reward_bound=0.387, batch=229 
3340: loss=0.278, reward_mean=0.290, reward_bound=0.430, batch=127 
3341: loss=0.249, reward_mean=0.320, reward_bound=0.002, batch=159 
3342: loss=0.249, reward_mean=0.280, reward_bound=0.016, batch=180 
3343: loss=0.256, reward_mean=0.230, reward_bound=0.030, batch=196 
3344: loss=0.251, reward_mean=0.260, reward_bound=0.052, batch=205 
3345: loss=0.257, reward_mean=0.250, reward_bound=0.098, batch=209 
3346: loss=0.261, reward_mean=0.310, reward_bound=0.122, batch=215 
3347: loss=0.259, reward_mean=0.250, reward_bound=0.135, batch=219 
3348: loss=0.255, reward_mean=0.320, reward_bound=0.150, batch=219 
3349: loss=0.252, reward_mean=0.330, reward_bound=0.185, batch=215 
3350: loss=0.261, reward_mean=0.250, reward_bound=0.206, batch=214 
3351: loss=0.254, reward_mean=0.290, reward_bound=0.229, batch=216 
3352: loss=0.253, reward_mean=0.270, reward_bound=0.254, batch=212 
3353: loss=0.259, reward_mean=0.330, reward_bound=0.282, batch=203 
3354: loss=0.262, reward_mean=0.350, reward_bound=0.235, batch=212 
3355: loss=0.257, reward_mean=0.240, reward_bound=0.254, batch=215 
3356: loss=0.259, reward_mean=0.310, reward_bound=0.314, batch=198 
3357: loss=0.255, reward_mean=0.210, reward_bound=0.124, batch=208 
3358: loss=0.257, reward_mean=0.240, reward_bound=0.154, batch=215 
3359: loss=0.249, reward_mean=0.270, reward_bound=0.206, batch=218 
3360: loss=0.249, reward_mean=0.270, reward_bound=0.229, batch=221 
3361: loss=0.250, reward_mean=0.290, reward_bound=0.282, batch=220 
3362: loss=0.248, reward_mean=0.250, reward_bound=0.304, batch=224 
3363: loss=0.249, reward_mean=0.250, reward_bound=0.311, batch=227 
3364: loss=0.251, reward_mean=0.260, reward_bound=0.314, batch=225 
3365: loss=0.258, reward_mean=0.330, reward_bound=0.349, batch=205 
3366: loss=0.255, reward_mean=0.340, reward_bound=0.260, batch=213 
3367: loss=0.254, reward_mean=0.290, reward_bound=0.314, batch=215 
3368: loss=0.253, reward_mean=0.280, reward_bound=0.296, batch=220 
3369: loss=0.252, reward_mean=0.260, reward_bound=0.349, batch=220 
3370: loss=0.250, reward_mean=0.280, reward_bound=0.338, batch=224 
3371: loss=0.250, reward_mean=0.260, reward_bound=0.384, batch=227 
3372: loss=0.266, reward_mean=0.200, reward_bound=0.387, batch=178 
3373: loss=0.260, reward_mean=0.270, reward_bound=0.061, batch=194 
3374: loss=0.258, reward_mean=0.240, reward_bound=0.086, batch=206 
3375: loss=0.252, reward_mean=0.200, reward_bound=0.115, batch=214 
3376: loss=0.256, reward_mean=0.280, reward_bound=0.150, batch=218 
3377: loss=0.263, reward_mean=0.310, reward_bound=0.185, batch=220 
3378: loss=0.264, reward_mean=0.300, reward_bound=0.206, batch=228 
3379: loss=0.271, reward_mean=0.300, reward_bound=0.208, batch=229 
3380: loss=0.275, reward_mean=0.310, reward_bound=0.254, batch=224 
3381: loss=0.271, reward_mean=0.210, reward_bound=0.282, batch=219 
3382: loss=0.270, reward_mean=0.300, reward_bound=0.314, batch=216 
3383: loss=0.271, reward_mean=0.230, reward_bound=0.301, batch=221 
3384: loss=0.270, reward_mean=0.350, reward_bound=0.314, batch=223 
3385: loss=0.268, reward_mean=0.240, reward_bound=0.301, batch=226 
3386: loss=0.272, reward_mean=0.310, reward_bound=0.349, batch=218 
3387: loss=0.274, reward_mean=0.240, reward_bound=0.257, batch=222 
3388: loss=0.267, reward_mean=0.260, reward_bound=0.387, batch=207 
3389: loss=0.270, reward_mean=0.320, reward_bound=0.254, batch=214 
3390: loss=0.276, reward_mean=0.260, reward_bound=0.280, batch=220 
3391: loss=0.270, reward_mean=0.330, reward_bound=0.304, batch=224 
3392: loss=0.271, reward_mean=0.320, reward_bound=0.345, batch=227 
3393: loss=0.268, reward_mean=0.330, reward_bound=0.349, batch=228 
3394: loss=0.268, reward_mean=0.290, reward_bound=0.387, batch=223 
3395: loss=0.266, reward_mean=0.240, reward_bound=0.322, batch=226 
3396: loss=0.268, reward_mean=0.240, reward_bound=0.368, batch=228 
3397: loss=0.267, reward_mean=0.270, reward_bound=0.321, batch=229 
3398: loss=0.266, reward_mean=0.170, reward_bound=0.328, batch=230 
3399: loss=0.266, reward_mean=0.300, reward_bound=0.376, batch=231 
3400: loss=0.267, reward_mean=0.220, reward_bound=0.387, batch=230 
3401: loss=0.271, reward_mean=0.390, reward_bound=0.430, batch=182 
3402: loss=0.268, reward_mean=0.330, reward_bound=0.122, batch=197 
3403: loss=0.276, reward_mean=0.210, reward_bound=0.122, batch=206 
3404: loss=0.276, reward_mean=0.240, reward_bound=0.150, batch=213 
3405: loss=0.276, reward_mean=0.320, reward_bound=0.206, batch=216 
3406: loss=0.279, reward_mean=0.260, reward_bound=0.229, batch=219 
3407: loss=0.276, reward_mean=0.300, reward_bound=0.254, batch=221 
3408: loss=0.276, reward_mean=0.290, reward_bound=0.282, batch=216 
3409: loss=0.274, reward_mean=0.310, reward_bound=0.268, batch=221 
3410: loss=0.273, reward_mean=0.300, reward_bound=0.282, batch=224 
3411: loss=0.267, reward_mean=0.320, reward_bound=0.314, batch=218 
3412: loss=0.268, reward_mean=0.370, reward_bound=0.349, batch=216 
3413: loss=0.271, reward_mean=0.260, reward_bound=0.331, batch=221 
3414: loss=0.267, reward_mean=0.250, reward_bound=0.349, batch=223 
3415: loss=0.265, reward_mean=0.220, reward_bound=0.190, batch=226 
3416: loss=0.269, reward_mean=0.270, reward_bound=0.284, batch=228 
3417: loss=0.269, reward_mean=0.290, reward_bound=0.349, batch=227 
3418: loss=0.272, reward_mean=0.310, reward_bound=0.387, batch=215 
3419: loss=0.275, reward_mean=0.320, reward_bound=0.314, batch=219 
3420: loss=0.271, reward_mean=0.250, reward_bound=0.215, batch=223 
3421: loss=0.272, reward_mean=0.340, reward_bound=0.271, batch=226 
3422: loss=0.276, reward_mean=0.190, reward_bound=0.298, batch=228 
3423: loss=0.277, reward_mean=0.280, reward_bound=0.349, batch=226 
3424: loss=0.276, reward_mean=0.310, reward_bound=0.298, batch=228 
3425: loss=0.277, reward_mean=0.300, reward_bound=0.387, batch=224 
3426: loss=0.276, reward_mean=0.230, reward_bound=0.426, batch=227 
3427: loss=0.277, reward_mean=0.280, reward_bound=0.422, batch=229 
3428: loss=0.277, reward_mean=0.180, reward_bound=0.381, batch=230 
3429: loss=0.273, reward_mean=0.270, reward_bound=0.430, batch=201 
3430: loss=0.270, reward_mean=0.310, reward_bound=0.135, batch=210 
3431: loss=0.270, reward_mean=0.210, reward_bound=0.146, batch=217 
3432: loss=0.266, reward_mean=0.220, reward_bound=0.163, batch=222 
3433: loss=0.269, reward_mean=0.300, reward_bound=0.213, batch=225 
3434: loss=0.269, reward_mean=0.270, reward_bound=0.282, batch=225 
3435: loss=0.274, reward_mean=0.250, reward_bound=0.314, batch=222 
3436: loss=0.275, reward_mean=0.220, reward_bound=0.349, batch=220 
3437: loss=0.273, reward_mean=0.220, reward_bound=0.229, batch=223 
3438: loss=0.273, reward_mean=0.280, reward_bound=0.301, batch=226 
3439: loss=0.274, reward_mean=0.230, reward_bound=0.331, batch=228 
3440: loss=0.274, reward_mean=0.220, reward_bound=0.349, batch=226 
3441: loss=0.286, reward_mean=0.310, reward_bound=0.387, batch=223 
3442: loss=0.287, reward_mean=0.240, reward_bound=0.387, batch=225 
3443: loss=0.276, reward_mean=0.250, reward_bound=0.430, batch=219 
3444: loss=0.274, reward_mean=0.170, reward_bound=0.328, batch=223 
3445: loss=0.274, reward_mean=0.250, reward_bound=0.335, batch=226 
3446: loss=0.276, reward_mean=0.270, reward_bound=0.349, batch=224 
3447: loss=0.276, reward_mean=0.230, reward_bound=0.384, batch=227 
3448: loss=0.277, reward_mean=0.230, reward_bound=0.387, batch=226 
3449: loss=0.277, reward_mean=0.280, reward_bound=0.331, batch=228 
3450: loss=0.275, reward_mean=0.310, reward_bound=0.353, batch=229 
3451: loss=0.274, reward_mean=0.240, reward_bound=0.430, batch=223 
3452: loss=0.274, reward_mean=0.350, reward_bound=0.314, batch=225 
3453: loss=0.274, reward_mean=0.240, reward_bound=0.387, batch=226 
3454: loss=0.274, reward_mean=0.230, reward_bound=0.409, batch=228 
3455: loss=0.273, reward_mean=0.260, reward_bound=0.430, batch=227 
3456: loss=0.272, reward_mean=0.190, reward_bound=0.325, batch=229 
3457: loss=0.276, reward_mean=0.220, reward_bound=0.263, batch=230 
3458: loss=0.269, reward_mean=0.220, reward_bound=0.376, batch=231 
3459: loss=0.271, reward_mean=0.270, reward_bound=0.387, batch=230 
3460: loss=0.272, reward_mean=0.170, reward_bound=0.430, batch=228 
3461: loss=0.271, reward_mean=0.260, reward_bound=0.435, batch=229 
3462: loss=0.271, reward_mean=0.300, reward_bound=0.405, batch=230 
3463: loss=0.272, reward_mean=0.240, reward_bound=0.356, batch=231 
3464: loss=0.273, reward_mean=0.310, reward_bound=0.387, batch=231 
3465: loss=0.272, reward_mean=0.300, reward_bound=0.478, batch=108 
3466: loss=0.243, reward_mean=0.270, reward_bound=0.000, batch=135 
3467: loss=0.237, reward_mean=0.270, reward_bound=0.000, batch=162 
3468: loss=0.252, reward_mean=0.320, reward_bound=0.006, batch=183 
3469: loss=0.254, reward_mean=0.140, reward_bound=0.000, batch=197 
3470: loss=0.253, reward_mean=0.270, reward_bound=0.018, batch=208 
3471: loss=0.253, reward_mean=0.260, reward_bound=0.038, batch=214 
3472: loss=0.257, reward_mean=0.290, reward_bound=0.080, batch=218 
3473: loss=0.250, reward_mean=0.360, reward_bound=0.109, batch=221 
3474: loss=0.249, reward_mean=0.270, reward_bound=0.150, batch=220 
3475: loss=0.252, reward_mean=0.270, reward_bound=0.167, batch=217 
3476: loss=0.260, reward_mean=0.330, reward_bound=0.185, batch=217 
3477: loss=0.268, reward_mean=0.300, reward_bound=0.206, batch=209 
3478: loss=0.269, reward_mean=0.260, reward_bound=0.229, batch=198 
3479: loss=0.269, reward_mean=0.320, reward_bound=0.206, batch=207 
3480: loss=0.269, reward_mean=0.280, reward_bound=0.229, batch=214 
3481: loss=0.270, reward_mean=0.250, reward_bound=0.254, batch=203 
3482: loss=0.271, reward_mean=0.260, reward_bound=0.206, batch=210 
3483: loss=0.271, reward_mean=0.320, reward_bound=0.274, batch=217 
3484: loss=0.269, reward_mean=0.220, reward_bound=0.198, batch=222 
3485: loss=0.281, reward_mean=0.270, reward_bound=0.282, batch=195 
3486: loss=0.289, reward_mean=0.240, reward_bound=0.115, batch=206 
3487: loss=0.285, reward_mean=0.380, reward_bound=0.185, batch=213 
3488: loss=0.283, reward_mean=0.290, reward_bound=0.229, batch=217 
3489: loss=0.280, reward_mean=0.210, reward_bound=0.206, batch=221 
3490: loss=0.278, reward_mean=0.250, reward_bound=0.254, batch=222 
3491: loss=0.284, reward_mean=0.250, reward_bound=0.282, batch=224 
3492: loss=0.273, reward_mean=0.260, reward_bound=0.314, batch=200 
3493: loss=0.268, reward_mean=0.220, reward_bound=0.135, batch=209 
3494: loss=0.267, reward_mean=0.260, reward_bound=0.194, batch=216 
3495: loss=0.273, reward_mean=0.290, reward_bound=0.229, batch=220 
3496: loss=0.277, reward_mean=0.300, reward_bound=0.282, batch=223 
3497: loss=0.270, reward_mean=0.270, reward_bound=0.314, batch=215 
3498: loss=0.269, reward_mean=0.300, reward_bound=0.296, batch=220 
3499: loss=0.270, reward_mean=0.170, reward_bound=0.222, batch=224 
3500: loss=0.272, reward_mean=0.270, reward_bound=0.229, batch=226 
3501: loss=0.274, reward_mean=0.310, reward_bound=0.298, batch=228 
3502: loss=0.273, reward_mean=0.290, reward_bound=0.317, batch=229 
3503: loss=0.271, reward_mean=0.320, reward_bound=0.349, batch=208 
3504: loss=0.269, reward_mean=0.290, reward_bound=0.254, batch=213 
3505: loss=0.267, reward_mean=0.250, reward_bound=0.244, batch=219 
3506: loss=0.271, reward_mean=0.280, reward_bound=0.314, batch=218 
3507: loss=0.268, reward_mean=0.260, reward_bound=0.286, batch=222 
3508: loss=0.263, reward_mean=0.300, reward_bound=0.349, batch=223 
3509: loss=0.286, reward_mean=0.250, reward_bound=0.387, batch=176 
3510: loss=0.276, reward_mean=0.370, reward_bound=0.122, batch=192 
3511: loss=0.285, reward_mean=0.330, reward_bound=0.172, batch=204 
3512: loss=0.283, reward_mean=0.350, reward_bound=0.229, batch=207 
3513: loss=0.289, reward_mean=0.300, reward_bound=0.277, batch=215 
3514: loss=0.288, reward_mean=0.250, reward_bound=0.314, batch=213 
3515: loss=0.284, reward_mean=0.280, reward_bound=0.349, batch=211 
3516: loss=0.288, reward_mean=0.330, reward_bound=0.229, batch=216 
3517: loss=0.288, reward_mean=0.300, reward_bound=0.230, batch=221 
3518: loss=0.287, reward_mean=0.210, reward_bound=0.314, batch=219 
3519: loss=0.286, reward_mean=0.240, reward_bound=0.328, batch=223 
3520: loss=0.285, reward_mean=0.240, reward_bound=0.349, batch=224 
3521: loss=0.285, reward_mean=0.270, reward_bound=0.339, batch=227 
3522: loss=0.284, reward_mean=0.330, reward_bound=0.387, batch=212 
3523: loss=0.287, reward_mean=0.270, reward_bound=0.198, batch=218 
3524: loss=0.283, reward_mean=0.290, reward_bound=0.282, batch=220 
3525: loss=0.281, reward_mean=0.310, reward_bound=0.387, batch=222 
3526: loss=0.279, reward_mean=0.250, reward_bound=0.387, batch=224 
3527: loss=0.277, reward_mean=0.230, reward_bound=0.426, batch=227 
3528: loss=0.280, reward_mean=0.250, reward_bound=0.407, batch=229 
3529: loss=0.282, reward_mean=0.330, reward_bound=0.430, batch=175 
3530: loss=0.278, reward_mean=0.310, reward_bound=0.124, batch=192 
3531: loss=0.277, reward_mean=0.260, reward_bound=0.155, batch=204 
3532: loss=0.279, reward_mean=0.290, reward_bound=0.185, batch=212 
3533: loss=0.274, reward_mean=0.310, reward_bound=0.229, batch=210 
3534: loss=0.270, reward_mean=0.300, reward_bound=0.254, batch=216 
3535: loss=0.271, reward_mean=0.290, reward_bound=0.241, batch=221 
3536: loss=0.278, reward_mean=0.340, reward_bound=0.282, batch=222 
3537: loss=0.274, reward_mean=0.240, reward_bound=0.314, batch=218 
3538: loss=0.275, reward_mean=0.260, reward_bound=0.317, batch=222 
3539: loss=0.276, reward_mean=0.350, reward_bound=0.349, batch=215 
3540: loss=0.281, reward_mean=0.310, reward_bound=0.289, batch=220 
3541: loss=0.282, reward_mean=0.270, reward_bound=0.314, batch=223 
3542: loss=0.281, reward_mean=0.210, reward_bound=0.301, batch=226 
3543: loss=0.285, reward_mean=0.320, reward_bound=0.331, batch=228 
3544: loss=0.282, reward_mean=0.160, reward_bound=0.349, batch=224 
3545: loss=0.285, reward_mean=0.270, reward_bound=0.254, batch=226 
3546: loss=0.284, reward_mean=0.190, reward_bound=0.349, batch=226 
3547: loss=0.284, reward_mean=0.180, reward_bound=0.316, batch=228 
3548: loss=0.283, reward_mean=0.280, reward_bound=0.353, batch=229 
3549: loss=0.276, reward_mean=0.280, reward_bound=0.387, batch=217 
3550: loss=0.279, reward_mean=0.280, reward_bound=0.308, batch=222 
3551: loss=0.281, reward_mean=0.330, reward_bound=0.324, batch=225 
3552: loss=0.281, reward_mean=0.240, reward_bound=0.356, batch=227 
3553: loss=0.276, reward_mean=0.250, reward_bound=0.387, batch=226 
3554: loss=0.279, reward_mean=0.230, reward_bound=0.430, batch=210 
3555: loss=0.281, reward_mean=0.220, reward_bound=0.304, batch=217 
3556: loss=0.278, reward_mean=0.280, reward_bound=0.277, batch=222 
3557: loss=0.280, reward_mean=0.340, reward_bound=0.314, batch=224 
3558: loss=0.281, reward_mean=0.240, reward_bound=0.349, batch=224 
3559: loss=0.280, reward_mean=0.240, reward_bound=0.349, batch=226 
3560: loss=0.279, reward_mean=0.250, reward_bound=0.387, batch=223 
3561: loss=0.279, reward_mean=0.230, reward_bound=0.371, batch=226 
3562: loss=0.280, reward_mean=0.290, reward_bound=0.282, batch=227 
3563: loss=0.278, reward_mean=0.260, reward_bound=0.349, batch=227 
3564: loss=0.280, reward_mean=0.210, reward_bound=0.430, batch=223 
3565: loss=0.279, reward_mean=0.280, reward_bound=0.372, batch=226 
3566: loss=0.279, reward_mean=0.360, reward_bound=0.351, batch=228 
3567: loss=0.279, reward_mean=0.290, reward_bound=0.353, batch=229 
3568: loss=0.282, reward_mean=0.250, reward_bound=0.387, batch=227 
3569: loss=0.281, reward_mean=0.340, reward_bound=0.387, batch=228 
3570: loss=0.281, reward_mean=0.300, reward_bound=0.430, batch=225 
3571: loss=0.280, reward_mean=0.280, reward_bound=0.440, batch=227 
3572: loss=0.279, reward_mean=0.310, reward_bound=0.342, batch=229 
3573: loss=0.281, reward_mean=0.260, reward_bound=0.430, batch=229 
3574: loss=0.282, reward_mean=0.210, reward_bound=0.478, batch=231 
3575: loss=0.282, reward_mean=0.250, reward_bound=0.430, batch=231 
3576: loss=0.273, reward_mean=0.190, reward_bound=0.478, batch=160 
3577: loss=0.269, reward_mean=0.320, reward_bound=0.063, batch=182 
3578: loss=0.268, reward_mean=0.170, reward_bound=0.007, batch=197 
3579: loss=0.276, reward_mean=0.300, reward_bound=0.070, batch=208 
3580: loss=0.287, reward_mean=0.230, reward_bound=0.098, batch=214 
3581: loss=0.290, reward_mean=0.280, reward_bound=0.167, batch=212 
3582: loss=0.286, reward_mean=0.340, reward_bound=0.206, batch=221 
3583: loss=0.281, reward_mean=0.260, reward_bound=0.229, batch=217 
3584: loss=0.275, reward_mean=0.280, reward_bound=0.254, batch=220 
3585: loss=0.271, reward_mean=0.230, reward_bound=0.247, batch=224 
3586: loss=0.279, reward_mean=0.280, reward_bound=0.282, batch=217 
3587: loss=0.272, reward_mean=0.350, reward_bound=0.314, batch=216 
3588: loss=0.272, reward_mean=0.290, reward_bound=0.314, batch=220 
3589: loss=0.277, reward_mean=0.210, reward_bound=0.349, batch=206 
3590: loss=0.279, reward_mean=0.250, reward_bound=0.268, batch=214 
3591: loss=0.282, reward_mean=0.180, reward_bound=0.280, batch=220 
3592: loss=0.283, reward_mean=0.290, reward_bound=0.314, batch=221 
3593: loss=0.284, reward_mean=0.260, reward_bound=0.349, batch=219 
3594: loss=0.281, reward_mean=0.150, reward_bound=0.263, batch=223 
3595: loss=0.280, reward_mean=0.270, reward_bound=0.282, batch=225 
3596: loss=0.281, reward_mean=0.290, reward_bound=0.356, batch=227 
3597: loss=0.280, reward_mean=0.240, reward_bound=0.380, batch=229 
3598: loss=0.276, reward_mean=0.280, reward_bound=0.387, batch=209 
3599: loss=0.278, reward_mean=0.200, reward_bound=0.239, batch=216 
3600: loss=0.280, reward_mean=0.210, reward_bound=0.217, batch=221 
3601: loss=0.281, reward_mean=0.320, reward_bound=0.282, batch=222 
3602: loss=0.280, reward_mean=0.310, reward_bound=0.282, batch=224 
3603: loss=0.276, reward_mean=0.350, reward_bound=0.314, batch=224 
3604: loss=0.273, reward_mean=0.200, reward_bound=0.339, batch=227 
3605: loss=0.268, reward_mean=0.310, reward_bound=0.380, batch=229 
3606: loss=0.271, reward_mean=0.310, reward_bound=0.387, batch=227 
3607: loss=0.264, reward_mean=0.280, reward_bound=0.430, batch=205 
3608: loss=0.268, reward_mean=0.300, reward_bound=0.273, batch=213 
3609: loss=0.268, reward_mean=0.250, reward_bound=0.322, batch=219 
3610: loss=0.271, reward_mean=0.210, reward_bound=0.192, batch=223 
3611: loss=0.271, reward_mean=0.320, reward_bound=0.349, batch=218 
3612: loss=0.267, reward_mean=0.300, reward_bound=0.353, batch=222 
3613: loss=0.265, reward_mean=0.330, reward_bound=0.272, batch=225 
3614: loss=0.261, reward_mean=0.270, reward_bound=0.387, batch=220 
3615: loss=0.260, reward_mean=0.260, reward_bound=0.296, batch=224 
3616: loss=0.264, reward_mean=0.310, reward_bound=0.345, batch=227 
3617: loss=0.266, reward_mean=0.280, reward_bound=0.380, batch=229 
3618: loss=0.262, reward_mean=0.260, reward_bound=0.387, batch=228 
3619: loss=0.267, reward_mean=0.220, reward_bound=0.430, batch=218 
3620: loss=0.269, reward_mean=0.280, reward_bound=0.392, batch=222 
3621: loss=0.268, reward_mean=0.260, reward_bound=0.336, batch=225 
3622: loss=0.269, reward_mean=0.260, reward_bound=0.321, batch=227 
3623: loss=0.271, reward_mean=0.300, reward_bound=0.387, batch=227 
3624: loss=0.270, reward_mean=0.230, reward_bound=0.373, batch=229 
3625: loss=0.271, reward_mean=0.230, reward_bound=0.430, batch=227 
3626: loss=0.271, reward_mean=0.270, reward_bound=0.414, batch=229 
3627: loss=0.273, reward_mean=0.360, reward_bound=0.450, batch=230 
3628: loss=0.272, reward_mean=0.240, reward_bound=0.464, batch=231 
3629: loss=0.276, reward_mean=0.230, reward_bound=0.478, batch=191 
3630: loss=0.274, reward_mean=0.310, reward_bound=0.206, batch=203 
3631: loss=0.270, reward_mean=0.310, reward_bound=0.229, batch=208 
3632: loss=0.266, reward_mean=0.330, reward_bound=0.260, batch=215 
3633: loss=0.261, reward_mean=0.210, reward_bound=0.240, batch=220 
3634: loss=0.265, reward_mean=0.210, reward_bound=0.304, batch=224 
3635: loss=0.266, reward_mean=0.180, reward_bound=0.311, batch=227 
3636: loss=0.267, reward_mean=0.250, reward_bound=0.314, batch=222 
3637: loss=0.266, reward_mean=0.230, reward_bound=0.254, batch=225 
3638: loss=0.266, reward_mean=0.290, reward_bound=0.260, batch=227 
3639: loss=0.265, reward_mean=0.290, reward_bound=0.349, batch=225 
3640: loss=0.264, reward_mean=0.300, reward_bound=0.329, batch=227 
3641: loss=0.268, reward_mean=0.290, reward_bound=0.387, batch=217 
3642: loss=0.263, reward_mean=0.230, reward_bound=0.335, batch=222 
3643: loss=0.266, reward_mean=0.290, reward_bound=0.360, batch=225 
3644: loss=0.267, reward_mean=0.280, reward_bound=0.314, batch=226 
3645: loss=0.268, reward_mean=0.260, reward_bound=0.349, batch=226 
3646: loss=0.266, reward_mean=0.230, reward_bound=0.368, batch=228 
3647: loss=0.266, reward_mean=0.340, reward_bound=0.387, batch=225 
3648: loss=0.266, reward_mean=0.250, reward_bound=0.396, batch=227 
3649: loss=0.264, reward_mean=0.270, reward_bound=0.414, batch=229 
3650: loss=0.264, reward_mean=0.300, reward_bound=0.430, batch=217 
3651: loss=0.266, reward_mean=0.290, reward_bound=0.469, batch=222 
3652: loss=0.264, reward_mean=0.350, reward_bound=0.292, batch=225 
3653: loss=0.265, reward_mean=0.280, reward_bound=0.396, batch=227 
3654: loss=0.264, reward_mean=0.300, reward_bound=0.422, batch=229 
3655: loss=0.262, reward_mean=0.310, reward_bound=0.405, batch=230 
3656: loss=0.262, reward_mean=0.260, reward_bound=0.418, batch=231 
3657: loss=0.263, reward_mean=0.230, reward_bound=0.430, batch=225 
3658: loss=0.261, reward_mean=0.320, reward_bound=0.356, batch=227 
3659: loss=0.264, reward_mean=0.230, reward_bound=0.422, batch=229 
3660: loss=0.264, reward_mean=0.280, reward_bound=0.430, batch=228 
3661: loss=0.264, reward_mean=0.290, reward_bound=0.430, batch=228 
3662: loss=0.264, reward_mean=0.330, reward_bound=0.353, batch=229 
3663: loss=0.263, reward_mean=0.260, reward_bound=0.364, batch=230 
3664: loss=0.267, reward_mean=0.300, reward_bound=0.430, batch=230 
3665: loss=0.269, reward_mean=0.410, reward_bound=0.464, batch=231 
3666: loss=0.273, reward_mean=0.280, reward_bound=0.478, batch=210 
3667: loss=0.275, reward_mean=0.330, reward_bound=0.274, batch=217 
3668: loss=0.279, reward_mean=0.240, reward_bound=0.224, batch=222 
3669: loss=0.283, reward_mean=0.270, reward_bound=0.282, batch=224 
3670: loss=0.283, reward_mean=0.290, reward_bound=0.282, batch=225 
3671: loss=0.279, reward_mean=0.260, reward_bound=0.314, batch=222 
3672: loss=0.277, reward_mean=0.230, reward_bound=0.349, batch=222 
3673: loss=0.274, reward_mean=0.290, reward_bound=0.324, batch=225 
3674: loss=0.278, reward_mean=0.240, reward_bound=0.349, batch=226 
3675: loss=0.278, reward_mean=0.290, reward_bound=0.368, batch=228 
3676: loss=0.277, reward_mean=0.250, reward_bound=0.387, batch=224 
3677: loss=0.278, reward_mean=0.250, reward_bound=0.426, batch=227 
3678: loss=0.279, reward_mean=0.280, reward_bound=0.430, batch=225 
3679: loss=0.281, reward_mean=0.270, reward_bound=0.387, batch=226 
3680: loss=0.278, reward_mean=0.270, reward_bound=0.430, batch=226 
3681: loss=0.277, reward_mean=0.260, reward_bound=0.241, batch=228 
3682: loss=0.278, reward_mean=0.270, reward_bound=0.387, batch=228 
3683: loss=0.277, reward_mean=0.280, reward_bound=0.392, batch=229 
3684: loss=0.278, reward_mean=0.320, reward_bound=0.430, batch=228 
3685: loss=0.278, reward_mean=0.280, reward_bound=0.387, batch=228 
3686: loss=0.278, reward_mean=0.390, reward_bound=0.430, batch=228 
3687: loss=0.278, reward_mean=0.290, reward_bound=0.478, batch=231 
3688: loss=0.276, reward_mean=0.290, reward_bound=0.478, batch=224 
3689: loss=0.276, reward_mean=0.270, reward_bound=0.430, batch=226 
3690: loss=0.277, reward_mean=0.260, reward_bound=0.335, batch=228 
3691: loss=0.276, reward_mean=0.250, reward_bound=0.387, batch=227 
3692: loss=0.279, reward_mean=0.270, reward_bound=0.380, batch=229 
3693: loss=0.275, reward_mean=0.290, reward_bound=0.405, batch=230 
3694: loss=0.274, reward_mean=0.300, reward_bound=0.430, batch=227 
3695: loss=0.273, reward_mean=0.310, reward_bound=0.478, batch=226 
3696: loss=0.273, reward_mean=0.290, reward_bound=0.430, batch=227 
3697: loss=0.275, reward_mean=0.230, reward_bound=0.414, batch=229 
3698: loss=0.275, reward_mean=0.170, reward_bound=0.381, batch=230 
3699: loss=0.273, reward_mean=0.190, reward_bound=0.430, batch=230 
3700: loss=0.273, reward_mean=0.270, reward_bound=0.478, batch=229 
3701: loss=0.273, reward_mean=0.340, reward_bound=0.430, batch=229 
3702: loss=0.272, reward_mean=0.260, reward_bound=0.343, batch=230 
3703: loss=0.274, reward_mean=0.190, reward_bound=0.387, batch=230 
3704: loss=0.273, reward_mean=0.270, reward_bound=0.478, batch=229 
3705: loss=0.273, reward_mean=0.370, reward_bound=0.500, batch=230 
3706: loss=0.271, reward_mean=0.310, reward_bound=0.451, batch=231 
3707: loss=0.271, reward_mean=0.230, reward_bound=0.387, batch=231 
3708: loss=0.271, reward_mean=0.240, reward_bound=0.430, batch=231 
3709: loss=0.273, reward_mean=0.370, reward_bound=0.478, batch=230 
3710: loss=0.273, reward_mean=0.250, reward_bound=0.515, batch=231 
3711: loss=0.273, reward_mean=0.300, reward_bound=0.349, batch=231 
3712: loss=0.273, reward_mean=0.310, reward_bound=0.387, batch=231 
3713: loss=0.273, reward_mean=0.300, reward_bound=0.478, batch=231 
3714: loss=0.273, reward_mean=0.250, reward_bound=0.387, batch=231 
3715: loss=0.273, reward_mean=0.280, reward_bound=0.387, batch=231 
3717: loss=0.205, reward_mean=0.310, reward_bound=0.000, batch=31 
3718: loss=0.205, reward_mean=0.220, reward_bound=0.000, batch=53 
3719: loss=0.208, reward_mean=0.260, reward_bound=0.000, batch=79 
3720: loss=0.204, reward_mean=0.220, reward_bound=0.000, batch=101 
3721: loss=0.204, reward_mean=0.280, reward_bound=0.000, batch=129 
3722: loss=0.207, reward_mean=0.340, reward_bound=0.001, batch=160 
3723: loss=0.221, reward_mean=0.300, reward_bound=0.003, batch=182 
3724: loss=0.229, reward_mean=0.290, reward_bound=0.010, batch=196 
3725: loss=0.235, reward_mean=0.280, reward_bound=0.016, batch=205 
3726: loss=0.244, reward_mean=0.310, reward_bound=0.028, batch=213 
3727: loss=0.245, reward_mean=0.270, reward_bound=0.042, batch=215 
3728: loss=0.254, reward_mean=0.280, reward_bound=0.052, batch=219 
3729: loss=0.253, reward_mean=0.240, reward_bound=0.067, batch=223 
3730: loss=0.250, reward_mean=0.300, reward_bound=0.085, batch=226 
3731: loss=0.243, reward_mean=0.310, reward_bound=0.098, batch=224 
3732: loss=0.235, reward_mean=0.330, reward_bound=0.122, batch=220 
3733: loss=0.227, reward_mean=0.290, reward_bound=0.135, batch=215 
3734: loss=0.222, reward_mean=0.280, reward_bound=0.150, batch=208 
3735: loss=0.218, reward_mean=0.310, reward_bound=0.167, batch=206 
3736: loss=0.222, reward_mean=0.300, reward_bound=0.185, batch=199 
3737: loss=0.218, reward_mean=0.340, reward_bound=0.157, batch=209 
3738: loss=0.221, reward_mean=0.250, reward_bound=0.167, batch=213 
3739: loss=0.221, reward_mean=0.380, reward_bound=0.206, batch=194 
3740: loss=0.223, reward_mean=0.360, reward_bound=0.229, batch=177 
3741: loss=0.222, reward_mean=0.310, reward_bound=0.122, batch=193 
3742: loss=0.225, reward_mean=0.330, reward_bound=0.185, batch=202 
3743: loss=0.222, reward_mean=0.290, reward_bound=0.145, batch=211 
3744: loss=0.221, reward_mean=0.300, reward_bound=0.206, batch=217 
3745: loss=0.217, reward_mean=0.340, reward_bound=0.254, batch=194 
3746: loss=0.224, reward_mean=0.330, reward_bound=0.164, batch=206 
3747: loss=0.228, reward_mean=0.210, reward_bound=0.101, batch=214 
3748: loss=0.219, reward_mean=0.390, reward_bound=0.254, batch=217 
3749: loss=0.218, reward_mean=0.400, reward_bound=0.277, batch=222 
3750: loss=0.230, reward_mean=0.400, reward_bound=0.282, batch=186 
3751: loss=0.229, reward_mean=0.360, reward_bound=0.206, batch=199 
3752: loss=0.230, reward_mean=0.340, reward_bound=0.194, batch=209 
3753: loss=0.230, reward_mean=0.350, reward_bound=0.229, batch=208 
3754: loss=0.234, reward_mean=0.330, reward_bound=0.208, batch=215 
3755: loss=0.232, reward_mean=0.290, reward_bound=0.229, batch=219 
3756: loss=0.230, reward_mean=0.330, reward_bound=0.254, batch=220 
3757: loss=0.223, reward_mean=0.390, reward_bound=0.282, batch=222 
3758: loss=0.223, reward_mean=0.320, reward_bound=0.282, batch=223 
3759: loss=0.229, reward_mean=0.400, reward_bound=0.314, batch=181 
3760: loss=0.231, reward_mean=0.270, reward_bound=0.065, batch=195 
3761: loss=0.228, reward_mean=0.320, reward_bound=0.167, batch=205 
3762: loss=0.222, reward_mean=0.370, reward_bound=0.229, batch=211 
3763: loss=0.223, reward_mean=0.320, reward_bound=0.185, batch=217 
3764: loss=0.225, reward_mean=0.370, reward_bound=0.254, batch=221 
3765: loss=0.228, reward_mean=0.320, reward_bound=0.314, batch=212 
3766: loss=0.233, reward_mean=0.340, reward_bound=0.292, batch=218 
3767: loss=0.232, reward_mean=0.440, reward_bound=0.314, batch=220 
3768: loss=0.231, reward_mean=0.330, reward_bound=0.338, batch=224 
3769: loss=0.220, reward_mean=0.310, reward_bound=0.349, batch=160 
3770: loss=0.217, reward_mean=0.400, reward_bound=0.135, batch=181 
3771: loss=0.220, reward_mean=0.350, reward_bound=0.167, batch=194 
3772: loss=0.213, reward_mean=0.300, reward_bound=0.134, batch=206 
3773: loss=0.218, reward_mean=0.270, reward_bound=0.176, batch=214 
3774: loss=0.219, reward_mean=0.310, reward_bound=0.185, batch=218 
3775: loss=0.217, reward_mean=0.420, reward_bound=0.206, batch=218 
3776: loss=0.205, reward_mean=0.320, reward_bound=0.229, batch=212 
3777: loss=0.205, reward_mean=0.370, reward_bound=0.254, batch=214 
3778: loss=0.202, reward_mean=0.280, reward_bound=0.204, batch=220 
3779: loss=0.212, reward_mean=0.420, reward_bound=0.282, batch=218 
3780: loss=0.215, reward_mean=0.330, reward_bound=0.314, batch=212 
3781: loss=0.217, reward_mean=0.320, reward_bound=0.302, batch=218 
3782: loss=0.218, reward_mean=0.290, reward_bound=0.349, batch=203 
3783: loss=0.216, reward_mean=0.320, reward_bound=0.198, batch=212 
3784: loss=0.221, reward_mean=0.340, reward_bound=0.229, batch=217 
3785: loss=0.218, reward_mean=0.340, reward_bound=0.254, batch=221 
3786: loss=0.218, reward_mean=0.310, reward_bound=0.254, batch=224 
3787: loss=0.225, reward_mean=0.340, reward_bound=0.314, batch=226 
3788: loss=0.223, reward_mean=0.310, reward_bound=0.331, batch=228 
3789: loss=0.220, reward_mean=0.280, reward_bound=0.349, batch=221 
3790: loss=0.218, reward_mean=0.370, reward_bound=0.349, batch=224 
3791: loss=0.216, reward_mean=0.340, reward_bound=0.345, batch=227 
3792: loss=0.194, reward_mean=0.350, reward_bound=0.387, batch=158 
3793: loss=0.206, reward_mean=0.310, reward_bound=0.065, batch=179 
3794: loss=0.204, reward_mean=0.340, reward_bound=0.083, batch=195 
3795: loss=0.206, reward_mean=0.330, reward_bound=0.101, batch=206 
3796: loss=0.199, reward_mean=0.370, reward_bound=0.167, batch=211 
3797: loss=0.198, reward_mean=0.380, reward_bound=0.206, batch=213 
3798: loss=0.196, reward_mean=0.320, reward_bound=0.229, batch=214 
3799: loss=0.194, reward_mean=0.280, reward_bound=0.229, batch=219 
3800: loss=0.194, reward_mean=0.320, reward_bound=0.254, batch=216 
3801: loss=0.192, reward_mean=0.280, reward_bound=0.254, batch=220 
3802: loss=0.195, reward_mean=0.340, reward_bound=0.282, batch=213 
3803: loss=0.194, reward_mean=0.400, reward_bound=0.198, batch=219 
3804: loss=0.194, reward_mean=0.430, reward_bound=0.229, batch=222 
3805: loss=0.187, reward_mean=0.400, reward_bound=0.314, batch=208 
3806: loss=0.181, reward_mean=0.280, reward_bound=0.257, batch=215 
3807: loss=0.183, reward_mean=0.290, reward_bound=0.240, batch=220 
3808: loss=0.185, reward_mean=0.270, reward_bound=0.282, batch=220 
3809: loss=0.187, reward_mean=0.340, reward_bound=0.304, batch=224 
3810: loss=0.188, reward_mean=0.410, reward_bound=0.314, batch=226 
3811: loss=0.189, reward_mean=0.360, reward_bound=0.349, batch=207 
3812: loss=0.187, reward_mean=0.300, reward_bound=0.087, batch=215 
3813: loss=0.185, reward_mean=0.290, reward_bound=0.185, batch=219 
3814: loss=0.186, reward_mean=0.280, reward_bound=0.185, batch=222 
3815: loss=0.187, reward_mean=0.370, reward_bound=0.254, batch=224 
3816: loss=0.184, reward_mean=0.280, reward_bound=0.314, batch=223 
3817: loss=0.185, reward_mean=0.380, reward_bound=0.335, batch=226 
3818: loss=0.185, reward_mean=0.340, reward_bound=0.298, batch=228 
3819: loss=0.183, reward_mean=0.260, reward_bound=0.317, batch=229 
3820: loss=0.190, reward_mean=0.410, reward_bound=0.387, batch=212 
3821: loss=0.188, reward_mean=0.370, reward_bound=0.349, batch=216 
3822: loss=0.188, reward_mean=0.360, reward_bound=0.268, batch=221 
3823: loss=0.188, reward_mean=0.330, reward_bound=0.254, batch=224 
3824: loss=0.188, reward_mean=0.310, reward_bound=0.282, batch=224 
3825: loss=0.191, reward_mean=0.390, reward_bound=0.314, batch=225 
3826: loss=0.189, reward_mean=0.250, reward_bound=0.356, batch=227 
3827: loss=0.190, reward_mean=0.360, reward_bound=0.380, batch=229 
3828: loss=0.191, reward_mean=0.330, reward_bound=0.364, batch=230 
3829: loss=0.190, reward_mean=0.360, reward_bound=0.387, batch=228 
3830: loss=0.179, reward_mean=0.320, reward_bound=0.430, batch=128 
3831: loss=0.180, reward_mean=0.290, reward_bound=0.000, batch=157 
3832: loss=0.180, reward_mean=0.240, reward_bound=0.002, batch=180 
3833: loss=0.189, reward_mean=0.300, reward_bound=0.024, batch=196 
3834: loss=0.193, reward_mean=0.430, reward_bound=0.065, batch=206 
3835: loss=0.194, reward_mean=0.280, reward_bound=0.089, batch=213 
3836: loss=0.190, reward_mean=0.230, reward_bound=0.109, batch=216 
3837: loss=0.191, reward_mean=0.340, reward_bound=0.135, batch=214 
3838: loss=0.192, reward_mean=0.270, reward_bound=0.150, batch=215 
3839: loss=0.192, reward_mean=0.350, reward_bound=0.170, batch=220 
3840: loss=0.195, reward_mean=0.390, reward_bound=0.185, batch=220 
3841: loss=0.195, reward_mean=0.290, reward_bound=0.206, batch=226 
3842: loss=0.200, reward_mean=0.320, reward_bound=0.217, batch=228 
3843: loss=0.194, reward_mean=0.260, reward_bound=0.229, batch=209 
3844: loss=0.192, reward_mean=0.340, reward_bound=0.254, batch=207 
3845: loss=0.191, reward_mean=0.340, reward_bound=0.167, batch=214 
3846: loss=0.191, reward_mean=0.330, reward_bound=0.229, batch=217 
3847: loss=0.196, reward_mean=0.380, reward_bound=0.254, batch=221 
3848: loss=0.198, reward_mean=0.280, reward_bound=0.282, batch=205 
3849: loss=0.197, reward_mean=0.310, reward_bound=0.254, batch=211 
3850: loss=0.199, reward_mean=0.380, reward_bound=0.229, batch=215 
3851: loss=0.196, reward_mean=0.300, reward_bound=0.254, batch=219 
3852: loss=0.183, reward_mean=0.350, reward_bound=0.314, batch=196 
3853: loss=0.187, reward_mean=0.430, reward_bound=0.282, batch=204 
3854: loss=0.187, reward_mean=0.310, reward_bound=0.202, batch=213 
3855: loss=0.188, reward_mean=0.460, reward_bound=0.282, batch=218 
3856: loss=0.186, reward_mean=0.220, reward_bound=0.217, batch=222 
3857: loss=0.185, reward_mean=0.360, reward_bound=0.314, batch=221 
3858: loss=0.177, reward_mean=0.270, reward_bound=0.349, batch=199 
3859: loss=0.181, reward_mean=0.360, reward_bound=0.174, batch=209 
3860: loss=0.179, reward_mean=0.310, reward_bound=0.194, batch=216 
3861: loss=0.185, reward_mean=0.360, reward_bound=0.229, batch=220 
3862: loss=0.179, reward_mean=0.400, reward_bound=0.274, batch=224 
3863: loss=0.173, reward_mean=0.390, reward_bound=0.314, batch=222 
3864: loss=0.172, reward_mean=0.340, reward_bound=0.349, batch=216 
3865: loss=0.178, reward_mean=0.350, reward_bound=0.256, batch=221 
3866: loss=0.175, reward_mean=0.320, reward_bound=0.282, batch=224 
3867: loss=0.175, reward_mean=0.290, reward_bound=0.345, batch=227 
3868: loss=0.179, reward_mean=0.390, reward_bound=0.349, batch=226 
3869: loss=0.180, reward_mean=0.400, reward_bound=0.368, batch=228 
3870: loss=0.178, reward_mean=0.380, reward_bound=0.387, batch=192 
3871: loss=0.181, reward_mean=0.260, reward_bound=0.145, batch=204 
3872: loss=0.187, reward_mean=0.390, reward_bound=0.183, batch=213 
3873: loss=0.185, reward_mean=0.340, reward_bound=0.206, batch=218 
3874: loss=0.187, reward_mean=0.370, reward_bound=0.229, batch=219 
3875: loss=0.188, reward_mean=0.260, reward_bound=0.254, batch=218 
3876: loss=0.188, reward_mean=0.320, reward_bound=0.282, batch=217 
3877: loss=0.188, reward_mean=0.380, reward_bound=0.277, batch=222 
3878: loss=0.191, reward_mean=0.320, reward_bound=0.292, batch=225 
3879: loss=0.187, reward_mean=0.310, reward_bound=0.314, batch=221 
3880: loss=0.187, reward_mean=0.400, reward_bound=0.314, batch=223 
3881: loss=0.185, reward_mean=0.340, reward_bound=0.349, batch=215 
3882: loss=0.187, reward_mean=0.370, reward_bound=0.234, batch=220 
3883: loss=0.185, reward_mean=0.460, reward_bound=0.282, batch=222 
3884: loss=0.185, reward_mean=0.350, reward_bound=0.314, batch=224 
3885: loss=0.185, reward_mean=0.270, reward_bound=0.342, batch=227 
3886: loss=0.184, reward_mean=0.340, reward_bound=0.314, batch=228 
3887: loss=0.183, reward_mean=0.320, reward_bound=0.387, batch=215 
3888: loss=0.185, reward_mean=0.470, reward_bound=0.356, batch=220 
3889: loss=0.184, reward_mean=0.400, reward_bound=0.387, batch=222 
3890: loss=0.183, reward_mean=0.280, reward_bound=0.314, batch=224 
3891: loss=0.182, reward_mean=0.320, reward_bound=0.345, batch=227 
3892: loss=0.183, reward_mean=0.460, reward_bound=0.349, batch=227 
3893: loss=0.181, reward_mean=0.320, reward_bound=0.401, batch=229 
3894: loss=0.184, reward_mean=0.290, reward_bound=0.430, batch=186 
3895: loss=0.187, reward_mean=0.290, reward_bound=0.085, batch=200 
3896: loss=0.193, reward_mean=0.310, reward_bound=0.122, batch=208 
3897: loss=0.179, reward_mean=0.430, reward_bound=0.206, batch=212 
3898: loss=0.180, reward_mean=0.290, reward_bound=0.229, batch=216 
3899: loss=0.185, reward_mean=0.280, reward_bound=0.254, batch=220 
3900: loss=0.187, reward_mean=0.330, reward_bound=0.282, batch=215 
3901: loss=0.184, reward_mean=0.330, reward_bound=0.314, batch=211 
3902: loss=0.186, reward_mean=0.340, reward_bound=0.282, batch=216 
3903: loss=0.182, reward_mean=0.280, reward_bound=0.241, batch=221 
3904: loss=0.181, reward_mean=0.290, reward_bound=0.254, batch=223 
3905: loss=0.180, reward_mean=0.390, reward_bound=0.349, batch=218 
3906: loss=0.185, reward_mean=0.360, reward_bound=0.321, batch=222 
3907: loss=0.187, reward_mean=0.330, reward_bound=0.387, batch=208 
3908: loss=0.192, reward_mean=0.360, reward_bound=0.185, batch=214 
3909: loss=0.190, reward_mean=0.380, reward_bound=0.252, batch=220 
3910: loss=0.189, reward_mean=0.330, reward_bound=0.282, batch=220 
3911: loss=0.188, reward_mean=0.420, reward_bound=0.314, batch=220 
3912: loss=0.185, reward_mean=0.330, reward_bound=0.240, batch=224 
3913: loss=0.186, reward_mean=0.380, reward_bound=0.349, batch=224 
3914: loss=0.188, reward_mean=0.250, reward_bound=0.277, batch=227 
3915: loss=0.186, reward_mean=0.380, reward_bound=0.308, batch=229 
3916: loss=0.184, reward_mean=0.300, reward_bound=0.364, batch=230 
3917: loss=0.184, reward_mean=0.390, reward_bound=0.356, batch=231 
3918: loss=0.187, reward_mean=0.340, reward_bound=0.387, batch=222 
3919: loss=0.188, reward_mean=0.260, reward_bound=0.400, batch=225 
3920: loss=0.187, reward_mean=0.280, reward_bound=0.289, batch=227 
3921: loss=0.190, reward_mean=0.340, reward_bound=0.349, batch=228 
3922: loss=0.185, reward_mean=0.290, reward_bound=0.430, batch=205 
3923: loss=0.190, reward_mean=0.370, reward_bound=0.289, batch=213 
3924: loss=0.182, reward_mean=0.390, reward_bound=0.349, batch=217 
3925: loss=0.186, reward_mean=0.320, reward_bound=0.206, batch=221 
3926: loss=0.181, reward_mean=0.310, reward_bound=0.282, batch=223 
3927: loss=0.180, reward_mean=0.320, reward_bound=0.358, batch=226 
3928: loss=0.183, reward_mean=0.350, reward_bound=0.387, batch=223 
3929: loss=0.183, reward_mean=0.290, reward_bound=0.387, batch=225 
3930: loss=0.183, reward_mean=0.420, reward_bound=0.387, batch=226 
3931: loss=0.183, reward_mean=0.350, reward_bound=0.409, batch=228 
3932: loss=0.183, reward_mean=0.280, reward_bound=0.392, batch=229 
3933: loss=0.185, reward_mean=0.380, reward_bound=0.430, batch=227 
3934: loss=0.185, reward_mean=0.310, reward_bound=0.469, batch=229 
3935: loss=0.186, reward_mean=0.340, reward_bound=0.450, batch=230 
3936: loss=0.186, reward_mean=0.400, reward_bound=0.430, batch=230 
3937: loss=0.186, reward_mean=0.330, reward_bound=0.349, batch=230 
3938: loss=0.169, reward_mean=0.340, reward_bound=0.478, batch=109 
3939: loss=0.163, reward_mean=0.320, reward_bound=0.000, batch=141 
3940: loss=0.169, reward_mean=0.350, reward_bound=0.007, batch=168 
3941: loss=0.182, reward_mean=0.320, reward_bound=0.025, batch=187 
3942: loss=0.187, reward_mean=0.410, reward_bound=0.052, batch=200 
3943: loss=0.183, reward_mean=0.450, reward_bound=0.089, batch=204 
3944: loss=0.187, reward_mean=0.370, reward_bound=0.109, batch=210 
3945: loss=0.192, reward_mean=0.430, reward_bound=0.135, batch=215 
3946: loss=0.192, reward_mean=0.370, reward_bound=0.150, batch=211 
3947: loss=0.188, reward_mean=0.330, reward_bound=0.167, batch=206 
3948: loss=0.190, reward_mean=0.320, reward_bound=0.185, batch=205 
3949: loss=0.189, reward_mean=0.350, reward_bound=0.206, batch=205 
3950: loss=0.188, reward_mean=0.330, reward_bound=0.157, batch=213 
3951: loss=0.187, reward_mean=0.430, reward_bound=0.229, batch=210 
3952: loss=0.189, reward_mean=0.430, reward_bound=0.206, batch=218 
3953: loss=0.177, reward_mean=0.360, reward_bound=0.254, batch=207 
3954: loss=0.178, reward_mean=0.410, reward_bound=0.277, batch=215 
3955: loss=0.178, reward_mean=0.440, reward_bound=0.189, batch=220 
3956: loss=0.174, reward_mean=0.330, reward_bound=0.222, batch=224 
3957: loss=0.180, reward_mean=0.380, reward_bound=0.282, batch=210 
3958: loss=0.182, reward_mean=0.400, reward_bound=0.206, batch=218 
3959: loss=0.179, reward_mean=0.390, reward_bound=0.282, batch=219 
3960: loss=0.172, reward_mean=0.370, reward_bound=0.314, batch=196 
3961: loss=0.171, reward_mean=0.410, reward_bound=0.206, batch=206 
3962: loss=0.174, reward_mean=0.350, reward_bound=0.229, batch=213 
3963: loss=0.175, reward_mean=0.430, reward_bound=0.271, batch=219 
3964: loss=0.177, reward_mean=0.300, reward_bound=0.314, batch=221 
3965: loss=0.177, reward_mean=0.320, reward_bound=0.282, batch=224 
3966: loss=0.179, reward_mean=0.350, reward_bound=0.314, batch=225 
3967: loss=0.179, reward_mean=0.340, reward_bound=0.321, batch=227 
3968: loss=0.189, reward_mean=0.400, reward_bound=0.349, batch=196 
3969: loss=0.189, reward_mean=0.450, reward_bound=0.268, batch=207 
3970: loss=0.188, reward_mean=0.280, reward_bound=0.224, batch=215 
3971: loss=0.185, reward_mean=0.330, reward_bound=0.229, batch=218 
3972: loss=0.188, reward_mean=0.350, reward_bound=0.169, batch=222 
3973: loss=0.193, reward_mean=0.350, reward_bound=0.254, batch=224 
3974: loss=0.191, reward_mean=0.310, reward_bound=0.314, batch=219 
3975: loss=0.186, reward_mean=0.450, reward_bound=0.349, batch=220 
3976: loss=0.189, reward_mean=0.380, reward_bound=0.347, batch=224 
3977: loss=0.188, reward_mean=0.340, reward_bound=0.254, batch=226 
3978: loss=0.177, reward_mean=0.350, reward_bound=0.387, batch=191 
3979: loss=0.177, reward_mean=0.330, reward_bound=0.098, batch=203 
3980: loss=0.176, reward_mean=0.380, reward_bound=0.185, batch=209 
3981: loss=0.186, reward_mean=0.450, reward_bound=0.239, batch=216 
3982: loss=0.190, reward_mean=0.350, reward_bound=0.241, batch=221 
3983: loss=0.192, reward_mean=0.430, reward_bound=0.254, batch=224 
3984: loss=0.188, reward_mean=0.330, reward_bound=0.314, batch=217 
3985: loss=0.187, reward_mean=0.300, reward_bound=0.314, batch=220 
3986: loss=0.190, reward_mean=0.410, reward_bound=0.282, batch=222 
3987: loss=0.189, reward_mean=0.360, reward_bound=0.272, batch=225 
3988: loss=0.187, reward_mean=0.320, reward_bound=0.321, batch=227 
3989: loss=0.190, reward_mean=0.340, reward_bound=0.349, batch=216 
3990: loss=0.189, reward_mean=0.290, reward_bound=0.241, batch=221 
3991: loss=0.186, reward_mean=0.360, reward_bound=0.254, batch=224 
3992: loss=0.187, reward_mean=0.340, reward_bound=0.282, batch=225 
3993: loss=0.192, reward_mean=0.340, reward_bound=0.314, batch=226 
3994: loss=0.182, reward_mean=0.420, reward_bound=0.387, batch=216 
3995: loss=0.180, reward_mean=0.350, reward_bound=0.176, batch=221 
3996: loss=0.178, reward_mean=0.450, reward_bound=0.314, batch=224 
3997: loss=0.181, reward_mean=0.310, reward_bound=0.387, batch=223 
3998: loss=0.183, reward_mean=0.370, reward_bound=0.335, batch=226 
3999: loss=0.174, reward_mean=0.370, reward_bound=0.430, batch=164 
4000: loss=0.184, reward_mean=0.390, reward_bound=0.088, batch=185 
4001: loss=0.191, reward_mean=0.460, reward_bound=0.135, batch=198 
4002: loss=0.185, reward_mean=0.300, reward_bound=0.137, batch=208 
4003: loss=0.181, reward_mean=0.420, reward_bound=0.206, batch=210 
4004: loss=0.190, reward_mean=0.300, reward_bound=0.229, batch=215 
4005: loss=0.176, reward_mean=0.390, reward_bound=0.254, batch=209 
4006: loss=0.179, reward_mean=0.300, reward_bound=0.250, batch=216 
4007: loss=0.179, reward_mean=0.430, reward_bound=0.241, batch=221 
4008: loss=0.179, reward_mean=0.320, reward_bound=0.254, batch=222 
4009: loss=0.175, reward_mean=0.390, reward_bound=0.282, batch=216 
4010: loss=0.172, reward_mean=0.470, reward_bound=0.282, batch=220 
4011: loss=0.177, reward_mean=0.320, reward_bound=0.314, batch=214 
4012: loss=0.179, reward_mean=0.330, reward_bound=0.311, batch=220 
4013: loss=0.177, reward_mean=0.350, reward_bound=0.180, batch=224 
4014: loss=0.177, reward_mean=0.430, reward_bound=0.314, batch=222 
4015: loss=0.176, reward_mean=0.430, reward_bound=0.349, batch=218 
4016: loss=0.174, reward_mean=0.340, reward_bound=0.314, batch=221 
4017: loss=0.173, reward_mean=0.340, reward_bound=0.349, batch=224 
4018: loss=0.174, reward_mean=0.410, reward_bound=0.387, batch=207 
4019: loss=0.172, reward_mean=0.390, reward_bound=0.245, batch=215 
4020: loss=0.174, reward_mean=0.320, reward_bound=0.234, batch=220 
4021: loss=0.174, reward_mean=0.410, reward_bound=0.254, batch=222 
4022: loss=0.170, reward_mean=0.440, reward_bound=0.324, batch=225 
4023: loss=0.175, reward_mean=0.440, reward_bound=0.349, batch=226 
4024: loss=0.173, reward_mean=0.420, reward_bound=0.387, batch=220 
4025: loss=0.172, reward_mean=0.410, reward_bound=0.349, batch=223 
4026: loss=0.170, reward_mean=0.400, reward_bound=0.372, batch=226 
4027: loss=0.171, reward_mean=0.380, reward_bound=0.368, batch=228 
4028: loss=0.170, reward_mean=0.370, reward_bound=0.387, batch=228 
4029: loss=0.170, reward_mean=0.360, reward_bound=0.357, batch=229 
4030: loss=0.177, reward_mean=0.410, reward_bound=0.430, batch=201 
4031: loss=0.175, reward_mean=0.350, reward_bound=0.254, batch=207 
4032: loss=0.174, reward_mean=0.460, reward_bound=0.198, batch=215 
4033: loss=0.175, reward_mean=0.350, reward_bound=0.206, batch=218 
4034: loss=0.175, reward_mean=0.420, reward_bound=0.282, batch=216 
4035: loss=0.171, reward_mean=0.450, reward_bound=0.314, batch=219 
4036: loss=0.173, reward_mean=0.430, reward_bound=0.314, batch=222 
4037: loss=0.176, reward_mean=0.320, reward_bound=0.349, batch=219 
4038: loss=0.176, reward_mean=0.380, reward_bound=0.328, batch=223 
4039: loss=0.175, reward_mean=0.410, reward_bound=0.335, batch=226 
4040: loss=0.175, reward_mean=0.420, reward_bound=0.349, batch=227 
4041: loss=0.173, reward_mean=0.370, reward_bound=0.387, batch=220 
4042: loss=0.172, reward_mean=0.300, reward_bound=0.338, batch=224 
4043: loss=0.174, reward_mean=0.330, reward_bound=0.254, batch=226 
4044: loss=0.176, reward_mean=0.400, reward_bound=0.349, batch=227 
4045: loss=0.175, reward_mean=0.340, reward_bound=0.308, batch=229 
4046: loss=0.176, reward_mean=0.360, reward_bound=0.364, batch=230 
4047: loss=0.171, reward_mean=0.470, reward_bound=0.387, batch=228 
4048: loss=0.172, reward_mean=0.410, reward_bound=0.430, batch=216 
4049: loss=0.175, reward_mean=0.430, reward_bound=0.298, batch=221 
4050: loss=0.178, reward_mean=0.430, reward_bound=0.314, batch=223 
4051: loss=0.176, reward_mean=0.480, reward_bound=0.349, batch=224 
4052: loss=0.175, reward_mean=0.380, reward_bound=0.387, batch=222 
4053: loss=0.177, reward_mean=0.330, reward_bound=0.387, batch=224 
4054: loss=0.176, reward_mean=0.380, reward_bound=0.387, batch=226 
4055: loss=0.176, reward_mean=0.430, reward_bound=0.409, batch=228 
4056: loss=0.177, reward_mean=0.330, reward_bound=0.289, batch=229 
4057: loss=0.176, reward_mean=0.440, reward_bound=0.364, batch=230 
4058: loss=0.172, reward_mean=0.450, reward_bound=0.430, batch=227 
4059: loss=0.173, reward_mean=0.360, reward_bound=0.422, batch=229 
4060: loss=0.173, reward_mean=0.420, reward_bound=0.405, batch=230 
4061: loss=0.173, reward_mean=0.370, reward_bound=0.376, batch=231 
4062: loss=0.173, reward_mean=0.380, reward_bound=0.430, batch=228 
4063: loss=0.172, reward_mean=0.460, reward_bound=0.478, batch=230 
4064: loss=0.172, reward_mean=0.330, reward_bound=0.406, batch=231 
4065: loss=0.172, reward_mean=0.380, reward_bound=0.430, batch=230 
4066: loss=0.171, reward_mean=0.430, reward_bound=0.464, batch=231 
4067: loss=0.171, reward_mean=0.410, reward_bound=0.349, batch=231 
4068: loss=0.166, reward_mean=0.350, reward_bound=0.478, batch=170 
4069: loss=0.169, reward_mean=0.370, reward_bound=0.049, batch=189 
4070: loss=0.176, reward_mean=0.440, reward_bound=0.103, batch=202 
4071: loss=0.178, reward_mean=0.490, reward_bound=0.167, batch=210 
4072: loss=0.166, reward_mean=0.390, reward_bound=0.185, batch=216 
4073: loss=0.161, reward_mean=0.380, reward_bound=0.206, batch=213 
4074: loss=0.159, reward_mean=0.410, reward_bound=0.229, batch=214 
4075: loss=0.158, reward_mean=0.370, reward_bound=0.254, batch=215 
4076: loss=0.157, reward_mean=0.300, reward_bound=0.240, batch=220 
4077: loss=0.158, reward_mean=0.310, reward_bound=0.282, batch=212 
4078: loss=0.157, reward_mean=0.270, reward_bound=0.282, batch=216 
4079: loss=0.156, reward_mean=0.400, reward_bound=0.314, batch=216 
4080: loss=0.156, reward_mean=0.350, reward_bound=0.254, batch=219 
4081: loss=0.162, reward_mean=0.380, reward_bound=0.250, batch=223 
4082: loss=0.161, reward_mean=0.290, reward_bound=0.301, batch=226 
4083: loss=0.161, reward_mean=0.370, reward_bound=0.349, batch=216 
4084: loss=0.165, reward_mean=0.420, reward_bound=0.387, batch=203 
4085: loss=0.163, reward_mean=0.420, reward_bound=0.282, batch=210 
4086: loss=0.164, reward_mean=0.410, reward_bound=0.274, batch=217 
4087: loss=0.165, reward_mean=0.410, reward_bound=0.282, batch=221 
4088: loss=0.165, reward_mean=0.440, reward_bound=0.314, batch=224 
4089: loss=0.164, reward_mean=0.450, reward_bound=0.349, batch=223 
4090: loss=0.164, reward_mean=0.420, reward_bound=0.335, batch=226 
4091: loss=0.167, reward_mean=0.450, reward_bound=0.368, batch=228 
4092: loss=0.160, reward_mean=0.400, reward_bound=0.387, batch=222 
4093: loss=0.158, reward_mean=0.400, reward_bound=0.360, batch=225 
4094: loss=0.158, reward_mean=0.310, reward_bound=0.314, batch=226 
4095: loss=0.158, reward_mean=0.370, reward_bound=0.314, batch=227 
4096: loss=0.158, reward_mean=0.480, reward_bound=0.380, batch=229 
4097: loss=0.155, reward_mean=0.350, reward_bound=0.430, batch=207 
4098: loss=0.156, reward_mean=0.380, reward_bound=0.282, batch=212 
4099: loss=0.154, reward_mean=0.340, reward_bound=0.236, batch=218 
4100: loss=0.153, reward_mean=0.410, reward_bound=0.282, batch=220 
4101: loss=0.151, reward_mean=0.390, reward_bound=0.304, batch=224 
4102: loss=0.152, reward_mean=0.360, reward_bound=0.349, batch=223 
4103: loss=0.154, reward_mean=0.310, reward_bound=0.301, batch=226 
4104: loss=0.154, reward_mean=0.370, reward_bound=0.387, batch=223 
4105: loss=0.155, reward_mean=0.370, reward_bound=0.430, batch=214 
4106: loss=0.153, reward_mean=0.420, reward_bound=0.254, batch=219 
4107: loss=0.155, reward_mean=0.290, reward_bound=0.295, batch=223 
4108: loss=0.153, reward_mean=0.480, reward_bound=0.372, batch=226 
4109: loss=0.154, reward_mean=0.410, reward_bound=0.387, batch=224 
4110: loss=0.154, reward_mean=0.420, reward_bound=0.349, batch=226 
4111: loss=0.156, reward_mean=0.410, reward_bound=0.430, batch=222 
4112: loss=0.155, reward_mean=0.400, reward_bound=0.373, batch=225 
4113: loss=0.156, reward_mean=0.330, reward_bound=0.312, batch=227 
4114: loss=0.156, reward_mean=0.430, reward_bound=0.387, batch=227 
4115: loss=0.155, reward_mean=0.390, reward_bound=0.380, batch=229 
4116: loss=0.155, reward_mean=0.400, reward_bound=0.349, batch=229 
4117: loss=0.155, reward_mean=0.380, reward_bound=0.364, batch=230 
4118: loss=0.158, reward_mean=0.380, reward_bound=0.387, batch=230 
4119: loss=0.157, reward_mean=0.390, reward_bound=0.430, batch=229 
4120: loss=0.156, reward_mean=0.450, reward_bound=0.450, batch=230 
4121: loss=0.156, reward_mean=0.380, reward_bound=0.430, batch=230 
4122: loss=0.160, reward_mean=0.440, reward_bound=0.478, batch=197 
4123: loss=0.159, reward_mean=0.350, reward_bound=0.254, batch=206 
4124: loss=0.159, reward_mean=0.350, reward_bound=0.229, batch=213 
4125: loss=0.157, reward_mean=0.330, reward_bound=0.254, batch=214 
4126: loss=0.156, reward_mean=0.430, reward_bound=0.229, batch=218 
4127: loss=0.155, reward_mean=0.330, reward_bound=0.257, batch=222 
4128: loss=0.154, reward_mean=0.390, reward_bound=0.282, batch=224 
4129: loss=0.162, reward_mean=0.400, reward_bound=0.314, batch=221 
4130: loss=0.166, reward_mean=0.340, reward_bound=0.314, batch=224 
4131: loss=0.161, reward_mean=0.250, reward_bound=0.349, batch=224 
4132: loss=0.161, reward_mean=0.370, reward_bound=0.252, batch=227 
4133: loss=0.162, reward_mean=0.340, reward_bound=0.277, batch=229 
4134: loss=0.161, reward_mean=0.370, reward_bound=0.349, batch=229 
4135: loss=0.162, reward_mean=0.370, reward_bound=0.364, batch=230 
4136: loss=0.158, reward_mean=0.320, reward_bound=0.387, batch=222 
4137: loss=0.158, reward_mean=0.360, reward_bound=0.360, batch=225 
4138: loss=0.157, reward_mean=0.300, reward_bound=0.387, batch=224 
4139: loss=0.157, reward_mean=0.410, reward_bound=0.387, batch=225 
4140: loss=0.156, reward_mean=0.370, reward_bound=0.396, batch=227 
4141: loss=0.157, reward_mean=0.400, reward_bound=0.430, batch=216 
4142: loss=0.154, reward_mean=0.410, reward_bound=0.268, batch=221 
4143: loss=0.153, reward_mean=0.360, reward_bound=0.314, batch=224 
4144: loss=0.154, reward_mean=0.390, reward_bound=0.349, batch=222 
4145: loss=0.155, reward_mean=0.340, reward_bound=0.360, batch=225 
4146: loss=0.158, reward_mean=0.400, reward_bound=0.321, batch=227 
4147: loss=0.157, reward_mean=0.350, reward_bound=0.380, batch=229 
4148: loss=0.159, reward_mean=0.400, reward_bound=0.387, batch=226 
4149: loss=0.158, reward_mean=0.440, reward_bound=0.409, batch=228 
4150: loss=0.158, reward_mean=0.420, reward_bound=0.392, batch=229 
4151: loss=0.159, reward_mean=0.380, reward_bound=0.405, batch=230 
4152: loss=0.155, reward_mean=0.440, reward_bound=0.430, batch=221 
4153: loss=0.154, reward_mean=0.330, reward_bound=0.430, batch=223 
4154: loss=0.153, reward_mean=0.400, reward_bound=0.387, batch=225 
4155: loss=0.153, reward_mean=0.450, reward_bound=0.356, batch=227 
4156: loss=0.152, reward_mean=0.370, reward_bound=0.422, batch=229 
4157: loss=0.151, reward_mean=0.390, reward_bound=0.381, batch=230 
4158: loss=0.152, reward_mean=0.400, reward_bound=0.430, batch=227 
4159: loss=0.151, reward_mean=0.370, reward_bound=0.380, batch=229 
4160: loss=0.151, reward_mean=0.420, reward_bound=0.430, batch=229 
4161: loss=0.152, reward_mean=0.330, reward_bound=0.328, batch=230 
4162: loss=0.154, reward_mean=0.410, reward_bound=0.478, batch=214 
4163: loss=0.155, reward_mean=0.380, reward_bound=0.349, batch=219 
4164: loss=0.154, reward_mean=0.400, reward_bound=0.295, batch=223 
4165: loss=0.151, reward_mean=0.350, reward_bound=0.314, batch=225 
4166: loss=0.151, reward_mean=0.370, reward_bound=0.349, batch=226 
4167: loss=0.155, reward_mean=0.380, reward_bound=0.368, batch=228 
4168: loss=0.153, reward_mean=0.390, reward_bound=0.387, batch=224 
4169: loss=0.156, reward_mean=0.440, reward_bound=0.311, batch=227 
4170: loss=0.153, reward_mean=0.390, reward_bound=0.314, batch=227 
4171: loss=0.153, reward_mean=0.380, reward_bound=0.349, batch=228 
4172: loss=0.153, reward_mean=0.380, reward_bound=0.349, batch=228 
4173: loss=0.156, reward_mean=0.400, reward_bound=0.430, batch=228 
4174: loss=0.155, reward_mean=0.440, reward_bound=0.357, batch=229 
4175: loss=0.155, reward_mean=0.310, reward_bound=0.430, batch=229 
4176: loss=0.155, reward_mean=0.370, reward_bound=0.450, batch=230 
4177: loss=0.155, reward_mean=0.440, reward_bound=0.478, batch=223 
4178: loss=0.154, reward_mean=0.420, reward_bound=0.372, batch=226 
4179: loss=0.154, reward_mean=0.420, reward_bound=0.409, batch=228 
4180: loss=0.156, reward_mean=0.340, reward_bound=0.435, batch=229 
4181: loss=0.155, reward_mean=0.420, reward_bound=0.450, batch=230 
4182: loss=0.156, reward_mean=0.380, reward_bound=0.338, batch=231 
4183: loss=0.155, reward_mean=0.320, reward_bound=0.430, batch=230 
4184: loss=0.156, reward_mean=0.310, reward_bound=0.418, batch=231 
4185: loss=0.156, reward_mean=0.410, reward_bound=0.430, batch=231 
4186: loss=0.156, reward_mean=0.380, reward_bound=0.387, batch=231 
4187: loss=0.156, reward_mean=0.420, reward_bound=0.430, batch=231 
4188: loss=0.157, reward_mean=0.370, reward_bound=0.478, batch=227 
4189: loss=0.157, reward_mean=0.470, reward_bound=0.430, batch=227 
4190: loss=0.157, reward_mean=0.380, reward_bound=0.460, batch=229 
4191: loss=0.157, reward_mean=0.330, reward_bound=0.405, batch=230 
4192: loss=0.157, reward_mean=0.340, reward_bound=0.418, batch=231 
4193: loss=0.157, reward_mean=0.410, reward_bound=0.430, batch=231 
4194: loss=0.157, reward_mean=0.420, reward_bound=0.478, batch=228 
4196: loss=0.181, reward_mean=0.430, reward_bound=0.000, batch=43 
4197: loss=0.174, reward_mean=0.380, reward_bound=0.000, batch=81 
4198: loss=0.161, reward_mean=0.430, reward_bound=0.000, batch=124 
4199: loss=0.172, reward_mean=0.440, reward_bound=0.001, batch=157 
4200: loss=0.183, reward_mean=0.440, reward_bound=0.022, batch=180 
4201: loss=0.187, reward_mean=0.440, reward_bound=0.038, batch=195 
4202: loss=0.181, reward_mean=0.370, reward_bound=0.058, batch=209 
4203: loss=0.179, reward_mean=0.430, reward_bound=0.072, batch=205 
4204: loss=0.174, reward_mean=0.420, reward_bound=0.098, batch=207 
4205: loss=0.173, reward_mean=0.440, reward_bound=0.109, batch=225 
4206: loss=0.170, reward_mean=0.320, reward_bound=0.122, batch=222 
4207: loss=0.170, reward_mean=0.410, reward_bound=0.150, batch=214 
4208: loss=0.172, reward_mean=0.400, reward_bound=0.167, batch=210 
4209: loss=0.179, reward_mean=0.370, reward_bound=0.185, batch=183 
4210: loss=0.178, reward_mean=0.380, reward_bound=0.095, batch=198 
4211: loss=0.176, reward_mean=0.380, reward_bound=0.111, batch=208 
4212: loss=0.173, reward_mean=0.460, reward_bound=0.167, batch=213 
4213: loss=0.174, reward_mean=0.380, reward_bound=0.206, batch=191 
4214: loss=0.171, reward_mean=0.470, reward_bound=0.206, batch=202 
4215: loss=0.171, reward_mean=0.460, reward_bound=0.229, batch=185 
4216: loss=0.168, reward_mean=0.390, reward_bound=0.170, batch=199 
4217: loss=0.167, reward_mean=0.380, reward_bound=0.185, batch=207 
4218: loss=0.165, reward_mean=0.320, reward_bound=0.202, batch=215 
4219: loss=0.164, reward_mean=0.360, reward_bound=0.229, batch=214 
4220: loss=0.166, reward_mean=0.370, reward_bound=0.204, batch=220 
4221: loss=0.163, reward_mean=0.510, reward_bound=0.254, batch=190 
4222: loss=0.161, reward_mean=0.370, reward_bound=0.185, batch=202 
4223: loss=0.163, reward_mean=0.400, reward_bound=0.206, batch=213 
4224: loss=0.160, reward_mean=0.390, reward_bound=0.206, batch=218 
4225: loss=0.158, reward_mean=0.370, reward_bound=0.229, batch=219 
4226: loss=0.159, reward_mean=0.450, reward_bound=0.254, batch=217 
4227: loss=0.161, reward_mean=0.400, reward_bound=0.272, batch=222 
4228: loss=0.160, reward_mean=0.430, reward_bound=0.282, batch=179 
4229: loss=0.158, reward_mean=0.430, reward_bound=0.194, batch=195 
4230: loss=0.159, reward_mean=0.420, reward_bound=0.157, batch=206 
4231: loss=0.159, reward_mean=0.420, reward_bound=0.206, batch=211 
4232: loss=0.163, reward_mean=0.370, reward_bound=0.229, batch=213 
4233: loss=0.164, reward_mean=0.370, reward_bound=0.254, batch=212 
4234: loss=0.166, reward_mean=0.350, reward_bound=0.229, batch=216 
4235: loss=0.164, reward_mean=0.480, reward_bound=0.282, batch=219 
4236: loss=0.164, reward_mean=0.420, reward_bound=0.206, batch=222 
4237: loss=0.163, reward_mean=0.400, reward_bound=0.282, batch=224 
4238: loss=0.162, reward_mean=0.440, reward_bound=0.311, batch=227 
4239: loss=0.170, reward_mean=0.400, reward_bound=0.314, batch=181 
4240: loss=0.174, reward_mean=0.370, reward_bound=0.089, batch=196 
4241: loss=0.176, reward_mean=0.410, reward_bound=0.185, batch=199 
4242: loss=0.178, reward_mean=0.390, reward_bound=0.206, batch=207 
4243: loss=0.180, reward_mean=0.420, reward_bound=0.229, batch=214 
4244: loss=0.182, reward_mean=0.330, reward_bound=0.254, batch=215 
4245: loss=0.178, reward_mean=0.400, reward_bound=0.282, batch=215 
4246: loss=0.178, reward_mean=0.360, reward_bound=0.254, batch=218 
4247: loss=0.178, reward_mean=0.320, reward_bound=0.286, batch=222 
4248: loss=0.176, reward_mean=0.350, reward_bound=0.254, batch=224 
4249: loss=0.176, reward_mean=0.400, reward_bound=0.311, batch=227 
4250: loss=0.177, reward_mean=0.390, reward_bound=0.314, batch=226 
4251: loss=0.176, reward_mean=0.370, reward_bound=0.314, batch=227 
4252: loss=0.180, reward_mean=0.400, reward_bound=0.349, batch=163 
4253: loss=0.176, reward_mean=0.460, reward_bound=0.080, batch=182 
4254: loss=0.176, reward_mean=0.390, reward_bound=0.092, batch=197 
4255: loss=0.180, reward_mean=0.320, reward_bound=0.098, batch=207 
4256: loss=0.179, reward_mean=0.360, reward_bound=0.147, batch=215 
4257: loss=0.178, reward_mean=0.460, reward_bound=0.185, batch=218 
4258: loss=0.180, reward_mean=0.340, reward_bound=0.206, batch=212 
4259: loss=0.181, reward_mean=0.370, reward_bound=0.236, batch=218 
4260: loss=0.181, reward_mean=0.380, reward_bound=0.208, batch=222 
4261: loss=0.177, reward_mean=0.470, reward_bound=0.282, batch=210 
4262: loss=0.181, reward_mean=0.400, reward_bound=0.274, batch=217 
4263: loss=0.183, reward_mean=0.330, reward_bound=0.267, batch=222 
4264: loss=0.179, reward_mean=0.460, reward_bound=0.314, batch=212 
4265: loss=0.174, reward_mean=0.510, reward_bound=0.349, batch=201 
4266: loss=0.173, reward_mean=0.440, reward_bound=0.206, batch=210 
4267: loss=0.172, reward_mean=0.350, reward_bound=0.254, batch=215 
4268: loss=0.169, reward_mean=0.440, reward_bound=0.349, batch=219 
4269: loss=0.170, reward_mean=0.450, reward_bound=0.328, batch=223 
4270: loss=0.168, reward_mean=0.460, reward_bound=0.349, batch=225 
4271: loss=0.174, reward_mean=0.360, reward_bound=0.387, batch=149 
4272: loss=0.176, reward_mean=0.370, reward_bound=0.015, batch=174 
4273: loss=0.183, reward_mean=0.400, reward_bound=0.058, batch=192 
4274: loss=0.179, reward_mean=0.410, reward_bound=0.098, batch=200 
4275: loss=0.179, reward_mean=0.380, reward_bound=0.122, batch=209 
4276: loss=0.179, reward_mean=0.350, reward_bound=0.135, batch=212 
4277: loss=0.181, reward_mean=0.420, reward_bound=0.150, batch=214 
4278: loss=0.177, reward_mean=0.460, reward_bound=0.167, batch=218 
4279: loss=0.185, reward_mean=0.380, reward_bound=0.206, batch=212 
4280: loss=0.186, reward_mean=0.440, reward_bound=0.229, batch=209 
4281: loss=0.184, reward_mean=0.410, reward_bound=0.194, batch=216 
4282: loss=0.176, reward_mean=0.500, reward_bound=0.254, batch=209 
4283: loss=0.175, reward_mean=0.380, reward_bound=0.254, batch=215 
4284: loss=0.176, reward_mean=0.390, reward_bound=0.254, batch=219 
4285: loss=0.178, reward_mean=0.340, reward_bound=0.282, batch=216 
4286: loss=0.177, reward_mean=0.340, reward_bound=0.314, batch=203 
4287: loss=0.173, reward_mean=0.440, reward_bound=0.160, batch=212 
4288: loss=0.174, reward_mean=0.430, reward_bound=0.191, batch=218 
4289: loss=0.174, reward_mean=0.350, reward_bound=0.254, batch=220 
4290: loss=0.174, reward_mean=0.360, reward_bound=0.274, batch=224 
4291: loss=0.172, reward_mean=0.380, reward_bound=0.345, batch=227 
4292: loss=0.174, reward_mean=0.420, reward_bound=0.349, batch=211 
4293: loss=0.172, reward_mean=0.420, reward_bound=0.254, batch=217 
4294: loss=0.172, reward_mean=0.380, reward_bound=0.282, batch=221 
4295: loss=0.175, reward_mean=0.390, reward_bound=0.314, batch=224 
4296: loss=0.176, reward_mean=0.300, reward_bound=0.345, batch=227 
4297: loss=0.177, reward_mean=0.420, reward_bound=0.349, batch=225 
4298: loss=0.176, reward_mean=0.410, reward_bound=0.356, batch=227 
4299: loss=0.176, reward_mean=0.430, reward_bound=0.387, batch=204 
4300: loss=0.174, reward_mean=0.400, reward_bound=0.119, batch=213 
4301: loss=0.178, reward_mean=0.360, reward_bound=0.167, batch=218 
4302: loss=0.182, reward_mean=0.380, reward_bound=0.229, batch=218 
4303: loss=0.181, reward_mean=0.360, reward_bound=0.208, batch=222 
4304: loss=0.182, reward_mean=0.350, reward_bound=0.229, batch=224 
4305: loss=0.180, reward_mean=0.480, reward_bound=0.282, batch=224 
4306: loss=0.176, reward_mean=0.380, reward_bound=0.349, batch=221 
4307: loss=0.178, reward_mean=0.380, reward_bound=0.349, batch=223 
4308: loss=0.178, reward_mean=0.390, reward_bound=0.387, batch=218 
4309: loss=0.180, reward_mean=0.400, reward_bound=0.317, batch=222 
4310: loss=0.179, reward_mean=0.380, reward_bound=0.324, batch=225 
4311: loss=0.180, reward_mean=0.470, reward_bound=0.349, batch=225 
4312: loss=0.179, reward_mean=0.390, reward_bound=0.356, batch=227 
4313: loss=0.177, reward_mean=0.390, reward_bound=0.387, batch=227 
4314: loss=0.178, reward_mean=0.340, reward_bound=0.349, batch=228 
4315: loss=0.177, reward_mean=0.300, reward_bound=0.317, batch=229 
4316: loss=0.180, reward_mean=0.370, reward_bound=0.364, batch=230 
4317: loss=0.206, reward_mean=0.380, reward_bound=0.430, batch=121 
4318: loss=0.194, reward_mean=0.410, reward_bound=0.025, batch=153 
4319: loss=0.194, reward_mean=0.400, reward_bound=0.039, batch=177 
4320: loss=0.187, reward_mean=0.360, reward_bound=0.070, batch=194 
4321: loss=0.186, reward_mean=0.420, reward_bound=0.098, batch=203 
4322: loss=0.191, reward_mean=0.310, reward_bound=0.109, batch=206 
4323: loss=0.190, reward_mean=0.350, reward_bound=0.135, batch=212 
4324: loss=0.183, reward_mean=0.400, reward_bound=0.155, batch=218 
4325: loss=0.186, reward_mean=0.350, reward_bound=0.167, batch=215 
4326: loss=0.190, reward_mean=0.420, reward_bound=0.206, batch=206 
4327: loss=0.195, reward_mean=0.490, reward_bound=0.229, batch=206 
4328: loss=0.204, reward_mean=0.420, reward_bound=0.254, batch=193 
4329: loss=0.206, reward_mean=0.430, reward_bound=0.160, batch=205 
4330: loss=0.208, reward_mean=0.440, reward_bound=0.229, batch=212 
4331: loss=0.208, reward_mean=0.470, reward_bound=0.254, batch=217 
4332: loss=0.207, reward_mean=0.380, reward_bound=0.282, batch=210 
4333: loss=0.207, reward_mean=0.350, reward_bound=0.200, batch=217 
4334: loss=0.201, reward_mean=0.380, reward_bound=0.314, batch=200 
4335: loss=0.199, reward_mean=0.400, reward_bound=0.210, batch=210 
4336: loss=0.196, reward_mean=0.320, reward_bound=0.222, batch=217 
4337: loss=0.201, reward_mean=0.430, reward_bound=0.282, batch=220 
4338: loss=0.199, reward_mean=0.300, reward_bound=0.314, batch=220 
4339: loss=0.199, reward_mean=0.300, reward_bound=0.281, batch=224 
4340: loss=0.196, reward_mean=0.300, reward_bound=0.345, batch=227 
4341: loss=0.201, reward_mean=0.320, reward_bound=0.349, batch=193 
4342: loss=0.204, reward_mean=0.400, reward_bound=0.220, batch=205 
4343: loss=0.203, reward_mean=0.450, reward_bound=0.254, batch=211 
4344: loss=0.201, reward_mean=0.370, reward_bound=0.282, batch=211 
4345: loss=0.202, reward_mean=0.380, reward_bound=0.282, batch=216 
4346: loss=0.204, reward_mean=0.300, reward_bound=0.298, batch=221 
4347: loss=0.203, reward_mean=0.440, reward_bound=0.314, batch=218 
4348: loss=0.202, reward_mean=0.350, reward_bound=0.231, batch=222 
4349: loss=0.199, reward_mean=0.340, reward_bound=0.172, batch=225 
4350: loss=0.199, reward_mean=0.380, reward_bound=0.189, batch=227 
4351: loss=0.200, reward_mean=0.400, reward_bound=0.277, batch=229 
4352: loss=0.205, reward_mean=0.400, reward_bound=0.314, batch=228 
4353: loss=0.203, reward_mean=0.440, reward_bound=0.349, batch=223 
4354: loss=0.203, reward_mean=0.360, reward_bound=0.358, batch=226 
4355: loss=0.197, reward_mean=0.390, reward_bound=0.387, batch=194 
4356: loss=0.191, reward_mean=0.430, reward_bound=0.226, batch=206 
4357: loss=0.188, reward_mean=0.360, reward_bound=0.178, batch=214 
4358: loss=0.186, reward_mean=0.270, reward_bound=0.204, batch=220 
4359: loss=0.188, reward_mean=0.350, reward_bound=0.229, batch=222 
4360: loss=0.190, reward_mean=0.250, reward_bound=0.181, batch=225 
4361: loss=0.192, reward_mean=0.340, reward_bound=0.254, batch=225 
4362: loss=0.193, reward_mean=0.390, reward_bound=0.260, batch=227 
4363: loss=0.190, reward_mean=0.340, reward_bound=0.282, batch=228 
4364: loss=0.191, reward_mean=0.330, reward_bound=0.314, batch=226 
4365: loss=0.190, reward_mean=0.370, reward_bound=0.298, batch=228 
4366: loss=0.191, reward_mean=0.390, reward_bound=0.317, batch=229 
4367: loss=0.195, reward_mean=0.350, reward_bound=0.349, batch=223 
4368: loss=0.199, reward_mean=0.420, reward_bound=0.335, batch=226 
4369: loss=0.200, reward_mean=0.390, reward_bound=0.349, batch=227 
4370: loss=0.199, reward_mean=0.410, reward_bound=0.349, batch=228 
4371: loss=0.192, reward_mean=0.470, reward_bound=0.387, batch=214 
4372: loss=0.193, reward_mean=0.320, reward_bound=0.282, batch=218 
4373: loss=0.194, reward_mean=0.320, reward_bound=0.349, batch=221 
4374: loss=0.192, reward_mean=0.350, reward_bound=0.387, batch=220 
4375: loss=0.192, reward_mean=0.460, reward_bound=0.376, batch=224 
4376: loss=0.193, reward_mean=0.410, reward_bound=0.384, batch=227 
4377: loss=0.194, reward_mean=0.350, reward_bound=0.387, batch=228 
4378: loss=0.193, reward_mean=0.430, reward_bound=0.430, batch=176 
4379: loss=0.189, reward_mean=0.400, reward_bound=0.158, batch=193 
4380: loss=0.190, reward_mean=0.350, reward_bound=0.206, batch=204 
4381: loss=0.195, reward_mean=0.410, reward_bound=0.206, batch=210 
4382: loss=0.191, reward_mean=0.300, reward_bound=0.229, batch=213 
4383: loss=0.192, reward_mean=0.470, reward_bound=0.271, batch=219 
4384: loss=0.191, reward_mean=0.440, reward_bound=0.282, batch=222 
4385: loss=0.189, reward_mean=0.330, reward_bound=0.292, batch=225 
4386: loss=0.195, reward_mean=0.360, reward_bound=0.314, batch=215 
4387: loss=0.197, reward_mean=0.390, reward_bound=0.289, batch=220 
4388: loss=0.196, reward_mean=0.350, reward_bound=0.314, batch=221 
4389: loss=0.196, reward_mean=0.400, reward_bound=0.349, batch=212 
4390: loss=0.193, reward_mean=0.440, reward_bound=0.314, batch=217 
4391: loss=0.195, reward_mean=0.370, reward_bound=0.308, batch=222 
4392: loss=0.194, reward_mean=0.320, reward_bound=0.314, batch=224 
4393: loss=0.193, reward_mean=0.390, reward_bound=0.345, batch=227 
4394: loss=0.194, reward_mean=0.350, reward_bound=0.380, batch=229 
4395: loss=0.193, reward_mean=0.410, reward_bound=0.364, batch=230 
4396: loss=0.190, reward_mean=0.390, reward_bound=0.387, batch=213 
4397: loss=0.190, reward_mean=0.380, reward_bound=0.244, batch=219 
4398: loss=0.190, reward_mean=0.260, reward_bound=0.239, batch=223 
4399: loss=0.192, reward_mean=0.430, reward_bound=0.301, batch=226 
4400: loss=0.196, reward_mean=0.450, reward_bound=0.314, batch=227 
4401: loss=0.196, reward_mean=0.370, reward_bound=0.349, batch=226 
4402: loss=0.197, reward_mean=0.350, reward_bound=0.331, batch=228 
4403: loss=0.199, reward_mean=0.410, reward_bound=0.317, batch=229 
4404: loss=0.195, reward_mean=0.430, reward_bound=0.387, batch=226 
4405: loss=0.195, reward_mean=0.290, reward_bound=0.316, batch=228 
4406: loss=0.194, reward_mean=0.370, reward_bound=0.430, batch=200 
4407: loss=0.190, reward_mean=0.390, reward_bound=0.200, batch=210 
4408: loss=0.193, reward_mean=0.490, reward_bound=0.254, batch=216 
4409: loss=0.191, reward_mean=0.430, reward_bound=0.314, batch=218 
4410: loss=0.191, reward_mean=0.420, reward_bound=0.349, batch=216 
4411: loss=0.195, reward_mean=0.400, reward_bound=0.331, batch=221 
4412: loss=0.197, reward_mean=0.370, reward_bound=0.254, batch=224 
4413: loss=0.193, reward_mean=0.400, reward_bound=0.349, batch=224 
4414: loss=0.192, reward_mean=0.410, reward_bound=0.282, batch=226 
4415: loss=0.191, reward_mean=0.410, reward_bound=0.387, batch=217 
4416: loss=0.194, reward_mean=0.390, reward_bound=0.342, batch=222 
4417: loss=0.194, reward_mean=0.330, reward_bound=0.349, batch=220 
4418: loss=0.196, reward_mean=0.410, reward_bound=0.356, batch=224 
4419: loss=0.194, reward_mean=0.420, reward_bound=0.380, batch=227 
4420: loss=0.193, reward_mean=0.330, reward_bound=0.380, batch=229 
4421: loss=0.192, reward_mean=0.560, reward_bound=0.387, batch=227 
4422: loss=0.192, reward_mean=0.450, reward_bound=0.387, batch=228 
4423: loss=0.194, reward_mean=0.360, reward_bound=0.430, batch=218 
4424: loss=0.197, reward_mean=0.350, reward_bound=0.257, batch=222 
4425: loss=0.199, reward_mean=0.420, reward_bound=0.292, batch=225 
4426: loss=0.194, reward_mean=0.350, reward_bound=0.356, batch=227 
4427: loss=0.192, reward_mean=0.360, reward_bound=0.387, batch=227 
4428: loss=0.193, reward_mean=0.380, reward_bound=0.373, batch=229 
4429: loss=0.191, reward_mean=0.300, reward_bound=0.387, batch=229 
4430: loss=0.192, reward_mean=0.370, reward_bound=0.430, batch=224 
4431: loss=0.213, reward_mean=0.400, reward_bound=0.478, batch=87 
4432: loss=0.206, reward_mean=0.410, reward_bound=0.000, batch=128 
4433: loss=0.207, reward_mean=0.400, reward_bound=0.005, batch=159 
4434: loss=0.209, reward_mean=0.340, reward_bound=0.015, batch=181 
4435: loss=0.214, reward_mean=0.390, reward_bound=0.038, batch=195 
4436: loss=0.218, reward_mean=0.420, reward_bound=0.072, batch=204 
4437: loss=0.213, reward_mean=0.360, reward_bound=0.097, batch=213 
4438: loss=0.205, reward_mean=0.470, reward_bound=0.117, batch=219 
4439: loss=0.205, reward_mean=0.410, reward_bound=0.135, batch=212 
4440: loss=0.210, reward_mean=0.440, reward_bound=0.150, batch=215 
4441: loss=0.204, reward_mean=0.470, reward_bound=0.167, batch=205 
4442: loss=0.200, reward_mean=0.390, reward_bound=0.185, batch=205 
4443: loss=0.191, reward_mean=0.360, reward_bound=0.206, batch=202 
4444: loss=0.191, reward_mean=0.390, reward_bound=0.229, batch=196 
4445: loss=0.201, reward_mean=0.470, reward_bound=0.254, batch=183 
4446: loss=0.199, reward_mean=0.360, reward_bound=0.082, batch=198 
4447: loss=0.201, reward_mean=0.440, reward_bound=0.137, batch=208 
4448: loss=0.201, reward_mean=0.370, reward_bound=0.150, batch=213 
4449: loss=0.203, reward_mean=0.410, reward_bound=0.185, batch=217 
4450: loss=0.203, reward_mean=0.370, reward_bound=0.229, batch=221 
4451: loss=0.204, reward_mean=0.420, reward_bound=0.254, batch=219 
4452: loss=0.209, reward_mean=0.410, reward_bound=0.282, batch=194 
4453: loss=0.207, reward_mean=0.360, reward_bound=0.167, batch=205 
4454: loss=0.208, reward_mean=0.440, reward_bound=0.206, batch=212 
4455: loss=0.209, reward_mean=0.430, reward_bound=0.229, batch=215 
4456: loss=0.208, reward_mean=0.360, reward_bound=0.254, batch=216 
4457: loss=0.206, reward_mean=0.350, reward_bound=0.282, batch=216 
4458: loss=0.211, reward_mean=0.320, reward_bound=0.314, batch=190 
4459: loss=0.213, reward_mean=0.530, reward_bound=0.185, batch=201 
4460: loss=0.216, reward_mean=0.390, reward_bound=0.206, batch=210 
4461: loss=0.213, reward_mean=0.450, reward_bound=0.229, batch=216 
4462: loss=0.209, reward_mean=0.390, reward_bound=0.254, batch=217 
4463: loss=0.211, reward_mean=0.450, reward_bound=0.254, batch=221 
4464: loss=0.211, reward_mean=0.380, reward_bound=0.282, batch=218 
4465: loss=0.208, reward_mean=0.370, reward_bound=0.314, batch=215 
4466: loss=0.206, reward_mean=0.370, reward_bound=0.321, batch=220 
4467: loss=0.206, reward_mean=0.340, reward_bound=0.314, batch=223 
4468: loss=0.203, reward_mean=0.430, reward_bound=0.349, batch=185 
4469: loss=0.205, reward_mean=0.400, reward_bound=0.138, batch=199 
4470: loss=0.207, reward_mean=0.420, reward_bound=0.174, batch=209 
4471: loss=0.211, reward_mean=0.410, reward_bound=0.229, batch=215 
4472: loss=0.214, reward_mean=0.470, reward_bound=0.282, batch=211 
4473: loss=0.210, reward_mean=0.380, reward_bound=0.314, batch=215 
4474: loss=0.210, reward_mean=0.440, reward_bound=0.282, batch=219 
4475: loss=0.209, reward_mean=0.310, reward_bound=0.265, batch=223 
4476: loss=0.209, reward_mean=0.430, reward_bound=0.314, batch=225 
4477: loss=0.211, reward_mean=0.270, reward_bound=0.349, batch=216 
4478: loss=0.210, reward_mean=0.370, reward_bound=0.186, batch=221 
4479: loss=0.211, reward_mean=0.370, reward_bound=0.254, batch=223 
4480: loss=0.216, reward_mean=0.390, reward_bound=0.387, batch=180 
4481: loss=0.220, reward_mean=0.370, reward_bound=0.157, batch=196 
4482: loss=0.219, reward_mean=0.410, reward_bound=0.122, batch=205 
4483: loss=0.220, reward_mean=0.350, reward_bound=0.167, batch=210 
4484: loss=0.222, reward_mean=0.340, reward_bound=0.185, batch=214 
4485: loss=0.221, reward_mean=0.370, reward_bound=0.226, batch=220 
4486: loss=0.216, reward_mean=0.410, reward_bound=0.229, batch=218 
4487: loss=0.223, reward_mean=0.320, reward_bound=0.254, batch=214 
4488: loss=0.228, reward_mean=0.390, reward_bound=0.282, batch=210 
4489: loss=0.228, reward_mean=0.410, reward_bound=0.206, batch=219 
4490: loss=0.227, reward_mean=0.470, reward_bound=0.239, batch=223 
4491: loss=0.228, reward_mean=0.320, reward_bound=0.254, batch=224 
4492: loss=0.232, reward_mean=0.340, reward_bound=0.282, batch=225 
4493: loss=0.224, reward_mean=0.330, reward_bound=0.314, batch=222 
4494: loss=0.224, reward_mean=0.430, reward_bound=0.282, batch=222 
4495: loss=0.228, reward_mean=0.400, reward_bound=0.349, batch=213 
4496: loss=0.229, reward_mean=0.290, reward_bound=0.244, batch=219 
4497: loss=0.228, reward_mean=0.450, reward_bound=0.282, batch=222 
4498: loss=0.228, reward_mean=0.420, reward_bound=0.263, batch=225 
4499: loss=0.227, reward_mean=0.530, reward_bound=0.314, batch=226 
4500: loss=0.227, reward_mean=0.440, reward_bound=0.349, batch=227 
4501: loss=0.226, reward_mean=0.370, reward_bound=0.308, batch=229 
4502: loss=0.223, reward_mean=0.320, reward_bound=0.387, batch=224 
4503: loss=0.223, reward_mean=0.410, reward_bound=0.345, batch=227 
4504: loss=0.222, reward_mean=0.400, reward_bound=0.387, batch=228 
4505: loss=0.222, reward_mean=0.340, reward_bound=0.392, batch=229 
4506: loss=0.221, reward_mean=0.330, reward_bound=0.405, batch=230 
4507: loss=0.203, reward_mean=0.370, reward_bound=0.430, batch=153 
4508: loss=0.211, reward_mean=0.470, reward_bound=0.047, batch=176 
4509: loss=0.210, reward_mean=0.450, reward_bound=0.076, batch=193 
4510: loss=0.216, reward_mean=0.310, reward_bound=0.080, batch=204 
4511: loss=0.222, reward_mean=0.340, reward_bound=0.097, batch=213 
4512: loss=0.222, reward_mean=0.440, reward_bound=0.122, batch=215 
4513: loss=0.222, reward_mean=0.340, reward_bound=0.150, batch=218 
4514: loss=0.216, reward_mean=0.320, reward_bound=0.185, batch=214 
4515: loss=0.216, reward_mean=0.380, reward_bound=0.206, batch=215 
4516: loss=0.224, reward_mean=0.490, reward_bound=0.229, batch=218 
4517: loss=0.212, reward_mean=0.380, reward_bound=0.254, batch=213 
4518: loss=0.210, reward_mean=0.350, reward_bound=0.220, batch=219 
4519: loss=0.214, reward_mean=0.280, reward_bound=0.265, batch=223 
4520: loss=0.204, reward_mean=0.340, reward_bound=0.282, batch=220 
4521: loss=0.202, reward_mean=0.380, reward_bound=0.274, batch=224 
4522: loss=0.202, reward_mean=0.390, reward_bound=0.280, batch=227 
4523: loss=0.208, reward_mean=0.370, reward_bound=0.314, batch=213 
4524: loss=0.205, reward_mean=0.500, reward_bound=0.282, batch=218 
4525: loss=0.204, reward_mean=0.420, reward_bound=0.314, batch=221 
4526: loss=0.204, reward_mean=0.450, reward_bound=0.349, batch=205 
4527: loss=0.200, reward_mean=0.350, reward_bound=0.185, batch=212 
4528: loss=0.198, reward_mean=0.370, reward_bound=0.282, batch=217 
4529: loss=0.204, reward_mean=0.480, reward_bound=0.302, batch=222 
4530: loss=0.202, reward_mean=0.320, reward_bound=0.314, batch=220 
4531: loss=0.202, reward_mean=0.400, reward_bound=0.349, batch=221 
4532: loss=0.202, reward_mean=0.440, reward_bound=0.314, batch=222 
4533: loss=0.200, reward_mean=0.440, reward_bound=0.292, batch=225 
4534: loss=0.201, reward_mean=0.410, reward_bound=0.321, batch=227 
4535: loss=0.200, reward_mean=0.380, reward_bound=0.342, batch=229 
4536: loss=0.199, reward_mean=0.420, reward_bound=0.349, batch=229 
4537: loss=0.195, reward_mean=0.330, reward_bound=0.387, batch=201 
4538: loss=0.198, reward_mean=0.350, reward_bound=0.122, batch=210 
4539: loss=0.195, reward_mean=0.430, reward_bound=0.185, batch=215 
4540: loss=0.192, reward_mean=0.370, reward_bound=0.210, batch=220 
4541: loss=0.195, reward_mean=0.320, reward_bound=0.254, batch=222 
4542: loss=0.194, reward_mean=0.400, reward_bound=0.282, batch=222 
4543: loss=0.193, reward_mean=0.470, reward_bound=0.314, batch=222 
4544: loss=0.192, reward_mean=0.430, reward_bound=0.349, batch=218 
4545: loss=0.190, reward_mean=0.360, reward_bound=0.317, batch=222 
4546: loss=0.189, reward_mean=0.300, reward_bound=0.349, batch=223 
4547: loss=0.188, reward_mean=0.350, reward_bound=0.311, batch=226 
4548: loss=0.189, reward_mean=0.450, reward_bound=0.349, batch=227 
4549: loss=0.193, reward_mean=0.300, reward_bound=0.387, batch=221 
4550: loss=0.193, reward_mean=0.250, reward_bound=0.282, batch=224 
4551: loss=0.194, reward_mean=0.340, reward_bound=0.345, batch=227 
4552: loss=0.192, reward_mean=0.460, reward_bound=0.349, batch=228 
4553: loss=0.192, reward_mean=0.420, reward_bound=0.387, batch=226 
4554: loss=0.191, reward_mean=0.420, reward_bound=0.390, batch=228 
4555: loss=0.191, reward_mean=0.430, reward_bound=0.430, batch=194 
4556: loss=0.194, reward_mean=0.370, reward_bound=0.226, batch=206 
4557: loss=0.198, reward_mean=0.420, reward_bound=0.241, batch=214 
4558: loss=0.195, reward_mean=0.340, reward_bound=0.247, batch=220 
4559: loss=0.189, reward_mean=0.380, reward_bound=0.254, batch=217 
4560: loss=0.190, reward_mean=0.390, reward_bound=0.282, batch=218 
4561: loss=0.193, reward_mean=0.450, reward_bound=0.286, batch=222 
4562: loss=0.193, reward_mean=0.330, reward_bound=0.314, batch=221 
4563: loss=0.192, reward_mean=0.430, reward_bound=0.282, batch=224 
4564: loss=0.191, reward_mean=0.390, reward_bound=0.282, batch=226 
4565: loss=0.190, reward_mean=0.390, reward_bound=0.331, batch=228 
4566: loss=0.192, reward_mean=0.430, reward_bound=0.349, batch=228 
4567: loss=0.188, reward_mean=0.430, reward_bound=0.387, batch=219 
4568: loss=0.188, reward_mean=0.420, reward_bound=0.328, batch=223 
4569: loss=0.188, reward_mean=0.400, reward_bound=0.372, batch=226 
4570: loss=0.190, reward_mean=0.450, reward_bound=0.387, batch=226 
4571: loss=0.190, reward_mean=0.460, reward_bound=0.390, batch=228 
4572: loss=0.190, reward_mean=0.370, reward_bound=0.392, batch=229 
4573: loss=0.189, reward_mean=0.410, reward_bound=0.430, batch=211 
4574: loss=0.191, reward_mean=0.450, reward_bound=0.314, batch=215 
4575: loss=0.194, reward_mean=0.490, reward_bound=0.289, batch=220 
4576: loss=0.191, reward_mean=0.330, reward_bound=0.314, batch=223 
4577: loss=0.194, reward_mean=0.410, reward_bound=0.349, batch=224 
4578: loss=0.188, reward_mean=0.440, reward_bound=0.387, batch=222 
4579: loss=0.189, reward_mean=0.310, reward_bound=0.263, batch=225 
4580: loss=0.190, reward_mean=0.360, reward_bound=0.349, batch=226 
4581: loss=0.193, reward_mean=0.400, reward_bound=0.409, batch=228 
4582: loss=0.193, reward_mean=0.400, reward_bound=0.392, batch=229 
4583: loss=0.193, reward_mean=0.320, reward_bound=0.364, batch=230 
4584: loss=0.189, reward_mean=0.410, reward_bound=0.430, batch=223 
4585: loss=0.188, reward_mean=0.510, reward_bound=0.372, batch=226 
4586: loss=0.195, reward_mean=0.360, reward_bound=0.409, batch=228 
4587: loss=0.189, reward_mean=0.440, reward_bound=0.430, batch=225 
4588: loss=0.191, reward_mean=0.550, reward_bound=0.396, batch=227 
4589: loss=0.191, reward_mean=0.380, reward_bound=0.387, batch=227 
4590: loss=0.191, reward_mean=0.390, reward_bound=0.380, batch=229 
4591: loss=0.192, reward_mean=0.440, reward_bound=0.343, batch=230 
4592: loss=0.191, reward_mean=0.410, reward_bound=0.418, batch=231 
4593: loss=0.191, reward_mean=0.420, reward_bound=0.387, batch=231 
4594: loss=0.191, reward_mean=0.430, reward_bound=0.387, batch=231 
4595: loss=0.191, reward_mean=0.380, reward_bound=0.387, batch=231 
4596: loss=0.191, reward_mean=0.410, reward_bound=0.387, batch=231 
4597: loss=0.188, reward_mean=0.390, reward_bound=0.430, batch=230 
4598: loss=0.188, reward_mean=0.530, reward_bound=0.418, batch=231 
4599: loss=0.188, reward_mean=0.430, reward_bound=0.349, batch=231 
4600: loss=0.188, reward_mean=0.440, reward_bound=0.430, batch=231 
4601: loss=0.188, reward_mean=0.460, reward_bound=0.430, batch=231 
4602: loss=0.190, reward_mean=0.380, reward_bound=0.478, batch=145 
4603: loss=0.191, reward_mean=0.400, reward_bound=0.034, batch=171 
4604: loss=0.190, reward_mean=0.460, reward_bound=0.072, batch=186 
4605: loss=0.186, reward_mean=0.440, reward_bound=0.098, batch=199 
4606: loss=0.185, reward_mean=0.430, reward_bound=0.114, batch=209 
4607: loss=0.184, reward_mean=0.390, reward_bound=0.141, batch=216 
4608: loss=0.189, reward_mean=0.440, reward_bound=0.167, batch=219 
4609: loss=0.190, reward_mean=0.340, reward_bound=0.185, batch=221 
4610: loss=0.189, reward_mean=0.440, reward_bound=0.229, batch=219 
4611: loss=0.190, reward_mean=0.430, reward_bound=0.265, batch=223 
4612: loss=0.182, reward_mean=0.420, reward_bound=0.282, batch=217 
4613: loss=0.181, reward_mean=0.430, reward_bound=0.314, batch=212 
4614: loss=0.180, reward_mean=0.440, reward_bound=0.263, batch=218 
4615: loss=0.182, reward_mean=0.440, reward_bound=0.317, batch=222 
4616: loss=0.181, reward_mean=0.360, reward_bound=0.314, batch=224 
4617: loss=0.179, reward_mean=0.430, reward_bound=0.349, batch=206 
4618: loss=0.185, reward_mean=0.530, reward_bound=0.282, batch=213 
4619: loss=0.185, reward_mean=0.420, reward_bound=0.227, batch=219 
4620: loss=0.186, reward_mean=0.440, reward_bound=0.254, batch=222 
4621: loss=0.186, reward_mean=0.380, reward_bound=0.263, batch=225 
4622: loss=0.187, reward_mean=0.400, reward_bound=0.282, batch=225 
4623: loss=0.185, reward_mean=0.400, reward_bound=0.314, batch=224 
4624: loss=0.185, reward_mean=0.500, reward_bound=0.314, batch=225 
4625: loss=0.181, reward_mean=0.390, reward_bound=0.349, batch=218 
4626: loss=0.182, reward_mean=0.410, reward_bound=0.254, batch=221 
4627: loss=0.183, reward_mean=0.400, reward_bound=0.349, batch=224 
4628: loss=0.182, reward_mean=0.360, reward_bound=0.384, batch=227 
4629: loss=0.189, reward_mean=0.460, reward_bound=0.387, batch=197 
4630: loss=0.183, reward_mean=0.420, reward_bound=0.167, batch=207 
4631: loss=0.185, reward_mean=0.420, reward_bound=0.185, batch=211 
4632: loss=0.186, reward_mean=0.440, reward_bound=0.229, batch=215 
4633: loss=0.186, reward_mean=0.430, reward_bound=0.260, batch=220 
4634: loss=0.186, reward_mean=0.400, reward_bound=0.200, batch=224 
4635: loss=0.184, reward_mean=0.450, reward_bound=0.282, batch=226 
4636: loss=0.180, reward_mean=0.490, reward_bound=0.314, batch=225 
4637: loss=0.185, reward_mean=0.420, reward_bound=0.349, batch=223 
4638: loss=0.185, reward_mean=0.390, reward_bound=0.349, batch=224 
4639: loss=0.184, reward_mean=0.390, reward_bound=0.387, batch=215 
4640: loss=0.184, reward_mean=0.420, reward_bound=0.349, batch=218 
4641: loss=0.185, reward_mean=0.450, reward_bound=0.392, batch=222 
4642: loss=0.184, reward_mean=0.460, reward_bound=0.430, batch=189 
4643: loss=0.185, reward_mean=0.260, reward_bound=0.135, batch=201 
4644: loss=0.189, reward_mean=0.400, reward_bound=0.185, batch=207 
4645: loss=0.187, reward_mean=0.470, reward_bound=0.229, batch=212 
4646: loss=0.186, reward_mean=0.380, reward_bound=0.236, batch=218 
4647: loss=0.186, reward_mean=0.340, reward_bound=0.254, batch=219 
4648: loss=0.181, reward_mean=0.370, reward_bound=0.282, batch=216 
4649: loss=0.186, reward_mean=0.450, reward_bound=0.314, batch=212 
4650: loss=0.184, reward_mean=0.340, reward_bound=0.213, batch=218 
4651: loss=0.188, reward_mean=0.420, reward_bound=0.314, batch=220 
4652: loss=0.191, reward_mean=0.440, reward_bound=0.314, batch=223 
4653: loss=0.194, reward_mean=0.400, reward_bound=0.349, batch=215 
4654: loss=0.192, reward_mean=0.420, reward_bound=0.387, batch=209 
4655: loss=0.189, reward_mean=0.410, reward_bound=0.229, batch=214 
4656: loss=0.186, reward_mean=0.470, reward_bound=0.314, batch=219 
4657: loss=0.185, reward_mean=0.440, reward_bound=0.278, batch=223 
4658: loss=0.185, reward_mean=0.390, reward_bound=0.314, batch=225 
4659: loss=0.186, reward_mean=0.400, reward_bound=0.349, batch=224 
4660: loss=0.189, reward_mean=0.390, reward_bound=0.387, batch=219 
4661: loss=0.188, reward_mean=0.440, reward_bound=0.364, batch=223 
4662: loss=0.189, reward_mean=0.410, reward_bound=0.301, batch=226 
4663: loss=0.190, reward_mean=0.390, reward_bound=0.314, batch=226 
4664: loss=0.190, reward_mean=0.380, reward_bound=0.301, batch=228 
4665: loss=0.191, reward_mean=0.380, reward_bound=0.349, batch=227 
4666: loss=0.193, reward_mean=0.390, reward_bound=0.387, batch=226 
4667: loss=0.196, reward_mean=0.370, reward_bound=0.430, batch=211 
4668: loss=0.193, reward_mean=0.420, reward_bound=0.282, batch=217 
4669: loss=0.193, reward_mean=0.380, reward_bound=0.277, batch=222 
4670: loss=0.192, reward_mean=0.390, reward_bound=0.263, batch=225 
4671: loss=0.193, reward_mean=0.440, reward_bound=0.321, batch=227 
4672: loss=0.193, reward_mean=0.370, reward_bound=0.349, batch=223 
4673: loss=0.192, reward_mean=0.420, reward_bound=0.335, batch=226 
4674: loss=0.191, reward_mean=0.380, reward_bound=0.368, batch=228 
4675: loss=0.193, reward_mean=0.460, reward_bound=0.387, batch=225 
4676: loss=0.192, reward_mean=0.300, reward_bound=0.365, batch=227 
4677: loss=0.194, reward_mean=0.350, reward_bound=0.387, batch=228 
4678: loss=0.196, reward_mean=0.410, reward_bound=0.430, batch=223 
4679: loss=0.197, reward_mean=0.390, reward_bound=0.349, batch=225 
4680: loss=0.198, reward_mean=0.430, reward_bound=0.365, batch=227 
4681: loss=0.199, reward_mean=0.400, reward_bound=0.342, batch=229 
4682: loss=0.199, reward_mean=0.390, reward_bound=0.309, batch=230 
4683: loss=0.199, reward_mean=0.410, reward_bound=0.349, batch=229 
4684: loss=0.200, reward_mean=0.380, reward_bound=0.430, batch=227 
4685: loss=0.201, reward_mean=0.290, reward_bound=0.314, batch=228 
4686: loss=0.199, reward_mean=0.430, reward_bound=0.353, batch=229 
4687: loss=0.198, reward_mean=0.280, reward_bound=0.364, batch=230 
4688: loss=0.198, reward_mean=0.380, reward_bound=0.387, batch=230 
4689: loss=0.198, reward_mean=0.410, reward_bound=0.464, batch=231 
4690: loss=0.198, reward_mean=0.400, reward_bound=0.387, batch=231 
4691: loss=0.194, reward_mean=0.380, reward_bound=0.478, batch=182 
4692: loss=0.195, reward_mean=0.410, reward_bound=0.179, batch=197 
4693: loss=0.198, reward_mean=0.350, reward_bound=0.182, batch=208 
4694: loss=0.196, reward_mean=0.380, reward_bound=0.206, batch=211 
4695: loss=0.196, reward_mean=0.440, reward_bound=0.229, batch=217 
4696: loss=0.194, reward_mean=0.420, reward_bound=0.254, batch=216 
4697: loss=0.192, reward_mean=0.370, reward_bound=0.268, batch=221 
4698: loss=0.192, reward_mean=0.450, reward_bound=0.282, batch=219 
4699: loss=0.195, reward_mean=0.380, reward_bound=0.164, batch=223 
4700: loss=0.192, reward_mean=0.420, reward_bound=0.271, batch=226 
4701: loss=0.194, reward_mean=0.430, reward_bound=0.298, batch=228 
4702: loss=0.195, reward_mean=0.470, reward_bound=0.317, batch=229 
4703: loss=0.191, reward_mean=0.460, reward_bound=0.349, batch=221 
4704: loss=0.191, reward_mean=0.340, reward_bound=0.349, batch=224 
4705: loss=0.198, reward_mean=0.420, reward_bound=0.387, batch=210 
4706: loss=0.197, reward_mean=0.350, reward_bound=0.142, batch=217 
4707: loss=0.200, reward_mean=0.320, reward_bound=0.185, batch=221 
4708: loss=0.198, reward_mean=0.350, reward_bound=0.254, batch=222 
4709: loss=0.197, reward_mean=0.400, reward_bound=0.314, batch=222 
4710: loss=0.194, reward_mean=0.370, reward_bound=0.349, batch=222 
4711: loss=0.194, reward_mean=0.460, reward_bound=0.349, batch=224 
4712: loss=0.198, reward_mean=0.310, reward_bound=0.387, batch=224 
4713: loss=0.198, reward_mean=0.380, reward_bound=0.349, batch=226 
4714: loss=0.197, reward_mean=0.360, reward_bound=0.368, batch=228 
4715: loss=0.197, reward_mean=0.370, reward_bound=0.387, batch=228 
4716: loss=0.198, reward_mean=0.400, reward_bound=0.392, batch=229 
4717: loss=0.199, reward_mean=0.380, reward_bound=0.381, batch=230 
4718: loss=0.195, reward_mean=0.470, reward_bound=0.430, batch=214 
4719: loss=0.192, reward_mean=0.350, reward_bound=0.305, batch=220 
4720: loss=0.194, reward_mean=0.430, reward_bound=0.338, batch=224 
4721: loss=0.193, reward_mean=0.390, reward_bound=0.345, batch=227 
4722: loss=0.192, reward_mean=0.310, reward_bound=0.380, batch=229 
4723: loss=0.193, reward_mean=0.350, reward_bound=0.387, batch=228 
4724: loss=0.195, reward_mean=0.340, reward_bound=0.430, batch=225 
4725: loss=0.196, reward_mean=0.410, reward_bound=0.440, batch=227 
4726: loss=0.197, reward_mean=0.390, reward_bound=0.387, batch=228 
4727: loss=0.197, reward_mean=0.430, reward_bound=0.435, batch=229 
4728: loss=0.197, reward_mean=0.390, reward_bound=0.478, batch=231 
4729: loss=0.197, reward_mean=0.410, reward_bound=0.478, batch=202 
4730: loss=0.201, reward_mean=0.430, reward_bound=0.245, batch=211 
4731: loss=0.201, reward_mean=0.370, reward_bound=0.206, batch=217 
4732: loss=0.200, reward_mean=0.350, reward_bound=0.277, batch=222 
4733: loss=0.202, reward_mean=0.340, reward_bound=0.292, batch=225 
4734: loss=0.199, reward_mean=0.350, reward_bound=0.321, batch=227 
4735: loss=0.195, reward_mean=0.420, reward_bound=0.349, batch=225 
4736: loss=0.202, reward_mean=0.310, reward_bound=0.387, batch=215 
4737: loss=0.203, reward_mean=0.380, reward_bound=0.314, batch=218 
4738: loss=0.200, reward_mean=0.370, reward_bound=0.387, batch=221 
4739: loss=0.199, reward_mean=0.400, reward_bound=0.349, batch=222 
4740: loss=0.199, reward_mean=0.440, reward_bound=0.387, batch=223 
4741: loss=0.197, reward_mean=0.440, reward_bound=0.430, batch=213 
4742: loss=0.200, reward_mean=0.400, reward_bound=0.301, batch=219 
4743: loss=0.199, reward_mean=0.320, reward_bound=0.265, batch=223 
4744: loss=0.198, reward_mean=0.440, reward_bound=0.335, batch=226 
4745: loss=0.198, reward_mean=0.400, reward_bound=0.316, batch=228 
4746: loss=0.199, reward_mean=0.390, reward_bound=0.349, batch=227 
4747: loss=0.198, reward_mean=0.440, reward_bound=0.380, batch=229 
4748: loss=0.197, reward_mean=0.460, reward_bound=0.387, batch=222 
4749: loss=0.197, reward_mean=0.370, reward_bound=0.336, batch=225 
4750: loss=0.196, reward_mean=0.460, reward_bound=0.356, batch=227 
4751: loss=0.194, reward_mean=0.380, reward_bound=0.387, batch=228 
4752: loss=0.194, reward_mean=0.370, reward_bound=0.387, batch=228 
4753: loss=0.193, reward_mean=0.300, reward_bound=0.392, batch=229 
4754: loss=0.193, reward_mean=0.400, reward_bound=0.405, batch=230 
4755: loss=0.196, reward_mean=0.430, reward_bound=0.430, batch=222 
4756: loss=0.194, reward_mean=0.430, reward_bound=0.272, batch=225 
4757: loss=0.194, reward_mean=0.360, reward_bound=0.321, batch=227 
4758: loss=0.195, reward_mean=0.350, reward_bound=0.349, batch=226 
4759: loss=0.195, reward_mean=0.430, reward_bound=0.349, batch=227 
4760: loss=0.194, reward_mean=0.370, reward_bound=0.422, batch=229 
4761: loss=0.194, reward_mean=0.340, reward_bound=0.430, batch=229 
4762: loss=0.194, reward_mean=0.430, reward_bound=0.364, batch=230 
4763: loss=0.194, reward_mean=0.430, reward_bound=0.418, batch=231 
4764: loss=0.194, reward_mean=0.430, reward_bound=0.387, batch=231 
4765: loss=0.194, reward_mean=0.370, reward_bound=0.430, batch=230 
4766: loss=0.196, reward_mean=0.420, reward_bound=0.478, batch=216 
4767: loss=0.197, reward_mean=0.390, reward_bound=0.314, batch=219 
4768: loss=0.197, reward_mean=0.430, reward_bound=0.343, batch=223 
4769: loss=0.195, reward_mean=0.440, reward_bound=0.413, batch=226 
4770: loss=0.195, reward_mean=0.420, reward_bound=0.387, batch=227 
4771: loss=0.195, reward_mean=0.360, reward_bound=0.380, batch=229 
4772: loss=0.195, reward_mean=0.350, reward_bound=0.314, batch=229 
4773: loss=0.194, reward_mean=0.440, reward_bound=0.430, batch=223 
4774: loss=0.193, reward_mean=0.350, reward_bound=0.349, batch=225 
4775: loss=0.193, reward_mean=0.330, reward_bound=0.430, batch=225 
4776: loss=0.193, reward_mean=0.400, reward_bound=0.314, batch=226 
4777: loss=0.194, reward_mean=0.390, reward_bound=0.409, batch=228 
4778: loss=0.193, reward_mean=0.440, reward_bound=0.357, batch=229 
4779: loss=0.195, reward_mean=0.460, reward_bound=0.430, batch=228 
4780: loss=0.195, reward_mean=0.390, reward_bound=0.392, batch=229 
4781: loss=0.194, reward_mean=0.400, reward_bound=0.328, batch=230 
4782: loss=0.195, reward_mean=0.350, reward_bound=0.418, batch=231 
4783: loss=0.194, reward_mean=0.360, reward_bound=0.430, batch=230 
4784: loss=0.194, reward_mean=0.420, reward_bound=0.478, batch=220 
4785: loss=0.193, reward_mean=0.400, reward_bound=0.329, batch=224 
4786: loss=0.194, reward_mean=0.400, reward_bound=0.345, batch=227 
4787: loss=0.194, reward_mean=0.350, reward_bound=0.342, batch=229 
4788: loss=0.192, reward_mean=0.440, reward_bound=0.349, batch=229 
4789: loss=0.190, reward_mean=0.360, reward_bound=0.405, batch=230 
4790: loss=0.194, reward_mean=0.340, reward_bound=0.430, batch=227 
4791: loss=0.194, reward_mean=0.490, reward_bound=0.430, batch=228 
4792: loss=0.194, reward_mean=0.430, reward_bound=0.435, batch=229 
4793: loss=0.194, reward_mean=0.350, reward_bound=0.381, batch=230 
4794: loss=0.194, reward_mean=0.380, reward_bound=0.430, batch=230 
4795: loss=0.194, reward_mean=0.440, reward_bound=0.451, batch=231 
4796: loss=0.194, reward_mean=0.360, reward_bound=0.430, batch=231 
4797: loss=0.194, reward_mean=0.370, reward_bound=0.349, batch=231 
4798: loss=0.194, reward_mean=0.350, reward_bound=0.314, batch=231 
4799: loss=0.192, reward_mean=0.450, reward_bound=0.478, batch=224 
4800: loss=0.192, reward_mean=0.370, reward_bound=0.349, batch=225 
4801: loss=0.194, reward_mean=0.460, reward_bound=0.396, batch=227 
4802: loss=0.195, reward_mean=0.420, reward_bound=0.342, batch=229 
4803: loss=0.195, reward_mean=0.440, reward_bound=0.405, batch=230 
4804: loss=0.195, reward_mean=0.390, reward_bound=0.418, batch=231 
4805: loss=0.192, reward_mean=0.340, reward_bound=0.430, batch=229 
4806: loss=0.192, reward_mean=0.340, reward_bound=0.364, batch=230 
4807: loss=0.196, reward_mean=0.430, reward_bound=0.451, batch=231 
4808: loss=0.195, reward_mean=0.450, reward_bound=0.478, batch=231 
4809: loss=0.195, reward_mean=0.340, reward_bound=0.478, batch=231 
4810: loss=0.194, reward_mean=0.350, reward_bound=0.387, batch=231 
4811: loss=0.194, reward_mean=0.430, reward_bound=0.478, batch=231 
4812: loss=0.194, reward_mean=0.380, reward_bound=0.387, batch=231 
4813: loss=0.194, reward_mean=0.380, reward_bound=0.430, batch=231 
4815: loss=0.184, reward_mean=0.340, reward_bound=0.000, batch=34 
4816: loss=0.205, reward_mean=0.390, reward_bound=0.000, batch=73 
4817: loss=0.200, reward_mean=0.430, reward_bound=0.000, batch=116 
4818: loss=0.205, reward_mean=0.400, reward_bound=0.000, batch=151 
4819: loss=0.206, reward_mean=0.390, reward_bound=0.003, batch=173 
4820: loss=0.205, reward_mean=0.360, reward_bound=0.010, batch=190 
4821: loss=0.210, reward_mean=0.440, reward_bound=0.025, batch=202 
4822: loss=0.207, reward_mean=0.460, reward_bound=0.047, batch=208 
4823: loss=0.205, reward_mean=0.390, reward_bound=0.065, batch=208 
4824: loss=0.204, reward_mean=0.370, reward_bound=0.080, batch=211 
4825: loss=0.211, reward_mean=0.390, reward_bound=0.098, batch=208 
4826: loss=0.210, reward_mean=0.460, reward_bound=0.109, batch=211 
4827: loss=0.213, reward_mean=0.380, reward_bound=0.122, batch=201 
4828: loss=0.210, reward_mean=0.500, reward_bound=0.135, batch=202 
4829: loss=0.208, reward_mean=0.490, reward_bound=0.150, batch=207 
4830: loss=0.211, reward_mean=0.470, reward_bound=0.167, batch=202 
4831: loss=0.205, reward_mean=0.450, reward_bound=0.185, batch=189 
4832: loss=0.202, reward_mean=0.320, reward_bound=0.206, batch=182 
4833: loss=0.201, reward_mean=0.440, reward_bound=0.126, batch=197 
4834: loss=0.203, reward_mean=0.420, reward_bound=0.182, batch=208 
4835: loss=0.202, reward_mean=0.420, reward_bound=0.185, batch=212 
4836: loss=0.203, reward_mean=0.390, reward_bound=0.229, batch=194 
4837: loss=0.202, reward_mean=0.350, reward_bound=0.185, batch=205 
4838: loss=0.201, reward_mean=0.350, reward_bound=0.135, batch=212 
4839: loss=0.201, reward_mean=0.480, reward_bound=0.229, batch=215 
4840: loss=0.200, reward_mean=0.450, reward_bound=0.254, batch=184 
4841: loss=0.200, reward_mean=0.440, reward_bound=0.147, batch=199 
4842: loss=0.199, reward_mean=0.380, reward_bound=0.150, batch=207 
4843: loss=0.197, reward_mean=0.430, reward_bound=0.185, batch=214 
4844: loss=0.197, reward_mean=0.440, reward_bound=0.185, batch=219 
4845: loss=0.197, reward_mean=0.440, reward_bound=0.206, batch=222 
4846: loss=0.196, reward_mean=0.390, reward_bound=0.229, batch=222 
4847: loss=0.194, reward_mean=0.380, reward_bound=0.282, batch=182 
4848: loss=0.192, reward_mean=0.330, reward_bound=0.063, batch=197 
4849: loss=0.188, reward_mean=0.300, reward_bound=0.105, batch=208 
4850: loss=0.199, reward_mean=0.440, reward_bound=0.167, batch=211 
4851: loss=0.193, reward_mean=0.410, reward_bound=0.206, batch=215 
4852: loss=0.195, reward_mean=0.330, reward_bound=0.185, batch=219 
4853: loss=0.195, reward_mean=0.490, reward_bound=0.254, batch=222 
4854: loss=0.193, reward_mean=0.410, reward_bound=0.263, batch=225 
4855: loss=0.192, reward_mean=0.330, reward_bound=0.282, batch=220 
4856: loss=0.192, reward_mean=0.350, reward_bound=0.274, batch=224 
4857: loss=0.192, reward_mean=0.410, reward_bound=0.275, batch=227 
4858: loss=0.190, reward_mean=0.360, reward_bound=0.282, batch=227 
4859: loss=0.189, reward_mean=0.390, reward_bound=0.314, batch=176 
4860: loss=0.190, reward_mean=0.400, reward_bound=0.076, batch=193 
4861: loss=0.188, reward_mean=0.410, reward_bound=0.130, batch=205 
4862: loss=0.184, reward_mean=0.480, reward_bound=0.170, batch=213 
4863: loss=0.186, reward_mean=0.420, reward_bound=0.185, batch=215 
4864: loss=0.176, reward_mean=0.500, reward_bound=0.229, batch=214 
4865: loss=0.178, reward_mean=0.460, reward_bound=0.254, batch=216 
4866: loss=0.178, reward_mean=0.410, reward_bound=0.282, batch=215 
4867: loss=0.178, reward_mean=0.350, reward_bound=0.194, batch=220 
4868: loss=0.182, reward_mean=0.450, reward_bound=0.314, batch=215 
4869: loss=0.177, reward_mean=0.420, reward_bound=0.349, batch=167 
4870: loss=0.172, reward_mean=0.440, reward_bound=0.078, batch=187 
4871: loss=0.172, reward_mean=0.400, reward_bound=0.119, batch=201 
4872: loss=0.177, reward_mean=0.370, reward_bound=0.122, batch=207 
4873: loss=0.181, reward_mean=0.460, reward_bound=0.185, batch=208 
4874: loss=0.179, reward_mean=0.420, reward_bound=0.185, batch=214 
4875: loss=0.179, reward_mean=0.540, reward_bound=0.229, batch=211 
4876: loss=0.180, reward_mean=0.410, reward_bound=0.254, batch=210 
4877: loss=0.175, reward_mean=0.400, reward_bound=0.282, batch=206 
4878: loss=0.173, reward_mean=0.520, reward_bound=0.229, batch=213 
4879: loss=0.172, reward_mean=0.380, reward_bound=0.261, batch=219 
4880: loss=0.176, reward_mean=0.500, reward_bound=0.295, batch=223 
4881: loss=0.177, reward_mean=0.450, reward_bound=0.314, batch=214 
4882: loss=0.177, reward_mean=0.400, reward_bound=0.229, batch=219 
4883: loss=0.177, reward_mean=0.410, reward_bound=0.295, batch=223 
4884: loss=0.178, reward_mean=0.420, reward_bound=0.290, batch=226 
4885: loss=0.178, reward_mean=0.380, reward_bound=0.314, batch=225 
4886: loss=0.181, reward_mean=0.390, reward_bound=0.349, batch=208 
4887: loss=0.183, reward_mean=0.480, reward_bound=0.286, batch=215 
4888: loss=0.181, reward_mean=0.350, reward_bound=0.189, batch=220 
4889: loss=0.185, reward_mean=0.380, reward_bound=0.288, batch=224 
4890: loss=0.182, reward_mean=0.440, reward_bound=0.349, batch=224 
4891: loss=0.182, reward_mean=0.490, reward_bound=0.314, batch=224 
4892: loss=0.187, reward_mean=0.330, reward_bound=0.384, batch=227 
4893: loss=0.186, reward_mean=0.490, reward_bound=0.380, batch=229 
4894: loss=0.182, reward_mean=0.490, reward_bound=0.387, batch=157 
4895: loss=0.180, reward_mean=0.400, reward_bound=0.065, batch=178 
4896: loss=0.178, reward_mean=0.490, reward_bound=0.089, batch=193 
4897: loss=0.182, reward_mean=0.470, reward_bound=0.122, batch=203 
4898: loss=0.181, reward_mean=0.510, reward_bound=0.135, batch=211 
4899: loss=0.178, reward_mean=0.400, reward_bound=0.167, batch=213 
4900: loss=0.174, reward_mean=0.410, reward_bound=0.185, batch=217 
4901: loss=0.177, reward_mean=0.410, reward_bound=0.206, batch=221 
4902: loss=0.177, reward_mean=0.380, reward_bound=0.229, batch=220 
4903: loss=0.183, reward_mean=0.520, reward_bound=0.254, batch=214 
4904: loss=0.184, reward_mean=0.360, reward_bound=0.180, batch=220 
4905: loss=0.187, reward_mean=0.450, reward_bound=0.282, batch=211 
4906: loss=0.187, reward_mean=0.460, reward_bound=0.282, batch=217 
4907: loss=0.184, reward_mean=0.440, reward_bound=0.314, batch=210 
4908: loss=0.186, reward_mean=0.390, reward_bound=0.274, batch=217 
4909: loss=0.184, reward_mean=0.450, reward_bound=0.308, batch=222 
4910: loss=0.185, reward_mean=0.400, reward_bound=0.314, batch=221 
4911: loss=0.181, reward_mean=0.460, reward_bound=0.349, batch=201 
4912: loss=0.181, reward_mean=0.430, reward_bound=0.206, batch=210 
4913: loss=0.180, reward_mean=0.420, reward_bound=0.274, batch=217 
4914: loss=0.180, reward_mean=0.490, reward_bound=0.282, batch=218 
4915: loss=0.181, reward_mean=0.390, reward_bound=0.286, batch=222 
4916: loss=0.180, reward_mean=0.480, reward_bound=0.314, batch=219 
4917: loss=0.180, reward_mean=0.460, reward_bound=0.278, batch=223 
4918: loss=0.179, reward_mean=0.500, reward_bound=0.349, batch=222 
4919: loss=0.179, reward_mean=0.390, reward_bound=0.282, batch=223 
4920: loss=0.181, reward_mean=0.470, reward_bound=0.387, batch=203 
4921: loss=0.181, reward_mean=0.410, reward_bound=0.244, batch=212 
4922: loss=0.181, reward_mean=0.450, reward_bound=0.314, batch=213 
4923: loss=0.180, reward_mean=0.410, reward_bound=0.322, batch=219 
4924: loss=0.179, reward_mean=0.500, reward_bound=0.349, batch=219 
4925: loss=0.177, reward_mean=0.380, reward_bound=0.237, batch=223 
4926: loss=0.177, reward_mean=0.340, reward_bound=0.244, batch=226 
4927: loss=0.179, reward_mean=0.410, reward_bound=0.314, batch=227 
4928: loss=0.179, reward_mean=0.410, reward_bound=0.349, batch=228 
4929: loss=0.177, reward_mean=0.430, reward_bound=0.387, batch=220 
4930: loss=0.175, reward_mean=0.410, reward_bound=0.338, batch=224 
4931: loss=0.175, reward_mean=0.510, reward_bound=0.280, batch=227 
4932: loss=0.176, reward_mean=0.330, reward_bound=0.254, batch=228 
4933: loss=0.177, reward_mean=0.410, reward_bound=0.282, batch=228 
4934: loss=0.177, reward_mean=0.460, reward_bound=0.349, batch=227 
4935: loss=0.177, reward_mean=0.390, reward_bound=0.342, batch=229 
4936: loss=0.176, reward_mean=0.400, reward_bound=0.349, batch=229 
4937: loss=0.173, reward_mean=0.460, reward_bound=0.430, batch=116 
4938: loss=0.161, reward_mean=0.460, reward_bound=0.008, batch=151 
4939: loss=0.162, reward_mean=0.500, reward_bound=0.034, batch=175 
4940: loss=0.167, reward_mean=0.500, reward_bound=0.073, batch=192 
4941: loss=0.169, reward_mean=0.360, reward_bound=0.089, batch=203 
4942: loss=0.173, reward_mean=0.510, reward_bound=0.130, batch=212 
4943: loss=0.174, reward_mean=0.430, reward_bound=0.150, batch=213 
4944: loss=0.177, reward_mean=0.430, reward_bound=0.185, batch=213 
4945: loss=0.177, reward_mean=0.450, reward_bound=0.206, batch=212 
4946: loss=0.178, reward_mean=0.450, reward_bound=0.229, batch=205 
4947: loss=0.177, reward_mean=0.420, reward_bound=0.254, batch=194 
4948: loss=0.175, reward_mean=0.420, reward_bound=0.204, batch=206 
4949: loss=0.172, reward_mean=0.420, reward_bound=0.206, batch=213 
4950: loss=0.172, reward_mean=0.440, reward_bound=0.254, batch=216 
4951: loss=0.172, reward_mean=0.390, reward_bound=0.254, batch=220 
4952: loss=0.172, reward_mean=0.370, reward_bound=0.274, batch=224 
4953: loss=0.173, reward_mean=0.360, reward_bound=0.282, batch=207 
4954: loss=0.171, reward_mean=0.400, reward_bound=0.277, batch=215 
4955: loss=0.170, reward_mean=0.450, reward_bound=0.254, batch=218 
4956: loss=0.170, reward_mean=0.380, reward_bound=0.314, batch=195 
4957: loss=0.166, reward_mean=0.390, reward_bound=0.189, batch=206 
4958: loss=0.165, reward_mean=0.370, reward_bound=0.206, batch=212 
4959: loss=0.168, reward_mean=0.420, reward_bound=0.254, batch=215 
4960: loss=0.164, reward_mean=0.480, reward_bound=0.314, batch=216 
4961: loss=0.170, reward_mean=0.430, reward_bound=0.349, batch=190 
4962: loss=0.167, reward_mean=0.380, reward_bound=0.131, batch=203 
4963: loss=0.167, reward_mean=0.400, reward_bound=0.150, batch=211 
4964: loss=0.166, reward_mean=0.440, reward_bound=0.185, batch=217 
4965: loss=0.160, reward_mean=0.510, reward_bound=0.229, batch=220 
4966: loss=0.160, reward_mean=0.470, reward_bound=0.254, batch=223 
4967: loss=0.160, reward_mean=0.440, reward_bound=0.301, batch=226 
4968: loss=0.166, reward_mean=0.460, reward_bound=0.314, batch=224 
4969: loss=0.165, reward_mean=0.440, reward_bound=0.345, batch=227 
4970: loss=0.166, reward_mean=0.380, reward_bound=0.349, batch=218 
4971: loss=0.165, reward_mean=0.420, reward_bound=0.317, batch=222 
4972: loss=0.172, reward_mean=0.470, reward_bound=0.387, batch=190 
4973: loss=0.171, reward_mean=0.450, reward_bound=0.229, batch=202 
4974: loss=0.170, reward_mean=0.390, reward_bound=0.206, batch=213 
4975: loss=0.170, reward_mean=0.410, reward_bound=0.220, batch=219 
4976: loss=0.167, reward_mean=0.390, reward_bound=0.239, batch=223 
4977: loss=0.167, reward_mean=0.380, reward_bound=0.254, batch=223 
4978: loss=0.169, reward_mean=0.510, reward_bound=0.314, batch=221 
4979: loss=0.174, reward_mean=0.400, reward_bound=0.314, batch=224 
4980: loss=0.174, reward_mean=0.400, reward_bound=0.345, batch=227 
4981: loss=0.173, reward_mean=0.390, reward_bound=0.314, batch=228 
4982: loss=0.173, reward_mean=0.430, reward_bound=0.289, batch=229 
4983: loss=0.169, reward_mean=0.450, reward_bound=0.349, batch=218 
4984: loss=0.168, reward_mean=0.480, reward_bound=0.353, batch=222 
4985: loss=0.169, reward_mean=0.480, reward_bound=0.387, batch=213 
4986: loss=0.171, reward_mean=0.400, reward_bound=0.322, batch=219 
4987: loss=0.168, reward_mean=0.450, reward_bound=0.349, batch=222 
4988: loss=0.169, reward_mean=0.420, reward_bound=0.349, batch=224 
4989: loss=0.168, reward_mean=0.370, reward_bound=0.387, batch=220 
4990: loss=0.169, reward_mean=0.480, reward_bound=0.282, batch=223 
4991: loss=0.168, reward_mean=0.350, reward_bound=0.314, batch=225 
4992: loss=0.169, reward_mean=0.350, reward_bound=0.349, batch=226 
4993: loss=0.169, reward_mean=0.430, reward_bound=0.387, batch=226 
4994: loss=0.168, reward_mean=0.410, reward_bound=0.409, batch=228 
4995: loss=0.172, reward_mean=0.480, reward_bound=0.430, batch=171 
4996: loss=0.172, reward_mean=0.390, reward_bound=0.122, batch=188 
4997: loss=0.178, reward_mean=0.260, reward_bound=0.035, batch=201 
4998: loss=0.179, reward_mean=0.420, reward_bound=0.135, batch=208 
4999: loss=0.174, reward_mean=0.330, reward_bound=0.152, batch=215 
5000: loss=0.174, reward_mean=0.370, reward_bound=0.206, batch=214 
5001: loss=0.171, reward_mean=0.460, reward_bound=0.229, batch=219 
5002: loss=0.161, reward_mean=0.420, reward_bound=0.254, batch=220 
5003: loss=0.164, reward_mean=0.390, reward_bound=0.282, batch=213 
5004: loss=0.164, reward_mean=0.400, reward_bound=0.282, batch=218 
5005: loss=0.169, reward_mean=0.440, reward_bound=0.314, batch=213 
5006: loss=0.167, reward_mean=0.390, reward_bound=0.282, batch=218 
5007: loss=0.167, reward_mean=0.320, reward_bound=0.234, batch=222 
5008: loss=0.166, reward_mean=0.410, reward_bound=0.349, batch=209 
5009: loss=0.168, reward_mean=0.370, reward_bound=0.127, batch=216 
5010: loss=0.164, reward_mean=0.360, reward_bound=0.206, batch=220 
5011: loss=0.163, reward_mean=0.330, reward_bound=0.229, batch=222 
5012: loss=0.165, reward_mean=0.370, reward_bound=0.263, batch=225 
5013: loss=0.165, reward_mean=0.540, reward_bound=0.289, batch=227 
5014: loss=0.164, reward_mean=0.500, reward_bound=0.314, batch=227 
5015: loss=0.164, reward_mean=0.430, reward_bound=0.342, batch=229 
5016: loss=0.166, reward_mean=0.480, reward_bound=0.349, batch=227 
5017: loss=0.167, reward_mean=0.400, reward_bound=0.387, batch=208 
5018: loss=0.165, reward_mean=0.360, reward_bound=0.187, batch=215 
5019: loss=0.166, reward_mean=0.450, reward_bound=0.229, batch=217 
5020: loss=0.166, reward_mean=0.440, reward_bound=0.254, batch=219 
5021: loss=0.167, reward_mean=0.520, reward_bound=0.314, batch=215 
5022: loss=0.164, reward_mean=0.460, reward_bound=0.349, batch=218 
5023: loss=0.166, reward_mean=0.480, reward_bound=0.349, batch=220 
5024: loss=0.165, reward_mean=0.420, reward_bound=0.376, batch=224 
5025: loss=0.166, reward_mean=0.390, reward_bound=0.387, batch=221 
5026: loss=0.171, reward_mean=0.480, reward_bound=0.430, batch=191 
5027: loss=0.174, reward_mean=0.380, reward_bound=0.185, batch=202 
5028: loss=0.174, reward_mean=0.510, reward_bound=0.179, batch=211 
5029: loss=0.174, reward_mean=0.460, reward_bound=0.206, batch=216 
5030: loss=0.173, reward_mean=0.450, reward_bound=0.229, batch=218 
5031: loss=0.178, reward_mean=0.400, reward_bound=0.254, batch=219 
5032: loss=0.180, reward_mean=0.420, reward_bound=0.265, batch=223 
5033: loss=0.179, reward_mean=0.470, reward_bound=0.282, batch=221 
5034: loss=0.179, reward_mean=0.340, reward_bound=0.254, batch=223 
5035: loss=0.175, reward_mean=0.450, reward_bound=0.314, batch=222 
5036: loss=0.170, reward_mean=0.430, reward_bound=0.349, batch=218 
5037: loss=0.169, reward_mean=0.440, reward_bound=0.317, batch=222 
5038: loss=0.168, reward_mean=0.440, reward_bound=0.272, batch=225 
5039: loss=0.167, reward_mean=0.380, reward_bound=0.349, batch=226 
5040: loss=0.170, reward_mean=0.410, reward_bound=0.387, batch=212 
5041: loss=0.170, reward_mean=0.400, reward_bound=0.213, batch=218 
5042: loss=0.168, reward_mean=0.470, reward_bound=0.282, batch=220 
5043: loss=0.172, reward_mean=0.340, reward_bound=0.349, batch=223 
5044: loss=0.171, reward_mean=0.430, reward_bound=0.387, batch=221 
5045: loss=0.171, reward_mean=0.360, reward_bound=0.282, batch=222 
5046: loss=0.170, reward_mean=0.530, reward_bound=0.302, batch=225 
5047: loss=0.170, reward_mean=0.470, reward_bound=0.356, batch=227 
5048: loss=0.169, reward_mean=0.290, reward_bound=0.387, batch=228 
5049: loss=0.168, reward_mean=0.410, reward_bound=0.317, batch=229 
5050: loss=0.168, reward_mean=0.470, reward_bound=0.430, batch=214 
5051: loss=0.168, reward_mean=0.460, reward_bound=0.280, batch=220 
5052: loss=0.168, reward_mean=0.410, reward_bound=0.314, batch=222 
5053: loss=0.167, reward_mean=0.430, reward_bound=0.349, batch=222 
5054: loss=0.166, reward_mean=0.360, reward_bound=0.282, batch=224 
5055: loss=0.165, reward_mean=0.400, reward_bound=0.311, batch=227 
5056: loss=0.167, reward_mean=0.410, reward_bound=0.314, batch=228 
5057: loss=0.168, reward_mean=0.380, reward_bound=0.317, batch=229 
5058: loss=0.168, reward_mean=0.360, reward_bound=0.349, batch=226 
5059: loss=0.165, reward_mean=0.420, reward_bound=0.387, batch=226 
5060: loss=0.165, reward_mean=0.540, reward_bound=0.390, batch=228 
5061: loss=0.167, reward_mean=0.340, reward_bound=0.430, batch=225 
5062: loss=0.166, reward_mean=0.450, reward_bound=0.396, batch=227 
5063: loss=0.166, reward_mean=0.360, reward_bound=0.224, batch=229 
5064: loss=0.166, reward_mean=0.360, reward_bound=0.314, batch=229 
5065: loss=0.166, reward_mean=0.430, reward_bound=0.430, batch=229 
5066: loss=0.166, reward_mean=0.350, reward_bound=0.343, batch=230 
5067: loss=0.165, reward_mean=0.500, reward_bound=0.418, batch=231 
5068: loss=0.142, reward_mean=0.420, reward_bound=0.478, batch=96 
5069: loss=0.170, reward_mean=0.350, reward_bound=0.000, batch=131 
5070: loss=0.165, reward_mean=0.480, reward_bound=0.006, batch=161 
5071: loss=0.170, reward_mean=0.480, reward_bound=0.038, batch=182 
5072: loss=0.178, reward_mean=0.490, reward_bound=0.065, batch=192 
5073: loss=0.180, reward_mean=0.420, reward_bound=0.089, batch=200 
5074: loss=0.172, reward_mean=0.400, reward_bound=0.109, batch=204 
5075: loss=0.174, reward_mean=0.320, reward_bound=0.122, batch=211 
5076: loss=0.176, reward_mean=0.370, reward_bound=0.150, batch=208 
5077: loss=0.178, reward_mean=0.430, reward_bound=0.167, batch=210 
5078: loss=0.168, reward_mean=0.470, reward_bound=0.185, batch=204 
5079: loss=0.166, reward_mean=0.390, reward_bound=0.183, batch=213 
5080: loss=0.166, reward_mean=0.420, reward_bound=0.206, batch=214 
5081: loss=0.170, reward_mean=0.420, reward_bound=0.226, batch=220 
5082: loss=0.168, reward_mean=0.400, reward_bound=0.222, batch=224 
5083: loss=0.162, reward_mean=0.380, reward_bound=0.229, batch=210 
5084: loss=0.162, reward_mean=0.410, reward_bound=0.247, batch=217 
5085: loss=0.164, reward_mean=0.330, reward_bound=0.254, batch=203 
5086: loss=0.164, reward_mean=0.400, reward_bound=0.198, batch=212 
5087: loss=0.164, reward_mean=0.480, reward_bound=0.282, batch=202 
5088: loss=0.171, reward_mean=0.330, reward_bound=0.155, batch=211 
5089: loss=0.173, reward_mean=0.480, reward_bound=0.185, batch=217 
5090: loss=0.165, reward_mean=0.390, reward_bound=0.254, batch=220 
5091: loss=0.163, reward_mean=0.380, reward_bound=0.282, batch=221 
5092: loss=0.163, reward_mean=0.390, reward_bound=0.206, batch=224 
5093: loss=0.167, reward_mean=0.510, reward_bound=0.314, batch=200 
5094: loss=0.168, reward_mean=0.410, reward_bound=0.200, batch=210 
5095: loss=0.165, reward_mean=0.410, reward_bound=0.314, batch=212 
5096: loss=0.164, reward_mean=0.410, reward_bound=0.292, batch=218 
5097: loss=0.167, reward_mean=0.480, reward_bound=0.317, batch=222 
5098: loss=0.167, reward_mean=0.490, reward_bound=0.314, batch=224 
5099: loss=0.164, reward_mean=0.460, reward_bound=0.349, batch=186 
5100: loss=0.168, reward_mean=0.370, reward_bound=0.143, batch=200 
5101: loss=0.171, reward_mean=0.360, reward_bound=0.150, batch=209 
5102: loss=0.171, reward_mean=0.440, reward_bound=0.148, batch=216 
5103: loss=0.172, reward_mean=0.410, reward_bound=0.196, batch=221 
5104: loss=0.168, reward_mean=0.450, reward_bound=0.229, batch=224 
5105: loss=0.160, reward_mean=0.500, reward_bound=0.254, batch=222 
5106: loss=0.160, reward_mean=0.390, reward_bound=0.263, batch=225 
5107: loss=0.159, reward_mean=0.500, reward_bound=0.282, batch=225 
5108: loss=0.158, reward_mean=0.530, reward_bound=0.314, batch=226 
5109: loss=0.159, reward_mean=0.430, reward_bound=0.349, batch=214 
5110: loss=0.160, reward_mean=0.400, reward_bound=0.254, batch=217 
5111: loss=0.159, reward_mean=0.410, reward_bound=0.308, batch=222 
5112: loss=0.158, reward_mean=0.430, reward_bound=0.314, batch=224 
5113: loss=0.157, reward_mean=0.420, reward_bound=0.349, batch=223 
5114: loss=0.157, reward_mean=0.520, reward_bound=0.349, batch=225 
5115: loss=0.151, reward_mean=0.400, reward_bound=0.387, batch=181 
5116: loss=0.159, reward_mean=0.390, reward_bound=0.150, batch=194 
5117: loss=0.159, reward_mean=0.440, reward_bound=0.165, batch=206 
5118: loss=0.156, reward_mean=0.520, reward_bound=0.196, batch=214 
5119: loss=0.158, reward_mean=0.360, reward_bound=0.206, batch=217 
5120: loss=0.158, reward_mean=0.480, reward_bound=0.249, batch=222 
5121: loss=0.154, reward_mean=0.430, reward_bound=0.254, batch=223 
5122: loss=0.157, reward_mean=0.430, reward_bound=0.282, batch=220 
5123: loss=0.152, reward_mean=0.380, reward_bound=0.314, batch=218 
5124: loss=0.151, reward_mean=0.370, reward_bound=0.286, batch=222 
5125: loss=0.151, reward_mean=0.440, reward_bound=0.314, batch=224 
5126: loss=0.150, reward_mean=0.450, reward_bound=0.349, batch=220 
5127: loss=0.145, reward_mean=0.530, reward_bound=0.387, batch=206 
5128: loss=0.145, reward_mean=0.520, reward_bound=0.316, batch=214 
5129: loss=0.146, reward_mean=0.410, reward_bound=0.345, batch=220 
5130: loss=0.144, reward_mean=0.450, reward_bound=0.338, batch=224 
5131: loss=0.142, reward_mean=0.520, reward_bound=0.349, batch=221 
5132: loss=0.143, reward_mean=0.400, reward_bound=0.349, batch=224 
5133: loss=0.142, reward_mean=0.520, reward_bound=0.387, batch=219 
5134: loss=0.143, reward_mean=0.410, reward_bound=0.328, batch=223 
5135: loss=0.143, reward_mean=0.450, reward_bound=0.301, batch=226 
5136: loss=0.142, reward_mean=0.500, reward_bound=0.349, batch=226 
5137: loss=0.146, reward_mean=0.470, reward_bound=0.387, batch=227 
5138: loss=0.145, reward_mean=0.470, reward_bound=0.414, batch=229 
5139: loss=0.146, reward_mean=0.390, reward_bound=0.430, batch=169 
5140: loss=0.141, reward_mean=0.340, reward_bound=0.052, batch=187 
5141: loss=0.143, reward_mean=0.440, reward_bound=0.097, batch=201 
5142: loss=0.139, reward_mean=0.530, reward_bound=0.135, batch=209 
5143: loss=0.144, reward_mean=0.460, reward_bound=0.185, batch=213 
5144: loss=0.151, reward_mean=0.470, reward_bound=0.229, batch=212 
5145: loss=0.143, reward_mean=0.350, reward_bound=0.254, batch=206 
5146: loss=0.145, reward_mean=0.500, reward_bound=0.268, batch=214 
5147: loss=0.145, reward_mean=0.350, reward_bound=0.167, batch=219 
5148: loss=0.149, reward_mean=0.450, reward_bound=0.282, batch=215 
5149: loss=0.150, reward_mean=0.440, reward_bound=0.260, batch=220 
5150: loss=0.149, reward_mean=0.390, reward_bound=0.282, batch=222 
5151: loss=0.146, reward_mean=0.290, reward_bound=0.314, batch=214 
5152: loss=0.145, reward_mean=0.340, reward_bound=0.229, batch=218 
5153: loss=0.147, reward_mean=0.420, reward_bound=0.286, batch=222 
5154: loss=0.147, reward_mean=0.510, reward_bound=0.272, batch=225 
5155: loss=0.143, reward_mean=0.410, reward_bound=0.314, batch=225 
5156: loss=0.140, reward_mean=0.410, reward_bound=0.349, batch=206 
5157: loss=0.144, reward_mean=0.390, reward_bound=0.230, batch=214 
5158: loss=0.145, reward_mean=0.410, reward_bound=0.226, batch=220 
5159: loss=0.145, reward_mean=0.370, reward_bound=0.274, batch=224 
5160: loss=0.144, reward_mean=0.510, reward_bound=0.311, batch=227 
5161: loss=0.140, reward_mean=0.370, reward_bound=0.314, batch=225 
5162: loss=0.141, reward_mean=0.360, reward_bound=0.349, batch=224 
5163: loss=0.143, reward_mean=0.350, reward_bound=0.387, batch=205 
5164: loss=0.143, reward_mean=0.360, reward_bound=0.185, batch=212 
5165: loss=0.141, reward_mean=0.450, reward_bound=0.282, batch=215 
5166: loss=0.141, reward_mean=0.430, reward_bound=0.234, batch=220 
5167: loss=0.144, reward_mean=0.450, reward_bound=0.314, batch=219 
5168: loss=0.143, reward_mean=0.410, reward_bound=0.265, batch=223 
5169: loss=0.145, reward_mean=0.440, reward_bound=0.282, batch=225 
5170: loss=0.143, reward_mean=0.420, reward_bound=0.314, batch=226 
5171: loss=0.141, reward_mean=0.460, reward_bound=0.349, batch=225 
5172: loss=0.141, reward_mean=0.400, reward_bound=0.387, batch=225 
5173: loss=0.141, reward_mean=0.400, reward_bound=0.234, batch=227 
5174: loss=0.141, reward_mean=0.420, reward_bound=0.349, batch=228 
5175: loss=0.142, reward_mean=0.450, reward_bound=0.392, batch=229 
5176: loss=0.142, reward_mean=0.480, reward_bound=0.360, batch=230 
5177: loss=0.141, reward_mean=0.330, reward_bound=0.430, batch=210 
5178: loss=0.138, reward_mean=0.460, reward_bound=0.206, batch=219 
5179: loss=0.143, reward_mean=0.540, reward_bound=0.254, batch=222 
5180: loss=0.143, reward_mean=0.480, reward_bound=0.314, batch=221 
5181: loss=0.142, reward_mean=0.500, reward_bound=0.349, batch=222 
5182: loss=0.144, reward_mean=0.460, reward_bound=0.387, batch=223 
5183: loss=0.146, reward_mean=0.320, reward_bound=0.261, batch=226 
5184: loss=0.149, reward_mean=0.470, reward_bound=0.349, batch=227 
5185: loss=0.148, reward_mean=0.420, reward_bound=0.422, batch=229 
5186: loss=0.146, reward_mean=0.440, reward_bound=0.430, batch=216 
5187: loss=0.148, reward_mean=0.450, reward_bound=0.298, batch=221 
5188: loss=0.148, reward_mean=0.430, reward_bound=0.282, batch=224 
5189: loss=0.146, reward_mean=0.380, reward_bound=0.345, batch=227 
5190: loss=0.145, reward_mean=0.450, reward_bound=0.349, batch=227 
5191: loss=0.145, reward_mean=0.410, reward_bound=0.380, batch=229 
5192: loss=0.150, reward_mean=0.440, reward_bound=0.387, batch=228 
5193: loss=0.149, reward_mean=0.460, reward_bound=0.293, batch=229 
5194: loss=0.149, reward_mean=0.450, reward_bound=0.349, batch=229 
5195: loss=0.149, reward_mean=0.440, reward_bound=0.328, batch=230 
5196: loss=0.152, reward_mean=0.500, reward_bound=0.430, batch=226 
5197: loss=0.152, reward_mean=0.370, reward_bound=0.430, batch=226 
5198: loss=0.151, reward_mean=0.460, reward_bound=0.331, batch=228 
5199: loss=0.151, reward_mean=0.440, reward_bound=0.387, batch=228 
5200: loss=0.152, reward_mean=0.440, reward_bound=0.430, batch=228 
5201: loss=0.151, reward_mean=0.350, reward_bound=0.435, batch=229 
5202: loss=0.151, reward_mean=0.480, reward_bound=0.349, batch=229 
5203: loss=0.151, reward_mean=0.450, reward_bound=0.478, batch=231 
5204: loss=0.146, reward_mean=0.430, reward_bound=0.478, batch=156 
5205: loss=0.153, reward_mean=0.370, reward_bound=0.076, batch=179 
5206: loss=0.153, reward_mean=0.350, reward_bound=0.080, batch=193 
5207: loss=0.152, reward_mean=0.480, reward_bound=0.130, batch=205 
5208: loss=0.151, reward_mean=0.440, reward_bound=0.135, batch=211 
5209: loss=0.148, reward_mean=0.430, reward_bound=0.167, batch=214 
5210: loss=0.149, reward_mean=0.400, reward_bound=0.185, batch=217 
5211: loss=0.149, reward_mean=0.440, reward_bound=0.206, batch=220 
5212: loss=0.150, reward_mean=0.510, reward_bound=0.254, batch=218 
5213: loss=0.149, reward_mean=0.520, reward_bound=0.282, batch=213 
5214: loss=0.149, reward_mean=0.370, reward_bound=0.314, batch=200 
5215: loss=0.154, reward_mean=0.430, reward_bound=0.222, batch=210 
5216: loss=0.155, reward_mean=0.380, reward_bound=0.247, batch=217 
5217: loss=0.153, reward_mean=0.450, reward_bound=0.254, batch=221 
5218: loss=0.152, reward_mean=0.420, reward_bound=0.314, batch=219 
5219: loss=0.155, reward_mean=0.460, reward_bound=0.349, batch=211 
5220: loss=0.154, reward_mean=0.470, reward_bound=0.282, batch=217 
5221: loss=0.154, reward_mean=0.530, reward_bound=0.349, batch=219 
5222: loss=0.151, reward_mean=0.390, reward_bound=0.295, batch=223 
5223: loss=0.152, reward_mean=0.400, reward_bound=0.314, batch=225 
5224: loss=0.146, reward_mean=0.360, reward_bound=0.387, batch=199 
5225: loss=0.148, reward_mean=0.440, reward_bound=0.174, batch=209 
5226: loss=0.145, reward_mean=0.460, reward_bound=0.254, batch=213 
5227: loss=0.148, reward_mean=0.420, reward_bound=0.282, batch=217 
5228: loss=0.144, reward_mean=0.350, reward_bound=0.314, batch=218 
5229: loss=0.146, reward_mean=0.370, reward_bound=0.317, batch=222 
5230: loss=0.145, reward_mean=0.390, reward_bound=0.292, batch=225 
5231: loss=0.152, reward_mean=0.510, reward_bound=0.349, batch=224 
5232: loss=0.148, reward_mean=0.480, reward_bound=0.387, batch=220 
5233: loss=0.147, reward_mean=0.390, reward_bound=0.376, batch=224 
5234: loss=0.147, reward_mean=0.410, reward_bound=0.345, batch=227 
5235: loss=0.150, reward_mean=0.470, reward_bound=0.387, batch=227 
5236: loss=0.150, reward_mean=0.430, reward_bound=0.380, batch=229 
5237: loss=0.151, reward_mean=0.380, reward_bound=0.405, batch=230 
5238: loss=0.152, reward_mean=0.430, reward_bound=0.338, batch=231 
5239: loss=0.151, reward_mean=0.420, reward_bound=0.387, batch=231 
5240: loss=0.148, reward_mean=0.410, reward_bound=0.430, batch=202 
5241: loss=0.153, reward_mean=0.360, reward_bound=0.206, batch=212 
5242: loss=0.156, reward_mean=0.460, reward_bound=0.191, batch=218 
5243: loss=0.154, reward_mean=0.380, reward_bound=0.254, batch=219 
5244: loss=0.150, reward_mean=0.550, reward_bound=0.349, batch=216 
5245: loss=0.150, reward_mean=0.450, reward_bound=0.230, batch=221 
5246: loss=0.151, reward_mean=0.360, reward_bound=0.314, batch=224 
5247: loss=0.150, reward_mean=0.420, reward_bound=0.345, batch=227 
5248: loss=0.151, reward_mean=0.350, reward_bound=0.342, batch=229 
5249: loss=0.149, reward_mean=0.570, reward_bound=0.349, batch=229 
5250: loss=0.146, reward_mean=0.460, reward_bound=0.387, batch=221 
5251: loss=0.148, reward_mean=0.310, reward_bound=0.254, batch=224 
5252: loss=0.148, reward_mean=0.400, reward_bound=0.280, batch=227 
5253: loss=0.146, reward_mean=0.450, reward_bound=0.282, batch=228 
5254: loss=0.145, reward_mean=0.450, reward_bound=0.349, batch=228 
5255: loss=0.145, reward_mean=0.380, reward_bound=0.387, batch=227 
5256: loss=0.146, reward_mean=0.490, reward_bound=0.430, batch=218 
5257: loss=0.145, reward_mean=0.400, reward_bound=0.353, batch=222 
5258: loss=0.145, reward_mean=0.390, reward_bound=0.292, batch=225 
5259: loss=0.145, reward_mean=0.430, reward_bound=0.349, batch=224 
5260: loss=0.144, reward_mean=0.430, reward_bound=0.384, batch=227 
5261: loss=0.144, reward_mean=0.430, reward_bound=0.342, batch=229 
5262: loss=0.144, reward_mean=0.370, reward_bound=0.364, batch=230 
5263: loss=0.145, reward_mean=0.390, reward_bound=0.387, batch=228 
5264: loss=0.145, reward_mean=0.450, reward_bound=0.430, batch=226 
5265: loss=0.143, reward_mean=0.420, reward_bound=0.478, batch=185 
5266: loss=0.147, reward_mean=0.440, reward_bound=0.206, batch=196 
5267: loss=0.151, reward_mean=0.480, reward_bound=0.196, batch=207 
5268: loss=0.150, reward_mean=0.390, reward_bound=0.229, batch=213 
5269: loss=0.149, reward_mean=0.440, reward_bound=0.254, batch=213 
5270: loss=0.149, reward_mean=0.370, reward_bound=0.254, batch=218 
5271: loss=0.146, reward_mean=0.390, reward_bound=0.257, batch=222 
5272: loss=0.148, reward_mean=0.420, reward_bound=0.282, batch=215 
5273: loss=0.152, reward_mean=0.390, reward_bound=0.234, batch=220 
5274: loss=0.148, reward_mean=0.390, reward_bound=0.274, batch=224 
5275: loss=0.149, reward_mean=0.390, reward_bound=0.282, batch=226 
5276: loss=0.148, reward_mean=0.420, reward_bound=0.314, batch=220 
5277: loss=0.152, reward_mean=0.440, reward_bound=0.338, batch=224 
5278: loss=0.154, reward_mean=0.400, reward_bound=0.282, batch=226 
5279: loss=0.151, reward_mean=0.440, reward_bound=0.331, batch=228 
5280: loss=0.150, reward_mean=0.380, reward_bound=0.349, batch=218 
5281: loss=0.151, reward_mean=0.400, reward_bound=0.321, batch=222 
5282: loss=0.144, reward_mean=0.450, reward_bound=0.387, batch=208 
5283: loss=0.143, reward_mean=0.490, reward_bound=0.260, batch=215 
5284: loss=0.143, reward_mean=0.360, reward_bound=0.314, batch=216 
5285: loss=0.145, reward_mean=0.510, reward_bound=0.349, batch=218 
5286: loss=0.143, reward_mean=0.430, reward_bound=0.387, batch=213 
5287: loss=0.144, reward_mean=0.320, reward_bound=0.301, batch=219 
5288: loss=0.144, reward_mean=0.500, reward_bound=0.295, batch=223 
5289: loss=0.144, reward_mean=0.400, reward_bound=0.349, batch=222 
5290: loss=0.144, reward_mean=0.490, reward_bound=0.360, batch=225 
5291: loss=0.144, reward_mean=0.330, reward_bound=0.387, batch=224 
5292: loss=0.145, reward_mean=0.420, reward_bound=0.422, batch=227 
5293: loss=0.145, reward_mean=0.430, reward_bound=0.342, batch=229 
5294: loss=0.148, reward_mean=0.480, reward_bound=0.381, batch=230 
5295: loss=0.145, reward_mean=0.380, reward_bound=0.430, batch=211 
5296: loss=0.145, reward_mean=0.400, reward_bound=0.254, batch=216 
5297: loss=0.146, reward_mean=0.360, reward_bound=0.298, batch=221 
5298: loss=0.148, reward_mean=0.470, reward_bound=0.314, batch=224 
5299: loss=0.147, reward_mean=0.570, reward_bound=0.345, batch=227 
5300: loss=0.150, reward_mean=0.460, reward_bound=0.349, batch=227 
5301: loss=0.149, reward_mean=0.400, reward_bound=0.308, batch=229 
5302: loss=0.149, reward_mean=0.390, reward_bound=0.387, batch=225 
5303: loss=0.147, reward_mean=0.470, reward_bound=0.430, batch=220 
5304: loss=0.148, reward_mean=0.390, reward_bound=0.365, batch=224 
5305: loss=0.148, reward_mean=0.430, reward_bound=0.280, batch=227 
5306: loss=0.147, reward_mean=0.470, reward_bound=0.342, batch=229 
5307: loss=0.146, reward_mean=0.380, reward_bound=0.364, batch=230 
5308: loss=0.146, reward_mean=0.450, reward_bound=0.387, batch=228 
5309: loss=0.146, reward_mean=0.400, reward_bound=0.392, batch=229 
5310: loss=0.145, reward_mean=0.410, reward_bound=0.405, batch=230 
5311: loss=0.145, reward_mean=0.390, reward_bound=0.430, batch=226 
5312: loss=0.145, reward_mean=0.400, reward_bound=0.430, batch=227 
5313: loss=0.145, reward_mean=0.490, reward_bound=0.387, batch=228 
5314: loss=0.145, reward_mean=0.430, reward_bound=0.362, batch=229 
5315: loss=0.145, reward_mean=0.360, reward_bound=0.343, batch=230 
5316: loss=0.145, reward_mean=0.400, reward_bound=0.430, batch=229 
5317: loss=0.146, reward_mean=0.400, reward_bound=0.424, batch=230 
5318: loss=0.145, reward_mean=0.440, reward_bound=0.451, batch=231 
5319: loss=0.143, reward_mean=0.500, reward_bound=0.478, batch=206 
5320: loss=0.140, reward_mean=0.410, reward_bound=0.282, batch=213 
5321: loss=0.140, reward_mean=0.470, reward_bound=0.282, batch=218 
5322: loss=0.142, reward_mean=0.460, reward_bound=0.286, batch=222 
5323: loss=0.145, reward_mean=0.430, reward_bound=0.282, batch=224 
5324: loss=0.144, reward_mean=0.430, reward_bound=0.314, batch=225 
5325: loss=0.150, reward_mean=0.430, reward_bound=0.349, batch=223 
5326: loss=0.149, reward_mean=0.400, reward_bound=0.387, batch=224 
5327: loss=0.148, reward_mean=0.410, reward_bound=0.426, batch=227 
5328: loss=0.148, reward_mean=0.380, reward_bound=0.314, batch=228 
5329: loss=0.147, reward_mean=0.420, reward_bound=0.317, batch=229 
5330: loss=0.147, reward_mean=0.400, reward_bound=0.387, batch=229 
5331: loss=0.144, reward_mean=0.430, reward_bound=0.430, batch=221 
5332: loss=0.142, reward_mean=0.400, reward_bound=0.229, batch=224 
5333: loss=0.142, reward_mean=0.420, reward_bound=0.314, batch=226 
5334: loss=0.143, reward_mean=0.470, reward_bound=0.387, batch=225 
5335: loss=0.143, reward_mean=0.490, reward_bound=0.296, batch=227 
5336: loss=0.141, reward_mean=0.410, reward_bound=0.380, batch=229 
5337: loss=0.144, reward_mean=0.410, reward_bound=0.430, batch=226 
5338: loss=0.144, reward_mean=0.400, reward_bound=0.478, batch=214 
5339: loss=0.144, reward_mean=0.450, reward_bound=0.252, batch=220 
5340: loss=0.144, reward_mean=0.450, reward_bound=0.304, batch=224 
5341: loss=0.145, reward_mean=0.400, reward_bound=0.314, batch=222 
5342: loss=0.146, reward_mean=0.370, reward_bound=0.349, batch=223 
5343: loss=0.146, reward_mean=0.450, reward_bound=0.358, batch=226 
5344: loss=0.145, reward_mean=0.460, reward_bound=0.368, batch=228 
5345: loss=0.146, reward_mean=0.490, reward_bound=0.387, batch=224 
5346: loss=0.145, reward_mean=0.430, reward_bound=0.430, batch=223 
5347: loss=0.146, reward_mean=0.370, reward_bound=0.314, batch=225 
5348: loss=0.146, reward_mean=0.450, reward_bound=0.387, batch=224 
5349: loss=0.145, reward_mean=0.480, reward_bound=0.422, batch=227 
5350: loss=0.145, reward_mean=0.450, reward_bound=0.366, batch=229 
5351: loss=0.145, reward_mean=0.350, reward_bound=0.343, batch=230 
5352: loss=0.143, reward_mean=0.440, reward_bound=0.430, batch=229 
5353: loss=0.144, reward_mean=0.450, reward_bound=0.478, batch=231 
5354: loss=0.144, reward_mean=0.370, reward_bound=0.387, batch=231 
5355: loss=0.141, reward_mean=0.390, reward_bound=0.478, batch=219 
5356: loss=0.142, reward_mean=0.460, reward_bound=0.328, batch=223 
5357: loss=0.142, reward_mean=0.410, reward_bound=0.314, batch=225 
5358: loss=0.143, reward_mean=0.480, reward_bound=0.321, batch=227 
5359: loss=0.143, reward_mean=0.460, reward_bound=0.380, batch=229 
5360: loss=0.143, reward_mean=0.470, reward_bound=0.387, batch=229 
5361: loss=0.141, reward_mean=0.510, reward_bound=0.430, batch=224 
5362: loss=0.141, reward_mean=0.350, reward_bound=0.384, batch=227 
5363: loss=0.141, reward_mean=0.460, reward_bound=0.387, batch=228 
5364: loss=0.141, reward_mean=0.470, reward_bound=0.430, batch=226 
5365: loss=0.141, reward_mean=0.450, reward_bound=0.409, batch=228 
5366: loss=0.142, reward_mean=0.440, reward_bound=0.321, batch=229 
5367: loss=0.141, reward_mean=0.510, reward_bound=0.364, batch=230 
5368: loss=0.140, reward_mean=0.520, reward_bound=0.387, batch=230 
5369: loss=0.140, reward_mean=0.410, reward_bound=0.406, batch=231 
5370: loss=0.141, reward_mean=0.400, reward_bound=0.430, batch=229 
5371: loss=0.141, reward_mean=0.470, reward_bound=0.450, batch=230 
5372: loss=0.141, reward_mean=0.440, reward_bound=0.478, batch=226 
5373: loss=0.140, reward_mean=0.430, reward_bound=0.349, batch=227 
5374: loss=0.140, reward_mean=0.400, reward_bound=0.342, batch=229 
5375: loss=0.140, reward_mean=0.350, reward_bound=0.349, batch=229 
5376: loss=0.141, reward_mean=0.340, reward_bound=0.430, batch=228 
5377: loss=0.140, reward_mean=0.520, reward_bound=0.435, batch=229 
5378: loss=0.140, reward_mean=0.500, reward_bound=0.450, batch=230 
5379: loss=0.141, reward_mean=0.550, reward_bound=0.478, batch=227 
5380: loss=0.140, reward_mean=0.440, reward_bound=0.422, batch=229 
5381: loss=0.141, reward_mean=0.450, reward_bound=0.430, batch=228 
5382: loss=0.140, reward_mean=0.490, reward_bound=0.435, batch=229 
5383: loss=0.140, reward_mean=0.440, reward_bound=0.450, batch=230 
5384: loss=0.140, reward_mean=0.380, reward_bound=0.430, batch=230 
5385: loss=0.139, reward_mean=0.420, reward_bound=0.376, batch=231 
5386: loss=0.140, reward_mean=0.450, reward_bound=0.387, batch=230 
5387: loss=0.139, reward_mean=0.420, reward_bound=0.464, batch=231 
5388: loss=0.140, reward_mean=0.480, reward_bound=0.478, batch=230 
5389: loss=0.140, reward_mean=0.410, reward_bound=0.478, batch=230 
5390: loss=0.140, reward_mean=0.520, reward_bound=0.418, batch=231 
5391: loss=0.140, reward_mean=0.440, reward_bound=0.387, batch=231 
5392: loss=0.141, reward_mean=0.500, reward_bound=0.478, batch=231 
5393: loss=0.141, reward_mean=0.390, reward_bound=0.430, batch=231 
5394: loss=0.141, reward_mean=0.460, reward_bound=0.430, batch=231 
5396: loss=0.146, reward_mean=0.400, reward_bound=0.000, batch=40 
5397: loss=0.140, reward_mean=0.370, reward_bound=0.000, batch=77 
5398: loss=0.149, reward_mean=0.570, reward_bound=0.001, batch=124 
5399: loss=0.154, reward_mean=0.480, reward_bound=0.006, batch=155 
5400: loss=0.156, reward_mean=0.580, reward_bound=0.023, batch=175 
5401: loss=0.155, reward_mean=0.460, reward_bound=0.031, batch=191 
5402: loss=0.155, reward_mean=0.390, reward_bound=0.042, batch=203 
5403: loss=0.157, reward_mean=0.420, reward_bound=0.052, batch=209 
5404: loss=0.157, reward_mean=0.410, reward_bound=0.065, batch=215 
5405: loss=0.157, reward_mean=0.490, reward_bound=0.080, batch=211 
5406: loss=0.155, reward_mean=0.580, reward_bound=0.098, batch=199 
5407: loss=0.153, reward_mean=0.480, reward_bound=0.109, batch=207 
5408: loss=0.151, reward_mean=0.320, reward_bound=0.122, batch=200 
5409: loss=0.151, reward_mean=0.440, reward_bound=0.135, batch=204 
5410: loss=0.148, reward_mean=0.380, reward_bound=0.150, batch=200 
5411: loss=0.147, reward_mean=0.360, reward_bound=0.167, batch=184 
5412: loss=0.148, reward_mean=0.510, reward_bound=0.185, batch=179 
5413: loss=0.146, reward_mean=0.430, reward_bound=0.140, batch=195 
5414: loss=0.146, reward_mean=0.440, reward_bound=0.185, batch=204 
5415: loss=0.144, reward_mean=0.380, reward_bound=0.206, batch=193 
5416: loss=0.144, reward_mean=0.460, reward_bound=0.178, batch=205 
5417: loss=0.144, reward_mean=0.430, reward_bound=0.189, batch=213 
5418: loss=0.145, reward_mean=0.370, reward_bound=0.206, batch=215 
5419: loss=0.145, reward_mean=0.380, reward_bound=0.229, batch=191 
5420: loss=0.146, reward_mean=0.440, reward_bound=0.167, batch=202 
5421: loss=0.148, reward_mean=0.480, reward_bound=0.191, batch=211 
5422: loss=0.149, reward_mean=0.370, reward_bound=0.206, batch=216 
5423: loss=0.148, reward_mean=0.440, reward_bound=0.229, batch=220 
5424: loss=0.149, reward_mean=0.450, reward_bound=0.254, batch=199 
5425: loss=0.150, reward_mean=0.500, reward_bound=0.229, batch=207 
5426: loss=0.149, reward_mean=0.490, reward_bound=0.277, batch=215 
5427: loss=0.148, reward_mean=0.350, reward_bound=0.194, batch=220 
5428: loss=0.145, reward_mean=0.410, reward_bound=0.282, batch=177 
5429: loss=0.147, reward_mean=0.440, reward_bound=0.150, batch=192 
5430: loss=0.143, reward_mean=0.380, reward_bound=0.155, batch=204 
5431: loss=0.143, reward_mean=0.430, reward_bound=0.204, batch=213 
5432: loss=0.144, reward_mean=0.440, reward_bound=0.206, batch=216 
5433: loss=0.146, reward_mean=0.400, reward_bound=0.229, batch=216 
5434: loss=0.146, reward_mean=0.490, reward_bound=0.254, batch=211 
5435: loss=0.146, reward_mean=0.430, reward_bound=0.185, batch=217 
5436: loss=0.144, reward_mean=0.410, reward_bound=0.229, batch=220 
5437: loss=0.144, reward_mean=0.540, reward_bound=0.282, batch=213 
5438: loss=0.140, reward_mean=0.450, reward_bound=0.314, batch=167 
5439: loss=0.144, reward_mean=0.500, reward_bound=0.122, batch=185 
5440: loss=0.142, reward_mean=0.410, reward_bound=0.106, batch=199 
5441: loss=0.144, reward_mean=0.440, reward_bound=0.135, batch=208 
5442: loss=0.146, reward_mean=0.460, reward_bound=0.167, batch=212 
5443: loss=0.144, reward_mean=0.490, reward_bound=0.185, batch=217 
5444: loss=0.146, reward_mean=0.330, reward_bound=0.206, batch=221 
5445: loss=0.141, reward_mean=0.420, reward_bound=0.229, batch=219 
5446: loss=0.140, reward_mean=0.440, reward_bound=0.254, batch=220 
5447: loss=0.140, reward_mean=0.370, reward_bound=0.282, batch=217 
5448: loss=0.139, reward_mean=0.470, reward_bound=0.314, batch=205 
5449: loss=0.139, reward_mean=0.370, reward_bound=0.167, batch=212 
5450: loss=0.140, reward_mean=0.420, reward_bound=0.213, batch=218 
5451: loss=0.146, reward_mean=0.420, reward_bound=0.231, batch=222 
5452: loss=0.143, reward_mean=0.460, reward_bound=0.324, batch=225 
5453: loss=0.140, reward_mean=0.390, reward_bound=0.349, batch=166 
5454: loss=0.141, reward_mean=0.370, reward_bound=0.080, batch=185 
5455: loss=0.143, reward_mean=0.520, reward_bound=0.098, batch=198 
5456: loss=0.148, reward_mean=0.410, reward_bound=0.150, batch=205 
5457: loss=0.146, reward_mean=0.470, reward_bound=0.167, batch=210 
5458: loss=0.146, reward_mean=0.500, reward_bound=0.167, batch=215 
5459: loss=0.147, reward_mean=0.420, reward_bound=0.185, batch=219 
5460: loss=0.148, reward_mean=0.470, reward_bound=0.206, batch=220 
5461: loss=0.149, reward_mean=0.330, reward_bound=0.229, batch=212 
5462: loss=0.148, reward_mean=0.500, reward_bound=0.263, batch=218 
5463: loss=0.147, reward_mean=0.410, reward_bound=0.282, batch=215 
5464: loss=0.147, reward_mean=0.420, reward_bound=0.229, batch=219 
5465: loss=0.149, reward_mean=0.410, reward_bound=0.239, batch=223 
5466: loss=0.144, reward_mean=0.400, reward_bound=0.314, batch=213 
5467: loss=0.145, reward_mean=0.330, reward_bound=0.178, batch=219 
5468: loss=0.145, reward_mean=0.480, reward_bound=0.295, batch=223 
5469: loss=0.142, reward_mean=0.510, reward_bound=0.349, batch=213 
5470: loss=0.127, reward_mean=0.500, reward_bound=0.387, batch=147 
5471: loss=0.133, reward_mean=0.430, reward_bound=0.037, batch=173 
5472: loss=0.139, reward_mean=0.500, reward_bound=0.085, batch=191 
5473: loss=0.141, reward_mean=0.410, reward_bound=0.098, batch=203 
5474: loss=0.145, reward_mean=0.410, reward_bound=0.109, batch=205 
5475: loss=0.140, reward_mean=0.400, reward_bound=0.150, batch=207 
5476: loss=0.141, reward_mean=0.390, reward_bound=0.135, batch=213 
5477: loss=0.138, reward_mean=0.360, reward_bound=0.185, batch=213 
5478: loss=0.138, reward_mean=0.360, reward_bound=0.206, batch=212 
5479: loss=0.139, reward_mean=0.490, reward_bound=0.229, batch=212 
5480: loss=0.140, reward_mean=0.450, reward_bound=0.254, batch=210 
5481: loss=0.141, reward_mean=0.410, reward_bound=0.247, batch=217 
5482: loss=0.143, reward_mean=0.450, reward_bound=0.277, batch=222 
5483: loss=0.137, reward_mean=0.460, reward_bound=0.282, batch=211 
5484: loss=0.133, reward_mean=0.460, reward_bound=0.314, batch=202 
5485: loss=0.136, reward_mean=0.440, reward_bound=0.167, batch=210 
5486: loss=0.135, reward_mean=0.400, reward_bound=0.254, batch=214 
5487: loss=0.135, reward_mean=0.480, reward_bound=0.282, batch=217 
5488: loss=0.135, reward_mean=0.410, reward_bound=0.229, batch=221 
5489: loss=0.133, reward_mean=0.470, reward_bound=0.314, batch=214 
5490: loss=0.130, reward_mean=0.500, reward_bound=0.252, batch=220 
5491: loss=0.133, reward_mean=0.340, reward_bound=0.254, batch=222 
5492: loss=0.130, reward_mean=0.430, reward_bound=0.292, batch=225 
5493: loss=0.133, reward_mean=0.430, reward_bound=0.314, batch=223 
5494: loss=0.131, reward_mean=0.430, reward_bound=0.335, batch=226 
5495: loss=0.128, reward_mean=0.440, reward_bound=0.349, batch=204 
5496: loss=0.129, reward_mean=0.380, reward_bound=0.282, batch=212 
5497: loss=0.130, reward_mean=0.490, reward_bound=0.254, batch=217 
5498: loss=0.132, reward_mean=0.420, reward_bound=0.249, batch=222 
5499: loss=0.130, reward_mean=0.470, reward_bound=0.292, batch=225 
5500: loss=0.129, reward_mean=0.390, reward_bound=0.349, batch=218 
5501: loss=0.123, reward_mean=0.430, reward_bound=0.387, batch=201 
5502: loss=0.123, reward_mean=0.520, reward_bound=0.282, batch=210 
5503: loss=0.127, reward_mean=0.450, reward_bound=0.222, batch=217 
5504: loss=0.126, reward_mean=0.430, reward_bound=0.277, batch=222 
5505: loss=0.126, reward_mean=0.370, reward_bound=0.245, batch=225 
5506: loss=0.123, reward_mean=0.480, reward_bound=0.314, batch=222 
5507: loss=0.122, reward_mean=0.470, reward_bound=0.324, batch=225 
5508: loss=0.125, reward_mean=0.360, reward_bound=0.246, batch=227 
5509: loss=0.122, reward_mean=0.460, reward_bound=0.342, batch=229 
5510: loss=0.122, reward_mean=0.490, reward_bound=0.349, batch=223 
5511: loss=0.122, reward_mean=0.440, reward_bound=0.282, batch=225 
5512: loss=0.125, reward_mean=0.560, reward_bound=0.387, batch=218 
5513: loss=0.123, reward_mean=0.420, reward_bound=0.286, batch=222 
5514: loss=0.124, reward_mean=0.510, reward_bound=0.314, batch=221 
5515: loss=0.123, reward_mean=0.470, reward_bound=0.349, batch=224 
5516: loss=0.124, reward_mean=0.370, reward_bound=0.387, batch=223 
5517: loss=0.124, reward_mean=0.410, reward_bound=0.301, batch=226 
5518: loss=0.125, reward_mean=0.370, reward_bound=0.314, batch=225 
5519: loss=0.125, reward_mean=0.480, reward_bound=0.356, batch=227 
5520: loss=0.123, reward_mean=0.410, reward_bound=0.422, batch=229 
5521: loss=0.118, reward_mean=0.330, reward_bound=0.430, batch=128 
5522: loss=0.142, reward_mean=0.360, reward_bound=0.007, batch=159 
5523: loss=0.132, reward_mean=0.430, reward_bound=0.049, batch=181 
5524: loss=0.135, reward_mean=0.490, reward_bound=0.098, batch=192 
5525: loss=0.141, reward_mean=0.520, reward_bound=0.122, batch=197 
5526: loss=0.136, reward_mean=0.440, reward_bound=0.147, batch=208 
5527: loss=0.135, reward_mean=0.400, reward_bound=0.150, batch=211 
5528: loss=0.127, reward_mean=0.450, reward_bound=0.167, batch=213 
5529: loss=0.120, reward_mean=0.400, reward_bound=0.185, batch=218 
5530: loss=0.118, reward_mean=0.380, reward_bound=0.206, batch=217 
5531: loss=0.120, reward_mean=0.460, reward_bound=0.229, batch=212 
5532: loss=0.119, reward_mean=0.500, reward_bound=0.185, batch=217 
5533: loss=0.122, reward_mean=0.490, reward_bound=0.245, batch=222 
5534: loss=0.119, reward_mean=0.360, reward_bound=0.254, batch=214 
5535: loss=0.118, reward_mean=0.470, reward_bound=0.277, batch=220 
5536: loss=0.116, reward_mean=0.510, reward_bound=0.282, batch=210 
5537: loss=0.116, reward_mean=0.530, reward_bound=0.282, batch=215 
5538: loss=0.115, reward_mean=0.460, reward_bound=0.260, batch=220 
5539: loss=0.118, reward_mean=0.570, reward_bound=0.314, batch=213 
5540: loss=0.119, reward_mean=0.430, reward_bound=0.235, batch=219 
5541: loss=0.119, reward_mean=0.470, reward_bound=0.254, batch=222 
5542: loss=0.120, reward_mean=0.440, reward_bound=0.282, batch=224 
5543: loss=0.116, reward_mean=0.490, reward_bound=0.314, batch=226 
5544: loss=0.115, reward_mean=0.440, reward_bound=0.298, batch=228 
5545: loss=0.120, reward_mean=0.400, reward_bound=0.349, batch=194 
5546: loss=0.118, reward_mean=0.440, reward_bound=0.185, batch=203 
5547: loss=0.121, reward_mean=0.460, reward_bound=0.254, batch=211 
5548: loss=0.122, reward_mean=0.420, reward_bound=0.167, batch=217 
5549: loss=0.123, reward_mean=0.430, reward_bound=0.277, batch=222 
5550: loss=0.123, reward_mean=0.430, reward_bound=0.282, batch=220 
5551: loss=0.120, reward_mean=0.420, reward_bound=0.314, batch=218 
5552: loss=0.120, reward_mean=0.420, reward_bound=0.314, batch=221 
5553: loss=0.122, reward_mean=0.500, reward_bound=0.314, batch=224 
5554: loss=0.121, reward_mean=0.480, reward_bound=0.314, batch=226 
5555: loss=0.119, reward_mean=0.460, reward_bound=0.349, batch=219 
5556: loss=0.119, reward_mean=0.520, reward_bound=0.282, batch=222 
5557: loss=0.118, reward_mean=0.380, reward_bound=0.314, batch=224 
5558: loss=0.120, reward_mean=0.420, reward_bound=0.384, batch=227 
5559: loss=0.119, reward_mean=0.360, reward_bound=0.380, batch=229 
5560: loss=0.121, reward_mean=0.460, reward_bound=0.387, batch=203 
5561: loss=0.123, reward_mean=0.330, reward_bound=0.220, batch=212 
5562: loss=0.119, reward_mean=0.450, reward_bound=0.229, batch=217 
5563: loss=0.119, reward_mean=0.460, reward_bound=0.282, batch=219 
5564: loss=0.120, reward_mean=0.420, reward_bound=0.314, batch=218 
5565: loss=0.119, reward_mean=0.360, reward_bound=0.314, batch=221 
5566: loss=0.119, reward_mean=0.500, reward_bound=0.314, batch=224 
5567: loss=0.120, reward_mean=0.450, reward_bound=0.349, batch=219 
5568: loss=0.122, reward_mean=0.410, reward_bound=0.265, batch=223 
5569: loss=0.121, reward_mean=0.430, reward_bound=0.335, batch=226 
5570: loss=0.121, reward_mean=0.430, reward_bound=0.349, batch=227 
5571: loss=0.122, reward_mean=0.400, reward_bound=0.387, batch=224 
5572: loss=0.122, reward_mean=0.430, reward_bound=0.426, batch=227 
5573: loss=0.121, reward_mean=0.440, reward_bound=0.430, batch=184 
5574: loss=0.116, reward_mean=0.440, reward_bound=0.167, batch=198 
5575: loss=0.120, reward_mean=0.460, reward_bound=0.185, batch=206 
5576: loss=0.121, reward_mean=0.340, reward_bound=0.206, batch=213 
5577: loss=0.117, reward_mean=0.390, reward_bound=0.229, batch=216 
5578: loss=0.119, reward_mean=0.430, reward_bound=0.268, batch=221 
5579: loss=0.119, reward_mean=0.480, reward_bound=0.282, batch=222 
5580: loss=0.118, reward_mean=0.410, reward_bound=0.314, batch=220 
5581: loss=0.118, reward_mean=0.490, reward_bound=0.349, batch=219 
5582: loss=0.117, reward_mean=0.480, reward_bound=0.364, batch=223 
5583: loss=0.117, reward_mean=0.360, reward_bound=0.387, batch=214 
5584: loss=0.120, reward_mean=0.430, reward_bound=0.249, batch=220 
5585: loss=0.118, reward_mean=0.430, reward_bound=0.247, batch=224 
5586: loss=0.118, reward_mean=0.430, reward_bound=0.254, batch=223 
5587: loss=0.118, reward_mean=0.340, reward_bound=0.314, batch=225 
5588: loss=0.116, reward_mean=0.440, reward_bound=0.349, batch=225 
5589: loss=0.118, reward_mean=0.410, reward_bound=0.349, batch=226 
5590: loss=0.117, reward_mean=0.380, reward_bound=0.387, batch=224 
5591: loss=0.117, reward_mean=0.330, reward_bound=0.345, batch=227 
5592: loss=0.116, reward_mean=0.460, reward_bound=0.349, batch=228 
5593: loss=0.117, reward_mean=0.440, reward_bound=0.392, batch=229 
5594: loss=0.118, reward_mean=0.450, reward_bound=0.405, batch=230 
5595: loss=0.120, reward_mean=0.390, reward_bound=0.430, batch=212 
5596: loss=0.119, reward_mean=0.450, reward_bound=0.236, batch=218 
5597: loss=0.120, reward_mean=0.410, reward_bound=0.254, batch=217 
5598: loss=0.121, reward_mean=0.380, reward_bound=0.277, batch=222 
5599: loss=0.121, reward_mean=0.540, reward_bound=0.314, batch=223 
5600: loss=0.121, reward_mean=0.340, reward_bound=0.244, batch=226 
5601: loss=0.122, reward_mean=0.470, reward_bound=0.349, batch=227 
5602: loss=0.122, reward_mean=0.390, reward_bound=0.387, batch=222 
5603: loss=0.122, reward_mean=0.460, reward_bound=0.324, batch=225 
5604: loss=0.122, reward_mean=0.490, reward_bound=0.396, batch=227 
5605: loss=0.122, reward_mean=0.460, reward_bound=0.380, batch=229 
5606: loss=0.121, reward_mean=0.450, reward_bound=0.387, batch=229 
5607: loss=0.121, reward_mean=0.430, reward_bound=0.430, batch=219 
5608: loss=0.122, reward_mean=0.470, reward_bound=0.328, batch=223 
5609: loss=0.120, reward_mean=0.360, reward_bound=0.349, batch=225 
5610: loss=0.120, reward_mean=0.440, reward_bound=0.356, batch=227 
5611: loss=0.121, reward_mean=0.440, reward_bound=0.387, batch=226 
5612: loss=0.121, reward_mean=0.480, reward_bound=0.409, batch=228 
5613: loss=0.121, reward_mean=0.400, reward_bound=0.430, batch=226 
5614: loss=0.123, reward_mean=0.430, reward_bound=0.271, batch=228 
5615: loss=0.121, reward_mean=0.500, reward_bound=0.430, batch=228 
5616: loss=0.121, reward_mean=0.470, reward_bound=0.435, batch=229 
5617: loss=0.120, reward_mean=0.360, reward_bound=0.478, batch=231 
5618: loss=0.120, reward_mean=0.410, reward_bound=0.387, batch=231 
5619: loss=0.114, reward_mean=0.400, reward_bound=0.478, batch=104 
5620: loss=0.117, reward_mean=0.440, reward_bound=0.004, batch=142 
5621: loss=0.119, reward_mean=0.390, reward_bound=0.018, batch=167 
5622: loss=0.121, reward_mean=0.420, reward_bound=0.028, batch=185 
5623: loss=0.115, reward_mean=0.390, reward_bound=0.039, batch=199 
5624: loss=0.120, reward_mean=0.400, reward_bound=0.058, batch=208 
5625: loss=0.121, reward_mean=0.390, reward_bound=0.080, batch=214 
5626: loss=0.119, reward_mean=0.370, reward_bound=0.108, batch=220 
5627: loss=0.120, reward_mean=0.420, reward_bound=0.131, batch=224 
5628: loss=0.122, reward_mean=0.410, reward_bound=0.149, batch=227 
5629: loss=0.122, reward_mean=0.290, reward_bound=0.150, batch=228 
5630: loss=0.122, reward_mean=0.400, reward_bound=0.167, batch=227 
5631: loss=0.124, reward_mean=0.500, reward_bound=0.185, batch=223 
5632: loss=0.120, reward_mean=0.440, reward_bound=0.206, batch=220 
5633: loss=0.116, reward_mean=0.330, reward_bound=0.229, batch=213 
5634: loss=0.110, reward_mean=0.470, reward_bound=0.254, batch=203 
5635: loss=0.108, reward_mean=0.390, reward_bound=0.206, batch=208 
5636: loss=0.109, reward_mean=0.420, reward_bound=0.229, batch=211 
5637: loss=0.109, reward_mean=0.370, reward_bound=0.229, batch=216 
5638: loss=0.112, reward_mean=0.420, reward_bound=0.254, batch=220 
5639: loss=0.115, reward_mean=0.350, reward_bound=0.194, batch=224 
5640: loss=0.107, reward_mean=0.500, reward_bound=0.282, batch=201 
5641: loss=0.109, reward_mean=0.430, reward_bound=0.254, batch=210 
5642: loss=0.109, reward_mean=0.440, reward_bound=0.247, batch=217 
5643: loss=0.112, reward_mean=0.390, reward_bound=0.249, batch=222 
5644: loss=0.106, reward_mean=0.370, reward_bound=0.314, batch=194 
5645: loss=0.107, reward_mean=0.380, reward_bound=0.183, batch=206 
5646: loss=0.104, reward_mean=0.460, reward_bound=0.229, batch=213 
5647: loss=0.106, reward_mean=0.440, reward_bound=0.271, batch=219 
5648: loss=0.106, reward_mean=0.430, reward_bound=0.282, batch=221 
5649: loss=0.107, reward_mean=0.420, reward_bound=0.314, batch=221 
5650: loss=0.109, reward_mean=0.350, reward_bound=0.314, batch=223 
5651: loss=0.109, reward_mean=0.440, reward_bound=0.282, batch=224 
5652: loss=0.104, reward_mean=0.460, reward_bound=0.349, batch=198 
5653: loss=0.106, reward_mean=0.430, reward_bound=0.208, batch=208 
5654: loss=0.104, reward_mean=0.400, reward_bound=0.169, batch=215 
5655: loss=0.109, reward_mean=0.500, reward_bound=0.234, batch=220 
5656: loss=0.109, reward_mean=0.430, reward_bound=0.254, batch=218 
5657: loss=0.108, reward_mean=0.470, reward_bound=0.231, batch=222 
5658: loss=0.111, reward_mean=0.510, reward_bound=0.282, batch=224 
5659: loss=0.112, reward_mean=0.490, reward_bound=0.314, batch=225 
5660: loss=0.107, reward_mean=0.440, reward_bound=0.349, batch=221 
5661: loss=0.110, reward_mean=0.550, reward_bound=0.387, batch=185 
5662: loss=0.110, reward_mean=0.500, reward_bound=0.138, batch=199 
5663: loss=0.108, reward_mean=0.440, reward_bound=0.194, batch=209 
5664: loss=0.112, reward_mean=0.470, reward_bound=0.206, batch=212 
5665: loss=0.112, reward_mean=0.380, reward_bound=0.229, batch=216 
5666: loss=0.112, reward_mean=0.380, reward_bound=0.254, batch=214 
5667: loss=0.117, reward_mean=0.470, reward_bound=0.254, batch=218 
5668: loss=0.115, reward_mean=0.440, reward_bound=0.282, batch=220 
5669: loss=0.116, reward_mean=0.390, reward_bound=0.314, batch=215 
5670: loss=0.115, reward_mean=0.420, reward_bound=0.314, batch=217 
5671: loss=0.113, reward_mean=0.300, reward_bound=0.308, batch=222 
5672: loss=0.111, reward_mean=0.460, reward_bound=0.349, batch=215 
5673: loss=0.110, reward_mean=0.380, reward_bound=0.157, batch=220 
5674: loss=0.111, reward_mean=0.480, reward_bound=0.247, batch=224 
5675: loss=0.112, reward_mean=0.380, reward_bound=0.280, batch=227 
5676: loss=0.111, reward_mean=0.470, reward_bound=0.314, batch=227 
5677: loss=0.110, reward_mean=0.360, reward_bound=0.342, batch=229 
5678: loss=0.111, reward_mean=0.500, reward_bound=0.349, batch=229 
5679: loss=0.110, reward_mean=0.430, reward_bound=0.387, batch=215 
5680: loss=0.111, reward_mean=0.430, reward_bound=0.396, batch=220 
5681: loss=0.112, reward_mean=0.480, reward_bound=0.430, batch=171 
5682: loss=0.111, reward_mean=0.420, reward_bound=0.098, batch=189 
5683: loss=0.118, reward_mean=0.350, reward_bound=0.067, batch=202 
5684: loss=0.117, reward_mean=0.340, reward_bound=0.122, batch=208 
5685: loss=0.114, reward_mean=0.400, reward_bound=0.150, batch=214 
5686: loss=0.114, reward_mean=0.460, reward_bound=0.185, batch=218 
5687: loss=0.118, reward_mean=0.380, reward_bound=0.206, batch=218 
5688: loss=0.112, reward_mean=0.420, reward_bound=0.229, batch=219 
5689: loss=0.113, reward_mean=0.430, reward_bound=0.254, batch=218 
5690: loss=0.114, reward_mean=0.450, reward_bound=0.282, batch=216 
5691: loss=0.116, reward_mean=0.370, reward_bound=0.298, batch=221 
5692: loss=0.111, reward_mean=0.530, reward_bound=0.314, batch=223 
5693: loss=0.109, reward_mean=0.440, reward_bound=0.349, batch=218 
5694: loss=0.108, reward_mean=0.410, reward_bound=0.286, batch=222 
5695: loss=0.109, reward_mean=0.390, reward_bound=0.314, batch=223 
5696: loss=0.109, reward_mean=0.430, reward_bound=0.335, batch=226 
5697: loss=0.109, reward_mean=0.440, reward_bound=0.349, batch=227 
5698: loss=0.109, reward_mean=0.420, reward_bound=0.387, batch=211 
5699: loss=0.106, reward_mean=0.430, reward_bound=0.282, batch=217 
5700: loss=0.105, reward_mean=0.380, reward_bound=0.373, batch=222 
5701: loss=0.107, reward_mean=0.360, reward_bound=0.387, batch=219 
5702: loss=0.106, reward_mean=0.430, reward_bound=0.387, batch=220 
5703: loss=0.106, reward_mean=0.480, reward_bound=0.304, batch=224 
5704: loss=0.106, reward_mean=0.390, reward_bound=0.311, batch=227 
5705: loss=0.107, reward_mean=0.390, reward_bound=0.349, batch=228 
5706: loss=0.107, reward_mean=0.440, reward_bound=0.387, batch=228 
5707: loss=0.107, reward_mean=0.550, reward_bound=0.317, batch=229 
5708: loss=0.107, reward_mean=0.530, reward_bound=0.405, batch=230 
5709: loss=0.108, reward_mean=0.430, reward_bound=0.418, batch=231 
5710: loss=0.110, reward_mean=0.460, reward_bound=0.430, batch=208 
5711: loss=0.112, reward_mean=0.440, reward_bound=0.314, batch=214 
5712: loss=0.112, reward_mean=0.490, reward_bound=0.254, batch=219 
5713: loss=0.116, reward_mean=0.380, reward_bound=0.282, batch=221 
5714: loss=0.113, reward_mean=0.510, reward_bound=0.349, batch=215 
5715: loss=0.111, reward_mean=0.380, reward_bound=0.314, batch=219 
5716: loss=0.112, reward_mean=0.450, reward_bound=0.328, batch=223 
5717: loss=0.116, reward_mean=0.480, reward_bound=0.372, batch=226 
5718: loss=0.116, reward_mean=0.410, reward_bound=0.321, batch=228 
5719: loss=0.116, reward_mean=0.470, reward_bound=0.353, batch=229 
5720: loss=0.115, reward_mean=0.410, reward_bound=0.387, batch=224 
5721: loss=0.118, reward_mean=0.420, reward_bound=0.345, batch=227 
5722: loss=0.116, reward_mean=0.330, reward_bound=0.380, batch=229 
5723: loss=0.116, reward_mean=0.460, reward_bound=0.282, batch=229 
5724: loss=0.115, reward_mean=0.490, reward_bound=0.387, batch=228 
5725: loss=0.114, reward_mean=0.460, reward_bound=0.430, batch=221 
5726: loss=0.114, reward_mean=0.430, reward_bound=0.314, batch=224 
5727: loss=0.113, reward_mean=0.450, reward_bound=0.311, batch=227 
5728: loss=0.113, reward_mean=0.420, reward_bound=0.349, batch=226 
5729: loss=0.115, reward_mean=0.420, reward_bound=0.409, batch=228 
5730: loss=0.116, reward_mean=0.380, reward_bound=0.357, batch=229 
5731: loss=0.116, reward_mean=0.470, reward_bound=0.430, batch=227 
5732: loss=0.109, reward_mean=0.390, reward_bound=0.478, batch=147 
5733: loss=0.122, reward_mean=0.490, reward_bound=0.070, batch=173 
5734: loss=0.124, reward_mean=0.480, reward_bound=0.109, batch=190 
5735: loss=0.123, reward_mean=0.310, reward_bound=0.131, batch=203 
5736: loss=0.119, reward_mean=0.440, reward_bound=0.150, batch=207 
5737: loss=0.119, reward_mean=0.430, reward_bound=0.167, batch=209 
5738: loss=0.117, reward_mean=0.400, reward_bound=0.185, batch=214 
5739: loss=0.112, reward_mean=0.500, reward_bound=0.206, batch=211 
5740: loss=0.114, reward_mean=0.410, reward_bound=0.229, batch=213 
5741: loss=0.114, reward_mean=0.320, reward_bound=0.220, batch=219 
5742: loss=0.117, reward_mean=0.460, reward_bound=0.254, batch=209 
5743: loss=0.118, reward_mean=0.480, reward_bound=0.229, batch=213 
5744: loss=0.120, reward_mean=0.470, reward_bound=0.206, batch=217 
5745: loss=0.116, reward_mean=0.400, reward_bound=0.282, batch=210 
5746: loss=0.115, reward_mean=0.440, reward_bound=0.274, batch=217 
5747: loss=0.114, reward_mean=0.400, reward_bound=0.282, batch=218 
5748: loss=0.110, reward_mean=0.430, reward_bound=0.314, batch=208 
5749: loss=0.110, reward_mean=0.410, reward_bound=0.208, batch=215 
5750: loss=0.116, reward_mean=0.480, reward_bound=0.254, batch=219 
5751: loss=0.114, reward_mean=0.510, reward_bound=0.328, batch=223 
5752: loss=0.107, reward_mean=0.420, reward_bound=0.349, batch=205 
5753: loss=0.109, reward_mean=0.430, reward_bound=0.189, batch=213 
5754: loss=0.112, reward_mean=0.440, reward_bound=0.254, batch=216 
5755: loss=0.115, reward_mean=0.360, reward_bound=0.150, batch=220 
5756: loss=0.113, reward_mean=0.420, reward_bound=0.175, batch=224 
5757: loss=0.112, reward_mean=0.400, reward_bound=0.254, batch=224 
5758: loss=0.110, reward_mean=0.400, reward_bound=0.282, batch=224 
5759: loss=0.108, reward_mean=0.510, reward_bound=0.314, batch=225 
5760: loss=0.108, reward_mean=0.350, reward_bound=0.349, batch=217 
5761: loss=0.106, reward_mean=0.430, reward_bound=0.254, batch=221 
5762: loss=0.108, reward_mean=0.380, reward_bound=0.349, batch=222 
5763: loss=0.104, reward_mean=0.360, reward_bound=0.387, batch=198 
5764: loss=0.102, reward_mean=0.370, reward_bound=0.187, batch=208 
5765: loss=0.102, reward_mean=0.450, reward_bound=0.257, batch=215 
5766: loss=0.102, reward_mean=0.540, reward_bound=0.282, batch=218 
5767: loss=0.101, reward_mean=0.470, reward_bound=0.314, batch=220 
5768: loss=0.100, reward_mean=0.400, reward_bound=0.282, batch=222 
5769: loss=0.101, reward_mean=0.530, reward_bound=0.349, batch=218 
5770: loss=0.101, reward_mean=0.340, reward_bound=0.190, batch=222 
5771: loss=0.100, reward_mean=0.430, reward_bound=0.282, batch=224 
5772: loss=0.102, reward_mean=0.400, reward_bound=0.314, batch=225 
5773: loss=0.102, reward_mean=0.350, reward_bound=0.356, batch=227 
5774: loss=0.102, reward_mean=0.420, reward_bound=0.373, batch=229 
5775: loss=0.104, reward_mean=0.380, reward_bound=0.387, batch=219 
5776: loss=0.104, reward_mean=0.520, reward_bound=0.282, batch=222 
5777: loss=0.104, reward_mean=0.440, reward_bound=0.282, batch=223 
5778: loss=0.103, reward_mean=0.420, reward_bound=0.314, batch=225 
5779: loss=0.100, reward_mean=0.500, reward_bound=0.430, batch=189 
5780: loss=0.099, reward_mean=0.420, reward_bound=0.182, batch=202 
5781: loss=0.106, reward_mean=0.460, reward_bound=0.236, batch=211 
5782: loss=0.103, reward_mean=0.520, reward_bound=0.254, batch=214 
5783: loss=0.103, reward_mean=0.470, reward_bound=0.252, batch=220 
5784: loss=0.104, reward_mean=0.410, reward_bound=0.254, batch=223 
5785: loss=0.105, reward_mean=0.470, reward_bound=0.301, batch=226 
5786: loss=0.101, reward_mean=0.440, reward_bound=0.314, batch=220 
5787: loss=0.100, reward_mean=0.360, reward_bound=0.304, batch=224 
5788: loss=0.103, reward_mean=0.490, reward_bound=0.349, batch=218 
5789: loss=0.104, reward_mean=0.370, reward_bound=0.282, batch=221 
5790: loss=0.103, reward_mean=0.340, reward_bound=0.229, batch=222 
5791: loss=0.104, reward_mean=0.430, reward_bound=0.282, batch=224 
5792: loss=0.104, reward_mean=0.460, reward_bound=0.349, batch=223 
5793: loss=0.103, reward_mean=0.430, reward_bound=0.387, batch=213 
5794: loss=0.105, reward_mean=0.450, reward_bound=0.349, batch=217 
5795: loss=0.109, reward_mean=0.330, reward_bound=0.216, batch=222 
5796: loss=0.104, reward_mean=0.470, reward_bound=0.263, batch=225 
5797: loss=0.104, reward_mean=0.430, reward_bound=0.289, batch=227 
5798: loss=0.106, reward_mean=0.520, reward_bound=0.314, batch=227 
5799: loss=0.106, reward_mean=0.420, reward_bound=0.349, batch=228 
5800: loss=0.103, reward_mean=0.540, reward_bound=0.387, batch=224 
5801: loss=0.103, reward_mean=0.490, reward_bound=0.345, batch=227 
5802: loss=0.106, reward_mean=0.360, reward_bound=0.380, batch=229 
5803: loss=0.106, reward_mean=0.380, reward_bound=0.364, batch=230 
5804: loss=0.105, reward_mean=0.380, reward_bound=0.418, batch=231 
5805: loss=0.103, reward_mean=0.350, reward_bound=0.430, batch=214 
5806: loss=0.101, reward_mean=0.480, reward_bound=0.280, batch=220 
5807: loss=0.104, reward_mean=0.580, reward_bound=0.376, batch=224 
5808: loss=0.103, reward_mean=0.430, reward_bound=0.387, batch=224 
5809: loss=0.103, reward_mean=0.380, reward_bound=0.430, batch=223 
5810: loss=0.102, reward_mean=0.490, reward_bound=0.314, batch=225 
5811: loss=0.104, reward_mean=0.480, reward_bound=0.440, batch=227 
5812: loss=0.103, reward_mean=0.450, reward_bound=0.469, batch=229 
5813: loss=0.103, reward_mean=0.380, reward_bound=0.381, batch=230 
5814: loss=0.104, reward_mean=0.440, reward_bound=0.406, batch=231 
5815: loss=0.104, reward_mean=0.500, reward_bound=0.430, batch=230 
5816: loss=0.104, reward_mean=0.350, reward_bound=0.464, batch=231 
5817: loss=0.104, reward_mean=0.430, reward_bound=0.478, batch=190 
5818: loss=0.104, reward_mean=0.480, reward_bound=0.229, batch=200 
5819: loss=0.103, reward_mean=0.400, reward_bound=0.254, batch=206 
5820: loss=0.105, reward_mean=0.470, reward_bound=0.268, batch=214 
5821: loss=0.104, reward_mean=0.500, reward_bound=0.282, batch=219 
5822: loss=0.105, reward_mean=0.410, reward_bound=0.314, batch=212 
5823: loss=0.108, reward_mean=0.380, reward_bound=0.282, batch=217 
5824: loss=0.113, reward_mean=0.470, reward_bound=0.314, batch=221 
5825: loss=0.112, reward_mean=0.460, reward_bound=0.254, batch=224 
5826: loss=0.112, reward_mean=0.400, reward_bound=0.349, batch=216 
5827: loss=0.111, reward_mean=0.470, reward_bound=0.349, batch=219 
5828: loss=0.109, reward_mean=0.480, reward_bound=0.343, batch=223 
5829: loss=0.109, reward_mean=0.490, reward_bound=0.372, batch=226 
5830: loss=0.109, reward_mean=0.470, reward_bound=0.368, batch=228 
5831: loss=0.108, reward_mean=0.410, reward_bound=0.353, batch=229 
5832: loss=0.106, reward_mean=0.490, reward_bound=0.387, batch=221 
5833: loss=0.106, reward_mean=0.500, reward_bound=0.349, batch=224 
5834: loss=0.109, reward_mean=0.410, reward_bound=0.384, batch=227 
5835: loss=0.105, reward_mean=0.500, reward_bound=0.387, batch=227 
5836: loss=0.101, reward_mean=0.470, reward_bound=0.430, batch=213 
5837: loss=0.103, reward_mean=0.380, reward_bound=0.206, batch=218 
5838: loss=0.102, reward_mean=0.390, reward_bound=0.314, batch=221 
5839: loss=0.103, reward_mean=0.370, reward_bound=0.349, batch=221 
5840: loss=0.103, reward_mean=0.430, reward_bound=0.314, batch=224 
5841: loss=0.103, reward_mean=0.440, reward_bound=0.349, batch=225 
5842: loss=0.102, reward_mean=0.390, reward_bound=0.303, batch=227 
5843: loss=0.104, reward_mean=0.490, reward_bound=0.380, batch=229 
5844: loss=0.102, reward_mean=0.470, reward_bound=0.387, batch=225 
5845: loss=0.101, reward_mean=0.330, reward_bound=0.396, batch=227 
5846: loss=0.102, reward_mean=0.490, reward_bound=0.430, batch=221 
5847: loss=0.103, reward_mean=0.390, reward_bound=0.282, batch=222 
5848: loss=0.105, reward_mean=0.510, reward_bound=0.387, batch=224 
5849: loss=0.104, reward_mean=0.430, reward_bound=0.419, batch=227 
5850: loss=0.103, reward_mean=0.380, reward_bound=0.308, batch=229 
5851: loss=0.104, reward_mean=0.460, reward_bound=0.349, batch=229 
5852: loss=0.104, reward_mean=0.520, reward_bound=0.430, batch=227 
5853: loss=0.104, reward_mean=0.430, reward_bound=0.387, batch=228 
5854: loss=0.104, reward_mean=0.490, reward_bound=0.478, batch=232 
5855: loss=0.101, reward_mean=0.420, reward_bound=0.478, batch=208 
5856: loss=0.100, reward_mean=0.410, reward_bound=0.264, batch=215 
5857: loss=0.100, reward_mean=0.460, reward_bound=0.234, batch=220 
5858: loss=0.103, reward_mean=0.450, reward_bound=0.304, batch=224 
5859: loss=0.103, reward_mean=0.430, reward_bound=0.308, batch=227 
5860: loss=0.101, reward_mean=0.430, reward_bound=0.342, batch=229 
5861: loss=0.105, reward_mean=0.430, reward_bound=0.349, batch=227 
5862: loss=0.105, reward_mean=0.460, reward_bound=0.387, batch=223 
5863: loss=0.106, reward_mean=0.430, reward_bound=0.314, batch=225 
5864: loss=0.104, reward_mean=0.410, reward_bound=0.396, batch=227 
5865: loss=0.103, reward_mean=0.460, reward_bound=0.342, batch=229 
5866: loss=0.104, reward_mean=0.450, reward_bound=0.381, batch=230 
5867: loss=0.101, reward_mean=0.400, reward_bound=0.430, batch=225 
5868: loss=0.100, reward_mean=0.550, reward_bound=0.440, batch=227 
5869: loss=0.099, reward_mean=0.490, reward_bound=0.469, batch=229 
5870: loss=0.099, reward_mean=0.440, reward_bound=0.430, batch=229 
5871: loss=0.099, reward_mean=0.410, reward_bound=0.381, batch=230 
5872: loss=0.099, reward_mean=0.330, reward_bound=0.430, batch=230 
5873: loss=0.100, reward_mean=0.480, reward_bound=0.418, batch=231 
5874: loss=0.100, reward_mean=0.560, reward_bound=0.349, batch=231 
5875: loss=0.099, reward_mean=0.460, reward_bound=0.430, batch=231 
5876: loss=0.099, reward_mean=0.420, reward_bound=0.430, batch=231 
5877: loss=0.098, reward_mean=0.400, reward_bound=0.478, batch=217 
5878: loss=0.100, reward_mean=0.450, reward_bound=0.249, batch=222 
5879: loss=0.100, reward_mean=0.410, reward_bound=0.254, batch=224 
5880: loss=0.101, reward_mean=0.450, reward_bound=0.311, batch=227 
5881: loss=0.097, reward_mean=0.390, reward_bound=0.314, batch=226 
5882: loss=0.098, reward_mean=0.380, reward_bound=0.368, batch=228 
5883: loss=0.098, reward_mean=0.450, reward_bound=0.349, batch=228 
5884: loss=0.100, reward_mean=0.480, reward_bound=0.387, batch=227 
5885: loss=0.101, reward_mean=0.390, reward_bound=0.430, batch=226 
5886: loss=0.100, reward_mean=0.440, reward_bound=0.409, batch=228 
5887: loss=0.100, reward_mean=0.420, reward_bound=0.357, batch=229 
5888: loss=0.101, reward_mean=0.420, reward_bound=0.430, batch=229 
5889: loss=0.101, reward_mean=0.420, reward_bound=0.405, batch=230 
5890: loss=0.100, reward_mean=0.450, reward_bound=0.406, batch=231 
5891: loss=0.101, reward_mean=0.470, reward_bound=0.430, batch=230 
5892: loss=0.100, reward_mean=0.490, reward_bound=0.451, batch=231 
5893: loss=0.100, reward_mean=0.480, reward_bound=0.430, batch=231 
5894: loss=0.100, reward_mean=0.360, reward_bound=0.430, batch=231 
5895: loss=0.097, reward_mean=0.470, reward_bound=0.478, batch=222 
5896: loss=0.098, reward_mean=0.560, reward_bound=0.415, batch=225 
5897: loss=0.099, reward_mean=0.380, reward_bound=0.396, batch=227 
5898: loss=0.099, reward_mean=0.450, reward_bound=0.422, batch=229 
5899: loss=0.098, reward_mean=0.370, reward_bound=0.381, batch=230 
5900: loss=0.099, reward_mean=0.440, reward_bound=0.418, batch=231 
5901: loss=0.098, reward_mean=0.350, reward_bound=0.430, batch=230 
5902: loss=0.097, reward_mean=0.460, reward_bound=0.478, batch=225 
5903: loss=0.098, reward_mean=0.420, reward_bound=0.440, batch=227 
5904: loss=0.098, reward_mean=0.440, reward_bound=0.349, batch=228 
5905: loss=0.098, reward_mean=0.410, reward_bound=0.435, batch=229 
5906: loss=0.098, reward_mean=0.500, reward_bound=0.424, batch=230 
5907: loss=0.096, reward_mean=0.490, reward_bound=0.478, batch=229 
5908: loss=0.095, reward_mean=0.400, reward_bound=0.405, batch=230 
5909: loss=0.095, reward_mean=0.550, reward_bound=0.418, batch=231 
5910: loss=0.096, reward_mean=0.440, reward_bound=0.478, batch=230 
5911: loss=0.097, reward_mean=0.480, reward_bound=0.464, batch=231 
5913: loss=0.126, reward_mean=0.450, reward_bound=0.000, batch=45 
5914: loss=0.128, reward_mean=0.440, reward_bound=0.000, batch=89 
5915: loss=0.122, reward_mean=0.410, reward_bound=0.000, batch=130 
5916: loss=0.125, reward_mean=0.560, reward_bound=0.004, batch=161 
5917: loss=0.128, reward_mean=0.470, reward_bound=0.013, batch=178 
5918: loss=0.122, reward_mean=0.370, reward_bound=0.018, batch=194 
5919: loss=0.123, reward_mean=0.520, reward_bound=0.038, batch=199 
5920: loss=0.123, reward_mean=0.430, reward_bound=0.052, batch=202 
5921: loss=0.124, reward_mean=0.390, reward_bound=0.065, batch=208 
5922: loss=0.126, reward_mean=0.530, reward_bound=0.089, batch=209 
5923: loss=0.121, reward_mean=0.480, reward_bound=0.109, batch=214 
5924: loss=0.123, reward_mean=0.510, reward_bound=0.122, batch=217 
5925: loss=0.121, reward_mean=0.450, reward_bound=0.135, batch=214 
5926: loss=0.121, reward_mean=0.540, reward_bound=0.150, batch=214 
5927: loss=0.120, reward_mean=0.360, reward_bound=0.167, batch=200 
5928: loss=0.118, reward_mean=0.530, reward_bound=0.185, batch=193 
5929: loss=0.119, reward_mean=0.500, reward_bound=0.206, batch=181 
5930: loss=0.119, reward_mean=0.460, reward_bound=0.229, batch=166 
5931: loss=0.115, reward_mean=0.490, reward_bound=0.098, batch=183 
5932: loss=0.114, reward_mean=0.490, reward_bound=0.135, batch=196 
5933: loss=0.111, reward_mean=0.500, reward_bound=0.150, batch=205 
5934: loss=0.114, reward_mean=0.430, reward_bound=0.185, batch=209 
5935: loss=0.116, reward_mean=0.490, reward_bound=0.229, batch=209 
5936: loss=0.116, reward_mean=0.490, reward_bound=0.254, batch=174 
5937: loss=0.118, reward_mean=0.440, reward_bound=0.107, batch=192 
5938: loss=0.120, reward_mean=0.510, reward_bound=0.135, batch=203 
5939: loss=0.114, reward_mean=0.510, reward_bound=0.167, batch=211 
5940: loss=0.114, reward_mean=0.440, reward_bound=0.185, batch=216 
5941: loss=0.119, reward_mean=0.490, reward_bound=0.229, batch=215 
5942: loss=0.118, reward_mean=0.500, reward_bound=0.254, batch=212 
5943: loss=0.120, reward_mean=0.440, reward_bound=0.282, batch=175 
5944: loss=0.120, reward_mean=0.370, reward_bound=0.056, batch=192 
5945: loss=0.117, reward_mean=0.510, reward_bound=0.109, batch=203 
5946: loss=0.118, reward_mean=0.490, reward_bound=0.150, batch=210 
5947: loss=0.115, reward_mean=0.510, reward_bound=0.180, batch=217 
5948: loss=0.117, reward_mean=0.480, reward_bound=0.185, batch=221 
5949: loss=0.117, reward_mean=0.470, reward_bound=0.206, batch=220 
5950: loss=0.116, reward_mean=0.520, reward_bound=0.247, batch=224 
5951: loss=0.114, reward_mean=0.390, reward_bound=0.254, batch=225 
5952: loss=0.115, reward_mean=0.460, reward_bound=0.282, batch=224 
5953: loss=0.109, reward_mean=0.450, reward_bound=0.314, batch=175 
5954: loss=0.116, reward_mean=0.530, reward_bound=0.189, batch=192 
5955: loss=0.115, reward_mean=0.490, reward_bound=0.179, batch=204 
5956: loss=0.115, reward_mean=0.420, reward_bound=0.206, batch=207 
5957: loss=0.114, reward_mean=0.470, reward_bound=0.229, batch=211 
5958: loss=0.111, reward_mean=0.480, reward_bound=0.254, batch=212 
5959: loss=0.112, reward_mean=0.460, reward_bound=0.254, batch=217 
5960: loss=0.110, reward_mean=0.510, reward_bound=0.282, batch=212 
5961: loss=0.111, reward_mean=0.470, reward_bound=0.314, batch=207 
5962: loss=0.111, reward_mean=0.420, reward_bound=0.254, batch=213 
5963: loss=0.115, reward_mean=0.350, reward_bound=0.301, batch=219 
5964: loss=0.113, reward_mean=0.520, reward_bound=0.314, batch=219 
5965: loss=0.114, reward_mean=0.430, reward_bound=0.254, batch=221 
5966: loss=0.114, reward_mean=0.520, reward_bound=0.314, batch=223 
5967: loss=0.114, reward_mean=0.480, reward_bound=0.314, batch=225 
5968: loss=0.114, reward_mean=0.480, reward_bound=0.296, batch=227 
5969: loss=0.114, reward_mean=0.400, reward_bound=0.342, batch=229 
5970: loss=0.106, reward_mean=0.520, reward_bound=0.349, batch=155 
5971: loss=0.112, reward_mean=0.520, reward_bound=0.112, batch=178 
5972: loss=0.109, reward_mean=0.460, reward_bound=0.122, batch=192 
5973: loss=0.108, reward_mean=0.400, reward_bound=0.126, batch=204 
5974: loss=0.110, reward_mean=0.450, reward_bound=0.150, batch=209 
5975: loss=0.111, reward_mean=0.400, reward_bound=0.174, batch=216 
5976: loss=0.110, reward_mean=0.460, reward_bound=0.185, batch=218 
5977: loss=0.105, reward_mean=0.460, reward_bound=0.206, batch=221 
5978: loss=0.105, reward_mean=0.440, reward_bound=0.229, batch=220 
5979: loss=0.103, reward_mean=0.460, reward_bound=0.254, batch=216 
5980: loss=0.102, reward_mean=0.480, reward_bound=0.229, batch=219 
5981: loss=0.102, reward_mean=0.430, reward_bound=0.282, batch=210 
5982: loss=0.102, reward_mean=0.520, reward_bound=0.314, batch=206 
5983: loss=0.102, reward_mean=0.440, reward_bound=0.206, batch=212 
5984: loss=0.104, reward_mean=0.510, reward_bound=0.282, batch=217 
5985: loss=0.106, reward_mean=0.500, reward_bound=0.342, batch=222 
5986: loss=0.104, reward_mean=0.480, reward_bound=0.349, batch=201 
5987: loss=0.103, reward_mean=0.520, reward_bound=0.254, batch=209 
5988: loss=0.102, reward_mean=0.530, reward_bound=0.314, batch=210 
5989: loss=0.102, reward_mean=0.440, reward_bound=0.222, batch=217 
5990: loss=0.102, reward_mean=0.450, reward_bound=0.282, batch=220 
5991: loss=0.103, reward_mean=0.470, reward_bound=0.296, batch=224 
5992: loss=0.102, reward_mean=0.490, reward_bound=0.282, batch=225 
5993: loss=0.103, reward_mean=0.460, reward_bound=0.314, batch=221 
5994: loss=0.107, reward_mean=0.530, reward_bound=0.349, batch=223 
5995: loss=0.115, reward_mean=0.490, reward_bound=0.387, batch=154 
5996: loss=0.107, reward_mean=0.450, reward_bound=0.057, batch=178 
5997: loss=0.108, reward_mean=0.410, reward_bound=0.109, batch=193 
5998: loss=0.111, reward_mean=0.510, reward_bound=0.150, batch=202 
5999: loss=0.110, reward_mean=0.480, reward_bound=0.167, batch=205 
6000: loss=0.110, reward_mean=0.550, reward_bound=0.185, batch=212 
6001: loss=0.112, reward_mean=0.450, reward_bound=0.229, batch=213 
6002: loss=0.110, reward_mean=0.550, reward_bound=0.254, batch=209 
6003: loss=0.112, reward_mean=0.470, reward_bound=0.206, batch=215 
6004: loss=0.110, reward_mean=0.510, reward_bound=0.254, batch=217 
6005: loss=0.112, reward_mean=0.510, reward_bound=0.282, batch=205 
6006: loss=0.112, reward_mean=0.490, reward_bound=0.205, batch=213 
6007: loss=0.115, reward_mean=0.480, reward_bound=0.220, batch=219 
6008: loss=0.117, reward_mean=0.440, reward_bound=0.182, batch=223 
6009: loss=0.114, reward_mean=0.460, reward_bound=0.254, batch=220 
6010: loss=0.112, reward_mean=0.440, reward_bound=0.282, batch=223 
6011: loss=0.112, reward_mean=0.480, reward_bound=0.314, batch=215 
6012: loss=0.114, reward_mean=0.360, reward_bound=0.349, batch=193 
6013: loss=0.115, reward_mean=0.530, reward_bound=0.150, batch=204 
6014: loss=0.112, reward_mean=0.420, reward_bound=0.185, batch=212 
6015: loss=0.114, reward_mean=0.380, reward_bound=0.206, batch=219 
6016: loss=0.111, reward_mean=0.480, reward_bound=0.229, batch=221 
6017: loss=0.111, reward_mean=0.430, reward_bound=0.229, batch=224 
6018: loss=0.116, reward_mean=0.460, reward_bound=0.254, batch=226 
6019: loss=0.115, reward_mean=0.440, reward_bound=0.282, batch=224 
6020: loss=0.114, reward_mean=0.420, reward_bound=0.314, batch=222 
6021: loss=0.114, reward_mean=0.480, reward_bound=0.349, batch=220 
6022: loss=0.113, reward_mean=0.440, reward_bound=0.329, batch=224 
6023: loss=0.114, reward_mean=0.520, reward_bound=0.349, batch=224 
6024: loss=0.115, reward_mean=0.430, reward_bound=0.345, batch=227 
6025: loss=0.116, reward_mean=0.490, reward_bound=0.349, batch=228 
6026: loss=0.115, reward_mean=0.440, reward_bound=0.387, batch=206 
6027: loss=0.115, reward_mean=0.420, reward_bound=0.186, batch=214 
6028: loss=0.119, reward_mean=0.390, reward_bound=0.254, batch=218 
6029: loss=0.121, reward_mean=0.520, reward_bound=0.231, batch=222 
6030: loss=0.120, reward_mean=0.520, reward_bound=0.292, batch=225 
6031: loss=0.121, reward_mean=0.430, reward_bound=0.314, batch=217 
6032: loss=0.120, reward_mean=0.430, reward_bound=0.224, batch=222 
6033: loss=0.120, reward_mean=0.400, reward_bound=0.229, batch=221 
6034: loss=0.120, reward_mean=0.530, reward_bound=0.349, batch=221 
6035: loss=0.122, reward_mean=0.460, reward_bound=0.314, batch=223 
6036: loss=0.124, reward_mean=0.450, reward_bound=0.322, batch=226 
6037: loss=0.122, reward_mean=0.520, reward_bound=0.349, batch=227 
6038: loss=0.122, reward_mean=0.390, reward_bound=0.308, batch=229 
6039: loss=0.120, reward_mean=0.370, reward_bound=0.387, batch=219 
6040: loss=0.120, reward_mean=0.460, reward_bound=0.278, batch=223 
6041: loss=0.121, reward_mean=0.340, reward_bound=0.301, batch=226 
6042: loss=0.119, reward_mean=0.440, reward_bound=0.331, batch=228 
6043: loss=0.120, reward_mean=0.390, reward_bound=0.387, batch=227 
6044: loss=0.120, reward_mean=0.430, reward_bound=0.422, batch=229 
6045: loss=0.119, reward_mean=0.440, reward_bound=0.430, batch=123 
6046: loss=0.134, reward_mean=0.510, reward_bound=0.048, batch=156 
6047: loss=0.136, reward_mean=0.420, reward_bound=0.047, batch=179 
6048: loss=0.130, reward_mean=0.380, reward_bound=0.061, batch=195 
6049: loss=0.133, reward_mean=0.450, reward_bound=0.089, batch=208 
6050: loss=0.133, reward_mean=0.460, reward_bound=0.122, batch=213 
6051: loss=0.133, reward_mean=0.420, reward_bound=0.150, batch=212 
6052: loss=0.132, reward_mean=0.390, reward_bound=0.167, batch=210 
6053: loss=0.134, reward_mean=0.490, reward_bound=0.185, batch=208 
6054: loss=0.132, reward_mean=0.450, reward_bound=0.206, batch=211 
6055: loss=0.133, reward_mean=0.390, reward_bound=0.229, batch=214 
6056: loss=0.133, reward_mean=0.510, reward_bound=0.254, batch=198 
6057: loss=0.134, reward_mean=0.550, reward_bound=0.229, batch=206 
6058: loss=0.134, reward_mean=0.550, reward_bound=0.241, batch=214 
6059: loss=0.132, reward_mean=0.450, reward_bound=0.252, batch=220 
6060: loss=0.131, reward_mean=0.320, reward_bound=0.254, batch=223 
6061: loss=0.124, reward_mean=0.340, reward_bound=0.282, batch=204 
6062: loss=0.125, reward_mean=0.380, reward_bound=0.204, batch=213 
6063: loss=0.126, reward_mean=0.490, reward_bound=0.244, batch=219 
6064: loss=0.125, reward_mean=0.410, reward_bound=0.314, batch=199 
6065: loss=0.121, reward_mean=0.430, reward_bound=0.229, batch=207 
6066: loss=0.124, reward_mean=0.440, reward_bound=0.254, batch=213 
6067: loss=0.123, reward_mean=0.440, reward_bound=0.244, batch=219 
6068: loss=0.126, reward_mean=0.420, reward_bound=0.282, batch=222 
6069: loss=0.125, reward_mean=0.550, reward_bound=0.314, batch=224 
6070: loss=0.124, reward_mean=0.430, reward_bound=0.345, batch=227 
6071: loss=0.123, reward_mean=0.440, reward_bound=0.349, batch=203 
6072: loss=0.124, reward_mean=0.410, reward_bound=0.154, batch=212 
6073: loss=0.123, reward_mean=0.450, reward_bound=0.229, batch=217 
6074: loss=0.123, reward_mean=0.460, reward_bound=0.254, batch=220 
6075: loss=0.124, reward_mean=0.400, reward_bound=0.216, batch=224 
6076: loss=0.122, reward_mean=0.360, reward_bound=0.280, batch=227 
6077: loss=0.121, reward_mean=0.460, reward_bound=0.308, batch=229 
6078: loss=0.124, reward_mean=0.400, reward_bound=0.314, batch=223 
6079: loss=0.122, reward_mean=0.400, reward_bound=0.280, batch=226 
6080: loss=0.123, reward_mean=0.400, reward_bound=0.349, batch=222 
6081: loss=0.123, reward_mean=0.490, reward_bound=0.314, batch=224 
6082: loss=0.123, reward_mean=0.410, reward_bound=0.308, batch=227 
6083: loss=0.122, reward_mean=0.350, reward_bound=0.380, batch=229 
6084: loss=0.125, reward_mean=0.500, reward_bound=0.387, batch=194 
6085: loss=0.126, reward_mean=0.410, reward_bound=0.204, batch=206 
6086: loss=0.125, reward_mean=0.430, reward_bound=0.186, batch=214 
6087: loss=0.128, reward_mean=0.590, reward_bound=0.229, batch=215 
6088: loss=0.127, reward_mean=0.400, reward_bound=0.254, batch=218 
6089: loss=0.125, reward_mean=0.400, reward_bound=0.254, batch=221 
6090: loss=0.126, reward_mean=0.360, reward_bound=0.282, batch=222 
6091: loss=0.127, reward_mean=0.400, reward_bound=0.314, batch=221 
6092: loss=0.129, reward_mean=0.400, reward_bound=0.349, batch=215 
6093: loss=0.128, reward_mean=0.440, reward_bound=0.260, batch=220 
6094: loss=0.129, reward_mean=0.420, reward_bound=0.314, batch=222 
6095: loss=0.129, reward_mean=0.470, reward_bound=0.314, batch=224 
6096: loss=0.131, reward_mean=0.340, reward_bound=0.384, batch=227 
6097: loss=0.133, reward_mean=0.490, reward_bound=0.387, batch=225 
6098: loss=0.133, reward_mean=0.430, reward_bound=0.387, batch=226 
6099: loss=0.133, reward_mean=0.480, reward_bound=0.390, batch=228 
6100: loss=0.131, reward_mean=0.360, reward_bound=0.430, batch=181 
6101: loss=0.136, reward_mean=0.390, reward_bound=0.089, batch=196 
6102: loss=0.135, reward_mean=0.390, reward_bound=0.122, batch=206 
6103: loss=0.128, reward_mean=0.440, reward_bound=0.176, batch=214 
6104: loss=0.130, reward_mean=0.450, reward_bound=0.226, batch=220 
6105: loss=0.129, reward_mean=0.460, reward_bound=0.254, batch=214 
6106: loss=0.132, reward_mean=0.440, reward_bound=0.206, batch=219 
6107: loss=0.130, reward_mean=0.460, reward_bound=0.282, batch=219 
6108: loss=0.130, reward_mean=0.460, reward_bound=0.314, batch=216 
6109: loss=0.129, reward_mean=0.460, reward_bound=0.298, batch=221 
6110: loss=0.132, reward_mean=0.270, reward_bound=0.314, batch=222 
6111: loss=0.130, reward_mean=0.440, reward_bound=0.349, batch=206 
6112: loss=0.132, reward_mean=0.440, reward_bound=0.217, batch=214 
6113: loss=0.130, reward_mean=0.420, reward_bound=0.252, batch=220 
6114: loss=0.130, reward_mean=0.380, reward_bound=0.254, batch=223 
6115: loss=0.129, reward_mean=0.430, reward_bound=0.282, batch=223 
6116: loss=0.129, reward_mean=0.400, reward_bound=0.314, batch=224 
6117: loss=0.129, reward_mean=0.590, reward_bound=0.282, batch=226 
6118: loss=0.128, reward_mean=0.440, reward_bound=0.331, batch=228 
6119: loss=0.129, reward_mean=0.390, reward_bound=0.349, batch=223 
6120: loss=0.129, reward_mean=0.410, reward_bound=0.387, batch=216 
6121: loss=0.130, reward_mean=0.420, reward_bound=0.254, batch=220 
6122: loss=0.127, reward_mean=0.490, reward_bound=0.376, batch=224 
6123: loss=0.126, reward_mean=0.520, reward_bound=0.384, batch=227 
6124: loss=0.125, reward_mean=0.410, reward_bound=0.387, batch=226 
6125: loss=0.124, reward_mean=0.260, reward_bound=0.321, batch=228 
6126: loss=0.125, reward_mean=0.410, reward_bound=0.392, batch=229 
6127: loss=0.130, reward_mean=0.460, reward_bound=0.430, batch=206 
6128: loss=0.129, reward_mean=0.510, reward_bound=0.282, batch=213 
6129: loss=0.127, reward_mean=0.420, reward_bound=0.282, batch=218 
6130: loss=0.131, reward_mean=0.450, reward_bound=0.314, batch=218 
6131: loss=0.129, reward_mean=0.500, reward_bound=0.349, batch=217 
6132: loss=0.130, reward_mean=0.390, reward_bound=0.282, batch=220 
6133: loss=0.130, reward_mean=0.400, reward_bound=0.274, batch=224 
6134: loss=0.130, reward_mean=0.450, reward_bound=0.282, batch=225 
6135: loss=0.130, reward_mean=0.330, reward_bound=0.216, batch=227 
6136: loss=0.132, reward_mean=0.340, reward_bound=0.308, batch=229 
6137: loss=0.126, reward_mean=0.430, reward_bound=0.349, batch=227 
6138: loss=0.126, reward_mean=0.490, reward_bound=0.314, batch=228 
6139: loss=0.130, reward_mean=0.470, reward_bound=0.387, batch=223 
6140: loss=0.131, reward_mean=0.530, reward_bound=0.430, batch=214 
6141: loss=0.130, reward_mean=0.350, reward_bound=0.282, batch=219 
6142: loss=0.129, reward_mean=0.410, reward_bound=0.314, batch=222 
6143: loss=0.128, reward_mean=0.350, reward_bound=0.229, batch=224 
6144: loss=0.128, reward_mean=0.430, reward_bound=0.349, batch=225 
6145: loss=0.129, reward_mean=0.460, reward_bound=0.387, batch=225 
6146: loss=0.129, reward_mean=0.360, reward_bound=0.430, batch=222 
6147: loss=0.129, reward_mean=0.370, reward_bound=0.478, batch=88 
6148: loss=0.152, reward_mean=0.380, reward_bound=0.000, batch=126 
6149: loss=0.148, reward_mean=0.490, reward_bound=0.011, batch=158 
6150: loss=0.150, reward_mean=0.430, reward_bound=0.032, batch=180 
6151: loss=0.150, reward_mean=0.450, reward_bound=0.058, batch=193 
6152: loss=0.157, reward_mean=0.500, reward_bound=0.072, batch=201 
6153: loss=0.152, reward_mean=0.450, reward_bound=0.109, batch=208 
6154: loss=0.150, reward_mean=0.530, reward_bound=0.135, batch=209 
6155: loss=0.153, reward_mean=0.370, reward_bound=0.150, batch=205 
6156: loss=0.154, reward_mean=0.410, reward_bound=0.167, batch=201 
6157: loss=0.149, reward_mean=0.520, reward_bound=0.185, batch=195 
6158: loss=0.150, reward_mean=0.460, reward_bound=0.175, batch=206 
6159: loss=0.140, reward_mean=0.490, reward_bound=0.229, batch=195 
6160: loss=0.137, reward_mean=0.550, reward_bound=0.206, batch=205 
6161: loss=0.139, reward_mean=0.450, reward_bound=0.206, batch=211 
6162: loss=0.139, reward_mean=0.420, reward_bound=0.229, batch=213 
6163: loss=0.141, reward_mean=0.370, reward_bound=0.244, batch=219 
6164: loss=0.136, reward_mean=0.430, reward_bound=0.254, batch=209 
6165: loss=0.133, reward_mean=0.390, reward_bound=0.282, batch=187 
6166: loss=0.130, reward_mean=0.460, reward_bound=0.163, batch=201 
6167: loss=0.131, reward_mean=0.330, reward_bound=0.167, batch=206 
6168: loss=0.129, reward_mean=0.410, reward_bound=0.168, batch=214 
6169: loss=0.133, reward_mean=0.420, reward_bound=0.206, batch=218 
6170: loss=0.132, reward_mean=0.420, reward_bound=0.231, batch=222 
6171: loss=0.133, reward_mean=0.490, reward_bound=0.254, batch=224 
6172: loss=0.133, reward_mean=0.410, reward_bound=0.282, batch=220 
6173: loss=0.129, reward_mean=0.480, reward_bound=0.314, batch=195 
6174: loss=0.131, reward_mean=0.580, reward_bound=0.282, batch=205 
6175: loss=0.131, reward_mean=0.370, reward_bound=0.185, batch=212 
6176: loss=0.129, reward_mean=0.380, reward_bound=0.213, batch=218 
6177: loss=0.131, reward_mean=0.440, reward_bound=0.257, batch=222 
6178: loss=0.130, reward_mean=0.440, reward_bound=0.314, batch=216 
6179: loss=0.129, reward_mean=0.450, reward_bound=0.331, batch=221 
6180: loss=0.130, reward_mean=0.500, reward_bound=0.349, batch=199 
6181: loss=0.134, reward_mean=0.400, reward_bound=0.229, batch=208 
6182: loss=0.132, reward_mean=0.520, reward_bound=0.206, batch=214 
6183: loss=0.135, reward_mean=0.500, reward_bound=0.254, batch=217 
6184: loss=0.135, reward_mean=0.440, reward_bound=0.249, batch=222 
6185: loss=0.134, reward_mean=0.420, reward_bound=0.292, batch=225 
6186: loss=0.133, reward_mean=0.360, reward_bound=0.314, batch=224 
6187: loss=0.128, reward_mean=0.480, reward_bound=0.349, batch=218 
6188: loss=0.127, reward_mean=0.570, reward_bound=0.349, batch=221 
6189: loss=0.131, reward_mean=0.510, reward_bound=0.387, batch=174 
6190: loss=0.133, reward_mean=0.480, reward_bound=0.135, batch=190 
6191: loss=0.136, reward_mean=0.310, reward_bound=0.121, batch=203 
6192: loss=0.144, reward_mean=0.400, reward_bound=0.167, batch=207 
6193: loss=0.142, reward_mean=0.350, reward_bound=0.185, batch=214 
6194: loss=0.135, reward_mean=0.390, reward_bound=0.206, batch=218 
6195: loss=0.132, reward_mean=0.450, reward_bound=0.254, batch=213 
6196: loss=0.132, reward_mean=0.450, reward_bound=0.206, batch=218 
6197: loss=0.133, reward_mean=0.480, reward_bound=0.282, batch=212 
6198: loss=0.131, reward_mean=0.460, reward_bound=0.314, batch=208 
6199: loss=0.133, reward_mean=0.460, reward_bound=0.314, batch=214 
6200: loss=0.137, reward_mean=0.430, reward_bound=0.349, batch=211 
6201: loss=0.139, reward_mean=0.390, reward_bound=0.229, batch=216 
6202: loss=0.140, reward_mean=0.360, reward_bound=0.268, batch=221 
6203: loss=0.139, reward_mean=0.390, reward_bound=0.282, batch=223 
6204: loss=0.137, reward_mean=0.470, reward_bound=0.349, batch=220 
6205: loss=0.135, reward_mean=0.450, reward_bound=0.296, batch=224 
6206: loss=0.134, reward_mean=0.470, reward_bound=0.226, batch=227 
6207: loss=0.138, reward_mean=0.530, reward_bound=0.380, batch=229 
6208: loss=0.131, reward_mean=0.390, reward_bound=0.387, batch=212 
6209: loss=0.131, reward_mean=0.480, reward_bound=0.292, batch=218 
6210: loss=0.129, reward_mean=0.420, reward_bound=0.317, batch=222 
6211: loss=0.130, reward_mean=0.400, reward_bound=0.324, batch=225 
6212: loss=0.135, reward_mean=0.430, reward_bound=0.430, batch=164 
6213: loss=0.142, reward_mean=0.410, reward_bound=0.058, batch=185 
6214: loss=0.148, reward_mean=0.400, reward_bound=0.082, batch=199 
6215: loss=0.138, reward_mean=0.460, reward_bound=0.157, batch=209 
6216: loss=0.143, reward_mean=0.360, reward_bound=0.206, batch=211 
6217: loss=0.141, reward_mean=0.490, reward_bound=0.229, batch=215 
6218: loss=0.140, reward_mean=0.490, reward_bound=0.282, batch=214 
6219: loss=0.137, reward_mean=0.490, reward_bound=0.254, batch=219 
6220: loss=0.135, reward_mean=0.490, reward_bound=0.314, batch=212 
6221: loss=0.132, reward_mean=0.410, reward_bound=0.254, batch=218 
6222: loss=0.136, reward_mean=0.380, reward_bound=0.317, batch=222 
6223: loss=0.135, reward_mean=0.400, reward_bound=0.254, batch=224 
6224: loss=0.131, reward_mean=0.510, reward_bound=0.349, batch=210 
6225: loss=0.133, reward_mean=0.520, reward_bound=0.349, batch=215 
6226: loss=0.134, reward_mean=0.450, reward_bound=0.387, batch=201 
6227: loss=0.135, reward_mean=0.450, reward_bound=0.254, batch=210 
6228: loss=0.134, reward_mean=0.410, reward_bound=0.247, batch=217 
6229: loss=0.136, reward_mean=0.320, reward_bound=0.249, batch=222 
6230: loss=0.135, reward_mean=0.310, reward_bound=0.263, batch=225 
6231: loss=0.138, reward_mean=0.480, reward_bound=0.282, batch=223 
6232: loss=0.138, reward_mean=0.420, reward_bound=0.301, batch=226 
6233: loss=0.136, reward_mean=0.370, reward_bound=0.314, batch=225 
6234: loss=0.136, reward_mean=0.420, reward_bound=0.321, batch=227 
6235: loss=0.133, reward_mean=0.460, reward_bound=0.349, batch=222 
6236: loss=0.132, reward_mean=0.400, reward_bound=0.349, batch=224 
6237: loss=0.134, reward_mean=0.430, reward_bound=0.387, batch=220 
6238: loss=0.134, reward_mean=0.550, reward_bound=0.282, batch=223 
6239: loss=0.133, reward_mean=0.480, reward_bound=0.335, batch=226 
6240: loss=0.133, reward_mean=0.430, reward_bound=0.349, batch=226 
6241: loss=0.133, reward_mean=0.500, reward_bound=0.387, batch=227 
6242: loss=0.133, reward_mean=0.440, reward_bound=0.387, batch=228 
6243: loss=0.133, reward_mean=0.470, reward_bound=0.357, batch=229 
6244: loss=0.136, reward_mean=0.480, reward_bound=0.430, batch=198 
6245: loss=0.135, reward_mean=0.390, reward_bound=0.152, batch=208 
6246: loss=0.132, reward_mean=0.390, reward_bound=0.187, batch=215 
6247: loss=0.133, reward_mean=0.490, reward_bound=0.254, batch=219 
6248: loss=0.132, reward_mean=0.390, reward_bound=0.282, batch=220 
6249: loss=0.132, reward_mean=0.520, reward_bound=0.314, batch=219 
6250: loss=0.134, reward_mean=0.460, reward_bound=0.328, batch=223 
6251: loss=0.133, reward_mean=0.410, reward_bound=0.322, batch=226 
6252: loss=0.132, reward_mean=0.410, reward_bound=0.349, batch=220 
6253: loss=0.133, reward_mean=0.410, reward_bound=0.266, batch=224 
6254: loss=0.131, reward_mean=0.430, reward_bound=0.311, batch=227 
6255: loss=0.132, reward_mean=0.450, reward_bound=0.349, batch=228 
6256: loss=0.135, reward_mean=0.500, reward_bound=0.387, batch=224 
6257: loss=0.135, reward_mean=0.470, reward_bound=0.345, batch=227 
6258: loss=0.137, reward_mean=0.500, reward_bound=0.342, batch=229 
6259: loss=0.138, reward_mean=0.400, reward_bound=0.292, batch=230 
6260: loss=0.137, reward_mean=0.440, reward_bound=0.418, batch=231 
6261: loss=0.137, reward_mean=0.350, reward_bound=0.349, batch=231 
6262: loss=0.137, reward_mean=0.380, reward_bound=0.254, batch=231 
6263: loss=0.136, reward_mean=0.460, reward_bound=0.430, batch=213 
6264: loss=0.137, reward_mean=0.420, reward_bound=0.314, batch=218 
6265: loss=0.139, reward_mean=0.480, reward_bound=0.254, batch=221 
6266: loss=0.136, reward_mean=0.490, reward_bound=0.349, batch=223 
6267: loss=0.137, reward_mean=0.480, reward_bound=0.387, batch=224 
6268: loss=0.136, reward_mean=0.420, reward_bound=0.308, batch=227 
6269: loss=0.136, reward_mean=0.430, reward_bound=0.308, batch=229 
6270: loss=0.138, reward_mean=0.420, reward_bound=0.314, batch=229 
6271: loss=0.138, reward_mean=0.470, reward_bound=0.387, batch=228 
6272: loss=0.137, reward_mean=0.410, reward_bound=0.430, batch=224 
6273: loss=0.138, reward_mean=0.500, reward_bound=0.387, batch=226 
6274: loss=0.138, reward_mean=0.310, reward_bound=0.368, batch=228 
6275: loss=0.138, reward_mean=0.350, reward_bound=0.353, batch=229 
6276: loss=0.137, reward_mean=0.470, reward_bound=0.387, batch=228 
6277: loss=0.138, reward_mean=0.460, reward_bound=0.392, batch=229 
6278: loss=0.138, reward_mean=0.410, reward_bound=0.430, batch=226 
6279: loss=0.137, reward_mean=0.410, reward_bound=0.433, batch=228 
6280: loss=0.137, reward_mean=0.460, reward_bound=0.478, batch=230 
6281: loss=0.138, reward_mean=0.330, reward_bound=0.451, batch=231 
6282: loss=0.129, reward_mean=0.440, reward_bound=0.478, batch=142 
6283: loss=0.136, reward_mean=0.460, reward_bound=0.044, batch=169 
6284: loss=0.136, reward_mean=0.460, reward_bound=0.061, batch=188 
6285: loss=0.136, reward_mean=0.310, reward_bound=0.065, batch=201 
6286: loss=0.143, reward_mean=0.430, reward_bound=0.109, batch=208 
6287: loss=0.142, reward_mean=0.490, reward_bound=0.137, batch=215 
6288: loss=0.138, reward_mean=0.380, reward_bound=0.153, batch=220 
6289: loss=0.136, reward_mean=0.350, reward_bound=0.167, batch=221 
6290: loss=0.136, reward_mean=0.400, reward_bound=0.185, batch=223 
6291: loss=0.137, reward_mean=0.430, reward_bound=0.206, batch=220 
6292: loss=0.139, reward_mean=0.540, reward_bound=0.229, batch=219 
6293: loss=0.134, reward_mean=0.410, reward_bound=0.254, batch=213 
6294: loss=0.135, reward_mean=0.530, reward_bound=0.271, batch=219 
6295: loss=0.130, reward_mean=0.390, reward_bound=0.282, batch=201 
6296: loss=0.132, reward_mean=0.400, reward_bound=0.135, batch=210 
6297: loss=0.134, reward_mean=0.540, reward_bound=0.216, batch=217 
6298: loss=0.131, reward_mean=0.390, reward_bound=0.229, batch=221 
6299: loss=0.130, reward_mean=0.490, reward_bound=0.282, batch=220 
6300: loss=0.131, reward_mean=0.510, reward_bound=0.314, batch=202 
6301: loss=0.132, reward_mean=0.400, reward_bound=0.254, batch=210 
6302: loss=0.131, reward_mean=0.390, reward_bound=0.146, batch=217 
6303: loss=0.130, reward_mean=0.450, reward_bound=0.249, batch=222 
6304: loss=0.132, reward_mean=0.420, reward_bound=0.282, batch=218 
6305: loss=0.132, reward_mean=0.360, reward_bound=0.254, batch=221 
6306: loss=0.129, reward_mean=0.500, reward_bound=0.314, batch=223 
6307: loss=0.128, reward_mean=0.550, reward_bound=0.301, batch=226 
6308: loss=0.131, reward_mean=0.510, reward_bound=0.349, batch=195 
6309: loss=0.134, reward_mean=0.480, reward_bound=0.314, batch=203 
6310: loss=0.136, reward_mean=0.370, reward_bound=0.135, batch=211 
6311: loss=0.137, reward_mean=0.360, reward_bound=0.167, batch=217 
6312: loss=0.137, reward_mean=0.450, reward_bound=0.185, batch=220 
6313: loss=0.134, reward_mean=0.520, reward_bound=0.282, batch=220 
6314: loss=0.133, reward_mean=0.500, reward_bound=0.296, batch=224 
6315: loss=0.134, reward_mean=0.490, reward_bound=0.349, batch=220 
6316: loss=0.133, reward_mean=0.490, reward_bound=0.314, batch=223 
6317: loss=0.134, reward_mean=0.440, reward_bound=0.282, batch=225 
6318: loss=0.134, reward_mean=0.420, reward_bound=0.321, batch=227 
6319: loss=0.133, reward_mean=0.450, reward_bound=0.349, batch=228 
6320: loss=0.132, reward_mean=0.440, reward_bound=0.387, batch=204 
6321: loss=0.135, reward_mean=0.440, reward_bound=0.280, batch=213 
6322: loss=0.138, reward_mean=0.490, reward_bound=0.271, batch=219 
6323: loss=0.135, reward_mean=0.400, reward_bound=0.282, batch=222 
6324: loss=0.133, reward_mean=0.470, reward_bound=0.349, batch=221 
6325: loss=0.133, reward_mean=0.470, reward_bound=0.387, batch=216 
6326: loss=0.133, reward_mean=0.490, reward_bound=0.217, batch=221 
6327: loss=0.132, reward_mean=0.490, reward_bound=0.349, batch=222 
6328: loss=0.130, reward_mean=0.430, reward_bound=0.387, batch=224 
6329: loss=0.130, reward_mean=0.480, reward_bound=0.387, batch=225 
6330: loss=0.128, reward_mean=0.480, reward_bound=0.430, batch=186 
6331: loss=0.130, reward_mean=0.390, reward_bound=0.158, batch=200 
6332: loss=0.125, reward_mean=0.370, reward_bound=0.180, batch=210 
6333: loss=0.129, reward_mean=0.430, reward_bound=0.200, batch=217 
6334: loss=0.132, reward_mean=0.390, reward_bound=0.206, batch=221 
6335: loss=0.133, reward_mean=0.440, reward_bound=0.254, batch=218 
6336: loss=0.137, reward_mean=0.400, reward_bound=0.282, batch=221 
6337: loss=0.138, reward_mean=0.350, reward_bound=0.314, batch=217 
6338: loss=0.141, reward_mean=0.400, reward_bound=0.308, batch=222 
6339: loss=0.139, reward_mean=0.450, reward_bound=0.314, batch=224 
6340: loss=0.137, reward_mean=0.460, reward_bound=0.349, batch=215 
6341: loss=0.138, reward_mean=0.490, reward_bound=0.289, batch=220 
6342: loss=0.138, reward_mean=0.520, reward_bound=0.349, batch=221 
6343: loss=0.139, reward_mean=0.540, reward_bound=0.349, batch=224 
6344: loss=0.141, reward_mean=0.350, reward_bound=0.380, batch=227 
6345: loss=0.140, reward_mean=0.420, reward_bound=0.361, batch=229 
6346: loss=0.137, reward_mean=0.430, reward_bound=0.387, batch=216 
6347: loss=0.131, reward_mean=0.450, reward_bound=0.430, batch=198 
6348: loss=0.131, reward_mean=0.390, reward_bound=0.090, batch=208 
6349: loss=0.132, reward_mean=0.440, reward_bound=0.208, batch=215 
6350: loss=0.136, reward_mean=0.440, reward_bound=0.282, batch=216 
6351: loss=0.136, reward_mean=0.410, reward_bound=0.314, batch=215 
6352: loss=0.133, reward_mean=0.310, reward_bound=0.260, batch=220 
6353: loss=0.134, reward_mean=0.460, reward_bound=0.247, batch=224 
6354: loss=0.134, reward_mean=0.440, reward_bound=0.254, batch=226 
6355: loss=0.134, reward_mean=0.250, reward_bound=0.282, batch=227 
6356: loss=0.135, reward_mean=0.380, reward_bound=0.342, batch=229 
6357: loss=0.131, reward_mean=0.530, reward_bound=0.349, batch=220 
6358: loss=0.133, reward_mean=0.410, reward_bound=0.349, batch=223 
6359: loss=0.132, reward_mean=0.420, reward_bound=0.301, batch=226 
6360: loss=0.132, reward_mean=0.370, reward_bound=0.349, batch=227 
6361: loss=0.132, reward_mean=0.420, reward_bound=0.349, batch=228 
6362: loss=0.132, reward_mean=0.450, reward_bound=0.387, batch=222 
6363: loss=0.132, reward_mean=0.620, reward_bound=0.400, batch=225 
6364: loss=0.129, reward_mean=0.420, reward_bound=0.430, batch=217 
6365: loss=0.131, reward_mean=0.410, reward_bound=0.349, batch=220 
6366: loss=0.130, reward_mean=0.440, reward_bound=0.349, batch=223 
6367: loss=0.129, reward_mean=0.400, reward_bound=0.387, batch=223 
6368: loss=0.130, reward_mean=0.470, reward_bound=0.387, batch=225 
6369: loss=0.129, reward_mean=0.380, reward_bound=0.387, batch=226 
6370: loss=0.129, reward_mean=0.490, reward_bound=0.409, batch=228 
6371: loss=0.128, reward_mean=0.430, reward_bound=0.392, batch=229 
6372: loss=0.128, reward_mean=0.370, reward_bound=0.430, batch=226 
6373: loss=0.127, reward_mean=0.440, reward_bound=0.380, batch=228 
6374: loss=0.127, reward_mean=0.430, reward_bound=0.435, batch=229 
6375: loss=0.127, reward_mean=0.490, reward_bound=0.405, batch=230 
6376: loss=0.127, reward_mean=0.430, reward_bound=0.430, batch=230 
6377: loss=0.127, reward_mean=0.410, reward_bound=0.464, batch=231 
6378: loss=0.132, reward_mean=0.510, reward_bound=0.478, batch=177 
6379: loss=0.132, reward_mean=0.430, reward_bound=0.063, batch=194 
6380: loss=0.133, reward_mean=0.440, reward_bound=0.109, batch=205 
6381: loss=0.133, reward_mean=0.440, reward_bound=0.135, batch=210 
6382: loss=0.140, reward_mean=0.390, reward_bound=0.162, batch=217 
6383: loss=0.143, reward_mean=0.450, reward_bound=0.167, batch=220 
6384: loss=0.141, reward_mean=0.400, reward_bound=0.206, batch=229 
6385: loss=0.143, reward_mean=0.470, reward_bound=0.215, batch=230 
6386: loss=0.141, reward_mean=0.450, reward_bound=0.247, batch=231 
6387: loss=0.138, reward_mean=0.440, reward_bound=0.254, batch=231 
6388: loss=0.137, reward_mean=0.470, reward_bound=0.282, batch=226 
6389: loss=0.138, reward_mean=0.420, reward_bound=0.298, batch=228 
6390: loss=0.138, reward_mean=0.490, reward_bound=0.314, batch=226 
6391: loss=0.139, reward_mean=0.410, reward_bound=0.349, batch=216 
6392: loss=0.141, reward_mean=0.380, reward_bound=0.206, batch=220 
6393: loss=0.141, reward_mean=0.380, reward_bound=0.216, batch=224 
6394: loss=0.139, reward_mean=0.410, reward_bound=0.282, batch=226 
6395: loss=0.139, reward_mean=0.440, reward_bound=0.349, batch=222 
6396: loss=0.139, reward_mean=0.490, reward_bound=0.349, batch=224 
6397: loss=0.137, reward_mean=0.370, reward_bound=0.387, batch=211 
6398: loss=0.135, reward_mean=0.390, reward_bound=0.185, batch=217 
6399: loss=0.138, reward_mean=0.450, reward_bound=0.342, batch=222 
6400: loss=0.137, reward_mean=0.460, reward_bound=0.324, batch=225 
6401: loss=0.136, reward_mean=0.470, reward_bound=0.387, batch=222 
6402: loss=0.136, reward_mean=0.380, reward_bound=0.400, batch=225 
6403: loss=0.136, reward_mean=0.350, reward_bound=0.396, batch=227 
6404: loss=0.137, reward_mean=0.430, reward_bound=0.422, batch=229 
6405: loss=0.135, reward_mean=0.440, reward_bound=0.430, batch=207 
6406: loss=0.139, reward_mean=0.420, reward_bound=0.224, batch=215 
6407: loss=0.137, reward_mean=0.420, reward_bound=0.282, batch=218 
6408: loss=0.135, reward_mean=0.420, reward_bound=0.314, batch=218 
6409: loss=0.136, reward_mean=0.430, reward_bound=0.317, batch=222 
6410: loss=0.136, reward_mean=0.450, reward_bound=0.324, batch=225 
6411: loss=0.135, reward_mean=0.460, reward_bound=0.349, batch=222 
6412: loss=0.135, reward_mean=0.460, reward_bound=0.360, batch=225 
6413: loss=0.135, reward_mean=0.320, reward_bound=0.321, batch=227 
6414: loss=0.134, reward_mean=0.420, reward_bound=0.349, batch=227 
6415: loss=0.134, reward_mean=0.390, reward_bound=0.387, batch=227 
6416: loss=0.133, reward_mean=0.420, reward_bound=0.414, batch=229 
6417: loss=0.132, reward_mean=0.380, reward_bound=0.430, batch=220 
6418: loss=0.135, reward_mean=0.370, reward_bound=0.216, batch=224 
6419: loss=0.132, reward_mean=0.360, reward_bound=0.308, batch=227 
6420: loss=0.133, reward_mean=0.450, reward_bound=0.349, batch=226 
6421: loss=0.132, reward_mean=0.500, reward_bound=0.387, batch=226 
6422: loss=0.133, reward_mean=0.490, reward_bound=0.430, batch=223 
6423: loss=0.132, reward_mean=0.490, reward_bound=0.314, batch=225 
6424: loss=0.133, reward_mean=0.450, reward_bound=0.356, batch=227 
6425: loss=0.131, reward_mean=0.520, reward_bound=0.387, batch=226 
6426: loss=0.131, reward_mean=0.430, reward_bound=0.454, batch=228 
6427: loss=0.130, reward_mean=0.500, reward_bound=0.435, batch=229 
6428: loss=0.130, reward_mean=0.380, reward_bound=0.450, batch=230 
6429: loss=0.131, reward_mean=0.530, reward_bound=0.418, batch=231 
6430: loss=0.131, reward_mean=0.470, reward_bound=0.430, batch=231 
6431: loss=0.131, reward_mean=0.450, reward_bound=0.430, batch=231 
6432: loss=0.128, reward_mean=0.380, reward_bound=0.478, batch=191 
6433: loss=0.141, reward_mean=0.420, reward_bound=0.135, batch=203 
6434: loss=0.131, reward_mean=0.430, reward_bound=0.244, batch=212 
6435: loss=0.130, reward_mean=0.410, reward_bound=0.236, batch=218 
6436: loss=0.133, reward_mean=0.440, reward_bound=0.257, batch=222 
6437: loss=0.130, reward_mean=0.430, reward_bound=0.282, batch=223 
6438: loss=0.129, reward_mean=0.490, reward_bound=0.314, batch=214 
6439: loss=0.128, reward_mean=0.470, reward_bound=0.314, batch=218 
6440: loss=0.128, reward_mean=0.450, reward_bound=0.314, batch=221 
6441: loss=0.127, reward_mean=0.400, reward_bound=0.349, batch=217 
6442: loss=0.127, reward_mean=0.490, reward_bound=0.380, batch=222 
6443: loss=0.129, reward_mean=0.440, reward_bound=0.254, batch=225 
6444: loss=0.128, reward_mean=0.350, reward_bound=0.289, batch=227 
6445: loss=0.129, reward_mean=0.490, reward_bound=0.387, batch=208 
6446: loss=0.130, reward_mean=0.440, reward_bound=0.208, batch=215 
6447: loss=0.130, reward_mean=0.340, reward_bound=0.170, batch=220 
6448: loss=0.128, reward_mean=0.430, reward_bound=0.254, batch=221 
6449: loss=0.127, reward_mean=0.430, reward_bound=0.282, batch=223 
6450: loss=0.127, reward_mean=0.440, reward_bound=0.314, batch=222 
6451: loss=0.127, reward_mean=0.480, reward_bound=0.349, batch=221 
6452: loss=0.131, reward_mean=0.450, reward_bound=0.387, batch=218 
6453: loss=0.130, reward_mean=0.490, reward_bound=0.392, batch=222 
6454: loss=0.130, reward_mean=0.480, reward_bound=0.336, batch=225 
6455: loss=0.131, reward_mean=0.400, reward_bound=0.430, batch=210 
6456: loss=0.132, reward_mean=0.480, reward_bound=0.349, batch=216 
6457: loss=0.132, reward_mean=0.480, reward_bound=0.260, batch=221 
6458: loss=0.132, reward_mean=0.370, reward_bound=0.254, batch=223 
6459: loss=0.130, reward_mean=0.480, reward_bound=0.314, batch=224 
6460: loss=0.132, reward_mean=0.470, reward_bound=0.282, batch=226 
6461: loss=0.133, reward_mean=0.450, reward_bound=0.368, batch=228 
6462: loss=0.131, reward_mean=0.490, reward_bound=0.387, batch=222 
6463: loss=0.133, reward_mean=0.450, reward_bound=0.360, batch=225 
6464: loss=0.132, reward_mean=0.370, reward_bound=0.321, batch=227 
6465: loss=0.132, reward_mean=0.470, reward_bound=0.349, batch=228 
6466: loss=0.131, reward_mean=0.410, reward_bound=0.387, batch=227 
6467: loss=0.130, reward_mean=0.430, reward_bound=0.342, batch=229 
6468: loss=0.131, reward_mean=0.320, reward_bound=0.349, batch=229 
6469: loss=0.133, reward_mean=0.420, reward_bound=0.430, batch=223 
6470: loss=0.136, reward_mean=0.360, reward_bound=0.426, batch=226 
6471: loss=0.135, reward_mean=0.510, reward_bound=0.409, batch=228 
6472: loss=0.135, reward_mean=0.430, reward_bound=0.357, batch=229 
6473: loss=0.135, reward_mean=0.440, reward_bound=0.430, batch=228 
6474: loss=0.135, reward_mean=0.490, reward_bound=0.330, batch=229 
6475: loss=0.135, reward_mean=0.380, reward_bound=0.478, batch=231 
6476: loss=0.131, reward_mean=0.350, reward_bound=0.478, batch=207 
6477: loss=0.129, reward_mean=0.410, reward_bound=0.282, batch=214 
6478: loss=0.131, reward_mean=0.430, reward_bound=0.183, batch=220 
6479: loss=0.131, reward_mean=0.460, reward_bound=0.338, batch=224 
6480: loss=0.130, reward_mean=0.440, reward_bound=0.314, batch=226 
6481: loss=0.130, reward_mean=0.480, reward_bound=0.316, batch=228 
6482: loss=0.132, reward_mean=0.390, reward_bound=0.349, batch=223 
6483: loss=0.131, reward_mean=0.360, reward_bound=0.314, batch=225 
6484: loss=0.132, reward_mean=0.470, reward_bound=0.387, batch=225 
6485: loss=0.133, reward_mean=0.440, reward_bound=0.314, batch=226 
6486: loss=0.134, reward_mean=0.400, reward_bound=0.368, batch=228 
6487: loss=0.134, reward_mean=0.460, reward_bound=0.392, batch=229 
6488: loss=0.134, reward_mean=0.430, reward_bound=0.405, batch=230 
6489: loss=0.129, reward_mean=0.410, reward_bound=0.430, batch=218 
6490: loss=0.130, reward_mean=0.370, reward_bound=0.257, batch=222 
6491: loss=0.133, reward_mean=0.390, reward_bound=0.292, batch=225 
6492: loss=0.135, reward_mean=0.410, reward_bound=0.321, batch=227 
6493: loss=0.130, reward_mean=0.390, reward_bound=0.349, batch=226 
6494: loss=0.129, reward_mean=0.410, reward_bound=0.331, batch=228 
6495: loss=0.129, reward_mean=0.450, reward_bound=0.353, batch=229 
6496: loss=0.130, reward_mean=0.440, reward_bound=0.387, batch=226 
6497: loss=0.132, reward_mean=0.390, reward_bound=0.331, batch=228 
6498: loss=0.129, reward_mean=0.430, reward_bound=0.353, batch=229 
6499: loss=0.131, reward_mean=0.370, reward_bound=0.387, batch=229 
6500: loss=0.128, reward_mean=0.480, reward_bound=0.430, batch=220 
6501: loss=0.127, reward_mean=0.460, reward_bound=0.338, batch=224 
6502: loss=0.129, reward_mean=0.360, reward_bound=0.349, batch=225 
6503: loss=0.129, reward_mean=0.420, reward_bound=0.321, batch=227 
6504: loss=0.130, reward_mean=0.410, reward_bound=0.380, batch=229 
6505: loss=0.129, reward_mean=0.430, reward_bound=0.387, batch=228 
6506: loss=0.128, reward_mean=0.500, reward_bound=0.430, batch=226 
6507: loss=0.131, reward_mean=0.440, reward_bound=0.433, batch=228 
6508: loss=0.131, reward_mean=0.430, reward_bound=0.435, batch=229 
6509: loss=0.131, reward_mean=0.400, reward_bound=0.424, batch=230 
6510: loss=0.131, reward_mean=0.350, reward_bound=0.451, batch=231 
6511: loss=0.132, reward_mean=0.380, reward_bound=0.478, batch=218 
6512: loss=0.132, reward_mean=0.460, reward_bound=0.430, batch=220 
6513: loss=0.134, reward_mean=0.450, reward_bound=0.338, batch=224 
6514: loss=0.133, reward_mean=0.390, reward_bound=0.345, batch=227 
6515: loss=0.135, reward_mean=0.430, reward_bound=0.349, batch=226 
6516: loss=0.134, reward_mean=0.370, reward_bound=0.351, batch=228 
6517: loss=0.132, reward_mean=0.460, reward_bound=0.430, batch=226 
6518: loss=0.132, reward_mean=0.440, reward_bound=0.390, batch=228 
6519: loss=0.133, reward_mean=0.520, reward_bound=0.478, batch=231 
6520: loss=0.133, reward_mean=0.440, reward_bound=0.387, batch=231 
6521: loss=0.132, reward_mean=0.500, reward_bound=0.478, batch=224 
6522: loss=0.131, reward_mean=0.430, reward_bound=0.426, batch=227 
6523: loss=0.131, reward_mean=0.490, reward_bound=0.422, batch=229 
6524: loss=0.131, reward_mean=0.360, reward_bound=0.430, batch=228 
6525: loss=0.132, reward_mean=0.510, reward_bound=0.478, batch=230 
6526: loss=0.132, reward_mean=0.400, reward_bound=0.406, batch=231 
6527: loss=0.132, reward_mean=0.380, reward_bound=0.478, batch=228 
6528: loss=0.132, reward_mean=0.290, reward_bound=0.402, batch=229 
6529: loss=0.132, reward_mean=0.410, reward_bound=0.405, batch=230 
6530: loss=0.132, reward_mean=0.460, reward_bound=0.478, batch=230 
6532: loss=0.160, reward_mean=0.440, reward_bound=0.000, batch=44 
6533: loss=0.161, reward_mean=0.450, reward_bound=0.000, batch=89 
6534: loss=0.157, reward_mean=0.400, reward_bound=0.000, batch=129 
6535: loss=0.158, reward_mean=0.430, reward_bound=0.002, batch=160 
6536: loss=0.156, reward_mean=0.370, reward_bound=0.008, batch=181 
6537: loss=0.154, reward_mean=0.490, reward_bound=0.015, batch=196 
6538: loss=0.156, reward_mean=0.400, reward_bound=0.025, batch=206 
6539: loss=0.150, reward_mean=0.490, reward_bound=0.042, batch=213 
6540: loss=0.152, reward_mean=0.440, reward_bound=0.058, batch=215 
6541: loss=0.151, reward_mean=0.530, reward_bound=0.080, batch=215 
6542: loss=0.150, reward_mean=0.400, reward_bound=0.098, batch=206 
6543: loss=0.150, reward_mean=0.440, reward_bound=0.109, batch=207 
6544: loss=0.154, reward_mean=0.440, reward_bound=0.122, batch=206 
6545: loss=0.151, reward_mean=0.500, reward_bound=0.135, batch=196 
6546: loss=0.154, reward_mean=0.400, reward_bound=0.150, batch=198 
6547: loss=0.149, reward_mean=0.480, reward_bound=0.167, batch=187 
6548: loss=0.147, reward_mean=0.480, reward_bound=0.147, batch=201 
6549: loss=0.145, reward_mean=0.430, reward_bound=0.150, batch=208 
6550: loss=0.143, reward_mean=0.490, reward_bound=0.185, batch=204 
6551: loss=0.140, reward_mean=0.510, reward_bound=0.206, batch=187 
6552: loss=0.140, reward_mean=0.470, reward_bound=0.167, batch=199 
6553: loss=0.139, reward_mean=0.520, reward_bound=0.157, batch=209 
6554: loss=0.141, reward_mean=0.480, reward_bound=0.185, batch=214 
6555: loss=0.144, reward_mean=0.530, reward_bound=0.229, batch=195 
6556: loss=0.144, reward_mean=0.530, reward_bound=0.150, batch=205 
6557: loss=0.144, reward_mean=0.530, reward_bound=0.206, batch=212 
6558: loss=0.142, reward_mean=0.560, reward_bound=0.236, batch=218 
6559: loss=0.140, reward_mean=0.420, reward_bound=0.254, batch=184 
6560: loss=0.142, reward_mean=0.430, reward_bound=0.134, batch=199 
6561: loss=0.141, reward_mean=0.540, reward_bound=0.167, batch=207 
6562: loss=0.142, reward_mean=0.420, reward_bound=0.185, batch=212 
6563: loss=0.140, reward_mean=0.550, reward_bound=0.229, batch=216 
6564: loss=0.139, reward_mean=0.420, reward_bound=0.254, batch=216 
6565: loss=0.141, reward_mean=0.490, reward_bound=0.254, batch=219 
6566: loss=0.137, reward_mean=0.480, reward_bound=0.282, batch=187 
6567: loss=0.140, reward_mean=0.430, reward_bound=0.182, batch=201 
6568: loss=0.137, reward_mean=0.420, reward_bound=0.122, batch=210 
6569: loss=0.137, reward_mean=0.510, reward_bound=0.185, batch=216 
6570: loss=0.140, reward_mean=0.430, reward_bound=0.217, batch=221 
6571: loss=0.138, reward_mean=0.540, reward_bound=0.254, batch=218 
6572: loss=0.141, reward_mean=0.500, reward_bound=0.282, batch=216 
6573: loss=0.146, reward_mean=0.500, reward_bound=0.314, batch=165 
6574: loss=0.143, reward_mean=0.480, reward_bound=0.141, batch=185 
6575: loss=0.139, reward_mean=0.490, reward_bound=0.101, batch=199 
6576: loss=0.140, reward_mean=0.360, reward_bound=0.141, batch=209 
6577: loss=0.141, reward_mean=0.450, reward_bound=0.150, batch=214 
6578: loss=0.144, reward_mean=0.460, reward_bound=0.206, batch=219 
6579: loss=0.143, reward_mean=0.420, reward_bound=0.229, batch=217 
6580: loss=0.146, reward_mean=0.480, reward_bound=0.254, batch=218 
6581: loss=0.146, reward_mean=0.480, reward_bound=0.257, batch=222 
6582: loss=0.146, reward_mean=0.390, reward_bound=0.263, batch=225 
6583: loss=0.147, reward_mean=0.450, reward_bound=0.282, batch=217 
6584: loss=0.146, reward_mean=0.490, reward_bound=0.282, batch=220 
6585: loss=0.146, reward_mean=0.430, reward_bound=0.304, batch=224 
6586: loss=0.146, reward_mean=0.460, reward_bound=0.311, batch=227 
6587: loss=0.147, reward_mean=0.550, reward_bound=0.314, batch=213 
6588: loss=0.148, reward_mean=0.490, reward_bound=0.206, batch=218 
6589: loss=0.147, reward_mean=0.490, reward_bound=0.229, batch=221 
6590: loss=0.147, reward_mean=0.450, reward_bound=0.314, batch=221 
6591: loss=0.148, reward_mean=0.330, reward_bound=0.282, batch=224 
6592: loss=0.138, reward_mean=0.570, reward_bound=0.349, batch=159 
6593: loss=0.141, reward_mean=0.390, reward_bound=0.047, batch=180 
6594: loss=0.144, reward_mean=0.520, reward_bound=0.089, batch=195 
6595: loss=0.144, reward_mean=0.310, reward_bound=0.109, batch=208 
6596: loss=0.145, reward_mean=0.410, reward_bound=0.135, batch=213 
6597: loss=0.146, reward_mean=0.490, reward_bound=0.167, batch=218 
6598: loss=0.139, reward_mean=0.520, reward_bound=0.206, batch=215 
6599: loss=0.137, reward_mean=0.450, reward_bound=0.229, batch=212 
6600: loss=0.137, reward_mean=0.450, reward_bound=0.254, batch=215 
