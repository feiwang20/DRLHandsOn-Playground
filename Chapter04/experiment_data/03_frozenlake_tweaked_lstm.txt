



2020-05-07 02-59-21

0: loss=1.406, reward_mean=0.010, reward_bound=0.000, batch=1 
1: loss=1.401, reward_mean=0.000, reward_bound=0.000, batch=1 
2: loss=1.383, reward_mean=0.030, reward_bound=0.000, batch=4 
3: loss=1.384, reward_mean=0.020, reward_bound=0.000, batch=6 
4: loss=1.384, reward_mean=0.010, reward_bound=0.000, batch=7 
5: loss=1.385, reward_mean=0.010, reward_bound=0.000, batch=8 
6: loss=1.385, reward_mean=0.000, reward_bound=0.000, batch=8 
7: loss=1.385, reward_mean=0.020, reward_bound=0.000, batch=10 
8: loss=1.385, reward_mean=0.020, reward_bound=0.000, batch=12 
9: loss=1.385, reward_mean=0.050, reward_bound=0.000, batch=17 
10: loss=1.384, reward_mean=0.020, reward_bound=0.000, batch=19 
11: loss=1.384, reward_mean=0.000, reward_bound=0.000, batch=19 
12: loss=1.384, reward_mean=0.000, reward_bound=0.000, batch=19 
13: loss=1.384, reward_mean=0.000, reward_bound=0.000, batch=19 
14: loss=1.383, reward_mean=0.020, reward_bound=0.000, batch=21 
15: loss=1.383, reward_mean=0.010, reward_bound=0.000, batch=22 
16: loss=1.383, reward_mean=0.040, reward_bound=0.000, batch=26 
17: loss=1.383, reward_mean=0.020, reward_bound=0.000, batch=28 
18: loss=1.383, reward_mean=0.010, reward_bound=0.000, batch=29 
19: loss=1.383, reward_mean=0.020, reward_bound=0.000, batch=31 
20: loss=1.383, reward_mean=0.030, reward_bound=0.000, batch=34 
21: loss=1.383, reward_mean=0.000, reward_bound=0.000, batch=34 
22: loss=1.383, reward_mean=0.030, reward_bound=0.000, batch=37 
23: loss=1.383, reward_mean=0.010, reward_bound=0.000, batch=38 
24: loss=1.383, reward_mean=0.010, reward_bound=0.000, batch=39 
25: loss=1.383, reward_mean=0.010, reward_bound=0.000, batch=40 
26: loss=1.382, reward_mean=0.020, reward_bound=0.000, batch=42 
27: loss=1.382, reward_mean=0.020, reward_bound=0.000, batch=44 
28: loss=1.382, reward_mean=0.020, reward_bound=0.000, batch=46 
29: loss=1.382, reward_mean=0.010, reward_bound=0.000, batch=47 
30: loss=1.382, reward_mean=0.010, reward_bound=0.000, batch=48 
31: loss=1.381, reward_mean=0.010, reward_bound=0.000, batch=49 
32: loss=1.381, reward_mean=0.010, reward_bound=0.000, batch=50 
33: loss=1.381, reward_mean=0.040, reward_bound=0.000, batch=54 
34: loss=1.381, reward_mean=0.030, reward_bound=0.000, batch=57 
35: loss=1.380, reward_mean=0.010, reward_bound=0.000, batch=58 
36: loss=1.380, reward_mean=0.010, reward_bound=0.000, batch=59 
37: loss=1.380, reward_mean=0.020, reward_bound=0.000, batch=61 
38: loss=1.380, reward_mean=0.020, reward_bound=0.000, batch=63 
39: loss=1.380, reward_mean=0.010, reward_bound=0.000, batch=64 
40: loss=1.380, reward_mean=0.020, reward_bound=0.000, batch=66 
41: loss=1.380, reward_mean=0.010, reward_bound=0.000, batch=67 
42: loss=1.379, reward_mean=0.000, reward_bound=0.000, batch=67 
43: loss=1.379, reward_mean=0.040, reward_bound=0.000, batch=71 
44: loss=1.379, reward_mean=0.000, reward_bound=0.000, batch=71 
45: loss=1.379, reward_mean=0.020, reward_bound=0.000, batch=73 
46: loss=1.379, reward_mean=0.020, reward_bound=0.000, batch=75 
47: loss=1.379, reward_mean=0.000, reward_bound=0.000, batch=75 
48: loss=1.378, reward_mean=0.020, reward_bound=0.000, batch=77 
49: loss=1.378, reward_mean=0.010, reward_bound=0.000, batch=78 
50: loss=1.378, reward_mean=0.050, reward_bound=0.000, batch=83 
51: loss=1.378, reward_mean=0.050, reward_bound=0.000, batch=88 
52: loss=1.377, reward_mean=0.040, reward_bound=0.000, batch=92 
53: loss=1.377, reward_mean=0.030, reward_bound=0.000, batch=95 
54: loss=1.377, reward_mean=0.000, reward_bound=0.000, batch=95 
55: loss=1.376, reward_mean=0.000, reward_bound=0.000, batch=95 
56: loss=1.376, reward_mean=0.000, reward_bound=0.000, batch=95 
57: loss=1.376, reward_mean=0.000, reward_bound=0.000, batch=95 
58: loss=1.375, reward_mean=0.000, reward_bound=0.000, batch=95 
59: loss=1.375, reward_mean=0.030, reward_bound=0.000, batch=98 
60: loss=1.374, reward_mean=0.000, reward_bound=0.000, batch=98 
61: loss=1.374, reward_mean=0.010, reward_bound=0.000, batch=99 
62: loss=1.373, reward_mean=0.020, reward_bound=0.000, batch=101 
63: loss=1.373, reward_mean=0.020, reward_bound=0.000, batch=103 
64: loss=1.372, reward_mean=0.010, reward_bound=0.000, batch=104 
65: loss=1.372, reward_mean=0.010, reward_bound=0.000, batch=105 
66: loss=1.372, reward_mean=0.030, reward_bound=0.000, batch=108 
67: loss=1.371, reward_mean=0.030, reward_bound=0.000, batch=111 
68: loss=1.371, reward_mean=0.030, reward_bound=0.000, batch=114 
69: loss=1.371, reward_mean=0.030, reward_bound=0.000, batch=117 
70: loss=1.371, reward_mean=0.000, reward_bound=0.000, batch=117 
71: loss=1.370, reward_mean=0.000, reward_bound=0.000, batch=117 
72: loss=1.370, reward_mean=0.030, reward_bound=0.000, batch=120 
73: loss=1.369, reward_mean=0.030, reward_bound=0.000, batch=123 
74: loss=1.369, reward_mean=0.020, reward_bound=0.000, batch=125 
75: loss=1.368, reward_mean=0.010, reward_bound=0.000, batch=126 
76: loss=1.368, reward_mean=0.050, reward_bound=0.000, batch=131 
77: loss=1.367, reward_mean=0.020, reward_bound=0.000, batch=133 
78: loss=1.367, reward_mean=0.020, reward_bound=0.000, batch=135 
79: loss=1.366, reward_mean=0.010, reward_bound=0.000, batch=136 
80: loss=1.366, reward_mean=0.040, reward_bound=0.000, batch=140 
81: loss=1.366, reward_mean=0.020, reward_bound=0.000, batch=142 
82: loss=1.365, reward_mean=0.030, reward_bound=0.000, batch=145 
83: loss=1.364, reward_mean=0.000, reward_bound=0.000, batch=145 
84: loss=1.364, reward_mean=0.020, reward_bound=0.000, batch=147 
85: loss=1.363, reward_mean=0.050, reward_bound=0.000, batch=152 
86: loss=1.363, reward_mean=0.010, reward_bound=0.000, batch=153 
87: loss=1.362, reward_mean=0.030, reward_bound=0.000, batch=156 
88: loss=1.361, reward_mean=0.010, reward_bound=0.000, batch=157 
89: loss=1.360, reward_mean=0.010, reward_bound=0.000, batch=158 
90: loss=1.360, reward_mean=0.010, reward_bound=0.000, batch=159 
91: loss=1.359, reward_mean=0.030, reward_bound=0.000, batch=162 
92: loss=1.359, reward_mean=0.000, reward_bound=0.000, batch=162 
93: loss=1.358, reward_mean=0.020, reward_bound=0.000, batch=164 
94: loss=1.357, reward_mean=0.010, reward_bound=0.000, batch=165 
95: loss=1.356, reward_mean=0.020, reward_bound=0.000, batch=167 
96: loss=1.355, reward_mean=0.030, reward_bound=0.000, batch=170 
97: loss=1.355, reward_mean=0.000, reward_bound=0.000, batch=170 
98: loss=1.354, reward_mean=0.030, reward_bound=0.000, batch=173 
99: loss=1.354, reward_mean=0.040, reward_bound=0.000, batch=177 
100: loss=1.353, reward_mean=0.020, reward_bound=0.000, batch=179 
101: loss=1.352, reward_mean=0.010, reward_bound=0.000, batch=180 
102: loss=1.351, reward_mean=0.030, reward_bound=0.000, batch=183 
103: loss=1.350, reward_mean=0.040, reward_bound=0.000, batch=187 
104: loss=1.349, reward_mean=0.020, reward_bound=0.000, batch=189 
105: loss=1.349, reward_mean=0.020, reward_bound=0.000, batch=191 
106: loss=1.348, reward_mean=0.020, reward_bound=0.000, batch=193 
107: loss=1.347, reward_mean=0.020, reward_bound=0.000, batch=195 
108: loss=1.346, reward_mean=0.000, reward_bound=0.000, batch=195 
109: loss=1.345, reward_mean=0.030, reward_bound=0.000, batch=198 
110: loss=1.345, reward_mean=0.000, reward_bound=0.000, batch=198 
111: loss=1.344, reward_mean=0.010, reward_bound=0.000, batch=199 
112: loss=1.343, reward_mean=0.040, reward_bound=0.000, batch=203 
113: loss=1.342, reward_mean=0.020, reward_bound=0.000, batch=205 
114: loss=1.341, reward_mean=0.030, reward_bound=0.000, batch=208 
115: loss=1.340, reward_mean=0.020, reward_bound=0.000, batch=210 
116: loss=1.340, reward_mean=0.010, reward_bound=0.000, batch=211 
117: loss=1.339, reward_mean=0.020, reward_bound=0.000, batch=213 
118: loss=1.338, reward_mean=0.040, reward_bound=0.000, batch=217 
119: loss=1.338, reward_mean=0.030, reward_bound=0.000, batch=220 
120: loss=1.337, reward_mean=0.010, reward_bound=0.000, batch=221 
121: loss=1.336, reward_mean=0.010, reward_bound=0.000, batch=222 
122: loss=1.336, reward_mean=0.030, reward_bound=0.004, batch=225 
123: loss=1.335, reward_mean=0.020, reward_bound=0.003, batch=227 
124: loss=1.334, reward_mean=0.030, reward_bound=0.016, batch=229 
125: loss=1.332, reward_mean=0.040, reward_bound=0.042, batch=228 
126: loss=1.331, reward_mean=0.050, reward_bound=0.066, batch=229 
127: loss=1.330, reward_mean=0.030, reward_bound=0.083, batch=230 
128: loss=1.329, reward_mean=0.020, reward_bound=0.089, batch=229 
129: loss=1.327, reward_mean=0.040, reward_bound=0.098, batch=226 
130: loss=1.326, reward_mean=0.010, reward_bound=0.000, batch=227 
131: loss=1.325, reward_mean=0.020, reward_bound=0.088, batch=229 
132: loss=1.325, reward_mean=0.000, reward_bound=0.000, batch=229 
133: loss=1.322, reward_mean=0.020, reward_bound=0.109, batch=223 
134: loss=1.322, reward_mean=0.000, reward_bound=0.000, batch=223 
135: loss=1.322, reward_mean=0.000, reward_bound=0.000, batch=223 
136: loss=1.321, reward_mean=0.020, reward_bound=0.000, batch=225 
137: loss=1.319, reward_mean=0.070, reward_bound=0.122, batch=226 
138: loss=1.316, reward_mean=0.050, reward_bound=0.135, batch=218 
139: loss=1.316, reward_mean=0.030, reward_bound=0.000, batch=221 
140: loss=1.313, reward_mean=0.060, reward_bound=0.150, batch=214 
141: loss=1.312, reward_mean=0.070, reward_bound=0.162, batch=220 
142: loss=1.310, reward_mean=0.050, reward_bound=0.150, batch=224 
143: loss=1.310, reward_mean=0.040, reward_bound=0.164, batch=227 
144: loss=1.308, reward_mean=0.040, reward_bound=0.167, batch=224 
145: loss=1.304, reward_mean=0.040, reward_bound=0.185, batch=215 
146: loss=1.304, reward_mean=0.050, reward_bound=0.007, batch=220 
147: loss=1.303, reward_mean=0.070, reward_bound=0.118, batch=224 
148: loss=1.301, reward_mean=0.060, reward_bound=0.204, batch=227 
149: loss=1.299, reward_mean=0.020, reward_bound=0.148, batch=229 
150: loss=1.299, reward_mean=0.020, reward_bound=0.174, batch=230 
151: loss=1.297, reward_mean=0.020, reward_bound=0.200, batch=231 
152: loss=1.298, reward_mean=0.030, reward_bound=0.206, batch=220 
153: loss=1.296, reward_mean=0.030, reward_bound=0.000, batch=223 
154: loss=1.295, reward_mean=0.030, reward_bound=0.073, batch=226 
155: loss=1.294, reward_mean=0.020, reward_bound=0.061, batch=228 
156: loss=1.293, reward_mean=0.020, reward_bound=0.077, batch=229 
157: loss=1.291, reward_mean=0.070, reward_bound=0.229, batch=209 
158: loss=1.291, reward_mean=0.010, reward_bound=0.000, batch=210 
159: loss=1.288, reward_mean=0.030, reward_bound=0.000, batch=213 
160: loss=1.289, reward_mean=0.090, reward_bound=0.171, batch=219 
161: loss=1.288, reward_mean=0.020, reward_bound=0.000, batch=221 
162: loss=1.288, reward_mean=0.020, reward_bound=0.000, batch=223 
163: loss=1.286, reward_mean=0.020, reward_bound=0.000, batch=225 
164: loss=1.286, reward_mean=0.030, reward_bound=0.054, batch=227 
165: loss=1.285, reward_mean=0.050, reward_bound=0.160, batch=229 
166: loss=1.285, reward_mean=0.020, reward_bound=0.167, batch=229 
167: loss=1.285, reward_mean=0.040, reward_bound=0.185, batch=229 
168: loss=1.286, reward_mean=0.060, reward_bound=0.215, batch=230 
169: loss=1.279, reward_mean=0.080, reward_bound=0.254, batch=208 
170: loss=1.277, reward_mean=0.020, reward_bound=0.000, batch=210 
171: loss=1.277, reward_mean=0.040, reward_bound=0.000, batch=214 
172: loss=1.277, reward_mean=0.000, reward_bound=0.000, batch=214 
173: loss=1.276, reward_mean=0.050, reward_bound=0.000, batch=219 
174: loss=1.273, reward_mean=0.050, reward_bound=0.120, batch=223 
175: loss=1.273, reward_mean=0.040, reward_bound=0.144, batch=226 
176: loss=1.275, reward_mean=0.040, reward_bound=0.158, batch=228 
177: loss=1.273, reward_mean=0.040, reward_bound=0.229, batch=228 
178: loss=1.271, reward_mean=0.050, reward_bound=0.282, batch=196 
179: loss=1.268, reward_mean=0.060, reward_bound=0.000, batch=202 
180: loss=1.266, reward_mean=0.100, reward_bound=0.058, batch=211 
181: loss=1.265, reward_mean=0.040, reward_bound=0.000, batch=215 
182: loss=1.264, reward_mean=0.030, reward_bound=0.000, batch=218 
183: loss=1.265, reward_mean=0.050, reward_bound=0.124, batch=222 
184: loss=1.264, reward_mean=0.010, reward_bound=0.000, batch=223 
185: loss=1.266, reward_mean=0.040, reward_bound=0.150, batch=224 
186: loss=1.264, reward_mean=0.040, reward_bound=0.097, batch=227 
187: loss=1.265, reward_mean=0.040, reward_bound=0.182, batch=229 
188: loss=1.264, reward_mean=0.050, reward_bound=0.206, batch=227 
189: loss=1.267, reward_mean=0.030, reward_bound=0.229, batch=224 
190: loss=1.266, reward_mean=0.040, reward_bound=0.245, batch=227 
191: loss=1.266, reward_mean=0.050, reward_bound=0.249, batch=229 
192: loss=1.262, reward_mean=0.070, reward_bound=0.282, batch=229 
193: loss=1.253, reward_mean=0.060, reward_bound=0.314, batch=183 
194: loss=1.251, reward_mean=0.020, reward_bound=0.000, batch=185 
195: loss=1.252, reward_mean=0.050, reward_bound=0.000, batch=190 
196: loss=1.250, reward_mean=0.030, reward_bound=0.000, batch=193 
197: loss=1.247, reward_mean=0.030, reward_bound=0.000, batch=196 
198: loss=1.247, reward_mean=0.020, reward_bound=0.000, batch=198 
199: loss=1.246, reward_mean=0.000, reward_bound=0.000, batch=198 
200: loss=1.244, reward_mean=0.040, reward_bound=0.000, batch=202 
201: loss=1.244, reward_mean=0.030, reward_bound=0.000, batch=205 
202: loss=1.242, reward_mean=0.030, reward_bound=0.000, batch=208 
203: loss=1.244, reward_mean=0.120, reward_bound=0.138, batch=215 
204: loss=1.243, reward_mean=0.010, reward_bound=0.000, batch=216 
205: loss=1.243, reward_mean=0.030, reward_bound=0.000, batch=219 
206: loss=1.243, reward_mean=0.040, reward_bound=0.039, batch=223 
207: loss=1.242, reward_mean=0.030, reward_bound=0.059, batch=226 
208: loss=1.241, reward_mean=0.080, reward_bound=0.185, batch=225 
209: loss=1.241, reward_mean=0.010, reward_bound=0.000, batch=226 
210: loss=1.240, reward_mean=0.050, reward_bound=0.206, batch=226 
211: loss=1.239, reward_mean=0.070, reward_bound=0.241, batch=228 
212: loss=1.238, reward_mean=0.020, reward_bound=0.176, batch=229 
213: loss=1.236, reward_mean=0.040, reward_bound=0.254, batch=222 
214: loss=1.234, reward_mean=0.070, reward_bound=0.245, batch=225 
215: loss=1.232, reward_mean=0.020, reward_bound=0.033, batch=227 
216: loss=1.231, reward_mean=0.020, reward_bound=0.108, batch=229 
217: loss=1.234, reward_mean=0.050, reward_bound=0.224, batch=230 
218: loss=1.236, reward_mean=0.040, reward_bound=0.282, batch=228 
219: loss=1.235, reward_mean=0.050, reward_bound=0.217, batch=229 
220: loss=1.235, reward_mean=0.010, reward_bound=0.126, batch=230 
221: loss=1.237, reward_mean=0.040, reward_bound=0.314, batch=228 
222: loss=1.219, reward_mean=0.050, reward_bound=0.349, batch=182 
223: loss=1.214, reward_mean=0.070, reward_bound=0.000, batch=189 
224: loss=1.212, reward_mean=0.040, reward_bound=0.000, batch=193 
225: loss=1.204, reward_mean=0.090, reward_bound=0.000, batch=202 
226: loss=1.202, reward_mean=0.050, reward_bound=0.000, batch=207 
227: loss=1.199, reward_mean=0.040, reward_bound=0.000, batch=211 
228: loss=1.196, reward_mean=0.040, reward_bound=0.000, batch=215 
229: loss=1.200, reward_mean=0.080, reward_bound=0.065, batch=219 
230: loss=1.198, reward_mean=0.030, reward_bound=0.000, batch=222 
231: loss=1.195, reward_mean=0.070, reward_bound=0.089, batch=225 
232: loss=1.199, reward_mean=0.050, reward_bound=0.167, batch=226 
233: loss=1.198, reward_mean=0.030, reward_bound=0.087, batch=228 
234: loss=1.201, reward_mean=0.070, reward_bound=0.206, batch=225 
235: loss=1.202, reward_mean=0.040, reward_bound=0.127, batch=227 
236: loss=1.201, reward_mean=0.080, reward_bound=0.229, batch=228 
237: loss=1.198, reward_mean=0.080, reward_bound=0.254, batch=226 
238: loss=1.198, reward_mean=0.060, reward_bound=0.229, batch=227 
239: loss=1.198, reward_mean=0.060, reward_bound=0.282, batch=223 
240: loss=1.197, reward_mean=0.050, reward_bound=0.252, batch=226 
241: loss=1.199, reward_mean=0.050, reward_bound=0.282, batch=227 
242: loss=1.201, reward_mean=0.050, reward_bound=0.314, batch=225 
243: loss=1.200, reward_mean=0.090, reward_bound=0.314, batch=226 
244: loss=1.200, reward_mean=0.030, reward_bound=0.235, batch=228 
245: loss=1.199, reward_mean=0.040, reward_bound=0.208, batch=229 
246: loss=1.203, reward_mean=0.080, reward_bound=0.349, batch=215 
247: loss=1.206, reward_mean=0.030, reward_bound=0.000, batch=218 
248: loss=1.201, reward_mean=0.070, reward_bound=0.171, batch=222 
249: loss=1.201, reward_mean=0.010, reward_bound=0.000, batch=223 
250: loss=1.198, reward_mean=0.070, reward_bound=0.229, batch=225 
251: loss=1.199, reward_mean=0.060, reward_bound=0.254, batch=225 
252: loss=1.197, reward_mean=0.040, reward_bound=0.190, batch=227 
253: loss=1.196, reward_mean=0.110, reward_bound=0.277, batch=229 
254: loss=1.197, reward_mean=0.050, reward_bound=0.314, batch=227 
255: loss=1.196, reward_mean=0.050, reward_bound=0.335, batch=229 
256: loss=1.195, reward_mean=0.070, reward_bound=0.292, batch=230 
257: loss=1.196, reward_mean=0.070, reward_bound=0.349, batch=228 
258: loss=1.195, reward_mean=0.110, reward_bound=0.286, batch=229 
259: loss=1.195, reward_mean=0.030, reward_bound=0.314, batch=229 
260: loss=1.179, reward_mean=0.090, reward_bound=0.387, batch=161 
261: loss=1.173, reward_mean=0.050, reward_bound=0.000, batch=166 
262: loss=1.172, reward_mean=0.060, reward_bound=0.000, batch=172 
263: loss=1.173, reward_mean=0.020, reward_bound=0.000, batch=174 
264: loss=1.166, reward_mean=0.060, reward_bound=0.000, batch=180 
265: loss=1.162, reward_mean=0.040, reward_bound=0.000, batch=184 
266: loss=1.164, reward_mean=0.050, reward_bound=0.000, batch=189 
267: loss=1.162, reward_mean=0.040, reward_bound=0.000, batch=193 
268: loss=1.160, reward_mean=0.060, reward_bound=0.000, batch=199 
269: loss=1.157, reward_mean=0.030, reward_bound=0.000, batch=202 
270: loss=1.155, reward_mean=0.030, reward_bound=0.000, batch=205 
271: loss=1.155, reward_mean=0.050, reward_bound=0.000, batch=210 
272: loss=1.157, reward_mean=0.090, reward_bound=0.020, batch=217 
273: loss=1.158, reward_mean=0.060, reward_bound=0.020, batch=221 
274: loss=1.163, reward_mean=0.090, reward_bound=0.109, batch=223 
275: loss=1.163, reward_mean=0.030, reward_bound=0.066, batch=226 
276: loss=1.167, reward_mean=0.070, reward_bound=0.122, batch=227 
277: loss=1.161, reward_mean=0.040, reward_bound=0.150, batch=227 
278: loss=1.160, reward_mean=0.040, reward_bound=0.142, batch=229 
279: loss=1.159, reward_mean=0.050, reward_bound=0.167, batch=226 
280: loss=1.160, reward_mean=0.040, reward_bound=0.185, batch=227 
281: loss=1.163, reward_mean=0.060, reward_bound=0.206, batch=220 
282: loss=1.165, reward_mean=0.090, reward_bound=0.229, batch=217 
283: loss=1.165, reward_mean=0.080, reward_bound=0.254, batch=217 
284: loss=1.169, reward_mean=0.060, reward_bound=0.201, batch=222 
285: loss=1.164, reward_mean=0.070, reward_bound=0.263, batch=225 
286: loss=1.162, reward_mean=0.080, reward_bound=0.282, batch=222 
287: loss=1.160, reward_mean=0.050, reward_bound=0.181, batch=225 
288: loss=1.161, reward_mean=0.080, reward_bound=0.314, batch=221 
289: loss=1.164, reward_mean=0.090, reward_bound=0.349, batch=207 
290: loss=1.162, reward_mean=0.080, reward_bound=0.057, batch=215 
291: loss=1.164, reward_mean=0.040, reward_bound=0.000, batch=219 
292: loss=1.157, reward_mean=0.080, reward_bound=0.102, batch=223 
293: loss=1.162, reward_mean=0.080, reward_bound=0.229, batch=225 
294: loss=1.161, reward_mean=0.060, reward_bound=0.254, batch=224 
295: loss=1.158, reward_mean=0.060, reward_bound=0.311, batch=227 
296: loss=1.160, reward_mean=0.130, reward_bound=0.314, batch=227 
297: loss=1.159, reward_mean=0.100, reward_bound=0.349, batch=224 
298: loss=1.158, reward_mean=0.080, reward_bound=0.280, batch=227 
299: loss=1.159, reward_mean=0.060, reward_bound=0.366, batch=229 
300: loss=1.156, reward_mean=0.030, reward_bound=0.174, batch=230 
301: loss=1.159, reward_mean=0.080, reward_bound=0.274, batch=231 
302: loss=1.165, reward_mean=0.130, reward_bound=0.387, batch=209 
303: loss=1.164, reward_mean=0.060, reward_bound=0.000, batch=215 
304: loss=1.163, reward_mean=0.110, reward_bound=0.175, batch=220 
305: loss=1.162, reward_mean=0.030, reward_bound=0.000, batch=223 
306: loss=1.158, reward_mean=0.090, reward_bound=0.244, batch=226 
307: loss=1.159, reward_mean=0.070, reward_bound=0.254, batch=226 
308: loss=1.161, reward_mean=0.050, reward_bound=0.282, batch=226 
309: loss=1.161, reward_mean=0.030, reward_bound=0.268, batch=228 
310: loss=1.160, reward_mean=0.050, reward_bound=0.286, batch=229 
311: loss=1.160, reward_mean=0.020, reward_bound=0.148, batch=230 
312: loss=1.158, reward_mean=0.070, reward_bound=0.314, batch=229 
313: loss=1.158, reward_mean=0.100, reward_bound=0.349, batch=229 
314: loss=1.158, reward_mean=0.070, reward_bound=0.387, batch=222 
315: loss=1.157, reward_mean=0.070, reward_bound=0.307, batch=225 
316: loss=1.156, reward_mean=0.040, reward_bound=0.157, batch=227 
317: loss=1.155, reward_mean=0.060, reward_bound=0.401, batch=229 
318: loss=1.155, reward_mean=0.040, reward_bound=0.405, batch=230 
319: loss=1.154, reward_mean=0.060, reward_bound=0.406, batch=231 
320: loss=1.154, reward_mean=0.070, reward_bound=0.387, batch=231 
321: loss=1.148, reward_mean=0.070, reward_bound=0.430, batch=131 
322: loss=1.140, reward_mean=0.040, reward_bound=0.000, batch=135 
323: loss=1.142, reward_mean=0.100, reward_bound=0.000, batch=145 
324: loss=1.144, reward_mean=0.060, reward_bound=0.000, batch=151 
325: loss=1.142, reward_mean=0.050, reward_bound=0.000, batch=156 
326: loss=1.137, reward_mean=0.090, reward_bound=0.000, batch=165 
327: loss=1.131, reward_mean=0.040, reward_bound=0.000, batch=169 
328: loss=1.129, reward_mean=0.060, reward_bound=0.000, batch=175 
329: loss=1.126, reward_mean=0.090, reward_bound=0.000, batch=184 
330: loss=1.118, reward_mean=0.100, reward_bound=0.000, batch=194 
331: loss=1.114, reward_mean=0.080, reward_bound=0.000, batch=202 
332: loss=1.113, reward_mean=0.090, reward_bound=0.022, batch=211 
333: loss=1.109, reward_mean=0.030, reward_bound=0.000, batch=214 
334: loss=1.110, reward_mean=0.040, reward_bound=0.000, batch=218 
335: loss=1.112, reward_mean=0.050, reward_bound=0.040, batch=222 
336: loss=1.110, reward_mean=0.060, reward_bound=0.080, batch=224 
337: loss=1.108, reward_mean=0.060, reward_bound=0.098, batch=226 
338: loss=1.108, reward_mean=0.070, reward_bound=0.143, batch=228 
339: loss=1.105, reward_mean=0.070, reward_bound=0.167, batch=224 
340: loss=1.101, reward_mean=0.030, reward_bound=0.109, batch=227 
341: loss=1.099, reward_mean=0.020, reward_bound=0.097, batch=229 
342: loss=1.102, reward_mean=0.090, reward_bound=0.185, batch=223 
343: loss=1.100, reward_mean=0.060, reward_bound=0.206, batch=225 
344: loss=1.099, reward_mean=0.030, reward_bound=0.042, batch=227 
345: loss=1.098, reward_mean=0.040, reward_bound=0.216, batch=229 
346: loss=1.100, reward_mean=0.080, reward_bound=0.229, batch=226 
347: loss=1.106, reward_mean=0.070, reward_bound=0.254, batch=217 
348: loss=1.104, reward_mean=0.040, reward_bound=0.000, batch=221 
349: loss=1.106, reward_mean=0.120, reward_bound=0.282, batch=207 
350: loss=1.102, reward_mean=0.070, reward_bound=0.000, batch=214 
351: loss=1.100, reward_mean=0.050, reward_bound=0.000, batch=219 
352: loss=1.097, reward_mean=0.090, reward_bound=0.206, batch=222 
353: loss=1.098, reward_mean=0.040, reward_bound=0.131, batch=225 
354: loss=1.093, reward_mean=0.070, reward_bound=0.229, batch=226 
355: loss=1.095, reward_mean=0.120, reward_bound=0.254, batch=226 
356: loss=1.093, reward_mean=0.020, reward_bound=0.141, batch=228 
357: loss=1.099, reward_mean=0.070, reward_bound=0.282, batch=228 
358: loss=1.111, reward_mean=0.070, reward_bound=0.314, batch=200 
359: loss=1.109, reward_mean=0.060, reward_bound=0.000, batch=206 
360: loss=1.108, reward_mean=0.070, reward_bound=0.000, batch=213 
361: loss=1.105, reward_mean=0.050, reward_bound=0.000, batch=218 
362: loss=1.107, reward_mean=0.070, reward_bound=0.092, batch=222 
363: loss=1.105, reward_mean=0.090, reward_bound=0.179, batch=225 
364: loss=1.106, reward_mean=0.070, reward_bound=0.210, batch=227 
365: loss=1.107, reward_mean=0.060, reward_bound=0.229, batch=226 
366: loss=1.106, reward_mean=0.090, reward_bound=0.254, batch=227 
367: loss=1.107, reward_mean=0.110, reward_bound=0.282, batch=226 
368: loss=1.108, reward_mean=0.090, reward_bound=0.314, batch=222 
369: loss=1.106, reward_mean=0.050, reward_bound=0.156, batch=225 
370: loss=1.107, reward_mean=0.040, reward_bound=0.205, batch=227 
371: loss=1.105, reward_mean=0.060, reward_bound=0.277, batch=229 
372: loss=1.103, reward_mean=0.060, reward_bound=0.314, batch=229 
373: loss=1.101, reward_mean=0.080, reward_bound=0.328, batch=230 
374: loss=1.108, reward_mean=0.050, reward_bound=0.349, batch=207 
375: loss=1.106, reward_mean=0.060, reward_bound=0.000, batch=213 
376: loss=1.104, reward_mean=0.050, reward_bound=0.000, batch=218 
377: loss=1.102, reward_mean=0.100, reward_bound=0.254, batch=220 
378: loss=1.102, reward_mean=0.030, reward_bound=0.000, batch=223 
379: loss=1.101, reward_mean=0.060, reward_bound=0.271, batch=226 
380: loss=1.101, reward_mean=0.070, reward_bound=0.282, batch=226 
381: loss=1.105, reward_mean=0.050, reward_bound=0.314, batch=226 
382: loss=1.104, reward_mean=0.060, reward_bound=0.314, batch=227 
383: loss=1.106, reward_mean=0.060, reward_bound=0.349, batch=228 
384: loss=1.106, reward_mean=0.040, reward_bound=0.353, batch=229 
385: loss=1.106, reward_mean=0.050, reward_bound=0.278, batch=230 
386: loss=1.112, reward_mean=0.050, reward_bound=0.387, batch=202 
387: loss=1.104, reward_mean=0.110, reward_bound=0.155, batch=211 
388: loss=1.104, reward_mean=0.060, reward_bound=0.000, batch=217 
389: loss=1.104, reward_mean=0.100, reward_bound=0.229, batch=220 
390: loss=1.100, reward_mean=0.080, reward_bound=0.247, batch=224 
391: loss=1.100, reward_mean=0.060, reward_bound=0.183, batch=227 
392: loss=1.100, reward_mean=0.040, reward_bound=0.220, batch=229 
393: loss=1.100, reward_mean=0.070, reward_bound=0.254, batch=228 
394: loss=1.099, reward_mean=0.020, reward_bound=0.150, batch=229 
395: loss=1.095, reward_mean=0.050, reward_bound=0.282, batch=226 
396: loss=1.096, reward_mean=0.060, reward_bound=0.210, batch=228 
397: loss=1.097, reward_mean=0.060, reward_bound=0.314, batch=221 
398: loss=1.098, reward_mean=0.060, reward_bound=0.206, batch=224 
399: loss=1.097, reward_mean=0.030, reward_bound=0.098, batch=227 
400: loss=1.096, reward_mean=0.100, reward_bound=0.254, batch=227 
401: loss=1.096, reward_mean=0.110, reward_bound=0.349, batch=227 
402: loss=1.097, reward_mean=0.060, reward_bound=0.254, batch=228 
403: loss=1.099, reward_mean=0.060, reward_bound=0.387, batch=225 
404: loss=1.098, reward_mean=0.070, reward_bound=0.289, batch=227 
405: loss=1.098, reward_mean=0.090, reward_bound=0.387, batch=226 
406: loss=1.096, reward_mean=0.050, reward_bound=0.390, batch=228 
407: loss=1.095, reward_mean=0.030, reward_bound=0.268, batch=229 
408: loss=1.095, reward_mean=0.050, reward_bound=0.349, batch=229 
409: loss=1.094, reward_mean=0.020, reward_bound=0.187, batch=230 
410: loss=1.095, reward_mean=0.040, reward_bound=0.376, batch=231 
411: loss=1.095, reward_mean=0.010, reward_bound=0.282, batch=231 
412: loss=1.095, reward_mean=0.020, reward_bound=0.349, batch=231 
413: loss=1.094, reward_mean=0.130, reward_bound=0.387, batch=231 
414: loss=1.121, reward_mean=0.050, reward_bound=0.430, batch=182 
415: loss=1.116, reward_mean=0.040, reward_bound=0.000, batch=186 
416: loss=1.111, reward_mean=0.070, reward_bound=0.000, batch=193 
417: loss=1.104, reward_mean=0.070, reward_bound=0.000, batch=200 
418: loss=1.095, reward_mean=0.100, reward_bound=0.041, batch=210 
419: loss=1.087, reward_mean=0.100, reward_bound=0.063, batch=217 
420: loss=1.095, reward_mean=0.100, reward_bound=0.087, batch=222 
421: loss=1.091, reward_mean=0.060, reward_bound=0.102, batch=225 
422: loss=1.090, reward_mean=0.060, reward_bound=0.167, batch=225 
423: loss=1.096, reward_mean=0.070, reward_bound=0.206, batch=222 
424: loss=1.096, reward_mean=0.050, reward_bound=0.213, batch=225 
425: loss=1.097, reward_mean=0.090, reward_bound=0.229, batch=225 
426: loss=1.097, reward_mean=0.110, reward_bound=0.254, batch=224 
427: loss=1.095, reward_mean=0.040, reward_bound=0.244, batch=227 
428: loss=1.096, reward_mean=0.050, reward_bound=0.277, batch=229 
429: loss=1.098, reward_mean=0.050, reward_bound=0.282, batch=228 
430: loss=1.097, reward_mean=0.010, reward_bound=0.031, batch=229 
431: loss=1.106, reward_mean=0.040, reward_bound=0.314, batch=220 
432: loss=1.106, reward_mean=0.050, reward_bound=0.170, batch=224 
433: loss=1.101, reward_mean=0.060, reward_bound=0.247, batch=227 
434: loss=1.101, reward_mean=0.080, reward_bound=0.342, batch=229 
435: loss=1.103, reward_mean=0.060, reward_bound=0.349, batch=222 
436: loss=1.102, reward_mean=0.080, reward_bound=0.263, batch=225 
437: loss=1.103, reward_mean=0.060, reward_bound=0.289, batch=227 
438: loss=1.100, reward_mean=0.050, reward_bound=0.314, batch=228 
439: loss=1.098, reward_mean=0.100, reward_bound=0.349, batch=228 
440: loss=1.103, reward_mean=0.070, reward_bound=0.387, batch=220 
441: loss=1.101, reward_mean=0.040, reward_bound=0.069, batch=224 
442: loss=1.097, reward_mean=0.050, reward_bound=0.160, batch=227 
443: loss=1.101, reward_mean=0.070, reward_bound=0.229, batch=228 
444: loss=1.099, reward_mean=0.050, reward_bound=0.349, batch=228 
445: loss=1.099, reward_mean=0.040, reward_bound=0.317, batch=229 
446: loss=1.098, reward_mean=0.090, reward_bound=0.387, batch=229 
447: loss=1.107, reward_mean=0.080, reward_bound=0.430, batch=211 
448: loss=1.107, reward_mean=0.080, reward_bound=0.282, batch=214 
449: loss=1.105, reward_mean=0.090, reward_bound=0.280, batch=220 
450: loss=1.106, reward_mean=0.040, reward_bound=0.062, batch=224 
451: loss=1.107, reward_mean=0.080, reward_bound=0.282, batch=225 
452: loss=1.108, reward_mean=0.080, reward_bound=0.314, batch=226 
453: loss=1.106, reward_mean=0.040, reward_bound=0.349, batch=227 
454: loss=1.104, reward_mean=0.090, reward_bound=0.380, batch=229 
455: loss=1.104, reward_mean=0.100, reward_bound=0.387, batch=224 
456: loss=1.100, reward_mean=0.070, reward_bound=0.252, batch=227 
457: loss=1.100, reward_mean=0.050, reward_bound=0.277, batch=229 
458: loss=1.102, reward_mean=0.060, reward_bound=0.295, batch=230 
459: loss=1.102, reward_mean=0.050, reward_bound=0.349, batch=229 
460: loss=1.102, reward_mean=0.100, reward_bound=0.387, batch=229 
461: loss=1.101, reward_mean=0.030, reward_bound=0.381, batch=230 
462: loss=1.103, reward_mean=0.030, reward_bound=0.430, batch=224 
463: loss=1.102, reward_mean=0.090, reward_bound=0.308, batch=227 
464: loss=1.104, reward_mean=0.060, reward_bound=0.349, batch=228 
465: loss=1.104, reward_mean=0.040, reward_bound=0.229, batch=228 
466: loss=1.103, reward_mean=0.040, reward_bound=0.392, batch=229 
467: loss=1.104, reward_mean=0.050, reward_bound=0.309, batch=230 
468: loss=1.102, reward_mean=0.080, reward_bound=0.406, batch=231 
469: loss=1.075, reward_mean=0.070, reward_bound=0.478, batch=95 
470: loss=1.069, reward_mean=0.050, reward_bound=0.000, batch=100 
471: loss=1.070, reward_mean=0.030, reward_bound=0.000, batch=103 
472: loss=1.071, reward_mean=0.050, reward_bound=0.000, batch=108 
473: loss=1.068, reward_mean=0.040, reward_bound=0.000, batch=112 
474: loss=1.062, reward_mean=0.070, reward_bound=0.000, batch=119 
475: loss=1.057, reward_mean=0.040, reward_bound=0.000, batch=123 
476: loss=1.055, reward_mean=0.060, reward_bound=0.000, batch=129 
477: loss=1.059, reward_mean=0.090, reward_bound=0.000, batch=138 
478: loss=1.051, reward_mean=0.090, reward_bound=0.000, batch=147 
479: loss=1.050, reward_mean=0.030, reward_bound=0.000, batch=150 
480: loss=1.054, reward_mean=0.040, reward_bound=0.000, batch=154 
481: loss=1.052, reward_mean=0.070, reward_bound=0.000, batch=161 
482: loss=1.052, reward_mean=0.070, reward_bound=0.000, batch=168 
483: loss=1.053, reward_mean=0.060, reward_bound=0.000, batch=174 
484: loss=1.052, reward_mean=0.060, reward_bound=0.000, batch=180 
485: loss=1.051, reward_mean=0.040, reward_bound=0.000, batch=184 
486: loss=1.049, reward_mean=0.040, reward_bound=0.000, batch=188 
487: loss=1.050, reward_mean=0.030, reward_bound=0.000, batch=191 
488: loss=1.045, reward_mean=0.100, reward_bound=0.000, batch=201 
489: loss=1.044, reward_mean=0.010, reward_bound=0.000, batch=202 
490: loss=1.041, reward_mean=0.060, reward_bound=0.000, batch=208 
491: loss=1.044, reward_mean=0.080, reward_bound=0.033, batch=215 
492: loss=1.044, reward_mean=0.040, reward_bound=0.000, batch=219 
493: loss=1.053, reward_mean=0.110, reward_bound=0.080, batch=221 
494: loss=1.046, reward_mean=0.070, reward_bound=0.098, batch=224 
495: loss=1.049, reward_mean=0.060, reward_bound=0.134, batch=227 
496: loss=1.055, reward_mean=0.100, reward_bound=0.163, batch=229 
497: loss=1.057, reward_mean=0.040, reward_bound=0.167, batch=229 
498: loss=1.053, reward_mean=0.070, reward_bound=0.185, batch=225 
499: loss=1.058, reward_mean=0.060, reward_bound=0.206, batch=219 
500: loss=1.052, reward_mean=0.110, reward_bound=0.229, batch=215 
501: loss=1.048, reward_mean=0.070, reward_bound=0.098, batch=219 
502: loss=1.053, reward_mean=0.060, reward_bound=0.172, batch=223 
503: loss=1.045, reward_mean=0.050, reward_bound=0.229, batch=225 
504: loss=1.046, reward_mean=0.090, reward_bound=0.234, batch=227 
505: loss=1.048, reward_mean=0.110, reward_bound=0.254, batch=216 
506: loss=1.048, reward_mean=0.070, reward_bound=0.206, batch=220 
507: loss=1.048, reward_mean=0.030, reward_bound=0.000, batch=223 
508: loss=1.045, reward_mean=0.070, reward_bound=0.181, batch=226 
509: loss=1.048, reward_mean=0.040, reward_bound=0.229, batch=227 
510: loss=1.057, reward_mean=0.100, reward_bound=0.282, batch=208 
511: loss=1.051, reward_mean=0.100, reward_bound=0.231, batch=215 
512: loss=1.053, reward_mean=0.070, reward_bound=0.254, batch=219 
513: loss=1.056, reward_mean=0.100, reward_bound=0.314, batch=202 
514: loss=1.055, reward_mean=0.050, reward_bound=0.000, batch=207 
515: loss=1.058, reward_mean=0.050, reward_bound=0.000, batch=212 
516: loss=1.060, reward_mean=0.070, reward_bound=0.081, batch=218 
517: loss=1.060, reward_mean=0.050, reward_bound=0.015, batch=222 
518: loss=1.058, reward_mean=0.060, reward_bound=0.155, batch=225 
519: loss=1.051, reward_mean=0.070, reward_bound=0.167, batch=226 
520: loss=1.053, reward_mean=0.040, reward_bound=0.196, batch=228 
521: loss=1.051, reward_mean=0.070, reward_bound=0.257, batch=229 
522: loss=1.046, reward_mean=0.040, reward_bound=0.282, batch=224 
523: loss=1.049, reward_mean=0.080, reward_bound=0.305, batch=227 
524: loss=1.047, reward_mean=0.040, reward_bound=0.163, batch=229 
525: loss=1.052, reward_mean=0.060, reward_bound=0.314, batch=228 
526: loss=1.051, reward_mean=0.070, reward_bound=0.317, batch=229 
527: loss=1.055, reward_mean=0.060, reward_bound=0.349, batch=200 
528: loss=1.061, reward_mean=0.100, reward_bound=0.033, batch=210 
529: loss=1.056, reward_mean=0.090, reward_bound=0.200, batch=217 
530: loss=1.064, reward_mean=0.070, reward_bound=0.206, batch=221 
531: loss=1.066, reward_mean=0.030, reward_bound=0.000, batch=224 
532: loss=1.062, reward_mean=0.080, reward_bound=0.229, batch=226 
533: loss=1.064, reward_mean=0.050, reward_bound=0.254, batch=226 
534: loss=1.059, reward_mean=0.040, reward_bound=0.282, batch=225 
535: loss=1.055, reward_mean=0.120, reward_bound=0.314, batch=224 
536: loss=1.053, reward_mean=0.040, reward_bound=0.303, batch=227 
537: loss=1.052, reward_mean=0.030, reward_bound=0.308, batch=229 
538: loss=1.053, reward_mean=0.040, reward_bound=0.216, batch=230 
539: loss=1.055, reward_mean=0.060, reward_bound=0.314, batch=230 
540: loss=1.053, reward_mean=0.110, reward_bound=0.349, batch=225 
541: loss=1.053, reward_mean=0.070, reward_bound=0.321, batch=227 
542: loss=1.052, reward_mean=0.050, reward_bound=0.342, batch=229 
543: loss=1.050, reward_mean=0.030, reward_bound=0.364, batch=230 
544: loss=1.053, reward_mean=0.060, reward_bound=0.387, batch=195 
545: loss=1.055, reward_mean=0.030, reward_bound=0.000, batch=198 
546: loss=1.058, reward_mean=0.050, reward_bound=0.000, batch=203 
547: loss=1.056, reward_mean=0.050, reward_bound=0.000, batch=208 
548: loss=1.057, reward_mean=0.060, reward_bound=0.000, batch=214 
549: loss=1.057, reward_mean=0.050, reward_bound=0.000, batch=219 
550: loss=1.053, reward_mean=0.060, reward_bound=0.072, batch=221 
551: loss=1.057, reward_mean=0.070, reward_bound=0.109, batch=224 
552: loss=1.057, reward_mean=0.080, reward_bound=0.183, batch=227 
553: loss=1.056, reward_mean=0.040, reward_bound=0.178, batch=229 
554: loss=1.051, reward_mean=0.040, reward_bound=0.206, batch=227 
555: loss=1.052, reward_mean=0.070, reward_bound=0.254, batch=227 
556: loss=1.049, reward_mean=0.050, reward_bound=0.282, batch=226 
557: loss=1.047, reward_mean=0.100, reward_bound=0.314, batch=223 
558: loss=1.048, reward_mean=0.070, reward_bound=0.349, batch=222 
559: loss=1.048, reward_mean=0.050, reward_bound=0.254, batch=225 
560: loss=1.049, reward_mean=0.100, reward_bound=0.314, batch=225 
561: loss=1.047, reward_mean=0.060, reward_bound=0.282, batch=226 
562: loss=1.049, reward_mean=0.080, reward_bound=0.349, batch=227 
563: loss=1.052, reward_mean=0.050, reward_bound=0.387, batch=219 
564: loss=1.048, reward_mean=0.100, reward_bound=0.278, batch=223 
565: loss=1.047, reward_mean=0.090, reward_bound=0.290, batch=226 
566: loss=1.046, reward_mean=0.030, reward_bound=0.260, batch=228 
567: loss=1.046, reward_mean=0.050, reward_bound=0.234, batch=229 
568: loss=1.048, reward_mean=0.090, reward_bound=0.328, batch=230 
569: loss=1.049, reward_mean=0.050, reward_bound=0.376, batch=231 
570: loss=1.051, reward_mean=0.080, reward_bound=0.387, batch=231 
571: loss=1.040, reward_mean=0.060, reward_bound=0.430, batch=177 
572: loss=1.039, reward_mean=0.050, reward_bound=0.000, batch=182 
573: loss=1.038, reward_mean=0.060, reward_bound=0.000, batch=188 
574: loss=1.045, reward_mean=0.050, reward_bound=0.000, batch=193 
575: loss=1.045, reward_mean=0.080, reward_bound=0.000, batch=201 
576: loss=1.045, reward_mean=0.100, reward_bound=0.009, batch=210 
577: loss=1.044, reward_mean=0.030, reward_bound=0.000, batch=213 
578: loss=1.044, reward_mean=0.060, reward_bound=0.039, batch=219 
579: loss=1.040, reward_mean=0.060, reward_bound=0.067, batch=223 
580: loss=1.041, reward_mean=0.080, reward_bound=0.134, batch=226 
581: loss=1.042, reward_mean=0.040, reward_bound=0.158, batch=228 
582: loss=1.033, reward_mean=0.140, reward_bound=0.206, batch=226 
583: loss=1.033, reward_mean=0.070, reward_bound=0.229, batch=227 
584: loss=1.030, reward_mean=0.110, reward_bound=0.277, batch=229 
585: loss=1.034, reward_mean=0.120, reward_bound=0.282, batch=225 
586: loss=1.033, reward_mean=0.120, reward_bound=0.314, batch=224 
587: loss=1.035, reward_mean=0.050, reward_bound=0.216, batch=227 
588: loss=1.033, reward_mean=0.040, reward_bound=0.224, batch=229 
589: loss=1.030, reward_mean=0.080, reward_bound=0.282, batch=228 
590: loss=1.030, reward_mean=0.090, reward_bound=0.317, batch=229 
591: loss=1.035, reward_mean=0.040, reward_bound=0.349, batch=215 
592: loss=1.032, reward_mean=0.030, reward_bound=0.000, batch=218 
593: loss=1.033, reward_mean=0.090, reward_bound=0.286, batch=222 
594: loss=1.030, reward_mean=0.070, reward_bound=0.349, batch=223 
595: loss=1.026, reward_mean=0.030, reward_bound=0.100, batch=226 
596: loss=1.029, reward_mean=0.080, reward_bound=0.185, batch=227 
597: loss=1.028, reward_mean=0.060, reward_bound=0.342, batch=229 
598: loss=1.030, reward_mean=0.080, reward_bound=0.387, batch=214 
599: loss=1.031, reward_mean=0.080, reward_bound=0.206, batch=219 
600: loss=1.028, reward_mean=0.030, reward_bound=0.000, batch=222 
601: loss=1.026, reward_mean=0.020, reward_bound=0.000, batch=224 
602: loss=1.030, reward_mean=0.070, reward_bound=0.224, batch=227 
603: loss=1.029, reward_mean=0.090, reward_bound=0.282, batch=228 
604: loss=1.031, reward_mean=0.040, reward_bound=0.234, batch=229 
605: loss=1.031, reward_mean=0.010, reward_bound=0.113, batch=230 
606: loss=1.027, reward_mean=0.050, reward_bound=0.314, batch=229 
607: loss=1.027, reward_mean=0.050, reward_bound=0.328, batch=230 
608: loss=1.026, reward_mean=0.050, reward_bound=0.349, batch=230 
609: loss=1.027, reward_mean=0.110, reward_bound=0.387, batch=228 
610: loss=1.026, reward_mean=0.120, reward_bound=0.297, batch=229 
611: loss=1.026, reward_mean=0.060, reward_bound=0.405, batch=230 
612: loss=1.025, reward_mean=0.060, reward_bound=0.418, batch=231 
613: loss=1.025, reward_mean=0.040, reward_bound=0.254, batch=231 
614: loss=1.032, reward_mean=0.080, reward_bound=0.430, batch=208 
615: loss=1.030, reward_mean=0.080, reward_bound=0.043, batch=215 
616: loss=1.024, reward_mean=0.060, reward_bound=0.095, batch=220 
617: loss=1.022, reward_mean=0.080, reward_bound=0.194, batch=224 
618: loss=1.024, reward_mean=0.100, reward_bound=0.280, batch=227 
619: loss=1.022, reward_mean=0.060, reward_bound=0.282, batch=227 
620: loss=1.021, reward_mean=0.050, reward_bound=0.256, batch=229 
621: loss=1.021, reward_mean=0.080, reward_bound=0.314, batch=228 
622: loss=1.022, reward_mean=0.090, reward_bound=0.349, batch=222 
623: loss=1.024, reward_mean=0.110, reward_bound=0.387, batch=223 
624: loss=1.023, reward_mean=0.060, reward_bound=0.229, batch=225 
625: loss=1.024, reward_mean=0.080, reward_bound=0.321, batch=227 
626: loss=1.023, reward_mean=0.070, reward_bound=0.349, batch=227 
627: loss=1.022, reward_mean=0.100, reward_bound=0.387, batch=227 
628: loss=1.021, reward_mean=0.100, reward_bound=0.422, batch=229 
629: loss=1.029, reward_mean=0.090, reward_bound=0.430, batch=222 
630: loss=1.027, reward_mean=0.080, reward_bound=0.387, batch=224 
631: loss=1.027, reward_mean=0.070, reward_bound=0.342, batch=227 
632: loss=1.025, reward_mean=0.050, reward_bound=0.206, batch=228 
633: loss=1.025, reward_mean=0.050, reward_bound=0.349, batch=228 
634: loss=1.025, reward_mean=0.040, reward_bound=0.353, batch=229 
635: loss=1.026, reward_mean=0.110, reward_bound=0.387, batch=228 
636: loss=1.025, reward_mean=0.070, reward_bound=0.392, batch=229 
637: loss=1.026, reward_mean=0.060, reward_bound=0.450, batch=230 
638: loss=1.025, reward_mean=0.040, reward_bound=0.406, batch=231 
639: loss=1.027, reward_mean=0.070, reward_bound=0.430, batch=231 
640: loss=1.027, reward_mean=0.110, reward_bound=0.430, batch=231 
641: loss=1.027, reward_mean=0.090, reward_bound=0.387, batch=231 
642: loss=1.037, reward_mean=0.070, reward_bound=0.478, batch=158 
643: loss=1.030, reward_mean=0.090, reward_bound=0.000, batch=167 
644: loss=1.028, reward_mean=0.010, reward_bound=0.000, batch=168 
645: loss=1.023, reward_mean=0.070, reward_bound=0.000, batch=175 
646: loss=1.019, reward_mean=0.080, reward_bound=0.000, batch=183 
647: loss=1.014, reward_mean=0.050, reward_bound=0.000, batch=188 
648: loss=1.018, reward_mean=0.110, reward_bound=0.000, batch=199 
649: loss=1.016, reward_mean=0.090, reward_bound=0.000, batch=208 
650: loss=1.009, reward_mean=0.050, reward_bound=0.000, batch=213 
651: loss=1.009, reward_mean=0.080, reward_bound=0.077, batch=219 
652: loss=1.011, reward_mean=0.110, reward_bound=0.122, batch=222 
653: loss=1.010, reward_mean=0.130, reward_bound=0.206, batch=226 
654: loss=1.009, reward_mean=0.020, reward_bound=0.083, batch=228 
655: loss=1.009, reward_mean=0.040, reward_bound=0.171, batch=229 
656: loss=1.008, reward_mean=0.110, reward_bound=0.229, batch=224 
657: loss=1.012, reward_mean=0.060, reward_bound=0.252, batch=227 
658: loss=1.012, reward_mean=0.020, reward_bound=0.088, batch=229 
659: loss=1.007, reward_mean=0.070, reward_bound=0.254, batch=227 
660: loss=1.009, reward_mean=0.070, reward_bound=0.282, batch=221 
661: loss=1.010, reward_mean=0.060, reward_bound=0.150, batch=224 
662: loss=1.015, reward_mean=0.100, reward_bound=0.314, batch=209 
663: loss=1.016, reward_mean=0.100, reward_bound=0.194, batch=216 
664: loss=1.015, reward_mean=0.050, reward_bound=0.040, batch=221 
665: loss=1.017, reward_mean=0.060, reward_bound=0.185, batch=224 
666: loss=1.013, reward_mean=0.090, reward_bound=0.282, batch=226 
667: loss=1.013, reward_mean=0.010, reward_bound=0.000, batch=227 
668: loss=1.015, reward_mean=0.040, reward_bound=0.220, batch=229 
669: loss=1.015, reward_mean=0.050, reward_bound=0.215, batch=230 
670: loss=1.018, reward_mean=0.120, reward_bound=0.349, batch=221 
671: loss=1.025, reward_mean=0.100, reward_bound=0.387, batch=200 
672: loss=1.023, reward_mean=0.090, reward_bound=0.000, batch=209 
673: loss=1.019, reward_mean=0.080, reward_bound=0.127, batch=216 
674: loss=1.020, reward_mean=0.020, reward_bound=0.000, batch=218 
675: loss=1.021, reward_mean=0.040, reward_bound=0.014, batch=222 
676: loss=1.023, reward_mean=0.050, reward_bound=0.140, batch=225 
677: loss=1.019, reward_mean=0.070, reward_bound=0.189, batch=227 
678: loss=1.017, reward_mean=0.090, reward_bound=0.254, batch=227 
679: loss=1.014, reward_mean=0.110, reward_bound=0.282, batch=228 
680: loss=1.018, reward_mean=0.060, reward_bound=0.314, batch=226 
681: loss=1.016, reward_mean=0.030, reward_bound=0.138, batch=228 
682: loss=1.013, reward_mean=0.070, reward_bound=0.349, batch=225 
683: loss=1.011, reward_mean=0.060, reward_bound=0.281, batch=227 
684: loss=1.016, reward_mean=0.060, reward_bound=0.387, batch=221 
685: loss=1.017, reward_mean=0.100, reward_bound=0.349, batch=223 
686: loss=1.018, reward_mean=0.060, reward_bound=0.244, batch=226 
687: loss=1.019, reward_mean=0.040, reward_bound=0.335, batch=228 
688: loss=1.015, reward_mean=0.070, reward_bound=0.387, batch=228 
689: loss=1.022, reward_mean=0.110, reward_bound=0.430, batch=201 
690: loss=1.022, reward_mean=0.060, reward_bound=0.000, batch=207 
691: loss=1.014, reward_mean=0.040, reward_bound=0.000, batch=211 
692: loss=1.007, reward_mean=0.050, reward_bound=0.000, batch=216 
693: loss=1.009, reward_mean=0.050, reward_bound=0.026, batch=221 
694: loss=1.012, reward_mean=0.040, reward_bound=0.052, batch=224 
695: loss=1.017, reward_mean=0.060, reward_bound=0.135, batch=226 
696: loss=1.015, reward_mean=0.070, reward_bound=0.217, batch=228 
697: loss=1.013, reward_mean=0.080, reward_bound=0.231, batch=229 
698: loss=1.017, reward_mean=0.060, reward_bound=0.282, batch=229 
699: loss=1.017, reward_mean=0.050, reward_bound=0.278, batch=230 
700: loss=1.017, reward_mean=0.040, reward_bound=0.314, batch=230 
701: loss=1.020, reward_mean=0.060, reward_bound=0.349, batch=225 
702: loss=1.018, reward_mean=0.070, reward_bound=0.349, batch=226 
703: loss=1.021, reward_mean=0.060, reward_bound=0.331, batch=228 
704: loss=1.021, reward_mean=0.030, reward_bound=0.349, batch=228 
705: loss=1.020, reward_mean=0.080, reward_bound=0.387, batch=224 
706: loss=1.016, reward_mean=0.060, reward_bound=0.345, batch=227 
707: loss=1.018, reward_mean=0.110, reward_bound=0.422, batch=229 
708: loss=1.013, reward_mean=0.100, reward_bound=0.430, batch=216 
709: loss=1.014, reward_mean=0.010, reward_bound=0.000, batch=217 
710: loss=1.012, reward_mean=0.100, reward_bound=0.245, batch=222 
711: loss=1.013, reward_mean=0.080, reward_bound=0.282, batch=224 
712: loss=1.010, reward_mean=0.060, reward_bound=0.349, batch=226 
713: loss=1.012, reward_mean=0.040, reward_bound=0.298, batch=228 
714: loss=1.011, reward_mean=0.070, reward_bound=0.314, batch=228 
715: loss=1.012, reward_mean=0.060, reward_bound=0.387, batch=224 
716: loss=1.012, reward_mean=0.080, reward_bound=0.387, batch=226 
717: loss=1.013, reward_mean=0.030, reward_bound=0.130, batch=228 
718: loss=1.013, reward_mean=0.090, reward_bound=0.349, batch=228 
719: loss=1.013, reward_mean=0.070, reward_bound=0.430, batch=225 
720: loss=1.017, reward_mean=0.040, reward_bound=0.254, batch=226 
721: loss=1.019, reward_mean=0.060, reward_bound=0.301, batch=228 
722: loss=1.017, reward_mean=0.080, reward_bound=0.357, batch=229 
723: loss=1.015, reward_mean=0.070, reward_bound=0.405, batch=230 
724: loss=1.016, reward_mean=0.030, reward_bound=0.266, batch=231 
725: loss=1.016, reward_mean=0.100, reward_bound=0.430, batch=229 
726: loss=1.017, reward_mean=0.100, reward_bound=0.478, batch=231 
727: loss=1.017, reward_mean=0.080, reward_bound=0.387, batch=231 
728: loss=1.021, reward_mean=0.090, reward_bound=0.478, batch=188 
729: loss=1.024, reward_mean=0.060, reward_bound=0.000, batch=194 
730: loss=1.025, reward_mean=0.060, reward_bound=0.000, batch=200 
731: loss=1.020, reward_mean=0.070, reward_bound=0.000, batch=207 
732: loss=1.028, reward_mean=0.120, reward_bound=0.150, batch=213 
733: loss=1.022, reward_mean=0.080, reward_bound=0.178, batch=219 
734: loss=1.021, reward_mean=0.050, reward_bound=0.140, batch=223 
735: loss=1.016, reward_mean=0.060, reward_bound=0.206, batch=222 
736: loss=1.018, reward_mean=0.040, reward_bound=0.179, batch=225 
737: loss=1.016, reward_mean=0.090, reward_bound=0.229, batch=226 
738: loss=1.013, reward_mean=0.100, reward_bound=0.282, batch=222 
739: loss=1.018, reward_mean=0.120, reward_bound=0.314, batch=222 
740: loss=1.015, reward_mean=0.050, reward_bound=0.283, batch=225 
741: loss=1.012, reward_mean=0.110, reward_bound=0.349, batch=221 
742: loss=1.010, reward_mean=0.070, reward_bound=0.167, batch=224 
743: loss=1.012, reward_mean=0.070, reward_bound=0.377, batch=227 
744: loss=1.011, reward_mean=0.040, reward_bound=0.206, batch=228 
745: loss=1.011, reward_mean=0.020, reward_bound=0.317, batch=229 
746: loss=1.011, reward_mean=0.030, reward_bound=0.309, batch=230 
747: loss=1.011, reward_mean=0.080, reward_bound=0.376, batch=231 
748: loss=1.018, reward_mean=0.090, reward_bound=0.387, batch=226 
749: loss=1.018, reward_mean=0.070, reward_bound=0.372, batch=228 
750: loss=1.017, reward_mean=0.030, reward_bound=0.325, batch=229 
751: loss=1.017, reward_mean=0.060, reward_bound=0.405, batch=230 
752: loss=1.019, reward_mean=0.050, reward_bound=0.430, batch=211 
753: loss=1.013, reward_mean=0.070, reward_bound=0.229, batch=217 
754: loss=1.011, reward_mean=0.070, reward_bound=0.342, batch=222 
755: loss=1.011, reward_mean=0.050, reward_bound=0.292, batch=225 
756: loss=1.009, reward_mean=0.090, reward_bound=0.314, batch=226 
757: loss=1.010, reward_mean=0.080, reward_bound=0.349, batch=225 
758: loss=1.008, reward_mean=0.060, reward_bound=0.321, batch=227 
759: loss=1.010, reward_mean=0.060, reward_bound=0.249, batch=229 
760: loss=1.015, reward_mean=0.090, reward_bound=0.387, batch=222 
761: loss=1.014, reward_mean=0.060, reward_bound=0.220, batch=225 
762: loss=1.014, reward_mean=0.070, reward_bound=0.260, batch=227 
763: loss=1.014, reward_mean=0.050, reward_bound=0.308, batch=229 
764: loss=1.017, reward_mean=0.120, reward_bound=0.349, batch=228 
765: loss=1.016, reward_mean=0.060, reward_bound=0.387, batch=227 
766: loss=1.017, reward_mean=0.030, reward_bound=0.166, batch=229 
767: loss=1.015, reward_mean=0.040, reward_bound=0.324, batch=230 
768: loss=1.015, reward_mean=0.090, reward_bound=0.376, batch=231 
769: loss=1.015, reward_mean=0.060, reward_bound=0.387, batch=231 
770: loss=1.015, reward_mean=0.030, reward_bound=0.430, batch=223 
771: loss=1.014, reward_mean=0.060, reward_bound=0.430, batch=225 
772: loss=1.013, reward_mean=0.060, reward_bound=0.440, batch=227 
773: loss=1.012, reward_mean=0.050, reward_bound=0.314, batch=228 
774: loss=1.013, reward_mean=0.050, reward_bound=0.349, batch=228 
775: loss=1.013, reward_mean=0.100, reward_bound=0.392, batch=229 
776: loss=1.014, reward_mean=0.040, reward_bound=0.360, batch=230 
777: loss=1.015, reward_mean=0.070, reward_bound=0.430, batch=229 
778: loss=1.014, reward_mean=0.040, reward_bound=0.364, batch=230 
779: loss=1.016, reward_mean=0.030, reward_bound=0.308, batch=231 
780: loss=1.017, reward_mean=0.080, reward_bound=0.387, batch=230 
781: loss=1.018, reward_mean=0.070, reward_bound=0.464, batch=231 
782: loss=1.018, reward_mean=0.030, reward_bound=0.430, batch=231 
783: loss=1.018, reward_mean=0.070, reward_bound=0.430, batch=231 
784: loss=1.018, reward_mean=0.060, reward_bound=0.478, batch=206 
785: loss=1.014, reward_mean=0.050, reward_bound=0.000, batch=211 
786: loss=1.013, reward_mean=0.090, reward_bound=0.109, batch=216 
787: loss=1.010, reward_mean=0.070, reward_bound=0.143, batch=221 
788: loss=1.007, reward_mean=0.050, reward_bound=0.167, batch=224 
789: loss=1.009, reward_mean=0.090, reward_bound=0.229, batch=226 
790: loss=1.011, reward_mean=0.070, reward_bound=0.282, batch=226 
791: loss=1.013, reward_mean=0.070, reward_bound=0.314, batch=227 
792: loss=1.014, reward_mean=0.110, reward_bound=0.380, batch=229 
793: loss=1.012, reward_mean=0.060, reward_bound=0.387, batch=225 
794: loss=1.009, reward_mean=0.070, reward_bound=0.356, batch=227 
795: loss=1.007, reward_mean=0.070, reward_bound=0.380, batch=229 
796: loss=1.011, reward_mean=0.080, reward_bound=0.387, batch=227 
797: loss=1.012, reward_mean=0.060, reward_bound=0.380, batch=229 
798: loss=1.010, reward_mean=0.060, reward_bound=0.387, batch=228 
799: loss=1.010, reward_mean=0.070, reward_bound=0.392, batch=229 
800: loss=1.010, reward_mean=0.060, reward_bound=0.381, batch=230 
801: loss=1.010, reward_mean=0.030, reward_bound=0.363, batch=231 
802: loss=1.016, reward_mean=0.100, reward_bound=0.430, batch=219 
803: loss=1.017, reward_mean=0.070, reward_bound=0.364, batch=223 
804: loss=1.016, reward_mean=0.030, reward_bound=0.169, batch=226 
805: loss=1.014, reward_mean=0.080, reward_bound=0.282, batch=227 
806: loss=1.015, reward_mean=0.080, reward_bound=0.387, batch=227 
807: loss=1.013, reward_mean=0.070, reward_bound=0.414, batch=229 
808: loss=1.013, reward_mean=0.080, reward_bound=0.430, batch=226 
809: loss=1.013, reward_mean=0.070, reward_bound=0.390, batch=228 
810: loss=1.012, reward_mean=0.070, reward_bound=0.392, batch=229 
811: loss=1.011, reward_mean=0.120, reward_bound=0.430, batch=229 
812: loss=1.011, reward_mean=0.060, reward_bound=0.478, batch=231 
813: loss=1.013, reward_mean=0.070, reward_bound=0.478, batch=221 
814: loss=1.013, reward_mean=0.100, reward_bound=0.254, batch=224 
815: loss=1.010, reward_mean=0.030, reward_bound=0.167, batch=227 
816: loss=1.010, reward_mean=0.080, reward_bound=0.314, batch=227 
817: loss=1.010, reward_mean=0.090, reward_bound=0.314, batch=228 
818: loss=1.011, reward_mean=0.060, reward_bound=0.349, batch=226 
819: loss=1.010, reward_mean=0.090, reward_bound=0.409, batch=228 
820: loss=1.010, reward_mean=0.050, reward_bound=0.325, batch=229 
821: loss=1.009, reward_mean=0.060, reward_bound=0.360, batch=230 
822: loss=1.011, reward_mean=0.090, reward_bound=0.430, batch=228 
823: loss=1.012, reward_mean=0.060, reward_bound=0.478, batch=231 
824: loss=1.014, reward_mean=0.130, reward_bound=0.478, batch=228 
825: loss=1.014, reward_mean=0.060, reward_bound=0.353, batch=229 
826: loss=1.013, reward_mean=0.030, reward_bound=0.364, batch=230 
827: loss=1.014, reward_mean=0.070, reward_bound=0.304, batch=231 
828: loss=1.016, reward_mean=0.080, reward_bound=0.387, batch=230 
829: loss=1.013, reward_mean=0.060, reward_bound=0.478, batch=229 
830: loss=1.014, reward_mean=0.020, reward_bound=0.211, batch=230 
831: loss=1.013, reward_mean=0.100, reward_bound=0.430, batch=229 
832: loss=1.012, reward_mean=0.020, reward_bound=0.169, batch=230 
833: loss=1.013, reward_mean=0.030, reward_bound=0.314, batch=229 
834: loss=1.013, reward_mean=0.090, reward_bound=0.387, batch=229 
835: loss=1.014, reward_mean=0.020, reward_bound=0.283, batch=230 
836: loss=1.014, reward_mean=0.030, reward_bound=0.365, batch=231 
837: loss=1.014, reward_mean=0.100, reward_bound=0.349, batch=231 
838: loss=1.012, reward_mean=0.040, reward_bound=0.387, batch=231 
839: loss=1.012, reward_mean=0.080, reward_bound=0.430, batch=230 
840: loss=1.012, reward_mean=0.040, reward_bound=0.296, batch=231 
841: loss=1.012, reward_mean=0.100, reward_bound=0.430, batch=231 
842: loss=1.012, reward_mean=0.040, reward_bound=0.349, batch=231 
843: loss=1.012, reward_mean=0.060, reward_bound=0.430, batch=231 
844: loss=1.013, reward_mean=0.050, reward_bound=0.478, batch=230 
845: loss=1.013, reward_mean=0.100, reward_bound=0.464, batch=231 
846: loss=1.013, reward_mean=0.050, reward_bound=0.349, batch=231 
847: loss=1.013, reward_mean=0.080, reward_bound=0.478, batch=230 
848: loss=1.012, reward_mean=0.010, reward_bound=0.271, batch=231 
849: loss=1.015, reward_mean=0.050, reward_bound=0.387, batch=231 
850: loss=1.011, reward_mean=0.070, reward_bound=0.430, batch=231 
851: loss=1.013, reward_mean=0.040, reward_bound=0.478, batch=231 
852: loss=1.013, reward_mean=0.020, reward_bound=0.229, batch=231 
853: loss=1.013, reward_mean=0.010, reward_bound=0.282, batch=231 
855: loss=0.990, reward_mean=0.060, reward_bound=0.000, batch=6 
856: loss=1.027, reward_mean=0.080, reward_bound=0.000, batch=14 
857: loss=0.997, reward_mean=0.040, reward_bound=0.000, batch=18 
858: loss=0.994, reward_mean=0.070, reward_bound=0.000, batch=25 
859: loss=0.983, reward_mean=0.050, reward_bound=0.000, batch=30 
860: loss=0.978, reward_mean=0.070, reward_bound=0.000, batch=37 
861: loss=0.971, reward_mean=0.050, reward_bound=0.000, batch=42 
862: loss=0.977, reward_mean=0.040, reward_bound=0.000, batch=46 
863: loss=0.955, reward_mean=0.110, reward_bound=0.000, batch=57 
864: loss=0.945, reward_mean=0.090, reward_bound=0.000, batch=66 
865: loss=0.938, reward_mean=0.070, reward_bound=0.000, batch=73 
866: loss=0.945, reward_mean=0.090, reward_bound=0.000, batch=82 
867: loss=0.944, reward_mean=0.120, reward_bound=0.000, batch=94 
868: loss=0.942, reward_mean=0.100, reward_bound=0.000, batch=104 
869: loss=0.940, reward_mean=0.150, reward_bound=0.000, batch=119 
870: loss=0.934, reward_mean=0.140, reward_bound=0.000, batch=133 
871: loss=0.931, reward_mean=0.100, reward_bound=0.000, batch=143 
872: loss=0.928, reward_mean=0.110, reward_bound=0.000, batch=154 
873: loss=0.924, reward_mean=0.060, reward_bound=0.000, batch=160 
874: loss=0.926, reward_mean=0.090, reward_bound=0.000, batch=169 
875: loss=0.921, reward_mean=0.150, reward_bound=0.000, batch=184 
876: loss=0.921, reward_mean=0.060, reward_bound=0.000, batch=190 
877: loss=0.918, reward_mean=0.090, reward_bound=0.000, batch=199 
878: loss=0.915, reward_mean=0.120, reward_bound=0.034, batch=208 
879: loss=0.915, reward_mean=0.060, reward_bound=0.000, batch=214 
880: loss=0.914, reward_mean=0.080, reward_bound=0.042, batch=219 
881: loss=0.911, reward_mean=0.110, reward_bound=0.067, batch=223 
882: loss=0.910, reward_mean=0.070, reward_bound=0.089, batch=225 
883: loss=0.908, reward_mean=0.080, reward_bound=0.098, batch=226 
884: loss=0.909, reward_mean=0.110, reward_bound=0.115, batch=228 
885: loss=0.909, reward_mean=0.110, reward_bound=0.135, batch=221 
886: loss=0.904, reward_mean=0.110, reward_bound=0.150, batch=217 
887: loss=0.907, reward_mean=0.090, reward_bound=0.167, batch=216 
888: loss=0.911, reward_mean=0.110, reward_bound=0.185, batch=210 
889: loss=0.912, reward_mean=0.100, reward_bound=0.131, batch=217 
890: loss=0.917, reward_mean=0.110, reward_bound=0.206, batch=202 
891: loss=0.916, reward_mean=0.130, reward_bound=0.179, batch=211 
892: loss=0.913, reward_mean=0.060, reward_bound=0.000, batch=217 
893: loss=0.908, reward_mean=0.140, reward_bound=0.229, batch=208 
894: loss=0.906, reward_mean=0.090, reward_bound=0.112, batch=215 
895: loss=0.910, reward_mean=0.090, reward_bound=0.153, batch=220 
896: loss=0.910, reward_mean=0.070, reward_bound=0.150, batch=224 
897: loss=0.905, reward_mean=0.120, reward_bound=0.167, batch=226 
898: loss=0.912, reward_mean=0.100, reward_bound=0.229, batch=227 
899: loss=0.910, reward_mean=0.100, reward_bound=0.254, batch=207 
900: loss=0.905, reward_mean=0.090, reward_bound=0.181, batch=215 
901: loss=0.905, reward_mean=0.110, reward_bound=0.234, batch=220 
902: loss=0.905, reward_mean=0.110, reward_bound=0.274, batch=224 
903: loss=0.905, reward_mean=0.090, reward_bound=0.280, batch=227 
904: loss=0.911, reward_mean=0.080, reward_bound=0.282, batch=191 
905: loss=0.913, reward_mean=0.060, reward_bound=0.000, batch=197 
906: loss=0.914, reward_mean=0.080, reward_bound=0.000, batch=205 
907: loss=0.910, reward_mean=0.070, reward_bound=0.000, batch=212 
908: loss=0.913, reward_mean=0.140, reward_bound=0.126, batch=218 
909: loss=0.914, reward_mean=0.100, reward_bound=0.138, batch=222 
910: loss=0.913, reward_mean=0.060, reward_bound=0.155, batch=225 
911: loss=0.909, reward_mean=0.090, reward_bound=0.185, batch=226 
912: loss=0.903, reward_mean=0.150, reward_bound=0.217, batch=228 
913: loss=0.902, reward_mean=0.120, reward_bound=0.229, batch=228 
914: loss=0.904, reward_mean=0.070, reward_bound=0.254, batch=224 
915: loss=0.905, reward_mean=0.100, reward_bound=0.311, batch=227 
916: loss=0.901, reward_mean=0.080, reward_bound=0.314, batch=183 
917: loss=0.897, reward_mean=0.110, reward_bound=0.000, batch=194 
918: loss=0.899, reward_mean=0.100, reward_bound=0.000, batch=204 
919: loss=0.900, reward_mean=0.070, reward_bound=0.000, batch=211 
920: loss=0.900, reward_mean=0.090, reward_bound=0.065, batch=217 
921: loss=0.900, reward_mean=0.110, reward_bound=0.132, batch=222 
922: loss=0.896, reward_mean=0.060, reward_bound=0.135, batch=224 
923: loss=0.895, reward_mean=0.100, reward_bound=0.183, batch=227 
924: loss=0.890, reward_mean=0.110, reward_bound=0.254, batch=225 
925: loss=0.894, reward_mean=0.080, reward_bound=0.282, batch=218 
926: loss=0.895, reward_mean=0.100, reward_bound=0.237, batch=222 
927: loss=0.892, reward_mean=0.070, reward_bound=0.172, batch=225 
928: loss=0.901, reward_mean=0.090, reward_bound=0.314, batch=217 
929: loss=0.900, reward_mean=0.130, reward_bound=0.220, batch=222 
930: loss=0.898, reward_mean=0.120, reward_bound=0.263, batch=225 
931: loss=0.895, reward_mean=0.090, reward_bound=0.289, batch=227 
932: loss=0.895, reward_mean=0.100, reward_bound=0.308, batch=229 
933: loss=0.883, reward_mean=0.140, reward_bound=0.349, batch=174 
934: loss=0.881, reward_mean=0.080, reward_bound=0.000, batch=182 
935: loss=0.888, reward_mean=0.090, reward_bound=0.000, batch=191 
936: loss=0.883, reward_mean=0.060, reward_bound=0.000, batch=197 
937: loss=0.881, reward_mean=0.140, reward_bound=0.102, batch=208 
938: loss=0.883, reward_mean=0.120, reward_bound=0.150, batch=212 
939: loss=0.880, reward_mean=0.110, reward_bound=0.167, batch=216 
940: loss=0.880, reward_mean=0.090, reward_bound=0.176, batch=221 
941: loss=0.878, reward_mean=0.080, reward_bound=0.167, batch=224 
942: loss=0.879, reward_mean=0.140, reward_bound=0.206, batch=224 
943: loss=0.883, reward_mean=0.110, reward_bound=0.229, batch=226 
944: loss=0.886, reward_mean=0.100, reward_bound=0.254, batch=227 
945: loss=0.882, reward_mean=0.120, reward_bound=0.282, batch=225 
946: loss=0.880, reward_mean=0.060, reward_bound=0.289, batch=227 
947: loss=0.880, reward_mean=0.070, reward_bound=0.249, batch=229 
948: loss=0.876, reward_mean=0.090, reward_bound=0.314, batch=220 
949: loss=0.877, reward_mean=0.100, reward_bound=0.296, batch=224 
950: loss=0.877, reward_mean=0.080, reward_bound=0.314, batch=224 
951: loss=0.878, reward_mean=0.080, reward_bound=0.254, batch=226 
952: loss=0.878, reward_mean=0.160, reward_bound=0.349, batch=217 
953: loss=0.878, reward_mean=0.100, reward_bound=0.282, batch=221 
954: loss=0.885, reward_mean=0.170, reward_bound=0.387, batch=150 
955: loss=0.875, reward_mean=0.110, reward_bound=0.000, batch=161 
956: loss=0.868, reward_mean=0.050, reward_bound=0.000, batch=166 
957: loss=0.862, reward_mean=0.110, reward_bound=0.000, batch=177 
958: loss=0.846, reward_mean=0.110, reward_bound=0.000, batch=188 
959: loss=0.837, reward_mean=0.140, reward_bound=0.006, batch=201 
960: loss=0.836, reward_mean=0.140, reward_bound=0.080, batch=208 
961: loss=0.842, reward_mean=0.160, reward_bound=0.111, batch=215 
962: loss=0.846, reward_mean=0.100, reward_bound=0.122, batch=218 
963: loss=0.851, reward_mean=0.120, reward_bound=0.150, batch=220 
964: loss=0.847, reward_mean=0.190, reward_bound=0.185, batch=222 
965: loss=0.847, reward_mean=0.140, reward_bound=0.206, batch=231 
966: loss=0.852, reward_mean=0.070, reward_bound=0.206, batch=226 
967: loss=0.852, reward_mean=0.050, reward_bound=0.217, batch=228 
968: loss=0.854, reward_mean=0.160, reward_bound=0.231, batch=229 
969: loss=0.851, reward_mean=0.110, reward_bound=0.254, batch=225 
970: loss=0.850, reward_mean=0.070, reward_bound=0.210, batch=227 
971: loss=0.853, reward_mean=0.100, reward_bound=0.282, batch=220 
972: loss=0.853, reward_mean=0.090, reward_bound=0.162, batch=224 
973: loss=0.854, reward_mean=0.130, reward_bound=0.280, batch=227 
974: loss=0.856, reward_mean=0.120, reward_bound=0.282, batch=228 
975: loss=0.858, reward_mean=0.120, reward_bound=0.314, batch=210 
976: loss=0.858, reward_mean=0.080, reward_bound=0.034, batch=217 
977: loss=0.857, reward_mean=0.100, reward_bound=0.150, batch=220 
978: loss=0.858, reward_mean=0.080, reward_bound=0.222, batch=224 
979: loss=0.859, reward_mean=0.050, reward_bound=0.229, batch=223 
980: loss=0.858, reward_mean=0.110, reward_bound=0.282, batch=225 
981: loss=0.859, reward_mean=0.060, reward_bound=0.185, batch=226 
982: loss=0.859, reward_mean=0.080, reward_bound=0.314, batch=225 
983: loss=0.855, reward_mean=0.090, reward_bound=0.349, batch=210 
984: loss=0.849, reward_mean=0.060, reward_bound=0.000, batch=216 
985: loss=0.855, reward_mean=0.100, reward_bound=0.241, batch=221 
986: loss=0.855, reward_mean=0.110, reward_bound=0.282, batch=222 
987: loss=0.855, reward_mean=0.070, reward_bound=0.193, batch=225 
988: loss=0.854, reward_mean=0.050, reward_bound=0.260, batch=227 
989: loss=0.858, reward_mean=0.120, reward_bound=0.314, batch=228 
990: loss=0.861, reward_mean=0.110, reward_bound=0.349, batch=222 
991: loss=0.862, reward_mean=0.080, reward_bound=0.272, batch=225 
992: loss=0.860, reward_mean=0.140, reward_bound=0.356, batch=227 
993: loss=0.863, reward_mean=0.020, reward_bound=0.015, batch=229 
994: loss=0.862, reward_mean=0.150, reward_bound=0.349, batch=229 
995: loss=0.861, reward_mean=0.090, reward_bound=0.364, batch=230 
996: loss=0.853, reward_mean=0.100, reward_bound=0.387, batch=205 
997: loss=0.852, reward_mean=0.080, reward_bound=0.020, batch=213 
998: loss=0.847, reward_mean=0.070, reward_bound=0.071, batch=219 
999: loss=0.847, reward_mean=0.100, reward_bound=0.135, batch=221 
1000: loss=0.848, reward_mean=0.080, reward_bound=0.167, batch=223 
1001: loss=0.847, reward_mean=0.070, reward_bound=0.220, batch=226 
1002: loss=0.852, reward_mean=0.100, reward_bound=0.229, batch=226 
1003: loss=0.853, reward_mean=0.100, reward_bound=0.254, batch=226 
1004: loss=0.854, reward_mean=0.080, reward_bound=0.282, batch=227 
1005: loss=0.854, reward_mean=0.090, reward_bound=0.314, batch=226 
1006: loss=0.852, reward_mean=0.080, reward_bound=0.349, batch=220 
1007: loss=0.851, reward_mean=0.130, reward_bound=0.376, batch=224 
1008: loss=0.850, reward_mean=0.050, reward_bound=0.280, batch=227 
1009: loss=0.852, reward_mean=0.120, reward_bound=0.380, batch=229 
1010: loss=0.851, reward_mean=0.090, reward_bound=0.364, batch=230 
1011: loss=0.851, reward_mean=0.100, reward_bound=0.356, batch=231 
1012: loss=0.856, reward_mean=0.150, reward_bound=0.387, batch=222 
1013: loss=0.857, reward_mean=0.080, reward_bound=0.254, batch=225 
1014: loss=0.852, reward_mean=0.110, reward_bound=0.329, batch=227 
1015: loss=0.849, reward_mean=0.150, reward_bound=0.387, batch=228 
1016: loss=0.848, reward_mean=0.080, reward_bound=0.297, batch=229 
1017: loss=0.881, reward_mean=0.070, reward_bound=0.430, batch=134 
1018: loss=0.867, reward_mean=0.080, reward_bound=0.000, batch=142 
1019: loss=0.874, reward_mean=0.090, reward_bound=0.000, batch=151 
1020: loss=0.867, reward_mean=0.130, reward_bound=0.000, batch=164 
1021: loss=0.862, reward_mean=0.110, reward_bound=0.000, batch=175 
1022: loss=0.857, reward_mean=0.060, reward_bound=0.000, batch=181 
1023: loss=0.857, reward_mean=0.090, reward_bound=0.000, batch=190 
1024: loss=0.854, reward_mean=0.080, reward_bound=0.000, batch=198 
1025: loss=0.854, reward_mean=0.070, reward_bound=0.000, batch=205 
1026: loss=0.853, reward_mean=0.070, reward_bound=0.000, batch=212 
1027: loss=0.857, reward_mean=0.090, reward_bound=0.072, batch=215 
1028: loss=0.857, reward_mean=0.080, reward_bound=0.089, batch=221 
1029: loss=0.857, reward_mean=0.130, reward_bound=0.122, batch=221 
1030: loss=0.860, reward_mean=0.170, reward_bound=0.185, batch=219 
1031: loss=0.860, reward_mean=0.130, reward_bound=0.206, batch=222 
1032: loss=0.860, reward_mean=0.070, reward_bound=0.229, batch=217 
1033: loss=0.876, reward_mean=0.120, reward_bound=0.254, batch=213 
1034: loss=0.868, reward_mean=0.080, reward_bound=0.058, batch=219 
1035: loss=0.869, reward_mean=0.130, reward_bound=0.225, batch=223 
1036: loss=0.867, reward_mean=0.140, reward_bound=0.282, batch=211 
1037: loss=0.869, reward_mean=0.110, reward_bound=0.185, batch=217 
1038: loss=0.872, reward_mean=0.130, reward_bound=0.314, batch=211 
1039: loss=0.872, reward_mean=0.130, reward_bound=0.254, batch=217 
1040: loss=0.881, reward_mean=0.170, reward_bound=0.349, batch=203 
1041: loss=0.884, reward_mean=0.040, reward_bound=0.000, batch=207 
1042: loss=0.879, reward_mean=0.060, reward_bound=0.000, batch=213 
1043: loss=0.874, reward_mean=0.130, reward_bound=0.122, batch=218 
1044: loss=0.872, reward_mean=0.110, reward_bound=0.152, batch=222 
1045: loss=0.875, reward_mean=0.080, reward_bound=0.198, batch=225 
1046: loss=0.871, reward_mean=0.060, reward_bound=0.229, batch=225 
1047: loss=0.872, reward_mean=0.090, reward_bound=0.254, batch=226 
1048: loss=0.873, reward_mean=0.100, reward_bound=0.282, batch=225 
1049: loss=0.875, reward_mean=0.110, reward_bound=0.314, batch=225 
1050: loss=0.874, reward_mean=0.100, reward_bound=0.349, batch=222 
1051: loss=0.879, reward_mean=0.100, reward_bound=0.387, batch=197 
1052: loss=0.875, reward_mean=0.150, reward_bound=0.245, batch=208 
1053: loss=0.867, reward_mean=0.090, reward_bound=0.138, batch=215 
1054: loss=0.866, reward_mean=0.100, reward_bound=0.189, batch=220 
1055: loss=0.866, reward_mean=0.170, reward_bound=0.274, batch=224 
1056: loss=0.864, reward_mean=0.080, reward_bound=0.269, batch=227 
1057: loss=0.862, reward_mean=0.070, reward_bound=0.282, batch=224 
1058: loss=0.868, reward_mean=0.090, reward_bound=0.314, batch=223 
1059: loss=0.866, reward_mean=0.100, reward_bound=0.349, batch=220 
1060: loss=0.868, reward_mean=0.080, reward_bound=0.175, batch=224 
1061: loss=0.874, reward_mean=0.080, reward_bound=0.224, batch=227 
1062: loss=0.870, reward_mean=0.070, reward_bound=0.229, batch=227 
1063: loss=0.868, reward_mean=0.050, reward_bound=0.282, batch=228 
1064: loss=0.872, reward_mean=0.110, reward_bound=0.387, batch=221 
1065: loss=0.882, reward_mean=0.120, reward_bound=0.430, batch=198 
1066: loss=0.875, reward_mean=0.080, reward_bound=0.000, batch=206 
1067: loss=0.874, reward_mean=0.120, reward_bound=0.136, batch=214 
1068: loss=0.872, reward_mean=0.070, reward_bound=0.138, batch=220 
1069: loss=0.872, reward_mean=0.090, reward_bound=0.200, batch=224 
1070: loss=0.877, reward_mean=0.110, reward_bound=0.206, batch=225 
1071: loss=0.872, reward_mean=0.100, reward_bound=0.254, batch=224 
1072: loss=0.875, reward_mean=0.080, reward_bound=0.282, batch=222 
1073: loss=0.876, reward_mean=0.070, reward_bound=0.292, batch=225 
1074: loss=0.877, reward_mean=0.120, reward_bound=0.314, batch=226 
1075: loss=0.879, reward_mean=0.110, reward_bound=0.349, batch=218 
1076: loss=0.876, reward_mean=0.120, reward_bound=0.293, batch=222 
1077: loss=0.875, reward_mean=0.080, reward_bound=0.314, batch=225 
1078: loss=0.874, reward_mean=0.070, reward_bound=0.321, batch=227 
1079: loss=0.875, reward_mean=0.100, reward_bound=0.387, batch=216 
1080: loss=0.871, reward_mean=0.100, reward_bound=0.268, batch=221 
1081: loss=0.868, reward_mean=0.050, reward_bound=0.282, batch=223 
1082: loss=0.872, reward_mean=0.090, reward_bound=0.372, batch=226 
1083: loss=0.871, reward_mean=0.150, reward_bound=0.368, batch=228 
1084: loss=0.873, reward_mean=0.150, reward_bound=0.387, batch=228 
1085: loss=0.879, reward_mean=0.110, reward_bound=0.430, batch=215 
1086: loss=0.880, reward_mean=0.120, reward_bound=0.321, batch=220 
1087: loss=0.879, reward_mean=0.140, reward_bound=0.387, batch=222 
1088: loss=0.878, reward_mean=0.100, reward_bound=0.349, batch=225 
1089: loss=0.880, reward_mean=0.090, reward_bound=0.337, batch=227 
1090: loss=0.882, reward_mean=0.070, reward_bound=0.342, batch=229 
1091: loss=0.880, reward_mean=0.090, reward_bound=0.364, batch=230 
1092: loss=0.882, reward_mean=0.130, reward_bound=0.430, batch=225 
1093: loss=0.883, reward_mean=0.090, reward_bound=0.266, batch=227 
1094: loss=0.883, reward_mean=0.090, reward_bound=0.342, batch=229 
1095: loss=0.890, reward_mean=0.150, reward_bound=0.405, batch=230 
1096: loss=0.878, reward_mean=0.110, reward_bound=0.464, batch=231 
1097: loss=0.870, reward_mean=0.120, reward_bound=0.478, batch=93 
1098: loss=0.869, reward_mean=0.100, reward_bound=0.000, batch=103 
1099: loss=0.868, reward_mean=0.110, reward_bound=0.000, batch=114 
1100: loss=0.860, reward_mean=0.090, reward_bound=0.000, batch=123 
1101: loss=0.849, reward_mean=0.100, reward_bound=0.000, batch=133 
1102: loss=0.848, reward_mean=0.030, reward_bound=0.000, batch=136 
1103: loss=0.858, reward_mean=0.080, reward_bound=0.000, batch=144 
1104: loss=0.855, reward_mean=0.050, reward_bound=0.000, batch=149 
1105: loss=0.854, reward_mean=0.100, reward_bound=0.000, batch=159 
1106: loss=0.851, reward_mean=0.070, reward_bound=0.000, batch=166 
1107: loss=0.852, reward_mean=0.080, reward_bound=0.000, batch=174 
1108: loss=0.837, reward_mean=0.130, reward_bound=0.000, batch=187 
1109: loss=0.826, reward_mean=0.150, reward_bound=0.014, batch=201 
1110: loss=0.817, reward_mean=0.170, reward_bound=0.065, batch=208 
1111: loss=0.816, reward_mean=0.090, reward_bound=0.073, batch=215 
1112: loss=0.814, reward_mean=0.090, reward_bound=0.089, batch=221 
1113: loss=0.823, reward_mean=0.130, reward_bound=0.098, batch=224 
1114: loss=0.827, reward_mean=0.130, reward_bound=0.109, batch=224 
1115: loss=0.823, reward_mean=0.100, reward_bound=0.135, batch=222 
1116: loss=0.823, reward_mean=0.120, reward_bound=0.167, batch=221 
1117: loss=0.820, reward_mean=0.060, reward_bound=0.185, batch=215 
1118: loss=0.822, reward_mean=0.070, reward_bound=0.206, batch=217 
1119: loss=0.823, reward_mean=0.060, reward_bound=0.160, batch=222 
1120: loss=0.821, reward_mean=0.120, reward_bound=0.229, batch=216 
1121: loss=0.820, reward_mean=0.130, reward_bound=0.217, batch=221 
1122: loss=0.819, reward_mean=0.070, reward_bound=0.229, batch=224 
1123: loss=0.820, reward_mean=0.070, reward_bound=0.254, batch=214 
1124: loss=0.816, reward_mean=0.070, reward_bound=0.182, batch=220 
1125: loss=0.818, reward_mean=0.070, reward_bound=0.185, batch=223 
1126: loss=0.822, reward_mean=0.110, reward_bound=0.254, batch=225 
1127: loss=0.815, reward_mean=0.070, reward_bound=0.282, batch=210 
1128: loss=0.815, reward_mean=0.050, reward_bound=0.000, batch=215 
1129: loss=0.817, reward_mean=0.050, reward_bound=0.016, batch=220 
1130: loss=0.815, reward_mean=0.080, reward_bound=0.122, batch=223 
1131: loss=0.812, reward_mean=0.100, reward_bound=0.160, batch=226 
1132: loss=0.807, reward_mean=0.090, reward_bound=0.196, batch=228 
1133: loss=0.808, reward_mean=0.060, reward_bound=0.206, batch=228 
1134: loss=0.815, reward_mean=0.100, reward_bound=0.254, batch=226 
1135: loss=0.814, reward_mean=0.030, reward_bound=0.209, batch=228 
1136: loss=0.815, reward_mean=0.090, reward_bound=0.282, batch=228 
1137: loss=0.817, reward_mean=0.130, reward_bound=0.314, batch=202 
1138: loss=0.812, reward_mean=0.070, reward_bound=0.000, batch=209 
1139: loss=0.806, reward_mean=0.060, reward_bound=0.000, batch=215 
1140: loss=0.805, reward_mean=0.050, reward_bound=0.022, batch=220 
1141: loss=0.805, reward_mean=0.060, reward_bound=0.163, batch=224 
1142: loss=0.807, reward_mean=0.100, reward_bound=0.254, batch=224 
1143: loss=0.804, reward_mean=0.070, reward_bound=0.269, batch=227 
1144: loss=0.803, reward_mean=0.130, reward_bound=0.282, batch=227 
1145: loss=0.811, reward_mean=0.110, reward_bound=0.349, batch=192 
1146: loss=0.814, reward_mean=0.060, reward_bound=0.000, batch=198 
1147: loss=0.806, reward_mean=0.090, reward_bound=0.000, batch=207 
1148: loss=0.807, reward_mean=0.140, reward_bound=0.206, batch=212 
1149: loss=0.805, reward_mean=0.090, reward_bound=0.220, batch=218 
1150: loss=0.808, reward_mean=0.130, reward_bound=0.314, batch=220 
1151: loss=0.802, reward_mean=0.150, reward_bound=0.349, batch=214 
1152: loss=0.799, reward_mean=0.110, reward_bound=0.206, batch=218 
1153: loss=0.799, reward_mean=0.080, reward_bound=0.166, batch=222 
1154: loss=0.792, reward_mean=0.050, reward_bound=0.132, batch=225 
1155: loss=0.798, reward_mean=0.070, reward_bound=0.266, batch=227 
1156: loss=0.794, reward_mean=0.100, reward_bound=0.349, batch=227 
1157: loss=0.812, reward_mean=0.080, reward_bound=0.387, batch=179 
1158: loss=0.820, reward_mean=0.070, reward_bound=0.000, batch=186 
1159: loss=0.821, reward_mean=0.120, reward_bound=0.000, batch=198 
1160: loss=0.815, reward_mean=0.080, reward_bound=0.000, batch=206 
1161: loss=0.811, reward_mean=0.070, reward_bound=0.000, batch=213 
1162: loss=0.806, reward_mean=0.100, reward_bound=0.117, batch=219 
1163: loss=0.802, reward_mean=0.130, reward_bound=0.167, batch=222 
1164: loss=0.795, reward_mean=0.090, reward_bound=0.206, batch=227 
1165: loss=0.798, reward_mean=0.080, reward_bound=0.206, batch=228 
1166: loss=0.801, reward_mean=0.070, reward_bound=0.229, batch=226 
1167: loss=0.797, reward_mean=0.140, reward_bound=0.254, batch=223 
1168: loss=0.795, reward_mean=0.050, reward_bound=0.160, batch=226 
1169: loss=0.801, reward_mean=0.060, reward_bound=0.196, batch=228 
1170: loss=0.798, reward_mean=0.100, reward_bound=0.282, batch=220 
1171: loss=0.796, reward_mean=0.100, reward_bound=0.254, batch=222 
1172: loss=0.795, reward_mean=0.150, reward_bound=0.314, batch=218 
1173: loss=0.791, reward_mean=0.050, reward_bound=0.169, batch=222 
1174: loss=0.794, reward_mean=0.090, reward_bound=0.213, batch=225 
1175: loss=0.795, reward_mean=0.080, reward_bound=0.254, batch=225 
1176: loss=0.796, reward_mean=0.100, reward_bound=0.296, batch=227 
1177: loss=0.795, reward_mean=0.080, reward_bound=0.335, batch=229 
1178: loss=0.801, reward_mean=0.080, reward_bound=0.349, batch=217 
1179: loss=0.804, reward_mean=0.050, reward_bound=0.226, batch=222 
1180: loss=0.801, reward_mean=0.130, reward_bound=0.349, batch=224 
1181: loss=0.798, reward_mean=0.100, reward_bound=0.384, batch=227 
1182: loss=0.798, reward_mean=0.120, reward_bound=0.380, batch=229 
1183: loss=0.800, reward_mean=0.100, reward_bound=0.387, batch=216 
1184: loss=0.803, reward_mean=0.080, reward_bound=0.301, batch=221 
1185: loss=0.803, reward_mean=0.080, reward_bound=0.349, batch=221 
1186: loss=0.804, reward_mean=0.110, reward_bound=0.314, batch=224 
1187: loss=0.803, reward_mean=0.080, reward_bound=0.345, batch=227 
1188: loss=0.802, reward_mean=0.080, reward_bound=0.342, batch=229 
1189: loss=0.800, reward_mean=0.070, reward_bound=0.349, batch=229 
1190: loss=0.798, reward_mean=0.090, reward_bound=0.387, batch=225 
1191: loss=0.796, reward_mean=0.080, reward_bound=0.349, batch=226 
1192: loss=0.825, reward_mean=0.140, reward_bound=0.430, batch=173 
1193: loss=0.823, reward_mean=0.090, reward_bound=0.000, batch=182 
1194: loss=0.819, reward_mean=0.050, reward_bound=0.000, batch=187 
1195: loss=0.813, reward_mean=0.130, reward_bound=0.000, batch=200 
1196: loss=0.812, reward_mean=0.100, reward_bound=0.030, batch=210 
1197: loss=0.817, reward_mean=0.060, reward_bound=0.000, batch=216 
1198: loss=0.809, reward_mean=0.110, reward_bound=0.104, batch=221 
1199: loss=0.814, reward_mean=0.110, reward_bound=0.135, batch=224 
1200: loss=0.815, reward_mean=0.070, reward_bound=0.167, batch=224 
1201: loss=0.813, reward_mean=0.070, reward_bound=0.174, batch=227 
1202: loss=0.809, reward_mean=0.170, reward_bound=0.224, batch=229 
1203: loss=0.812, reward_mean=0.120, reward_bound=0.254, batch=225 
1204: loss=0.813, reward_mean=0.110, reward_bound=0.282, batch=223 
1205: loss=0.812, reward_mean=0.080, reward_bound=0.314, batch=223 
1206: loss=0.808, reward_mean=0.070, reward_bound=0.311, batch=226 
1207: loss=0.807, reward_mean=0.070, reward_bound=0.349, batch=220 
1208: loss=0.809, reward_mean=0.070, reward_bound=0.248, batch=224 
1209: loss=0.802, reward_mean=0.130, reward_bound=0.314, batch=226 
1210: loss=0.804, reward_mean=0.090, reward_bound=0.368, batch=228 
1211: loss=0.804, reward_mean=0.180, reward_bound=0.387, batch=223 
1212: loss=0.804, reward_mean=0.140, reward_bound=0.398, batch=226 
1213: loss=0.803, reward_mean=0.100, reward_bound=0.387, batch=227 
1214: loss=0.804, reward_mean=0.150, reward_bound=0.373, batch=229 
1215: loss=0.802, reward_mean=0.080, reward_bound=0.387, batch=229 
1216: loss=0.804, reward_mean=0.070, reward_bound=0.405, batch=230 
1217: loss=0.807, reward_mean=0.060, reward_bound=0.406, batch=231 
1218: loss=0.813, reward_mean=0.150, reward_bound=0.430, batch=206 
1219: loss=0.816, reward_mean=0.070, reward_bound=0.000, batch=213 
1220: loss=0.814, reward_mean=0.110, reward_bound=0.112, batch=219 
1221: loss=0.814, reward_mean=0.070, reward_bound=0.215, batch=223 
1222: loss=0.811, reward_mean=0.060, reward_bound=0.190, batch=226 
1223: loss=0.819, reward_mean=0.100, reward_bound=0.254, batch=227 
1224: loss=0.817, reward_mean=0.060, reward_bound=0.277, batch=229 
1225: loss=0.820, reward_mean=0.090, reward_bound=0.282, batch=226 
1226: loss=0.822, reward_mean=0.140, reward_bound=0.298, batch=228 
1227: loss=0.815, reward_mean=0.100, reward_bound=0.349, batch=226 
1228: loss=0.813, reward_mean=0.110, reward_bound=0.387, batch=223 
1229: loss=0.817, reward_mean=0.110, reward_bound=0.349, batch=225 
1230: loss=0.817, reward_mean=0.080, reward_bound=0.303, batch=227 
1231: loss=0.811, reward_mean=0.110, reward_bound=0.387, batch=228 
1232: loss=0.811, reward_mean=0.090, reward_bound=0.387, batch=228 
1233: loss=0.812, reward_mean=0.140, reward_bound=0.430, batch=224 
1234: loss=0.812, reward_mean=0.080, reward_bound=0.224, batch=227 
1235: loss=0.815, reward_mean=0.060, reward_bound=0.297, batch=229 
1236: loss=0.815, reward_mean=0.070, reward_bound=0.278, batch=230 
1237: loss=0.812, reward_mean=0.120, reward_bound=0.349, batch=229 
1238: loss=0.813, reward_mean=0.110, reward_bound=0.405, batch=230 
1239: loss=0.811, reward_mean=0.070, reward_bound=0.329, batch=231 
1240: loss=0.815, reward_mean=0.080, reward_bound=0.430, batch=231 
1241: loss=0.829, reward_mean=0.080, reward_bound=0.478, batch=158 
1242: loss=0.817, reward_mean=0.070, reward_bound=0.000, batch=165 
1243: loss=0.823, reward_mean=0.090, reward_bound=0.000, batch=174 
1244: loss=0.833, reward_mean=0.140, reward_bound=0.000, batch=188 
1245: loss=0.833, reward_mean=0.060, reward_bound=0.000, batch=194 
1246: loss=0.829, reward_mean=0.100, reward_bound=0.000, batch=204 
1247: loss=0.840, reward_mean=0.060, reward_bound=0.000, batch=210 
1248: loss=0.829, reward_mean=0.120, reward_bound=0.077, batch=217 
1249: loss=0.834, reward_mean=0.110, reward_bound=0.117, batch=222 
1250: loss=0.842, reward_mean=0.170, reward_bound=0.172, batch=225 
1251: loss=0.842, reward_mean=0.110, reward_bound=0.189, batch=227 
1252: loss=0.833, reward_mean=0.160, reward_bound=0.206, batch=227 
1253: loss=0.833, reward_mean=0.080, reward_bound=0.229, batch=225 
1254: loss=0.834, reward_mean=0.040, reward_bound=0.171, batch=227 
1255: loss=0.827, reward_mean=0.070, reward_bound=0.254, batch=217 
1256: loss=0.829, reward_mean=0.070, reward_bound=0.185, batch=221 
1257: loss=0.828, reward_mean=0.050, reward_bound=0.167, batch=224 
1258: loss=0.832, reward_mean=0.140, reward_bound=0.282, batch=220 
1259: loss=0.837, reward_mean=0.070, reward_bound=0.167, batch=223 
1260: loss=0.829, reward_mean=0.050, reward_bound=0.206, batch=225 
1261: loss=0.830, reward_mean=0.140, reward_bound=0.314, batch=218 
1262: loss=0.826, reward_mean=0.160, reward_bound=0.349, batch=213 
1263: loss=0.828, reward_mean=0.100, reward_bound=0.154, batch=219 
1264: loss=0.827, reward_mean=0.060, reward_bound=0.148, batch=223 
1265: loss=0.822, reward_mean=0.100, reward_bound=0.220, batch=226 
1266: loss=0.829, reward_mean=0.130, reward_bound=0.331, batch=228 
1267: loss=0.829, reward_mean=0.100, reward_bound=0.317, batch=229 
1268: loss=0.827, reward_mean=0.170, reward_bound=0.349, batch=229 
1269: loss=0.819, reward_mean=0.100, reward_bound=0.387, batch=209 
1270: loss=0.815, reward_mean=0.070, reward_bound=0.023, batch=216 
1271: loss=0.810, reward_mean=0.070, reward_bound=0.119, batch=221 
1272: loss=0.815, reward_mean=0.110, reward_bound=0.206, batch=222 
1273: loss=0.816, reward_mean=0.140, reward_bound=0.272, batch=225 
1274: loss=0.815, reward_mean=0.090, reward_bound=0.227, batch=227 
1275: loss=0.814, reward_mean=0.080, reward_bound=0.314, batch=225 
1276: loss=0.813, reward_mean=0.090, reward_bound=0.349, batch=222 
1277: loss=0.811, reward_mean=0.110, reward_bound=0.185, batch=225 
1278: loss=0.811, reward_mean=0.090, reward_bound=0.349, batch=226 
1279: loss=0.810, reward_mean=0.080, reward_bound=0.335, batch=228 
1280: loss=0.814, reward_mean=0.090, reward_bound=0.387, batch=222 
1281: loss=0.813, reward_mean=0.110, reward_bound=0.302, batch=225 
1282: loss=0.809, reward_mean=0.050, reward_bound=0.356, batch=227 
1283: loss=0.808, reward_mean=0.080, reward_bound=0.342, batch=229 
1284: loss=0.808, reward_mean=0.060, reward_bound=0.309, batch=230 
1285: loss=0.809, reward_mean=0.060, reward_bound=0.376, batch=231 
1286: loss=0.811, reward_mean=0.050, reward_bound=0.387, batch=230 
1287: loss=0.811, reward_mean=0.100, reward_bound=0.349, batch=230 
1288: loss=0.813, reward_mean=0.130, reward_bound=0.418, batch=231 
1289: loss=0.813, reward_mean=0.090, reward_bound=0.387, batch=231 
1290: loss=0.813, reward_mean=0.080, reward_bound=0.349, batch=231 
1291: loss=0.813, reward_mean=0.050, reward_bound=0.314, batch=231 
1292: loss=0.818, reward_mean=0.080, reward_bound=0.430, batch=200 
1293: loss=0.823, reward_mean=0.060, reward_bound=0.000, batch=206 
1294: loss=0.818, reward_mean=0.080, reward_bound=0.075, batch=214 
1295: loss=0.819, reward_mean=0.080, reward_bound=0.130, batch=220 
1296: loss=0.816, reward_mean=0.100, reward_bound=0.162, batch=224 
1297: loss=0.828, reward_mean=0.110, reward_bound=0.229, batch=225 
1298: loss=0.830, reward_mean=0.050, reward_bound=0.282, batch=226 
1299: loss=0.824, reward_mean=0.080, reward_bound=0.314, batch=221 
1300: loss=0.824, reward_mean=0.080, reward_bound=0.349, batch=218 
1301: loss=0.822, reward_mean=0.080, reward_bound=0.268, batch=222 
1302: loss=0.831, reward_mean=0.150, reward_bound=0.387, batch=218 
1303: loss=0.832, reward_mean=0.090, reward_bound=0.231, batch=222 
1304: loss=0.833, reward_mean=0.080, reward_bound=0.254, batch=224 
1305: loss=0.840, reward_mean=0.100, reward_bound=0.314, batch=226 
1306: loss=0.836, reward_mean=0.090, reward_bound=0.349, batch=227 
1307: loss=0.835, reward_mean=0.080, reward_bound=0.387, batch=226 
1308: loss=0.834, reward_mean=0.100, reward_bound=0.372, batch=228 
1309: loss=0.830, reward_mean=0.080, reward_bound=0.430, batch=218 
1310: loss=0.829, reward_mean=0.150, reward_bound=0.317, batch=222 
1311: loss=0.829, reward_mean=0.070, reward_bound=0.349, batch=223 
1312: loss=0.832, reward_mean=0.090, reward_bound=0.413, batch=226 
1313: loss=0.829, reward_mean=0.090, reward_bound=0.368, batch=228 
1314: loss=0.829, reward_mean=0.050, reward_bound=0.430, batch=225 
1315: loss=0.831, reward_mean=0.070, reward_bound=0.296, batch=227 
1316: loss=0.829, reward_mean=0.100, reward_bound=0.335, batch=229 
1317: loss=0.828, reward_mean=0.100, reward_bound=0.405, batch=230 
1318: loss=0.828, reward_mean=0.080, reward_bound=0.430, batch=229 
1319: loss=0.830, reward_mean=0.090, reward_bound=0.405, batch=230 
1320: loss=0.827, reward_mean=0.080, reward_bound=0.464, batch=231 
1321: loss=0.819, reward_mean=0.090, reward_bound=0.478, batch=184 
1322: loss=0.816, reward_mean=0.090, reward_bound=0.000, batch=193 
1323: loss=0.810, reward_mean=0.060, reward_bound=0.000, batch=199 
1324: loss=0.810, reward_mean=0.110, reward_bound=0.067, batch=209 
1325: loss=0.806, reward_mean=0.050, reward_bound=0.000, batch=214 
1326: loss=0.815, reward_mean=0.080, reward_bound=0.079, batch=220 
1327: loss=0.813, reward_mean=0.080, reward_bound=0.106, batch=224 
1328: loss=0.808, reward_mean=0.090, reward_bound=0.165, batch=227 
1329: loss=0.809, reward_mean=0.100, reward_bound=0.229, batch=226 
1330: loss=0.808, reward_mean=0.100, reward_bound=0.254, batch=224 
1331: loss=0.806, reward_mean=0.120, reward_bound=0.282, batch=224 
1332: loss=0.806, reward_mean=0.090, reward_bound=0.311, batch=227 
1333: loss=0.807, reward_mean=0.090, reward_bound=0.314, batch=222 
1334: loss=0.805, reward_mean=0.070, reward_bound=0.324, batch=225 
1335: loss=0.804, reward_mean=0.080, reward_bound=0.321, batch=227 
1336: loss=0.808, reward_mean=0.080, reward_bound=0.349, batch=218 
1337: loss=0.808, reward_mean=0.130, reward_bound=0.349, batch=219 
1338: loss=0.808, reward_mean=0.130, reward_bound=0.328, batch=223 
1339: loss=0.810, reward_mean=0.100, reward_bound=0.335, batch=226 
1340: loss=0.808, reward_mean=0.100, reward_bound=0.349, batch=227 
1341: loss=0.810, reward_mean=0.150, reward_bound=0.342, batch=229 
1342: loss=0.809, reward_mean=0.070, reward_bound=0.265, batch=230 
1343: loss=0.806, reward_mean=0.130, reward_bound=0.376, batch=231 
1344: loss=0.809, reward_mean=0.090, reward_bound=0.387, batch=221 
1345: loss=0.812, reward_mean=0.090, reward_bound=0.229, batch=223 
1346: loss=0.809, reward_mean=0.110, reward_bound=0.358, batch=226 
1347: loss=0.812, reward_mean=0.110, reward_bound=0.241, batch=228 
1348: loss=0.810, reward_mean=0.110, reward_bound=0.254, batch=228 
1349: loss=0.811, reward_mean=0.090, reward_bound=0.286, batch=229 
1350: loss=0.809, reward_mean=0.070, reward_bound=0.349, batch=229 
1351: loss=0.812, reward_mean=0.120, reward_bound=0.405, batch=230 
1352: loss=0.808, reward_mean=0.130, reward_bound=0.430, batch=213 
1353: loss=0.803, reward_mean=0.060, reward_bound=0.025, batch=219 
1354: loss=0.803, reward_mean=0.090, reward_bound=0.282, batch=221 
1355: loss=0.803, reward_mean=0.060, reward_bound=0.229, batch=224 
1356: loss=0.804, reward_mean=0.080, reward_bound=0.314, batch=223 
1357: loss=0.800, reward_mean=0.090, reward_bound=0.314, batch=225 
1358: loss=0.802, reward_mean=0.150, reward_bound=0.349, batch=223 
1359: loss=0.801, reward_mean=0.100, reward_bound=0.271, batch=226 
1360: loss=0.800, reward_mean=0.070, reward_bound=0.196, batch=228 
1361: loss=0.802, reward_mean=0.110, reward_bound=0.282, batch=227 
1362: loss=0.806, reward_mean=0.070, reward_bound=0.387, batch=222 
1363: loss=0.803, reward_mean=0.110, reward_bound=0.360, batch=225 
1364: loss=0.800, reward_mean=0.090, reward_bound=0.321, batch=227 
1365: loss=0.805, reward_mean=0.130, reward_bound=0.387, batch=225 
1366: loss=0.802, reward_mean=0.060, reward_bound=0.253, batch=227 
1367: loss=0.801, reward_mean=0.130, reward_bound=0.414, batch=229 
1368: loss=0.801, reward_mean=0.070, reward_bound=0.349, batch=229 
1369: loss=0.804, reward_mean=0.160, reward_bound=0.430, batch=223 
1370: loss=0.805, reward_mean=0.050, reward_bound=0.235, batch=226 
1371: loss=0.803, reward_mean=0.110, reward_bound=0.282, batch=227 
1372: loss=0.802, reward_mean=0.080, reward_bound=0.380, batch=229 
1373: loss=0.804, reward_mean=0.090, reward_bound=0.387, batch=228 
1374: loss=0.802, reward_mean=0.090, reward_bound=0.297, batch=229 
1375: loss=0.803, reward_mean=0.120, reward_bound=0.430, batch=226 
1376: loss=0.802, reward_mean=0.070, reward_bound=0.390, batch=228 
1377: loss=0.802, reward_mean=0.070, reward_bound=0.317, batch=229 
1378: loss=0.800, reward_mean=0.120, reward_bound=0.349, batch=229 
1379: loss=0.800, reward_mean=0.030, reward_bound=0.279, batch=230 
1380: loss=0.797, reward_mean=0.070, reward_bound=0.418, batch=231 
1381: loss=0.802, reward_mean=0.110, reward_bound=0.430, batch=231 
1382: loss=0.815, reward_mean=0.130, reward_bound=0.478, batch=204 
1383: loss=0.810, reward_mean=0.090, reward_bound=0.098, batch=213 
1384: loss=0.804, reward_mean=0.060, reward_bound=0.039, batch=219 
1385: loss=0.801, reward_mean=0.090, reward_bound=0.157, batch=223 
1386: loss=0.799, reward_mean=0.150, reward_bound=0.206, batch=225 
1387: loss=0.805, reward_mean=0.060, reward_bound=0.229, batch=226 
1388: loss=0.803, reward_mean=0.090, reward_bound=0.256, batch=228 
1389: loss=0.805, reward_mean=0.070, reward_bound=0.314, batch=228 
1390: loss=0.809, reward_mean=0.100, reward_bound=0.349, batch=226 
1391: loss=0.808, reward_mean=0.150, reward_bound=0.387, batch=223 
1392: loss=0.810, reward_mean=0.110, reward_bound=0.372, batch=226 
1393: loss=0.806, reward_mean=0.070, reward_bound=0.387, batch=226 
1394: loss=0.803, reward_mean=0.110, reward_bound=0.390, batch=228 
1395: loss=0.804, reward_mean=0.120, reward_bound=0.392, batch=229 
1396: loss=0.809, reward_mean=0.110, reward_bound=0.430, batch=223 
1397: loss=0.810, reward_mean=0.070, reward_bound=0.235, batch=226 
1398: loss=0.812, reward_mean=0.090, reward_bound=0.282, batch=227 
1399: loss=0.808, reward_mean=0.090, reward_bound=0.342, batch=229 
1400: loss=0.809, reward_mean=0.120, reward_bound=0.364, batch=230 
1401: loss=0.809, reward_mean=0.100, reward_bound=0.387, batch=228 
1402: loss=0.810, reward_mean=0.060, reward_bound=0.241, batch=229 
1403: loss=0.810, reward_mean=0.110, reward_bound=0.328, batch=230 
1404: loss=0.809, reward_mean=0.090, reward_bound=0.430, batch=224 
1405: loss=0.810, reward_mean=0.090, reward_bound=0.422, batch=227 
1406: loss=0.811, reward_mean=0.030, reward_bound=0.223, batch=229 
1407: loss=0.809, reward_mean=0.070, reward_bound=0.360, batch=230 
1408: loss=0.809, reward_mean=0.060, reward_bound=0.387, batch=230 
1409: loss=0.808, reward_mean=0.100, reward_bound=0.347, batch=231 
1410: loss=0.808, reward_mean=0.120, reward_bound=0.314, batch=231 
1411: loss=0.808, reward_mean=0.080, reward_bound=0.314, batch=231 
1412: loss=0.809, reward_mean=0.080, reward_bound=0.387, batch=230 
1413: loss=0.807, reward_mean=0.100, reward_bound=0.365, batch=231 
1414: loss=0.809, reward_mean=0.090, reward_bound=0.387, batch=230 
1415: loss=0.809, reward_mean=0.060, reward_bound=0.247, batch=231 
1416: loss=0.806, reward_mean=0.080, reward_bound=0.430, batch=229 
1417: loss=0.807, reward_mean=0.090, reward_bound=0.450, batch=230 
1418: loss=0.808, reward_mean=0.120, reward_bound=0.464, batch=231 
1419: loss=0.808, reward_mean=0.110, reward_bound=0.387, batch=231 
1420: loss=0.808, reward_mean=0.080, reward_bound=0.430, batch=231 
1421: loss=0.814, reward_mean=0.060, reward_bound=0.478, batch=219 
1422: loss=0.814, reward_mean=0.030, reward_bound=0.000, batch=222 
1423: loss=0.813, reward_mean=0.120, reward_bound=0.349, batch=225 
1424: loss=0.812, reward_mean=0.060, reward_bound=0.199, batch=227 
1425: loss=0.811, reward_mean=0.130, reward_bound=0.282, batch=228 
1426: loss=0.812, reward_mean=0.160, reward_bound=0.392, batch=229 
1427: loss=0.814, reward_mean=0.120, reward_bound=0.430, batch=224 
1428: loss=0.810, reward_mean=0.120, reward_bound=0.308, batch=227 
1429: loss=0.807, reward_mean=0.090, reward_bound=0.314, batch=228 
1430: loss=0.811, reward_mean=0.140, reward_bound=0.387, batch=227 
1431: loss=0.809, reward_mean=0.070, reward_bound=0.414, batch=229 
1432: loss=0.809, reward_mean=0.100, reward_bound=0.405, batch=230 
1433: loss=0.808, reward_mean=0.080, reward_bound=0.376, batch=231 
1434: loss=0.814, reward_mean=0.080, reward_bound=0.430, batch=228 
1435: loss=0.816, reward_mean=0.080, reward_bound=0.478, batch=230 
1436: loss=0.815, reward_mean=0.090, reward_bound=0.478, batch=225 
1437: loss=0.814, reward_mean=0.100, reward_bound=0.356, batch=227 
1438: loss=0.817, reward_mean=0.160, reward_bound=0.430, batch=227 
1439: loss=0.816, reward_mean=0.090, reward_bound=0.373, batch=229 
1440: loss=0.813, reward_mean=0.080, reward_bound=0.405, batch=230 
1441: loss=0.814, reward_mean=0.100, reward_bound=0.430, batch=229 
1442: loss=0.813, reward_mean=0.090, reward_bound=0.424, batch=230 
1443: loss=0.813, reward_mean=0.060, reward_bound=0.439, batch=231 
1444: loss=0.817, reward_mean=0.140, reward_bound=0.478, batch=228 
1445: loss=0.817, reward_mean=0.080, reward_bound=0.387, batch=228 
1446: loss=0.816, reward_mean=0.100, reward_bound=0.484, batch=229 
1447: loss=0.815, reward_mean=0.020, reward_bound=0.105, batch=230 
1448: loss=0.815, reward_mean=0.050, reward_bound=0.240, batch=231 
1449: loss=0.814, reward_mean=0.080, reward_bound=0.430, batch=231 
1451: loss=0.701, reward_mean=0.110, reward_bound=0.000, batch=11 
1452: loss=0.732, reward_mean=0.140, reward_bound=0.000, batch=25 
1453: loss=0.738, reward_mean=0.110, reward_bound=0.000, batch=36 
1454: loss=0.719, reward_mean=0.050, reward_bound=0.000, batch=41 
1455: loss=0.733, reward_mean=0.110, reward_bound=0.000, batch=52 
1456: loss=0.744, reward_mean=0.070, reward_bound=0.000, batch=59 
1457: loss=0.740, reward_mean=0.090, reward_bound=0.000, batch=68 
1458: loss=0.738, reward_mean=0.100, reward_bound=0.000, batch=78 
1459: loss=0.735, reward_mean=0.100, reward_bound=0.000, batch=88 
1460: loss=0.720, reward_mean=0.120, reward_bound=0.000, batch=100 
1461: loss=0.715, reward_mean=0.100, reward_bound=0.000, batch=110 
1462: loss=0.712, reward_mean=0.090, reward_bound=0.000, batch=119 
1463: loss=0.708, reward_mean=0.050, reward_bound=0.000, batch=124 
1464: loss=0.702, reward_mean=0.100, reward_bound=0.000, batch=134 
1465: loss=0.694, reward_mean=0.090, reward_bound=0.000, batch=143 
1466: loss=0.697, reward_mean=0.070, reward_bound=0.000, batch=150 
1467: loss=0.694, reward_mean=0.090, reward_bound=0.000, batch=159 
1468: loss=0.693, reward_mean=0.170, reward_bound=0.000, batch=176 
1469: loss=0.693, reward_mean=0.090, reward_bound=0.000, batch=185 
1470: loss=0.689, reward_mean=0.110, reward_bound=0.000, batch=196 
1471: loss=0.688, reward_mean=0.090, reward_bound=0.000, batch=205 
1472: loss=0.685, reward_mean=0.170, reward_bound=0.052, batch=212 
1473: loss=0.680, reward_mean=0.130, reward_bound=0.082, batch=218 
1474: loss=0.680, reward_mean=0.120, reward_bound=0.090, batch=222 
1475: loss=0.680, reward_mean=0.100, reward_bound=0.098, batch=223 
1476: loss=0.677, reward_mean=0.130, reward_bound=0.122, batch=219 
1477: loss=0.682, reward_mean=0.150, reward_bound=0.141, batch=223 
1478: loss=0.684, reward_mean=0.070, reward_bound=0.150, batch=210 
1479: loss=0.686, reward_mean=0.050, reward_bound=0.000, batch=215 
1480: loss=0.681, reward_mean=0.120, reward_bound=0.167, batch=208 
1481: loss=0.683, reward_mean=0.130, reward_bound=0.169, batch=215 
1482: loss=0.679, reward_mean=0.190, reward_bound=0.185, batch=214 
1483: loss=0.673, reward_mean=0.080, reward_bound=0.109, batch=219 
1484: loss=0.672, reward_mean=0.080, reward_bound=0.185, batch=222 
1485: loss=0.671, reward_mean=0.080, reward_bound=0.206, batch=228 
1486: loss=0.667, reward_mean=0.150, reward_bound=0.206, batch=217 
1487: loss=0.665, reward_mean=0.090, reward_bound=0.210, batch=222 
1488: loss=0.662, reward_mean=0.190, reward_bound=0.229, batch=213 
1489: loss=0.657, reward_mean=0.080, reward_bound=0.155, batch=219 
1490: loss=0.658, reward_mean=0.120, reward_bound=0.239, batch=223 
1491: loss=0.647, reward_mean=0.110, reward_bound=0.254, batch=204 
1492: loss=0.641, reward_mean=0.090, reward_bound=0.058, batch=213 
1493: loss=0.648, reward_mean=0.170, reward_bound=0.271, batch=219 
1494: loss=0.638, reward_mean=0.110, reward_bound=0.282, batch=201 
1495: loss=0.642, reward_mean=0.090, reward_bound=0.000, batch=210 
1496: loss=0.640, reward_mean=0.120, reward_bound=0.098, batch=216 
1497: loss=0.636, reward_mean=0.080, reward_bound=0.217, batch=221 
1498: loss=0.632, reward_mean=0.070, reward_bound=0.206, batch=224 
1499: loss=0.635, reward_mean=0.140, reward_bound=0.229, batch=226 
1500: loss=0.635, reward_mean=0.090, reward_bound=0.254, batch=225 
1501: loss=0.635, reward_mean=0.080, reward_bound=0.289, batch=227 
1502: loss=0.635, reward_mean=0.150, reward_bound=0.314, batch=184 
1503: loss=0.632, reward_mean=0.120, reward_bound=0.000, batch=196 
1504: loss=0.628, reward_mean=0.070, reward_bound=0.000, batch=203 
1505: loss=0.627, reward_mean=0.080, reward_bound=0.000, batch=211 
1506: loss=0.620, reward_mean=0.130, reward_bound=0.052, batch=216 
1507: loss=0.619, reward_mean=0.090, reward_bound=0.068, batch=221 
1508: loss=0.615, reward_mean=0.100, reward_bound=0.098, batch=223 
1509: loss=0.611, reward_mean=0.130, reward_bound=0.167, batch=225 
1510: loss=0.610, reward_mean=0.120, reward_bound=0.206, batch=226 
1511: loss=0.616, reward_mean=0.110, reward_bound=0.241, batch=228 
1512: loss=0.620, reward_mean=0.090, reward_bound=0.257, batch=229 
1513: loss=0.615, reward_mean=0.090, reward_bound=0.282, batch=222 
1514: loss=0.618, reward_mean=0.070, reward_bound=0.236, batch=225 
1515: loss=0.616, reward_mean=0.140, reward_bound=0.314, batch=217 
1516: loss=0.614, reward_mean=0.160, reward_bound=0.308, batch=222 
1517: loss=0.616, reward_mean=0.110, reward_bound=0.349, batch=173 
1518: loss=0.611, reward_mean=0.100, reward_bound=0.000, batch=183 
1519: loss=0.613, reward_mean=0.090, reward_bound=0.000, batch=192 
1520: loss=0.611, reward_mean=0.090, reward_bound=0.000, batch=201 
1521: loss=0.607, reward_mean=0.120, reward_bound=0.058, batch=210 
1522: loss=0.605, reward_mean=0.090, reward_bound=0.089, batch=216 
1523: loss=0.601, reward_mean=0.120, reward_bound=0.122, batch=220 
1524: loss=0.603, reward_mean=0.170, reward_bound=0.162, batch=224 
1525: loss=0.607, reward_mean=0.100, reward_bound=0.185, batch=225 
1526: loss=0.609, reward_mean=0.110, reward_bound=0.206, batch=226 
1527: loss=0.609, reward_mean=0.170, reward_bound=0.282, batch=222 
1528: loss=0.604, reward_mean=0.130, reward_bound=0.314, batch=220 
1529: loss=0.603, reward_mean=0.110, reward_bound=0.240, batch=224 
1530: loss=0.600, reward_mean=0.090, reward_bound=0.282, batch=226 
1531: loss=0.606, reward_mean=0.130, reward_bound=0.349, batch=217 
1532: loss=0.605, reward_mean=0.110, reward_bound=0.282, batch=221 
1533: loss=0.608, reward_mean=0.130, reward_bound=0.282, batch=224 
1534: loss=0.607, reward_mean=0.120, reward_bound=0.314, batch=226 
1535: loss=0.601, reward_mean=0.110, reward_bound=0.349, batch=224 
1536: loss=0.600, reward_mean=0.080, reward_bound=0.314, batch=226 
1537: loss=0.602, reward_mean=0.140, reward_bound=0.368, batch=228 
1538: loss=0.603, reward_mean=0.120, reward_bound=0.245, batch=229 
1539: loss=0.602, reward_mean=0.050, reward_bound=0.307, batch=230 
1540: loss=0.607, reward_mean=0.060, reward_bound=0.387, batch=161 
1541: loss=0.613, reward_mean=0.130, reward_bound=0.000, batch=174 
1542: loss=0.614, reward_mean=0.130, reward_bound=0.000, batch=187 
1543: loss=0.611, reward_mean=0.120, reward_bound=0.000, batch=199 
1544: loss=0.613, reward_mean=0.130, reward_bound=0.061, batch=209 
1545: loss=0.615, reward_mean=0.120, reward_bound=0.098, batch=215 
1546: loss=0.611, reward_mean=0.130, reward_bound=0.138, batch=220 
1547: loss=0.613, reward_mean=0.130, reward_bound=0.167, batch=221 
1548: loss=0.605, reward_mean=0.130, reward_bound=0.206, batch=220 
1549: loss=0.606, reward_mean=0.140, reward_bound=0.229, batch=222 
1550: loss=0.607, reward_mean=0.060, reward_bound=0.254, batch=212 
1551: loss=0.608, reward_mean=0.150, reward_bound=0.185, batch=218 
1552: loss=0.612, reward_mean=0.140, reward_bound=0.229, batch=221 
1553: loss=0.608, reward_mean=0.080, reward_bound=0.185, batch=224 
1554: loss=0.611, reward_mean=0.140, reward_bound=0.229, batch=226 
1555: loss=0.608, reward_mean=0.120, reward_bound=0.268, batch=228 
1556: loss=0.606, reward_mean=0.080, reward_bound=0.234, batch=229 
1557: loss=0.612, reward_mean=0.150, reward_bound=0.282, batch=214 
1558: loss=0.619, reward_mean=0.190, reward_bound=0.314, batch=217 
1559: loss=0.614, reward_mean=0.140, reward_bound=0.297, batch=222 
1560: loss=0.621, reward_mean=0.140, reward_bound=0.349, batch=208 
1561: loss=0.627, reward_mean=0.070, reward_bound=0.005, batch=215 
1562: loss=0.624, reward_mean=0.110, reward_bound=0.124, batch=220 
1563: loss=0.623, reward_mean=0.080, reward_bound=0.150, batch=223 
1564: loss=0.624, reward_mean=0.100, reward_bound=0.229, batch=225 
1565: loss=0.622, reward_mean=0.130, reward_bound=0.321, batch=227 
1566: loss=0.622, reward_mean=0.160, reward_bound=0.308, batch=229 
1567: loss=0.617, reward_mean=0.160, reward_bound=0.349, batch=224 
1568: loss=0.616, reward_mean=0.140, reward_bound=0.342, batch=227 
1569: loss=0.624, reward_mean=0.090, reward_bound=0.387, batch=206 
1570: loss=0.607, reward_mean=0.090, reward_bound=0.034, batch=214 
1571: loss=0.607, reward_mean=0.140, reward_bound=0.165, batch=220 
1572: loss=0.614, reward_mean=0.120, reward_bound=0.200, batch=224 
1573: loss=0.621, reward_mean=0.160, reward_bound=0.282, batch=224 
1574: loss=0.611, reward_mean=0.170, reward_bound=0.314, batch=224 
1575: loss=0.619, reward_mean=0.140, reward_bound=0.349, batch=225 
1576: loss=0.618, reward_mean=0.170, reward_bound=0.387, batch=219 
1577: loss=0.616, reward_mean=0.140, reward_bound=0.314, batch=222 
1578: loss=0.619, reward_mean=0.080, reward_bound=0.349, batch=224 
1579: loss=0.619, reward_mean=0.100, reward_bound=0.349, batch=226 
1580: loss=0.620, reward_mean=0.150, reward_bound=0.349, batch=227 
1581: loss=0.616, reward_mean=0.090, reward_bound=0.387, batch=225 
1582: loss=0.617, reward_mean=0.100, reward_bound=0.430, batch=131 
1583: loss=0.610, reward_mean=0.070, reward_bound=0.000, batch=138 
1584: loss=0.612, reward_mean=0.150, reward_bound=0.000, batch=153 
1585: loss=0.614, reward_mean=0.180, reward_bound=0.000, batch=171 
1586: loss=0.618, reward_mean=0.120, reward_bound=0.000, batch=183 
1587: loss=0.617, reward_mean=0.090, reward_bound=0.000, batch=192 
1588: loss=0.614, reward_mean=0.110, reward_bound=0.000, batch=203 
1589: loss=0.618, reward_mean=0.120, reward_bound=0.041, batch=212 
1590: loss=0.613, reward_mean=0.140, reward_bound=0.072, batch=217 
1591: loss=0.610, reward_mean=0.070, reward_bound=0.073, batch=222 
1592: loss=0.612, reward_mean=0.110, reward_bound=0.109, batch=224 
1593: loss=0.612, reward_mean=0.100, reward_bound=0.149, batch=227 
1594: loss=0.610, reward_mean=0.150, reward_bound=0.167, batch=227 
1595: loss=0.610, reward_mean=0.070, reward_bound=0.185, batch=225 
1596: loss=0.617, reward_mean=0.130, reward_bound=0.206, batch=222 
1597: loss=0.609, reward_mean=0.110, reward_bound=0.229, batch=219 
1598: loss=0.608, reward_mean=0.190, reward_bound=0.254, batch=212 
1599: loss=0.606, reward_mean=0.130, reward_bound=0.201, batch=218 
1600: loss=0.617, reward_mean=0.120, reward_bound=0.282, batch=215 
1601: loss=0.616, reward_mean=0.170, reward_bound=0.314, batch=201 
1602: loss=0.612, reward_mean=0.090, reward_bound=0.000, batch=210 
1603: loss=0.614, reward_mean=0.120, reward_bound=0.109, batch=217 
1604: loss=0.605, reward_mean=0.200, reward_bound=0.224, batch=222 
1605: loss=0.606, reward_mean=0.130, reward_bound=0.254, batch=223 
1606: loss=0.605, reward_mean=0.080, reward_bound=0.282, batch=225 
1607: loss=0.605, reward_mean=0.060, reward_bound=0.289, batch=227 
1608: loss=0.603, reward_mean=0.060, reward_bound=0.272, batch=229 
1609: loss=0.607, reward_mean=0.130, reward_bound=0.314, batch=229 
1610: loss=0.617, reward_mean=0.070, reward_bound=0.349, batch=203 
1611: loss=0.612, reward_mean=0.080, reward_bound=0.000, batch=211 
1612: loss=0.615, reward_mean=0.140, reward_bound=0.135, batch=217 
1613: loss=0.617, reward_mean=0.070, reward_bound=0.163, batch=222 
1614: loss=0.601, reward_mean=0.150, reward_bound=0.236, batch=225 
1615: loss=0.606, reward_mean=0.110, reward_bound=0.282, batch=223 
1616: loss=0.605, reward_mean=0.140, reward_bound=0.314, batch=224 
1617: loss=0.606, reward_mean=0.110, reward_bound=0.254, batch=226 
1618: loss=0.610, reward_mean=0.090, reward_bound=0.349, batch=222 
1619: loss=0.609, reward_mean=0.090, reward_bound=0.229, batch=224 
1620: loss=0.608, reward_mean=0.150, reward_bound=0.273, batch=227 
1621: loss=0.603, reward_mean=0.120, reward_bound=0.282, batch=227 
1622: loss=0.603, reward_mean=0.090, reward_bound=0.387, batch=200 
1623: loss=0.605, reward_mean=0.080, reward_bound=0.000, batch=208 
1624: loss=0.602, reward_mean=0.100, reward_bound=0.069, batch=215 
1625: loss=0.606, reward_mean=0.060, reward_bound=0.030, batch=220 
1626: loss=0.607, reward_mean=0.060, reward_bound=0.103, batch=224 
1627: loss=0.605, reward_mean=0.070, reward_bound=0.134, batch=227 
1628: loss=0.611, reward_mean=0.160, reward_bound=0.206, batch=228 
1629: loss=0.616, reward_mean=0.120, reward_bound=0.282, batch=222 
1630: loss=0.616, reward_mean=0.100, reward_bound=0.263, batch=225 
1631: loss=0.612, reward_mean=0.070, reward_bound=0.282, batch=226 
1632: loss=0.615, reward_mean=0.100, reward_bound=0.314, batch=222 
1633: loss=0.615, reward_mean=0.100, reward_bound=0.272, batch=225 
1634: loss=0.612, reward_mean=0.090, reward_bound=0.321, batch=227 
1635: loss=0.613, reward_mean=0.070, reward_bound=0.308, batch=229 
1636: loss=0.606, reward_mean=0.140, reward_bound=0.349, batch=226 
1637: loss=0.605, reward_mean=0.090, reward_bound=0.314, batch=227 
1638: loss=0.604, reward_mean=0.150, reward_bound=0.349, batch=228 
1639: loss=0.601, reward_mean=0.110, reward_bound=0.387, batch=222 
1640: loss=0.601, reward_mean=0.060, reward_bound=0.167, batch=225 
1641: loss=0.603, reward_mean=0.100, reward_bound=0.289, batch=227 
1642: loss=0.600, reward_mean=0.120, reward_bound=0.349, batch=228 
1643: loss=0.599, reward_mean=0.200, reward_bound=0.387, batch=226 
1644: loss=0.600, reward_mean=0.150, reward_bound=0.390, batch=228 
1645: loss=0.612, reward_mean=0.130, reward_bound=0.430, batch=186 
1646: loss=0.603, reward_mean=0.100, reward_bound=0.000, batch=196 
1647: loss=0.594, reward_mean=0.140, reward_bound=0.122, batch=207 
1648: loss=0.596, reward_mean=0.080, reward_bound=0.010, batch=215 
1649: loss=0.592, reward_mean=0.140, reward_bound=0.138, batch=220 
1650: loss=0.592, reward_mean=0.120, reward_bound=0.167, batch=223 
1651: loss=0.596, reward_mean=0.100, reward_bound=0.185, batch=222 
1652: loss=0.597, reward_mean=0.130, reward_bound=0.206, batch=229 
1653: loss=0.592, reward_mean=0.120, reward_bound=0.206, batch=227 
1654: loss=0.594, reward_mean=0.180, reward_bound=0.254, batch=225 
1655: loss=0.604, reward_mean=0.120, reward_bound=0.282, batch=225 
1656: loss=0.601, reward_mean=0.140, reward_bound=0.314, batch=220 
1657: loss=0.606, reward_mean=0.100, reward_bound=0.282, batch=223 
1658: loss=0.604, reward_mean=0.100, reward_bound=0.178, batch=226 
1659: loss=0.597, reward_mean=0.150, reward_bound=0.349, batch=215 
1660: loss=0.593, reward_mean=0.130, reward_bound=0.254, batch=219 
1661: loss=0.589, reward_mean=0.130, reward_bound=0.314, batch=222 
1662: loss=0.591, reward_mean=0.120, reward_bound=0.349, batch=224 
1663: loss=0.591, reward_mean=0.070, reward_bound=0.282, batch=226 
1664: loss=0.592, reward_mean=0.090, reward_bound=0.331, batch=228 
1665: loss=0.591, reward_mean=0.070, reward_bound=0.317, batch=229 
1666: loss=0.591, reward_mean=0.080, reward_bound=0.349, batch=229 
1667: loss=0.588, reward_mean=0.100, reward_bound=0.328, batch=230 
1668: loss=0.595, reward_mean=0.090, reward_bound=0.387, batch=219 
1669: loss=0.598, reward_mean=0.100, reward_bound=0.309, batch=223 
1670: loss=0.597, reward_mean=0.100, reward_bound=0.261, batch=226 
1671: loss=0.594, reward_mean=0.090, reward_bound=0.387, batch=225 
1672: loss=0.594, reward_mean=0.070, reward_bound=0.396, batch=227 
1673: loss=0.603, reward_mean=0.160, reward_bound=0.366, batch=229 
1674: loss=0.602, reward_mean=0.100, reward_bound=0.430, batch=213 
1675: loss=0.597, reward_mean=0.080, reward_bound=0.144, batch=219 
1676: loss=0.593, reward_mean=0.120, reward_bound=0.185, batch=221 
1677: loss=0.596, reward_mean=0.140, reward_bound=0.282, batch=223 
1678: loss=0.596, reward_mean=0.130, reward_bound=0.349, batch=225 
1679: loss=0.601, reward_mean=0.100, reward_bound=0.356, batch=227 
1680: loss=0.599, reward_mean=0.140, reward_bound=0.380, batch=229 
1681: loss=0.601, reward_mean=0.120, reward_bound=0.387, batch=224 
1682: loss=0.602, reward_mean=0.070, reward_bound=0.185, batch=226 
1683: loss=0.595, reward_mean=0.110, reward_bound=0.229, batch=227 
1684: loss=0.601, reward_mean=0.130, reward_bound=0.349, batch=228 
1685: loss=0.601, reward_mean=0.140, reward_bound=0.392, batch=229 
1686: loss=0.600, reward_mean=0.150, reward_bound=0.360, batch=230 
1687: loss=0.594, reward_mean=0.130, reward_bound=0.430, batch=224 
1688: loss=0.591, reward_mean=0.080, reward_bound=0.252, batch=227 
1689: loss=0.590, reward_mean=0.090, reward_bound=0.277, batch=229 
1690: loss=0.589, reward_mean=0.140, reward_bound=0.405, batch=230 
1691: loss=0.588, reward_mean=0.130, reward_bound=0.418, batch=231 
1692: loss=0.593, reward_mean=0.110, reward_bound=0.430, batch=229 
1693: loss=0.594, reward_mean=0.130, reward_bound=0.450, batch=230 
1694: loss=0.584, reward_mean=0.130, reward_bound=0.478, batch=101 
1695: loss=0.571, reward_mean=0.110, reward_bound=0.000, batch=112 
1696: loss=0.582, reward_mean=0.160, reward_bound=0.000, batch=128 
1697: loss=0.576, reward_mean=0.070, reward_bound=0.000, batch=135 
1698: loss=0.584, reward_mean=0.130, reward_bound=0.000, batch=148 
1699: loss=0.574, reward_mean=0.110, reward_bound=0.000, batch=159 
1700: loss=0.567, reward_mean=0.140, reward_bound=0.000, batch=173 
1701: loss=0.574, reward_mean=0.100, reward_bound=0.000, batch=183 
1702: loss=0.570, reward_mean=0.080, reward_bound=0.000, batch=191 
1703: loss=0.568, reward_mean=0.090, reward_bound=0.000, batch=200 
1704: loss=0.562, reward_mean=0.110, reward_bound=0.016, batch=210 
1705: loss=0.554, reward_mean=0.130, reward_bound=0.033, batch=217 
1706: loss=0.537, reward_mean=0.110, reward_bound=0.056, batch=222 
1707: loss=0.542, reward_mean=0.180, reward_bound=0.109, batch=224 
1708: loss=0.547, reward_mean=0.120, reward_bound=0.149, batch=227 
1709: loss=0.543, reward_mean=0.200, reward_bound=0.167, batch=227 
1710: loss=0.541, reward_mean=0.160, reward_bound=0.185, batch=226 
1711: loss=0.558, reward_mean=0.200, reward_bound=0.229, batch=219 
1712: loss=0.555, reward_mean=0.150, reward_bound=0.239, batch=223 
1713: loss=0.557, reward_mean=0.100, reward_bound=0.204, batch=226 
1714: loss=0.569, reward_mean=0.150, reward_bound=0.254, batch=211 
1715: loss=0.566, reward_mean=0.100, reward_bound=0.229, batch=217 
1716: loss=0.563, reward_mean=0.100, reward_bound=0.277, batch=222 
1717: loss=0.563, reward_mean=0.090, reward_bound=0.229, batch=223 
1718: loss=0.558, reward_mean=0.160, reward_bound=0.282, batch=202 
1719: loss=0.556, reward_mean=0.080, reward_bound=0.000, batch=210 
1720: loss=0.555, reward_mean=0.120, reward_bound=0.157, batch=217 
1721: loss=0.558, reward_mean=0.060, reward_bound=0.140, batch=222 
1722: loss=0.557, reward_mean=0.120, reward_bound=0.172, batch=225 
1723: loss=0.557, reward_mean=0.140, reward_bound=0.254, batch=226 
1724: loss=0.556, reward_mean=0.150, reward_bound=0.298, batch=228 
1725: loss=0.556, reward_mean=0.140, reward_bound=0.314, batch=211 
1726: loss=0.556, reward_mean=0.100, reward_bound=0.254, batch=217 
1727: loss=0.552, reward_mean=0.150, reward_bound=0.254, batch=220 
1728: loss=0.557, reward_mean=0.120, reward_bound=0.274, batch=224 
1729: loss=0.558, reward_mean=0.140, reward_bound=0.345, batch=227 
1730: loss=0.570, reward_mean=0.110, reward_bound=0.349, batch=198 
1731: loss=0.568, reward_mean=0.060, reward_bound=0.000, batch=204 
1732: loss=0.567, reward_mean=0.130, reward_bound=0.135, batch=212 
1733: loss=0.573, reward_mean=0.150, reward_bound=0.229, batch=216 
1734: loss=0.569, reward_mean=0.060, reward_bound=0.217, batch=221 
1735: loss=0.576, reward_mean=0.140, reward_bound=0.254, batch=224 
1736: loss=0.576, reward_mean=0.080, reward_bound=0.277, batch=227 
1737: loss=0.578, reward_mean=0.080, reward_bound=0.254, batch=228 
1738: loss=0.576, reward_mean=0.130, reward_bound=0.314, batch=225 
1739: loss=0.580, reward_mean=0.170, reward_bound=0.349, batch=223 
1740: loss=0.585, reward_mean=0.100, reward_bound=0.334, batch=226 
1741: loss=0.587, reward_mean=0.100, reward_bound=0.368, batch=228 
1742: loss=0.586, reward_mean=0.140, reward_bound=0.387, batch=189 
1743: loss=0.578, reward_mean=0.080, reward_bound=0.000, batch=197 
1744: loss=0.581, reward_mean=0.150, reward_bound=0.062, batch=208 
1745: loss=0.582, reward_mean=0.150, reward_bound=0.167, batch=214 
1746: loss=0.582, reward_mean=0.080, reward_bound=0.150, batch=219 
1747: loss=0.578, reward_mean=0.150, reward_bound=0.206, batch=217 
1748: loss=0.576, reward_mean=0.150, reward_bound=0.229, batch=221 
1749: loss=0.582, reward_mean=0.090, reward_bound=0.254, batch=219 
1750: loss=0.579, reward_mean=0.150, reward_bound=0.265, batch=223 
1751: loss=0.575, reward_mean=0.140, reward_bound=0.271, batch=226 
1752: loss=0.578, reward_mean=0.170, reward_bound=0.282, batch=224 
1753: loss=0.572, reward_mean=0.180, reward_bound=0.314, batch=222 
1754: loss=0.571, reward_mean=0.100, reward_bound=0.349, batch=219 
1755: loss=0.567, reward_mean=0.060, reward_bound=0.147, batch=223 
1756: loss=0.566, reward_mean=0.200, reward_bound=0.282, batch=224 
1757: loss=0.565, reward_mean=0.150, reward_bound=0.349, batch=225 
1758: loss=0.569, reward_mean=0.090, reward_bound=0.260, batch=227 
1759: loss=0.563, reward_mean=0.120, reward_bound=0.380, batch=229 
1760: loss=0.564, reward_mean=0.120, reward_bound=0.343, batch=230 
1761: loss=0.573, reward_mean=0.190, reward_bound=0.387, batch=223 
1762: loss=0.571, reward_mean=0.150, reward_bound=0.372, batch=226 
1763: loss=0.569, reward_mean=0.150, reward_bound=0.349, batch=227 
1764: loss=0.564, reward_mean=0.120, reward_bound=0.430, batch=172 
1765: loss=0.571, reward_mean=0.100, reward_bound=0.000, batch=182 
1766: loss=0.581, reward_mean=0.120, reward_bound=0.000, batch=194 
1767: loss=0.578, reward_mean=0.090, reward_bound=0.000, batch=203 
1768: loss=0.582, reward_mean=0.100, reward_bound=0.021, batch=212 
1769: loss=0.583, reward_mean=0.140, reward_bound=0.092, batch=218 
1770: loss=0.574, reward_mean=0.210, reward_bound=0.152, batch=222 
1771: loss=0.565, reward_mean=0.100, reward_bound=0.167, batch=224 
1772: loss=0.568, reward_mean=0.180, reward_bound=0.229, batch=224 
1773: loss=0.578, reward_mean=0.100, reward_bound=0.254, batch=222 
1774: loss=0.568, reward_mean=0.090, reward_bound=0.282, batch=214 
1775: loss=0.570, reward_mean=0.080, reward_bound=0.226, batch=220 
1776: loss=0.567, reward_mean=0.130, reward_bound=0.314, batch=214 
1777: loss=0.564, reward_mean=0.120, reward_bound=0.226, batch=220 
1778: loss=0.572, reward_mean=0.160, reward_bound=0.349, batch=210 
1779: loss=0.569, reward_mean=0.090, reward_bound=0.147, batch=217 
1780: loss=0.566, reward_mean=0.060, reward_bound=0.087, batch=222 
1781: loss=0.564, reward_mean=0.090, reward_bound=0.161, batch=225 
1782: loss=0.568, reward_mean=0.150, reward_bound=0.254, batch=226 
1783: loss=0.564, reward_mean=0.150, reward_bound=0.298, batch=228 
1784: loss=0.566, reward_mean=0.090, reward_bound=0.314, batch=226 
1785: loss=0.565, reward_mean=0.140, reward_bound=0.368, batch=228 
1786: loss=0.566, reward_mean=0.100, reward_bound=0.353, batch=229 
1787: loss=0.561, reward_mean=0.140, reward_bound=0.387, batch=217 
1788: loss=0.562, reward_mean=0.190, reward_bound=0.342, batch=222 
1789: loss=0.561, reward_mean=0.110, reward_bound=0.324, batch=225 
1790: loss=0.557, reward_mean=0.150, reward_bound=0.349, batch=225 
1791: loss=0.560, reward_mean=0.140, reward_bound=0.387, batch=223 
1792: loss=0.559, reward_mean=0.110, reward_bound=0.387, batch=225 
1793: loss=0.559, reward_mean=0.150, reward_bound=0.387, batch=225 
1794: loss=0.561, reward_mean=0.110, reward_bound=0.430, batch=208 
1795: loss=0.562, reward_mean=0.130, reward_bound=0.187, batch=215 
1796: loss=0.558, reward_mean=0.060, reward_bound=0.075, batch=220 
1797: loss=0.554, reward_mean=0.080, reward_bound=0.122, batch=223 
1798: loss=0.556, reward_mean=0.170, reward_bound=0.301, batch=226 
1799: loss=0.565, reward_mean=0.100, reward_bound=0.314, batch=225 
1800: loss=0.562, reward_mean=0.090, reward_bound=0.203, batch=227 
1801: loss=0.553, reward_mean=0.170, reward_bound=0.349, batch=227 
1802: loss=0.554, reward_mean=0.070, reward_bound=0.373, batch=229 
1803: loss=0.553, reward_mean=0.080, reward_bound=0.307, batch=230 
1804: loss=0.550, reward_mean=0.130, reward_bound=0.387, batch=229 
1805: loss=0.549, reward_mean=0.130, reward_bound=0.430, batch=220 
1806: loss=0.546, reward_mean=0.090, reward_bound=0.376, batch=224 
1807: loss=0.548, reward_mean=0.160, reward_bound=0.345, batch=227 
1808: loss=0.543, reward_mean=0.130, reward_bound=0.349, batch=228 
1809: loss=0.543, reward_mean=0.110, reward_bound=0.293, batch=229 
1810: loss=0.542, reward_mean=0.160, reward_bound=0.387, batch=228 
1811: loss=0.541, reward_mean=0.060, reward_bound=0.392, batch=229 
1812: loss=0.541, reward_mean=0.130, reward_bound=0.405, batch=230 
1813: loss=0.540, reward_mean=0.080, reward_bound=0.356, batch=231 
1814: loss=0.540, reward_mean=0.140, reward_bound=0.387, batch=231 
1815: loss=0.538, reward_mean=0.150, reward_bound=0.430, batch=229 
1816: loss=0.536, reward_mean=0.110, reward_bound=0.364, batch=230 
1817: loss=0.534, reward_mean=0.100, reward_bound=0.376, batch=231 
1818: loss=0.537, reward_mean=0.130, reward_bound=0.387, batch=230 
1819: loss=0.537, reward_mean=0.090, reward_bound=0.418, batch=231 
1820: loss=0.537, reward_mean=0.170, reward_bound=0.387, batch=231 
1821: loss=0.546, reward_mean=0.170, reward_bound=0.478, batch=161 
1822: loss=0.525, reward_mean=0.120, reward_bound=0.000, batch=173 
1823: loss=0.511, reward_mean=0.150, reward_bound=0.000, batch=188 
1824: loss=0.514, reward_mean=0.160, reward_bound=0.020, batch=201 
1825: loss=0.518, reward_mean=0.150, reward_bound=0.065, batch=210 
1826: loss=0.533, reward_mean=0.170, reward_bound=0.118, batch=217 
1827: loss=0.530, reward_mean=0.190, reward_bound=0.147, batch=222 
1828: loss=0.523, reward_mean=0.100, reward_bound=0.185, batch=221 
1829: loss=0.519, reward_mean=0.150, reward_bound=0.206, batch=223 
1830: loss=0.524, reward_mean=0.170, reward_bound=0.254, batch=217 
1831: loss=0.529, reward_mean=0.130, reward_bound=0.282, batch=215 
1832: loss=0.528, reward_mean=0.150, reward_bound=0.289, batch=220 
1833: loss=0.525, reward_mean=0.090, reward_bound=0.282, batch=223 
1834: loss=0.542, reward_mean=0.150, reward_bound=0.314, batch=213 
1835: loss=0.543, reward_mean=0.100, reward_bound=0.244, batch=219 
1836: loss=0.543, reward_mean=0.170, reward_bound=0.278, batch=223 
1837: loss=0.542, reward_mean=0.080, reward_bound=0.301, batch=226 
1838: loss=0.539, reward_mean=0.120, reward_bound=0.314, batch=226 
1839: loss=0.533, reward_mean=0.100, reward_bound=0.349, batch=207 
1840: loss=0.538, reward_mean=0.110, reward_bound=0.229, batch=214 
1841: loss=0.541, reward_mean=0.140, reward_bound=0.133, batch=220 
1842: loss=0.542, reward_mean=0.110, reward_bound=0.200, batch=224 
1843: loss=0.540, reward_mean=0.080, reward_bound=0.249, batch=227 
1844: loss=0.542, reward_mean=0.110, reward_bound=0.254, batch=226 
1845: loss=0.532, reward_mean=0.220, reward_bound=0.314, batch=225 
1846: loss=0.529, reward_mean=0.140, reward_bound=0.356, batch=227 
1847: loss=0.522, reward_mean=0.180, reward_bound=0.387, batch=208 
1848: loss=0.522, reward_mean=0.170, reward_bound=0.208, batch=215 
1849: loss=0.520, reward_mean=0.130, reward_bound=0.260, batch=220 
1850: loss=0.530, reward_mean=0.120, reward_bound=0.282, batch=222 
1851: loss=0.534, reward_mean=0.150, reward_bound=0.292, batch=225 
1852: loss=0.536, reward_mean=0.100, reward_bound=0.314, batch=224 
1853: loss=0.535, reward_mean=0.100, reward_bound=0.337, batch=227 
1854: loss=0.534, reward_mean=0.110, reward_bound=0.342, batch=229 
1855: loss=0.531, reward_mean=0.100, reward_bound=0.349, batch=223 
1856: loss=0.532, reward_mean=0.120, reward_bound=0.372, batch=226 
1857: loss=0.531, reward_mean=0.100, reward_bound=0.387, batch=222 
1858: loss=0.529, reward_mean=0.120, reward_bound=0.387, batch=224 
1859: loss=0.546, reward_mean=0.150, reward_bound=0.430, batch=188 
1860: loss=0.539, reward_mean=0.070, reward_bound=0.000, batch=195 
1861: loss=0.538, reward_mean=0.110, reward_bound=0.004, batch=206 
1862: loss=0.549, reward_mean=0.100, reward_bound=0.046, batch=214 
1863: loss=0.549, reward_mean=0.060, reward_bound=0.052, batch=220 
1864: loss=0.552, reward_mean=0.130, reward_bound=0.157, batch=224 
1865: loss=0.554, reward_mean=0.100, reward_bound=0.183, batch=227 
1866: loss=0.543, reward_mean=0.100, reward_bound=0.229, batch=223 
1867: loss=0.545, reward_mean=0.080, reward_bound=0.227, batch=226 
1868: loss=0.544, reward_mean=0.110, reward_bound=0.254, batch=222 
1869: loss=0.543, reward_mean=0.120, reward_bound=0.245, batch=225 
1870: loss=0.541, reward_mean=0.170, reward_bound=0.282, batch=226 
1871: loss=0.539, reward_mean=0.160, reward_bound=0.298, batch=228 
1872: loss=0.542, reward_mean=0.030, reward_bound=0.314, batch=228 
1873: loss=0.542, reward_mean=0.090, reward_bound=0.289, batch=229 
1874: loss=0.548, reward_mean=0.110, reward_bound=0.349, batch=219 
1875: loss=0.547, reward_mean=0.140, reward_bound=0.278, batch=223 
1876: loss=0.546, reward_mean=0.100, reward_bound=0.314, batch=225 
1877: loss=0.546, reward_mean=0.140, reward_bound=0.321, batch=227 
1878: loss=0.545, reward_mean=0.160, reward_bound=0.380, batch=229 
1879: loss=0.555, reward_mean=0.120, reward_bound=0.387, batch=219 
1880: loss=0.558, reward_mean=0.140, reward_bound=0.349, batch=222 
1881: loss=0.555, reward_mean=0.160, reward_bound=0.387, batch=222 
1882: loss=0.554, reward_mean=0.160, reward_bound=0.360, batch=225 
1883: loss=0.554, reward_mean=0.150, reward_bound=0.282, batch=225 
1884: loss=0.553, reward_mean=0.060, reward_bound=0.356, batch=227 
1885: loss=0.551, reward_mean=0.110, reward_bound=0.366, batch=229 
1886: loss=0.551, reward_mean=0.120, reward_bound=0.387, batch=227 
1887: loss=0.542, reward_mean=0.110, reward_bound=0.430, batch=207 
1888: loss=0.545, reward_mean=0.100, reward_bound=0.115, batch=215 
1889: loss=0.544, reward_mean=0.110, reward_bound=0.206, batch=219 
1890: loss=0.548, reward_mean=0.130, reward_bound=0.229, batch=222 
1891: loss=0.545, reward_mean=0.060, reward_bound=0.282, batch=221 
1892: loss=0.546, reward_mean=0.100, reward_bound=0.314, batch=221 
1893: loss=0.547, reward_mean=0.130, reward_bound=0.349, batch=222 
1894: loss=0.545, reward_mean=0.090, reward_bound=0.360, batch=225 
1895: loss=0.541, reward_mean=0.130, reward_bound=0.387, batch=221 
1896: loss=0.542, reward_mean=0.150, reward_bound=0.430, batch=218 
1897: loss=0.538, reward_mean=0.140, reward_bound=0.286, batch=222 
1898: loss=0.537, reward_mean=0.120, reward_bound=0.292, batch=225 
1899: loss=0.543, reward_mean=0.180, reward_bound=0.314, batch=226 
1900: loss=0.548, reward_mean=0.140, reward_bound=0.349, batch=227 
1901: loss=0.550, reward_mean=0.160, reward_bound=0.380, batch=229 
1902: loss=0.549, reward_mean=0.120, reward_bound=0.387, batch=226 
1903: loss=0.549, reward_mean=0.040, reward_bound=0.271, batch=228 
1904: loss=0.551, reward_mean=0.090, reward_bound=0.392, batch=229 
1905: loss=0.549, reward_mean=0.110, reward_bound=0.430, batch=222 
1906: loss=0.548, reward_mean=0.160, reward_bound=0.445, batch=225 
1907: loss=0.548, reward_mean=0.080, reward_bound=0.396, batch=227 
1908: loss=0.551, reward_mean=0.120, reward_bound=0.422, batch=229 
1909: loss=0.549, reward_mean=0.140, reward_bound=0.430, batch=227 
1910: loss=0.547, reward_mean=0.100, reward_bound=0.349, batch=228 
1911: loss=0.548, reward_mean=0.140, reward_bound=0.435, batch=229 
1912: loss=0.548, reward_mean=0.070, reward_bound=0.349, batch=229 
1913: loss=0.548, reward_mean=0.190, reward_bound=0.430, batch=229 
1914: loss=0.548, reward_mean=0.150, reward_bound=0.430, batch=229 
1915: loss=0.547, reward_mean=0.120, reward_bound=0.405, batch=230 
1916: loss=0.544, reward_mean=0.100, reward_bound=0.304, batch=231 
1917: loss=0.548, reward_mean=0.120, reward_bound=0.430, batch=230 
1918: loss=0.547, reward_mean=0.160, reward_bound=0.464, batch=231 
1919: loss=0.555, reward_mean=0.080, reward_bound=0.478, batch=187 
1920: loss=0.546, reward_mean=0.080, reward_bound=0.000, batch=195 
1921: loss=0.539, reward_mean=0.130, reward_bound=0.027, batch=206 
1922: loss=0.541, reward_mean=0.100, reward_bound=0.061, batch=214 
1923: loss=0.557, reward_mean=0.180, reward_bound=0.167, batch=219 
1924: loss=0.553, reward_mean=0.150, reward_bound=0.229, batch=218 
1925: loss=0.553, reward_mean=0.080, reward_bound=0.206, batch=221 
1926: loss=0.561, reward_mean=0.100, reward_bound=0.254, batch=224 
1927: loss=0.552, reward_mean=0.120, reward_bound=0.282, batch=225 
1928: loss=0.556, reward_mean=0.180, reward_bound=0.314, batch=218 
1929: loss=0.553, reward_mean=0.160, reward_bound=0.254, batch=220 
1930: loss=0.557, reward_mean=0.080, reward_bound=0.282, batch=223 
1931: loss=0.555, reward_mean=0.080, reward_bound=0.244, batch=226 
1932: loss=0.545, reward_mean=0.120, reward_bound=0.349, batch=218 
1933: loss=0.539, reward_mean=0.100, reward_bound=0.132, batch=222 
1934: loss=0.546, reward_mean=0.160, reward_bound=0.282, batch=224 
1935: loss=0.543, reward_mean=0.150, reward_bound=0.349, batch=226 
1936: loss=0.546, reward_mean=0.140, reward_bound=0.387, batch=214 
1937: loss=0.545, reward_mean=0.150, reward_bound=0.314, batch=218 
1938: loss=0.543, reward_mean=0.160, reward_bound=0.353, batch=222 
1939: loss=0.542, reward_mean=0.140, reward_bound=0.387, batch=223 
1940: loss=0.539, reward_mean=0.150, reward_bound=0.372, batch=226 
1941: loss=0.539, reward_mean=0.110, reward_bound=0.409, batch=228 
1942: loss=0.540, reward_mean=0.110, reward_bound=0.430, batch=218 
1943: loss=0.540, reward_mean=0.130, reward_bound=0.317, batch=222 
1944: loss=0.544, reward_mean=0.130, reward_bound=0.387, batch=224 
1945: loss=0.544, reward_mean=0.120, reward_bound=0.229, batch=226 
1946: loss=0.541, reward_mean=0.080, reward_bound=0.314, batch=227 
1947: loss=0.539, reward_mean=0.140, reward_bound=0.414, batch=229 
1948: loss=0.538, reward_mean=0.170, reward_bound=0.364, batch=230 
1949: loss=0.541, reward_mean=0.110, reward_bound=0.387, batch=230 
1950: loss=0.540, reward_mean=0.110, reward_bound=0.430, batch=226 
1951: loss=0.541, reward_mean=0.150, reward_bound=0.387, batch=227 
1952: loss=0.540, reward_mean=0.090, reward_bound=0.254, batch=228 
1953: loss=0.539, reward_mean=0.050, reward_bound=0.392, batch=229 
1954: loss=0.539, reward_mean=0.110, reward_bound=0.405, batch=230 
1955: loss=0.539, reward_mean=0.200, reward_bound=0.387, batch=230 
1956: loss=0.538, reward_mean=0.120, reward_bound=0.395, batch=231 
1957: loss=0.541, reward_mean=0.090, reward_bound=0.430, batch=229 
1958: loss=0.542, reward_mean=0.120, reward_bound=0.478, batch=231 
1959: loss=0.543, reward_mean=0.100, reward_bound=0.478, batch=207 
1960: loss=0.542, reward_mean=0.110, reward_bound=0.140, batch=215 
1961: loss=0.543, reward_mean=0.130, reward_bound=0.229, batch=218 
1962: loss=0.543, reward_mean=0.140, reward_bound=0.254, batch=221 
1963: loss=0.544, reward_mean=0.150, reward_bound=0.349, batch=220 
1964: loss=0.546, reward_mean=0.130, reward_bound=0.304, batch=224 
1965: loss=0.545, reward_mean=0.160, reward_bound=0.349, batch=225 
1966: loss=0.541, reward_mean=0.190, reward_bound=0.356, batch=227 
1967: loss=0.541, reward_mean=0.150, reward_bound=0.387, batch=221 
1968: loss=0.537, reward_mean=0.100, reward_bound=0.254, batch=224 
1969: loss=0.539, reward_mean=0.110, reward_bound=0.311, batch=227 
1970: loss=0.543, reward_mean=0.150, reward_bound=0.342, batch=229 
1971: loss=0.545, reward_mean=0.110, reward_bound=0.364, batch=230 
1972: loss=0.544, reward_mean=0.160, reward_bound=0.430, batch=218 
1973: loss=0.543, reward_mean=0.140, reward_bound=0.387, batch=220 
1974: loss=0.540, reward_mean=0.100, reward_bound=0.254, batch=223 
1975: loss=0.540, reward_mean=0.070, reward_bound=0.244, batch=226 
1976: loss=0.539, reward_mean=0.090, reward_bound=0.298, batch=228 
1977: loss=0.540, reward_mean=0.110, reward_bound=0.314, batch=227 
1978: loss=0.541, reward_mean=0.150, reward_bound=0.387, batch=227 
1979: loss=0.543, reward_mean=0.130, reward_bound=0.430, batch=223 
1980: loss=0.544, reward_mean=0.150, reward_bound=0.290, batch=226 
1981: loss=0.545, reward_mean=0.110, reward_bound=0.331, batch=228 
1982: loss=0.546, reward_mean=0.170, reward_bound=0.387, batch=226 
1983: loss=0.548, reward_mean=0.080, reward_bound=0.351, batch=228 
1984: loss=0.549, reward_mean=0.160, reward_bound=0.392, batch=229 
1985: loss=0.548, reward_mean=0.100, reward_bound=0.381, batch=230 
1986: loss=0.552, reward_mean=0.090, reward_bound=0.338, batch=231 
1987: loss=0.548, reward_mean=0.160, reward_bound=0.430, batch=228 
1988: loss=0.548, reward_mean=0.140, reward_bound=0.435, batch=229 
1989: loss=0.546, reward_mean=0.170, reward_bound=0.405, batch=230 
1990: loss=0.546, reward_mean=0.120, reward_bound=0.387, batch=230 
1991: loss=0.550, reward_mean=0.110, reward_bound=0.464, batch=231 
1992: loss=0.550, reward_mean=0.110, reward_bound=0.430, batch=231 
1993: loss=0.540, reward_mean=0.110, reward_bound=0.478, batch=216 
1994: loss=0.541, reward_mean=0.160, reward_bound=0.331, batch=221 
1995: loss=0.543, reward_mean=0.110, reward_bound=0.282, batch=224 
1996: loss=0.543, reward_mean=0.100, reward_bound=0.269, batch=227 
1997: loss=0.541, reward_mean=0.060, reward_bound=0.282, batch=227 
1998: loss=0.540, reward_mean=0.140, reward_bound=0.349, batch=227 
1999: loss=0.535, reward_mean=0.170, reward_bound=0.387, batch=224 
2000: loss=0.534, reward_mean=0.090, reward_bound=0.387, batch=225 
2001: loss=0.534, reward_mean=0.090, reward_bound=0.321, batch=227 
2002: loss=0.534, reward_mean=0.190, reward_bound=0.414, batch=229 
2003: loss=0.534, reward_mean=0.120, reward_bound=0.430, batch=227 
2004: loss=0.532, reward_mean=0.120, reward_bound=0.422, batch=229 
2005: loss=0.537, reward_mean=0.140, reward_bound=0.450, batch=230 
2006: loss=0.544, reward_mean=0.150, reward_bound=0.478, batch=220 
2007: loss=0.543, reward_mean=0.110, reward_bound=0.338, batch=224 
2008: loss=0.542, reward_mean=0.090, reward_bound=0.342, batch=227 
2009: loss=0.542, reward_mean=0.090, reward_bound=0.308, batch=229 
2010: loss=0.544, reward_mean=0.090, reward_bound=0.328, batch=230 
2011: loss=0.542, reward_mean=0.080, reward_bound=0.349, batch=229 
2012: loss=0.538, reward_mean=0.100, reward_bound=0.387, batch=227 
2013: loss=0.535, reward_mean=0.120, reward_bound=0.422, batch=229 
2014: loss=0.540, reward_mean=0.130, reward_bound=0.430, batch=225 
2015: loss=0.540, reward_mean=0.080, reward_bound=0.356, batch=227 
2016: loss=0.544, reward_mean=0.150, reward_bound=0.387, batch=228 
2017: loss=0.545, reward_mean=0.120, reward_bound=0.392, batch=229 
2018: loss=0.544, reward_mean=0.070, reward_bound=0.364, batch=230 
2019: loss=0.545, reward_mean=0.110, reward_bound=0.387, batch=230 
2020: loss=0.543, reward_mean=0.120, reward_bound=0.430, batch=228 
2021: loss=0.542, reward_mean=0.110, reward_bound=0.397, batch=229 
2022: loss=0.541, reward_mean=0.090, reward_bound=0.380, batch=230 
2023: loss=0.539, reward_mean=0.090, reward_bound=0.464, batch=231 
2024: loss=0.541, reward_mean=0.140, reward_bound=0.478, batch=224 
2025: loss=0.538, reward_mean=0.090, reward_bound=0.311, batch=227 
2026: loss=0.536, reward_mean=0.150, reward_bound=0.277, batch=229 
2027: loss=0.538, reward_mean=0.130, reward_bound=0.349, batch=227 
2028: loss=0.537, reward_mean=0.120, reward_bound=0.422, batch=229 
2029: loss=0.538, reward_mean=0.120, reward_bound=0.430, batch=229 
2030: loss=0.537, reward_mean=0.110, reward_bound=0.424, batch=230 
2031: loss=0.538, reward_mean=0.170, reward_bound=0.451, batch=231 
2032: loss=0.540, reward_mean=0.090, reward_bound=0.478, batch=228 
2034: loss=0.446, reward_mean=0.130, reward_bound=0.000, batch=13 
2035: loss=0.453, reward_mean=0.120, reward_bound=0.000, batch=25 
2036: loss=0.474, reward_mean=0.090, reward_bound=0.000, batch=34 
2037: loss=0.476, reward_mean=0.190, reward_bound=0.000, batch=53 
2038: loss=0.483, reward_mean=0.140, reward_bound=0.000, batch=67 
2039: loss=0.476, reward_mean=0.170, reward_bound=0.000, batch=84 
2040: loss=0.463, reward_mean=0.110, reward_bound=0.000, batch=95 
2041: loss=0.455, reward_mean=0.200, reward_bound=0.000, batch=115 
2042: loss=0.448, reward_mean=0.120, reward_bound=0.000, batch=127 
2043: loss=0.442, reward_mean=0.160, reward_bound=0.000, batch=143 
2044: loss=0.426, reward_mean=0.190, reward_bound=0.000, batch=162 
2045: loss=0.422, reward_mean=0.170, reward_bound=0.000, batch=179 
2046: loss=0.422, reward_mean=0.230, reward_bound=0.016, batch=195 
2047: loss=0.426, reward_mean=0.260, reward_bound=0.034, batch=205 
2048: loss=0.434, reward_mean=0.170, reward_bound=0.047, batch=212 
2049: loss=0.430, reward_mean=0.220, reward_bound=0.089, batch=217 
2050: loss=0.427, reward_mean=0.170, reward_bound=0.098, batch=217 
2051: loss=0.422, reward_mean=0.180, reward_bound=0.109, batch=230 
2052: loss=0.425, reward_mean=0.150, reward_bound=0.109, batch=226 
2053: loss=0.423, reward_mean=0.110, reward_bound=0.122, batch=217 
2054: loss=0.419, reward_mean=0.220, reward_bound=0.135, batch=209 
2055: loss=0.422, reward_mean=0.190, reward_bound=0.150, batch=208 
2056: loss=0.421, reward_mean=0.250, reward_bound=0.167, batch=206 
2057: loss=0.427, reward_mean=0.170, reward_bound=0.185, batch=197 
2058: loss=0.422, reward_mean=0.250, reward_bound=0.206, batch=190 
2059: loss=0.410, reward_mean=0.180, reward_bound=0.041, batch=203 
2060: loss=0.413, reward_mean=0.210, reward_bound=0.098, batch=211 
2061: loss=0.415, reward_mean=0.180, reward_bound=0.150, batch=217 
2062: loss=0.415, reward_mean=0.180, reward_bound=0.206, batch=220 
2063: loss=0.418, reward_mean=0.210, reward_bound=0.229, batch=202 
2064: loss=0.413, reward_mean=0.140, reward_bound=0.117, batch=211 
2065: loss=0.409, reward_mean=0.240, reward_bound=0.185, batch=216 
2066: loss=0.414, reward_mean=0.210, reward_bound=0.229, batch=220 
2067: loss=0.411, reward_mean=0.240, reward_bound=0.254, batch=199 
2068: loss=0.418, reward_mean=0.180, reward_bound=0.157, batch=209 
2069: loss=0.418, reward_mean=0.160, reward_bound=0.215, batch=216 
2070: loss=0.418, reward_mean=0.230, reward_bound=0.241, batch=221 
2071: loss=0.415, reward_mean=0.220, reward_bound=0.282, batch=188 
2072: loss=0.400, reward_mean=0.150, reward_bound=0.026, batch=201 
2073: loss=0.404, reward_mean=0.210, reward_bound=0.135, batch=209 
2074: loss=0.406, reward_mean=0.150, reward_bound=0.141, batch=216 
2075: loss=0.410, reward_mean=0.210, reward_bound=0.186, batch=221 
2076: loss=0.419, reward_mean=0.210, reward_bound=0.229, batch=224 
2077: loss=0.412, reward_mean=0.210, reward_bound=0.254, batch=224 
2078: loss=0.415, reward_mean=0.160, reward_bound=0.282, batch=222 
2079: loss=0.401, reward_mean=0.250, reward_bound=0.314, batch=178 
2080: loss=0.402, reward_mean=0.130, reward_bound=0.000, batch=191 
2081: loss=0.393, reward_mean=0.220, reward_bound=0.072, batch=203 
2082: loss=0.400, reward_mean=0.230, reward_bound=0.109, batch=211 
2083: loss=0.401, reward_mean=0.230, reward_bound=0.150, batch=216 
2084: loss=0.394, reward_mean=0.220, reward_bound=0.185, batch=218 
2085: loss=0.395, reward_mean=0.170, reward_bound=0.206, batch=220 
2086: loss=0.394, reward_mean=0.160, reward_bound=0.229, batch=219 
2087: loss=0.400, reward_mean=0.270, reward_bound=0.254, batch=217 
2088: loss=0.404, reward_mean=0.180, reward_bound=0.282, batch=216 
2089: loss=0.400, reward_mean=0.190, reward_bound=0.217, batch=221 
2090: loss=0.401, reward_mean=0.170, reward_bound=0.254, batch=223 
2091: loss=0.404, reward_mean=0.180, reward_bound=0.282, batch=225 
2092: loss=0.404, reward_mean=0.220, reward_bound=0.314, batch=215 
2093: loss=0.402, reward_mean=0.170, reward_bound=0.282, batch=219 
2094: loss=0.400, reward_mean=0.200, reward_bound=0.254, batch=222 
2095: loss=0.398, reward_mean=0.240, reward_bound=0.324, batch=225 
2096: loss=0.416, reward_mean=0.190, reward_bound=0.349, batch=175 
2097: loss=0.420, reward_mean=0.160, reward_bound=0.000, batch=191 
2098: loss=0.412, reward_mean=0.140, reward_bound=0.038, batch=203 
2099: loss=0.418, reward_mean=0.110, reward_bound=0.047, batch=211 
2100: loss=0.422, reward_mean=0.230, reward_bound=0.122, batch=217 
2101: loss=0.419, reward_mean=0.220, reward_bound=0.202, batch=222 
2102: loss=0.411, reward_mean=0.150, reward_bound=0.206, batch=229 
2103: loss=0.424, reward_mean=0.220, reward_bound=0.229, batch=226 
2104: loss=0.422, reward_mean=0.130, reward_bound=0.254, batch=222 
2105: loss=0.427, reward_mean=0.190, reward_bound=0.282, batch=219 
2106: loss=0.422, reward_mean=0.230, reward_bound=0.314, batch=215 
2107: loss=0.417, reward_mean=0.200, reward_bound=0.321, batch=220 
2108: loss=0.420, reward_mean=0.110, reward_bound=0.229, batch=223 
2109: loss=0.420, reward_mean=0.200, reward_bound=0.335, batch=226 
2110: loss=0.408, reward_mean=0.150, reward_bound=0.349, batch=217 
2111: loss=0.405, reward_mean=0.160, reward_bound=0.185, batch=221 
2112: loss=0.404, reward_mean=0.190, reward_bound=0.314, batch=222 
2113: loss=0.402, reward_mean=0.170, reward_bound=0.213, batch=225 
2114: loss=0.406, reward_mean=0.210, reward_bound=0.266, batch=227 
2115: loss=0.406, reward_mean=0.190, reward_bound=0.314, batch=227 
2116: loss=0.405, reward_mean=0.190, reward_bound=0.314, batch=228 
2117: loss=0.403, reward_mean=0.190, reward_bound=0.349, batch=224 
2118: loss=0.400, reward_mean=0.180, reward_bound=0.387, batch=154 
2119: loss=0.404, reward_mean=0.200, reward_bound=0.000, batch=174 
2120: loss=0.389, reward_mean=0.180, reward_bound=0.008, batch=192 
2121: loss=0.402, reward_mean=0.180, reward_bound=0.022, batch=204 
2122: loss=0.410, reward_mean=0.170, reward_bound=0.058, batch=213 
2123: loss=0.415, reward_mean=0.210, reward_bound=0.098, batch=218 
2124: loss=0.405, reward_mean=0.160, reward_bound=0.135, batch=221 
2125: loss=0.402, reward_mean=0.140, reward_bound=0.167, batch=222 
2126: loss=0.400, reward_mean=0.170, reward_bound=0.185, batch=219 
2127: loss=0.401, reward_mean=0.130, reward_bound=0.215, batch=223 
2128: loss=0.395, reward_mean=0.160, reward_bound=0.229, batch=222 
2129: loss=0.393, reward_mean=0.220, reward_bound=0.254, batch=221 
2130: loss=0.393, reward_mean=0.220, reward_bound=0.282, batch=219 
2131: loss=0.392, reward_mean=0.130, reward_bound=0.265, batch=223 
2132: loss=0.390, reward_mean=0.200, reward_bound=0.314, batch=216 
2133: loss=0.390, reward_mean=0.150, reward_bound=0.268, batch=221 
2134: loss=0.388, reward_mean=0.230, reward_bound=0.314, batch=224 
2135: loss=0.393, reward_mean=0.190, reward_bound=0.349, batch=208 
2136: loss=0.390, reward_mean=0.180, reward_bound=0.282, batch=213 
2137: loss=0.394, reward_mean=0.230, reward_bound=0.227, batch=219 
2138: loss=0.383, reward_mean=0.190, reward_bound=0.295, batch=223 
2139: loss=0.386, reward_mean=0.200, reward_bound=0.314, batch=224 
2140: loss=0.387, reward_mean=0.210, reward_bound=0.305, batch=227 
2141: loss=0.386, reward_mean=0.190, reward_bound=0.308, batch=229 
2142: loss=0.383, reward_mean=0.140, reward_bound=0.314, batch=228 
2143: loss=0.392, reward_mean=0.180, reward_bound=0.353, batch=229 
2144: loss=0.396, reward_mean=0.150, reward_bound=0.387, batch=207 
2145: loss=0.403, reward_mean=0.230, reward_bound=0.224, batch=215 
2146: loss=0.410, reward_mean=0.170, reward_bound=0.260, batch=220 
2147: loss=0.413, reward_mean=0.230, reward_bound=0.282, batch=223 
2148: loss=0.404, reward_mean=0.210, reward_bound=0.314, batch=217 
2149: loss=0.407, reward_mean=0.140, reward_bound=0.292, batch=222 
2150: loss=0.409, reward_mean=0.190, reward_bound=0.314, batch=224 
2151: loss=0.411, reward_mean=0.160, reward_bound=0.311, batch=227 
2152: loss=0.409, reward_mean=0.250, reward_bound=0.342, batch=229 
2153: loss=0.406, reward_mean=0.240, reward_bound=0.349, batch=224 
2154: loss=0.405, reward_mean=0.150, reward_bound=0.345, batch=227 
2155: loss=0.404, reward_mean=0.150, reward_bound=0.387, batch=223 
2156: loss=0.404, reward_mean=0.180, reward_bound=0.398, batch=226 
2157: loss=0.401, reward_mean=0.160, reward_bound=0.316, batch=228 
2158: loss=0.402, reward_mean=0.150, reward_bound=0.387, batch=227 
2159: loss=0.402, reward_mean=0.180, reward_bound=0.414, batch=229 
2160: loss=0.401, reward_mean=0.120, reward_bound=0.381, batch=230 
2161: loss=0.401, reward_mean=0.140, reward_bound=0.387, batch=230 
2162: loss=0.389, reward_mean=0.170, reward_bound=0.430, batch=126 
2163: loss=0.399, reward_mean=0.180, reward_bound=0.000, batch=144 
2164: loss=0.385, reward_mean=0.200, reward_bound=0.000, batch=164 
2165: loss=0.379, reward_mean=0.170, reward_bound=0.000, batch=181 
2166: loss=0.371, reward_mean=0.210, reward_bound=0.034, batch=195 
2167: loss=0.369, reward_mean=0.170, reward_bound=0.052, batch=204 
2168: loss=0.378, reward_mean=0.170, reward_bound=0.072, batch=211 
2169: loss=0.375, reward_mean=0.180, reward_bound=0.098, batch=215 
2170: loss=0.378, reward_mean=0.170, reward_bound=0.112, batch=220 
2171: loss=0.373, reward_mean=0.180, reward_bound=0.150, batch=215 
2172: loss=0.371, reward_mean=0.160, reward_bound=0.170, batch=220 
2173: loss=0.373, reward_mean=0.150, reward_bound=0.185, batch=221 
2174: loss=0.378, reward_mean=0.150, reward_bound=0.206, batch=218 
2175: loss=0.378, reward_mean=0.250, reward_bound=0.229, batch=212 
2176: loss=0.375, reward_mean=0.210, reward_bound=0.179, batch=218 
2177: loss=0.377, reward_mean=0.170, reward_bound=0.229, batch=221 
2178: loss=0.374, reward_mean=0.230, reward_bound=0.254, batch=221 
2179: loss=0.368, reward_mean=0.190, reward_bound=0.282, batch=209 
2180: loss=0.367, reward_mean=0.180, reward_bound=0.225, batch=216 
2181: loss=0.369, reward_mean=0.220, reward_bound=0.254, batch=220 
2182: loss=0.369, reward_mean=0.200, reward_bound=0.282, batch=222 
2183: loss=0.377, reward_mean=0.190, reward_bound=0.314, batch=206 
2184: loss=0.372, reward_mean=0.200, reward_bound=0.256, batch=214 
2185: loss=0.381, reward_mean=0.230, reward_bound=0.349, batch=194 
2186: loss=0.369, reward_mean=0.140, reward_bound=0.064, batch=206 
2187: loss=0.358, reward_mean=0.200, reward_bound=0.158, batch=214 
2188: loss=0.361, reward_mean=0.200, reward_bound=0.185, batch=219 
2189: loss=0.364, reward_mean=0.140, reward_bound=0.229, batch=221 
2190: loss=0.373, reward_mean=0.180, reward_bound=0.254, batch=224 
2191: loss=0.368, reward_mean=0.210, reward_bound=0.282, batch=226 
2192: loss=0.376, reward_mean=0.240, reward_bound=0.314, batch=223 
2193: loss=0.375, reward_mean=0.140, reward_bound=0.349, batch=223 
2194: loss=0.373, reward_mean=0.210, reward_bound=0.358, batch=226 
2195: loss=0.377, reward_mean=0.200, reward_bound=0.387, batch=203 
2196: loss=0.373, reward_mean=0.200, reward_bound=0.244, batch=212 
2197: loss=0.366, reward_mean=0.180, reward_bound=0.282, batch=215 
2198: loss=0.371, reward_mean=0.220, reward_bound=0.260, batch=220 
2199: loss=0.369, reward_mean=0.140, reward_bound=0.282, batch=222 
2200: loss=0.362, reward_mean=0.210, reward_bound=0.314, batch=222 
2201: loss=0.366, reward_mean=0.180, reward_bound=0.349, batch=219 
2202: loss=0.367, reward_mean=0.190, reward_bound=0.343, batch=223 
2203: loss=0.369, reward_mean=0.240, reward_bound=0.387, batch=223 
2204: loss=0.367, reward_mean=0.170, reward_bound=0.349, batch=225 
2205: loss=0.370, reward_mean=0.110, reward_bound=0.387, batch=226 
2206: loss=0.369, reward_mean=0.150, reward_bound=0.387, batch=227 
2207: loss=0.360, reward_mean=0.140, reward_bound=0.430, batch=174 
2208: loss=0.363, reward_mean=0.190, reward_bound=0.018, batch=191 
2209: loss=0.359, reward_mean=0.160, reward_bound=0.028, batch=203 
2210: loss=0.367, reward_mean=0.160, reward_bound=0.074, batch=212 
2211: loss=0.364, reward_mean=0.220, reward_bound=0.122, batch=217 
2212: loss=0.369, reward_mean=0.200, reward_bound=0.163, batch=222 
2213: loss=0.359, reward_mean=0.100, reward_bound=0.167, batch=222 
2214: loss=0.364, reward_mean=0.190, reward_bound=0.185, batch=221 
2215: loss=0.363, reward_mean=0.140, reward_bound=0.206, batch=221 
2216: loss=0.355, reward_mean=0.210, reward_bound=0.229, batch=220 
2217: loss=0.361, reward_mean=0.200, reward_bound=0.254, batch=222 
2218: loss=0.363, reward_mean=0.160, reward_bound=0.245, batch=225 
2219: loss=0.364, reward_mean=0.210, reward_bound=0.282, batch=218 
2220: loss=0.362, reward_mean=0.150, reward_bound=0.286, batch=222 
2221: loss=0.360, reward_mean=0.240, reward_bound=0.254, batch=224 
2222: loss=0.362, reward_mean=0.140, reward_bound=0.311, batch=227 
2223: loss=0.360, reward_mean=0.190, reward_bound=0.308, batch=229 
2224: loss=0.359, reward_mean=0.170, reward_bound=0.278, batch=230 
2225: loss=0.353, reward_mean=0.280, reward_bound=0.314, batch=226 
2226: loss=0.357, reward_mean=0.160, reward_bound=0.349, batch=211 
2227: loss=0.352, reward_mean=0.130, reward_bound=0.150, batch=217 
2228: loss=0.361, reward_mean=0.250, reward_bound=0.277, batch=222 
2229: loss=0.363, reward_mean=0.150, reward_bound=0.314, batch=220 
2230: loss=0.366, reward_mean=0.150, reward_bound=0.314, batch=223 
2231: loss=0.357, reward_mean=0.200, reward_bound=0.349, batch=224 
2232: loss=0.361, reward_mean=0.110, reward_bound=0.337, batch=227 
2233: loss=0.362, reward_mean=0.170, reward_bound=0.380, batch=229 
2234: loss=0.361, reward_mean=0.210, reward_bound=0.364, batch=230 
2235: loss=0.362, reward_mean=0.110, reward_bound=0.376, batch=231 
2236: loss=0.366, reward_mean=0.190, reward_bound=0.387, batch=217 
2237: loss=0.366, reward_mean=0.170, reward_bound=0.349, batch=221 
2238: loss=0.366, reward_mean=0.140, reward_bound=0.254, batch=224 
2239: loss=0.367, reward_mean=0.220, reward_bound=0.345, batch=227 
2240: loss=0.370, reward_mean=0.160, reward_bound=0.349, batch=225 
2241: loss=0.370, reward_mean=0.140, reward_bound=0.273, batch=227 
2242: loss=0.369, reward_mean=0.160, reward_bound=0.349, batch=228 
2243: loss=0.368, reward_mean=0.190, reward_bound=0.293, batch=229 
2244: loss=0.364, reward_mean=0.170, reward_bound=0.387, batch=225 
2245: loss=0.365, reward_mean=0.200, reward_bound=0.430, batch=203 
2246: loss=0.365, reward_mean=0.240, reward_bound=0.282, batch=211 
2247: loss=0.366, reward_mean=0.150, reward_bound=0.229, batch=217 
2248: loss=0.367, reward_mean=0.210, reward_bound=0.224, batch=222 
2249: loss=0.370, reward_mean=0.180, reward_bound=0.314, batch=217 
2250: loss=0.367, reward_mean=0.230, reward_bound=0.314, batch=220 
2251: loss=0.362, reward_mean=0.260, reward_bound=0.349, batch=217 
2252: loss=0.360, reward_mean=0.200, reward_bound=0.342, batch=222 
2253: loss=0.364, reward_mean=0.180, reward_bound=0.349, batch=224 
2254: loss=0.365, reward_mean=0.130, reward_bound=0.280, batch=227 
2255: loss=0.363, reward_mean=0.180, reward_bound=0.342, batch=229 
2256: loss=0.362, reward_mean=0.180, reward_bound=0.349, batch=229 
2257: loss=0.369, reward_mean=0.190, reward_bound=0.387, batch=220 
2258: loss=0.369, reward_mean=0.150, reward_bound=0.376, batch=224 
2259: loss=0.368, reward_mean=0.170, reward_bound=0.349, batch=226 
2260: loss=0.367, reward_mean=0.190, reward_bound=0.368, batch=228 
2261: loss=0.370, reward_mean=0.170, reward_bound=0.387, batch=226 
2262: loss=0.370, reward_mean=0.240, reward_bound=0.298, batch=228 
2263: loss=0.371, reward_mean=0.210, reward_bound=0.392, batch=229 
2264: loss=0.371, reward_mean=0.200, reward_bound=0.430, batch=219 
2265: loss=0.372, reward_mean=0.130, reward_bound=0.314, batch=222 
2266: loss=0.355, reward_mean=0.270, reward_bound=0.478, batch=86 
2267: loss=0.330, reward_mean=0.130, reward_bound=0.000, batch=99 
2268: loss=0.336, reward_mean=0.190, reward_bound=0.000, batch=118 
2269: loss=0.348, reward_mean=0.240, reward_bound=0.000, batch=142 
2270: loss=0.356, reward_mean=0.180, reward_bound=0.000, batch=160 
2271: loss=0.357, reward_mean=0.110, reward_bound=0.000, batch=171 
2272: loss=0.353, reward_mean=0.160, reward_bound=0.000, batch=187 
2273: loss=0.352, reward_mean=0.170, reward_bound=0.010, batch=201 
2274: loss=0.353, reward_mean=0.220, reward_bound=0.047, batch=208 
2275: loss=0.349, reward_mean=0.130, reward_bound=0.058, batch=213 
2276: loss=0.350, reward_mean=0.150, reward_bound=0.069, batch=219 
2277: loss=0.357, reward_mean=0.150, reward_bound=0.089, batch=220 
2278: loss=0.356, reward_mean=0.230, reward_bound=0.122, batch=222 
2279: loss=0.351, reward_mean=0.220, reward_bound=0.140, batch=225 
2280: loss=0.351, reward_mean=0.220, reward_bound=0.150, batch=224 
2281: loss=0.348, reward_mean=0.180, reward_bound=0.167, batch=224 
2282: loss=0.354, reward_mean=0.180, reward_bound=0.185, batch=222 
2283: loss=0.351, reward_mean=0.180, reward_bound=0.206, batch=231 
2284: loss=0.354, reward_mean=0.130, reward_bound=0.206, batch=222 
2285: loss=0.351, reward_mean=0.180, reward_bound=0.229, batch=216 
2286: loss=0.346, reward_mean=0.190, reward_bound=0.254, batch=202 
2287: loss=0.347, reward_mean=0.200, reward_bound=0.229, batch=210 
2288: loss=0.350, reward_mean=0.170, reward_bound=0.150, batch=216 
2289: loss=0.349, reward_mean=0.240, reward_bound=0.282, batch=204 
2290: loss=0.348, reward_mean=0.210, reward_bound=0.224, batch=213 
2291: loss=0.352, reward_mean=0.210, reward_bound=0.254, batch=218 
2292: loss=0.351, reward_mean=0.170, reward_bound=0.257, batch=222 
2293: loss=0.352, reward_mean=0.230, reward_bound=0.282, batch=220 
2294: loss=0.352, reward_mean=0.140, reward_bound=0.216, batch=224 
2295: loss=0.348, reward_mean=0.230, reward_bound=0.280, batch=227 
2296: loss=0.350, reward_mean=0.150, reward_bound=0.308, batch=229 
2297: loss=0.350, reward_mean=0.190, reward_bound=0.314, batch=200 
2298: loss=0.339, reward_mean=0.150, reward_bound=0.076, batch=210 
2299: loss=0.340, reward_mean=0.250, reward_bound=0.150, batch=216 
2300: loss=0.342, reward_mean=0.210, reward_bound=0.217, batch=221 
2301: loss=0.344, reward_mean=0.120, reward_bound=0.254, batch=223 
2302: loss=0.346, reward_mean=0.180, reward_bound=0.282, batch=224 
2303: loss=0.350, reward_mean=0.190, reward_bound=0.314, batch=220 
2304: loss=0.350, reward_mean=0.190, reward_bound=0.254, batch=223 
2305: loss=0.355, reward_mean=0.150, reward_bound=0.235, batch=226 
2306: loss=0.346, reward_mean=0.160, reward_bound=0.298, batch=228 
2307: loss=0.349, reward_mean=0.150, reward_bound=0.314, batch=228 
2308: loss=0.353, reward_mean=0.190, reward_bound=0.349, batch=190 
2309: loss=0.358, reward_mean=0.190, reward_bound=0.063, batch=203 
2310: loss=0.356, reward_mean=0.180, reward_bound=0.160, batch=212 
2311: loss=0.354, reward_mean=0.200, reward_bound=0.229, batch=215 
2312: loss=0.354, reward_mean=0.110, reward_bound=0.254, batch=216 
2313: loss=0.353, reward_mean=0.230, reward_bound=0.254, batch=220 
2314: loss=0.352, reward_mean=0.190, reward_bound=0.229, batch=223 
2315: loss=0.362, reward_mean=0.130, reward_bound=0.282, batch=220 
2316: loss=0.360, reward_mean=0.130, reward_bound=0.304, batch=224 
2317: loss=0.361, reward_mean=0.150, reward_bound=0.311, batch=227 
2318: loss=0.352, reward_mean=0.230, reward_bound=0.314, batch=226 
2319: loss=0.358, reward_mean=0.090, reward_bound=0.349, batch=220 
2320: loss=0.356, reward_mean=0.220, reward_bound=0.314, batch=223 
2321: loss=0.348, reward_mean=0.210, reward_bound=0.387, batch=180 
2322: loss=0.341, reward_mean=0.090, reward_bound=0.000, batch=189 
2323: loss=0.346, reward_mean=0.130, reward_bound=0.023, batch=202 
2324: loss=0.352, reward_mean=0.120, reward_bound=0.047, batch=211 
2325: loss=0.353, reward_mean=0.210, reward_bound=0.122, batch=216 
2326: loss=0.342, reward_mean=0.170, reward_bound=0.135, batch=219 
2327: loss=0.340, reward_mean=0.120, reward_bound=0.150, batch=220 
2328: loss=0.345, reward_mean=0.140, reward_bound=0.185, batch=222 
2329: loss=0.339, reward_mean=0.200, reward_bound=0.206, batch=229 
2330: loss=0.347, reward_mean=0.200, reward_bound=0.229, batch=222 
2331: loss=0.347, reward_mean=0.280, reward_bound=0.254, batch=221 
2332: loss=0.346, reward_mean=0.130, reward_bound=0.206, batch=224 
2333: loss=0.351, reward_mean=0.120, reward_bound=0.252, batch=227 
2334: loss=0.345, reward_mean=0.120, reward_bound=0.282, batch=225 
2335: loss=0.349, reward_mean=0.140, reward_bound=0.314, batch=213 
2336: loss=0.344, reward_mean=0.140, reward_bound=0.122, batch=218 
2337: loss=0.347, reward_mean=0.190, reward_bound=0.211, batch=222 
2338: loss=0.345, reward_mean=0.180, reward_bound=0.292, batch=225 
2339: loss=0.344, reward_mean=0.130, reward_bound=0.314, batch=226 
2340: loss=0.342, reward_mean=0.190, reward_bound=0.314, batch=227 
2341: loss=0.342, reward_mean=0.150, reward_bound=0.342, batch=229 
2342: loss=0.335, reward_mean=0.230, reward_bound=0.349, batch=212 
2343: loss=0.336, reward_mean=0.190, reward_bound=0.198, batch=218 
2344: loss=0.328, reward_mean=0.220, reward_bound=0.314, batch=219 
2345: loss=0.330, reward_mean=0.090, reward_bound=0.349, batch=220 
2346: loss=0.334, reward_mean=0.180, reward_bound=0.376, batch=224 
2347: loss=0.334, reward_mean=0.210, reward_bound=0.380, batch=227 
2348: loss=0.341, reward_mean=0.250, reward_bound=0.387, batch=219 
2349: loss=0.340, reward_mean=0.220, reward_bound=0.364, batch=223 
2350: loss=0.338, reward_mean=0.170, reward_bound=0.372, batch=226 
2351: loss=0.345, reward_mean=0.160, reward_bound=0.387, batch=223 
2352: loss=0.366, reward_mean=0.260, reward_bound=0.430, batch=161 
2353: loss=0.361, reward_mean=0.170, reward_bound=0.000, batch=178 
2354: loss=0.368, reward_mean=0.170, reward_bound=0.020, batch=194 
2355: loss=0.350, reward_mean=0.280, reward_bound=0.119, batch=206 
2356: loss=0.343, reward_mean=0.120, reward_bound=0.075, batch=214 
2357: loss=0.348, reward_mean=0.210, reward_bound=0.150, batch=218 
2358: loss=0.353, reward_mean=0.120, reward_bound=0.167, batch=221 
2359: loss=0.355, reward_mean=0.260, reward_bound=0.206, batch=217 
2360: loss=0.363, reward_mean=0.170, reward_bound=0.229, batch=218 
2361: loss=0.361, reward_mean=0.150, reward_bound=0.254, batch=219 
2362: loss=0.362, reward_mean=0.200, reward_bound=0.282, batch=215 
2363: loss=0.359, reward_mean=0.130, reward_bound=0.216, batch=220 
2364: loss=0.355, reward_mean=0.190, reward_bound=0.304, batch=224 
2365: loss=0.357, reward_mean=0.190, reward_bound=0.314, batch=211 
2366: loss=0.362, reward_mean=0.130, reward_bound=0.135, batch=217 
2367: loss=0.363, reward_mean=0.100, reward_bound=0.167, batch=221 
2368: loss=0.360, reward_mean=0.140, reward_bound=0.282, batch=224 
2369: loss=0.362, reward_mean=0.210, reward_bound=0.314, batch=226 
2370: loss=0.363, reward_mean=0.120, reward_bound=0.349, batch=214 
2371: loss=0.366, reward_mean=0.190, reward_bound=0.185, batch=219 
2372: loss=0.362, reward_mean=0.130, reward_bound=0.328, batch=223 
2373: loss=0.365, reward_mean=0.170, reward_bound=0.349, batch=224 
2374: loss=0.361, reward_mean=0.130, reward_bound=0.305, batch=227 
2375: loss=0.363, reward_mean=0.220, reward_bound=0.349, batch=228 
2376: loss=0.367, reward_mean=0.170, reward_bound=0.387, batch=211 
2377: loss=0.364, reward_mean=0.100, reward_bound=0.282, batch=215 
2378: loss=0.360, reward_mean=0.160, reward_bound=0.229, batch=219 
2379: loss=0.367, reward_mean=0.180, reward_bound=0.282, batch=221 
2380: loss=0.368, reward_mean=0.150, reward_bound=0.314, batch=224 
2381: loss=0.371, reward_mean=0.120, reward_bound=0.204, batch=227 
2382: loss=0.369, reward_mean=0.100, reward_bound=0.277, batch=229 
2383: loss=0.366, reward_mean=0.150, reward_bound=0.328, batch=230 
2384: loss=0.367, reward_mean=0.230, reward_bound=0.349, batch=226 
2385: loss=0.363, reward_mean=0.190, reward_bound=0.387, batch=224 
2386: loss=0.364, reward_mean=0.140, reward_bound=0.422, batch=227 
2387: loss=0.355, reward_mean=0.130, reward_bound=0.430, batch=193 
2388: loss=0.355, reward_mean=0.200, reward_bound=0.144, batch=205 
2389: loss=0.352, reward_mean=0.140, reward_bound=0.124, batch=213 
2390: loss=0.349, reward_mean=0.190, reward_bound=0.160, batch=219 
2391: loss=0.349, reward_mean=0.140, reward_bound=0.194, batch=223 
2392: loss=0.361, reward_mean=0.190, reward_bound=0.244, batch=226 
2393: loss=0.361, reward_mean=0.220, reward_bound=0.254, batch=223 
2394: loss=0.360, reward_mean=0.170, reward_bound=0.282, batch=224 
2395: loss=0.362, reward_mean=0.210, reward_bound=0.314, batch=221 
2396: loss=0.360, reward_mean=0.220, reward_bound=0.349, batch=220 
2397: loss=0.356, reward_mean=0.160, reward_bound=0.222, batch=224 
2398: loss=0.354, reward_mean=0.200, reward_bound=0.345, batch=227 
2399: loss=0.362, reward_mean=0.210, reward_bound=0.380, batch=229 
2400: loss=0.361, reward_mean=0.190, reward_bound=0.364, batch=230 
2401: loss=0.355, reward_mean=0.140, reward_bound=0.387, batch=221 
2402: loss=0.352, reward_mean=0.190, reward_bound=0.282, batch=224 
2403: loss=0.356, reward_mean=0.150, reward_bound=0.314, batch=226 
2404: loss=0.355, reward_mean=0.190, reward_bound=0.368, batch=228 
2405: loss=0.354, reward_mean=0.190, reward_bound=0.387, batch=228 
2406: loss=0.353, reward_mean=0.170, reward_bound=0.325, batch=229 
2407: loss=0.356, reward_mean=0.140, reward_bound=0.364, batch=230 
2408: loss=0.353, reward_mean=0.120, reward_bound=0.418, batch=231 
2409: loss=0.348, reward_mean=0.180, reward_bound=0.430, batch=216 
2410: loss=0.345, reward_mean=0.090, reward_bound=0.189, batch=221 
2411: loss=0.345, reward_mean=0.160, reward_bound=0.254, batch=224 
2412: loss=0.347, reward_mean=0.200, reward_bound=0.314, batch=225 
2413: loss=0.342, reward_mean=0.120, reward_bound=0.356, batch=227 
2414: loss=0.345, reward_mean=0.190, reward_bound=0.387, batch=226 
2415: loss=0.343, reward_mean=0.210, reward_bound=0.409, batch=228 
2416: loss=0.344, reward_mean=0.220, reward_bound=0.392, batch=229 
2417: loss=0.344, reward_mean=0.110, reward_bound=0.387, batch=229 
2418: loss=0.350, reward_mean=0.160, reward_bound=0.430, batch=224 
2419: loss=0.358, reward_mean=0.160, reward_bound=0.345, batch=227 
2420: loss=0.350, reward_mean=0.170, reward_bound=0.349, batch=228 
2421: loss=0.354, reward_mean=0.160, reward_bound=0.387, batch=228 
2422: loss=0.348, reward_mean=0.240, reward_bound=0.430, batch=226 
2423: loss=0.347, reward_mean=0.140, reward_bound=0.430, batch=227 
2424: loss=0.346, reward_mean=0.170, reward_bound=0.469, batch=229 
2425: loss=0.346, reward_mean=0.170, reward_bound=0.328, batch=230 
2426: loss=0.346, reward_mean=0.160, reward_bound=0.430, batch=230 
2427: loss=0.346, reward_mean=0.160, reward_bound=0.430, batch=230 
2428: loss=0.345, reward_mean=0.160, reward_bound=0.418, batch=231 
2429: loss=0.332, reward_mean=0.120, reward_bound=0.478, batch=143 
2430: loss=0.346, reward_mean=0.170, reward_bound=0.000, batch=160 
2431: loss=0.333, reward_mean=0.210, reward_bound=0.000, batch=181 
2432: loss=0.325, reward_mean=0.130, reward_bound=0.000, batch=194 
2433: loss=0.336, reward_mean=0.180, reward_bound=0.019, batch=206 
2434: loss=0.332, reward_mean=0.150, reward_bound=0.072, batch=214 
2435: loss=0.334, reward_mean=0.230, reward_bound=0.109, batch=218 
2436: loss=0.336, reward_mean=0.130, reward_bound=0.150, batch=216 
2437: loss=0.332, reward_mean=0.300, reward_bound=0.185, batch=219 
2438: loss=0.342, reward_mean=0.210, reward_bound=0.206, batch=220 
2439: loss=0.338, reward_mean=0.110, reward_bound=0.229, batch=215 
2440: loss=0.340, reward_mean=0.130, reward_bound=0.229, batch=219 
2441: loss=0.347, reward_mean=0.150, reward_bound=0.254, batch=210 
2442: loss=0.348, reward_mean=0.150, reward_bound=0.229, batch=215 
2443: loss=0.348, reward_mean=0.150, reward_bound=0.260, batch=220 
2444: loss=0.351, reward_mean=0.150, reward_bound=0.274, batch=224 
2445: loss=0.346, reward_mean=0.130, reward_bound=0.282, batch=213 
2446: loss=0.351, reward_mean=0.180, reward_bound=0.314, batch=206 
2447: loss=0.359, reward_mean=0.110, reward_bound=0.076, batch=214 
2448: loss=0.353, reward_mean=0.170, reward_bound=0.165, batch=220 
2449: loss=0.347, reward_mean=0.180, reward_bound=0.229, batch=222 
2450: loss=0.346, reward_mean=0.180, reward_bound=0.282, batch=220 
2451: loss=0.346, reward_mean=0.110, reward_bound=0.200, batch=224 
2452: loss=0.346, reward_mean=0.160, reward_bound=0.311, batch=227 
2453: loss=0.346, reward_mean=0.250, reward_bound=0.314, batch=224 
2454: loss=0.348, reward_mean=0.240, reward_bound=0.349, batch=203 
2455: loss=0.337, reward_mean=0.160, reward_bound=0.190, batch=212 
2456: loss=0.340, reward_mean=0.110, reward_bound=0.140, batch=218 
2457: loss=0.353, reward_mean=0.160, reward_bound=0.206, batch=220 
2458: loss=0.360, reward_mean=0.190, reward_bound=0.247, batch=224 
2459: loss=0.361, reward_mean=0.200, reward_bound=0.254, batch=225 
2460: loss=0.354, reward_mean=0.210, reward_bound=0.289, batch=227 
2461: loss=0.352, reward_mean=0.170, reward_bound=0.314, batch=223 
2462: loss=0.352, reward_mean=0.150, reward_bound=0.335, batch=226 
2463: loss=0.350, reward_mean=0.120, reward_bound=0.349, batch=223 
2464: loss=0.353, reward_mean=0.100, reward_bound=0.358, batch=226 
2465: loss=0.343, reward_mean=0.150, reward_bound=0.387, batch=206 
2466: loss=0.342, reward_mean=0.190, reward_bound=0.196, batch=214 
2467: loss=0.344, reward_mean=0.160, reward_bound=0.252, batch=220 
2468: loss=0.346, reward_mean=0.200, reward_bound=0.254, batch=222 
2469: loss=0.350, reward_mean=0.150, reward_bound=0.314, batch=222 
2470: loss=0.349, reward_mean=0.110, reward_bound=0.263, batch=225 
2471: loss=0.351, reward_mean=0.170, reward_bound=0.349, batch=224 
2472: loss=0.349, reward_mean=0.140, reward_bound=0.342, batch=227 
2473: loss=0.351, reward_mean=0.150, reward_bound=0.349, batch=228 
2474: loss=0.347, reward_mean=0.190, reward_bound=0.387, batch=225 
2475: loss=0.350, reward_mean=0.210, reward_bound=0.430, batch=189 
2476: loss=0.347, reward_mean=0.170, reward_bound=0.102, batch=202 
2477: loss=0.347, reward_mean=0.180, reward_bound=0.155, batch=211 
2478: loss=0.345, reward_mean=0.170, reward_bound=0.150, batch=217 
2479: loss=0.345, reward_mean=0.220, reward_bound=0.224, batch=222 
2480: loss=0.344, reward_mean=0.150, reward_bound=0.229, batch=222 
2481: loss=0.342, reward_mean=0.140, reward_bound=0.229, batch=224 
2482: loss=0.346, reward_mean=0.150, reward_bound=0.254, batch=221 
2483: loss=0.346, reward_mean=0.160, reward_bound=0.282, batch=222 
2484: loss=0.346, reward_mean=0.200, reward_bound=0.272, batch=225 
2485: loss=0.344, reward_mean=0.150, reward_bound=0.289, batch=227 
2486: loss=0.342, reward_mean=0.160, reward_bound=0.314, batch=225 
2487: loss=0.339, reward_mean=0.140, reward_bound=0.349, batch=219 
2488: loss=0.338, reward_mean=0.170, reward_bound=0.295, batch=223 
2489: loss=0.340, reward_mean=0.170, reward_bound=0.335, batch=226 
2490: loss=0.341, reward_mean=0.160, reward_bound=0.349, batch=226 
2491: loss=0.347, reward_mean=0.190, reward_bound=0.387, batch=212 
2492: loss=0.346, reward_mean=0.130, reward_bound=0.236, batch=218 
2493: loss=0.345, reward_mean=0.160, reward_bound=0.282, batch=220 
2494: loss=0.342, reward_mean=0.190, reward_bound=0.304, batch=224 
2495: loss=0.343, reward_mean=0.200, reward_bound=0.314, batch=225 
2496: loss=0.341, reward_mean=0.190, reward_bound=0.321, batch=227 
2497: loss=0.347, reward_mean=0.190, reward_bound=0.349, batch=224 
2498: loss=0.347, reward_mean=0.230, reward_bound=0.384, batch=227 
2499: loss=0.346, reward_mean=0.100, reward_bound=0.373, batch=229 
2500: loss=0.342, reward_mean=0.120, reward_bound=0.387, batch=228 
2501: loss=0.342, reward_mean=0.130, reward_bound=0.357, batch=229 
2502: loss=0.351, reward_mean=0.160, reward_bound=0.430, batch=212 
2503: loss=0.343, reward_mean=0.210, reward_bound=0.213, batch=218 
2504: loss=0.345, reward_mean=0.100, reward_bound=0.208, batch=222 
2505: loss=0.347, reward_mean=0.160, reward_bound=0.229, batch=224 
2506: loss=0.353, reward_mean=0.140, reward_bound=0.254, batch=225 
2507: loss=0.351, reward_mean=0.250, reward_bound=0.282, batch=225 
2508: loss=0.350, reward_mean=0.220, reward_bound=0.349, batch=226 
2509: loss=0.345, reward_mean=0.170, reward_bound=0.387, batch=223 
2510: loss=0.354, reward_mean=0.130, reward_bound=0.358, batch=226 
2511: loss=0.350, reward_mean=0.120, reward_bound=0.387, batch=226 
2512: loss=0.353, reward_mean=0.190, reward_bound=0.430, batch=225 
2513: loss=0.355, reward_mean=0.160, reward_bound=0.396, batch=227 
2514: loss=0.354, reward_mean=0.200, reward_bound=0.430, batch=228 
2515: loss=0.355, reward_mean=0.120, reward_bound=0.397, batch=229 
2516: loss=0.354, reward_mean=0.210, reward_bound=0.478, batch=232 
2517: loss=0.331, reward_mean=0.190, reward_bound=0.478, batch=182 
2518: loss=0.323, reward_mean=0.170, reward_bound=0.040, batch=197 
2519: loss=0.315, reward_mean=0.130, reward_bound=0.057, batch=208 
2520: loss=0.333, reward_mean=0.220, reward_bound=0.150, batch=212 
2521: loss=0.325, reward_mean=0.170, reward_bound=0.185, batch=217 
2522: loss=0.332, reward_mean=0.170, reward_bound=0.229, batch=217 
2523: loss=0.319, reward_mean=0.210, reward_bound=0.254, batch=218 
2524: loss=0.321, reward_mean=0.110, reward_bound=0.161, batch=222 
2525: loss=0.326, reward_mean=0.220, reward_bound=0.282, batch=221 
2526: loss=0.324, reward_mean=0.130, reward_bound=0.314, batch=215 
2527: loss=0.325, reward_mean=0.160, reward_bound=0.260, batch=220 
2528: loss=0.322, reward_mean=0.150, reward_bound=0.282, batch=222 
2529: loss=0.324, reward_mean=0.210, reward_bound=0.191, batch=225 
2530: loss=0.323, reward_mean=0.150, reward_bound=0.321, batch=227 
