# original nn
fei@fei-Inspiron-5580:~/Deep-Reinforcement-Learning-Hands-On/Chapter04$ python3 01_cartpole.py 
0: loss=0.700, reward_mean=22.6, reward_bound=27.0
1: loss=0.678, reward_mean=25.6, reward_bound=33.5
2: loss=0.668, reward_mean=36.4, reward_bound=42.5
3: loss=0.647, reward_mean=47.1, reward_bound=50.0
4: loss=0.645, reward_mean=50.6, reward_bound=47.5
5: loss=0.619, reward_mean=44.4, reward_bound=49.5
6: loss=0.624, reward_mean=49.8, reward_bound=53.5
7: loss=0.624, reward_mean=54.4, reward_bound=72.0
8: loss=0.603, reward_mean=52.1, reward_bound=60.0
9: loss=0.600, reward_mean=51.9, reward_bound=58.0
10: loss=0.608, reward_mean=58.9, reward_bound=76.0
11: loss=0.598, reward_mean=64.3, reward_bound=72.0
12: loss=0.603, reward_mean=68.8, reward_bound=71.5
13: loss=0.587, reward_mean=69.9, reward_bound=83.5
14: loss=0.571, reward_mean=76.4, reward_bound=85.5
15: loss=0.598, reward_mean=81.4, reward_bound=90.0
16: loss=0.569, reward_mean=62.2, reward_bound=73.0
17: loss=0.576, reward_mean=71.7, reward_bound=79.5
18: loss=0.574, reward_mean=69.7, reward_bound=86.0
19: loss=0.564, reward_mean=83.9, reward_bound=99.5
20: loss=0.562, reward_mean=89.8, reward_bound=103.5
21: loss=0.563, reward_mean=76.1, reward_bound=91.5
22: loss=0.564, reward_mean=102.6, reward_bound=130.0
23: loss=0.573, reward_mean=95.4, reward_bound=103.5
24: loss=0.559, reward_mean=95.2, reward_bound=108.0
25: loss=0.549, reward_mean=112.9, reward_bound=142.0
26: loss=0.558, reward_mean=95.1, reward_bound=97.0
27: loss=0.551, reward_mean=93.1, reward_bound=107.5
28: loss=0.557, reward_mean=80.2, reward_bound=95.5
29: loss=0.533, reward_mean=86.6, reward_bound=86.5
30: loss=0.549, reward_mean=78.9, reward_bound=89.5
31: loss=0.537, reward_mean=108.6, reward_bound=115.5
32: loss=0.535, reward_mean=102.4, reward_bound=100.0
33: loss=0.548, reward_mean=114.3, reward_bound=139.0
34: loss=0.522, reward_mean=140.6, reward_bound=150.5
35: loss=0.533, reward_mean=146.7, reward_bound=165.0
36: loss=0.527, reward_mean=160.9, reward_bound=200.0
37: loss=0.535, reward_mean=180.4, reward_bound=200.0
38: loss=0.534, reward_mean=144.3, reward_bound=163.0
39: loss=0.523, reward_mean=158.1, reward_bound=200.0
40: loss=0.513, reward_mean=171.0, reward_bound=200.0
41: loss=0.525, reward_mean=162.7, reward_bound=200.0
42: loss=0.524, reward_mean=184.7, reward_bound=200.0
43: loss=0.526, reward_mean=200.0, reward_bound=200.0
Solved!


# num_layer=1, hidden_size=128, batch_size=16, percentile=70

## trial1
fei@fei-Inspiron-5580:~/Deep-Reinforcement-Learning-Hands-On/Chapter04$ python3 01_cartpole_lstm.py 
0: loss=0.693, reward_mean=26.5, reward_bound=28.0
1: loss=0.690, reward_mean=28.4, reward_bound=32.5
2: loss=0.684, reward_mean=19.9, reward_bound=24.0
3: loss=0.684, reward_mean=25.2, reward_bound=27.5
4: loss=0.685, reward_mean=27.6, reward_bound=30.0
5: loss=0.677, reward_mean=32.9, reward_bound=39.0
6: loss=0.683, reward_mean=26.2, reward_bound=27.0
7: loss=0.671, reward_mean=33.7, reward_bound=43.5
8: loss=0.654, reward_mean=31.4, reward_bound=36.5
9: loss=0.661, reward_mean=33.6, reward_bound=35.5
10: loss=0.675, reward_mean=34.6, reward_bound=34.5
11: loss=0.649, reward_mean=31.8, reward_bound=35.0
12: loss=0.650, reward_mean=36.3, reward_bound=50.0
13: loss=0.645, reward_mean=40.8, reward_bound=50.5
14: loss=0.640, reward_mean=43.3, reward_bound=54.5
15: loss=0.640, reward_mean=37.5, reward_bound=39.0
16: loss=0.633, reward_mean=46.1, reward_bound=52.0
17: loss=0.617, reward_mean=56.7, reward_bound=61.5
18: loss=0.617, reward_mean=51.8, reward_bound=56.5
19: loss=0.634, reward_mean=50.0, reward_bound=61.5
20: loss=0.620, reward_mean=49.8, reward_bound=62.0
21: loss=0.619, reward_mean=53.8, reward_bound=61.5
22: loss=0.608, reward_mean=61.0, reward_bound=67.0
23: loss=0.610, reward_mean=59.2, reward_bound=70.0
24: loss=0.621, reward_mean=53.1, reward_bound=52.0
25: loss=0.612, reward_mean=50.4, reward_bound=66.0
26: loss=0.601, reward_mean=78.8, reward_bound=105.0
27: loss=0.602, reward_mean=69.4, reward_bound=77.0
28: loss=0.595, reward_mean=84.7, reward_bound=99.5
29: loss=0.598, reward_mean=76.2, reward_bound=80.0
30: loss=0.598, reward_mean=93.6, reward_bound=117.0
31: loss=0.597, reward_mean=128.4, reward_bound=158.5
32: loss=0.585, reward_mean=109.2, reward_bound=141.0
33: loss=0.591, reward_mean=145.6, reward_bound=170.0
34: loss=0.581, reward_mean=141.3, reward_bound=165.5
35: loss=0.577, reward_mean=159.2, reward_bound=188.5
36: loss=0.576, reward_mean=158.6, reward_bound=188.5
37: loss=0.578, reward_mean=166.1, reward_bound=200.0
38: loss=0.577, reward_mean=158.6, reward_bound=199.5
39: loss=0.568, reward_mean=151.9, reward_bound=196.5
40: loss=0.565, reward_mean=171.1, reward_bound=200.0
41: loss=0.559, reward_mean=182.1, reward_bound=200.0
42: loss=0.555, reward_mean=157.9, reward_bound=200.0
43: loss=0.556, reward_mean=190.9, reward_bound=200.0
44: loss=0.552, reward_mean=188.5, reward_bound=200.0
45: loss=0.555, reward_mean=199.2, reward_bound=200.0
Solved!

## trial2
fei@fei-Inspiron-5580:~/Deep-Reinforcement-Learning-Hands-On/Chapter04$ python3 01_cartpole_lstm.py 
0: loss=0.694, reward_mean=27.2, reward_bound=31.0
1: loss=0.692, reward_mean=26.1, reward_bound=31.5
2: loss=0.688, reward_mean=23.1, reward_bound=24.0
3: loss=0.687, reward_mean=26.0, reward_bound=30.0
4: loss=0.686, reward_mean=25.8, reward_bound=29.0
5: loss=0.688, reward_mean=34.7, reward_bound=39.0
6: loss=0.675, reward_mean=27.4, reward_bound=26.0
7: loss=0.672, reward_mean=28.8, reward_bound=29.0
8: loss=0.679, reward_mean=29.9, reward_bound=30.5
9: loss=0.670, reward_mean=27.8, reward_bound=29.5
10: loss=0.663, reward_mean=35.0, reward_bound=46.5
11: loss=0.661, reward_mean=31.6, reward_bound=39.5
12: loss=0.651, reward_mean=34.9, reward_bound=42.0
13: loss=0.645, reward_mean=32.7, reward_bound=39.5
14: loss=0.649, reward_mean=32.4, reward_bound=38.0
15: loss=0.654, reward_mean=37.1, reward_bound=47.5
16: loss=0.647, reward_mean=45.2, reward_bound=53.0
17: loss=0.628, reward_mean=55.4, reward_bound=55.5
18: loss=0.618, reward_mean=40.9, reward_bound=42.5
19: loss=0.609, reward_mean=56.8, reward_bound=67.0
20: loss=0.615, reward_mean=55.9, reward_bound=64.5
21: loss=0.625, reward_mean=57.2, reward_bound=72.0
22: loss=0.608, reward_mean=48.2, reward_bound=61.0
23: loss=0.598, reward_mean=56.6, reward_bound=59.0
24: loss=0.615, reward_mean=57.8, reward_bound=69.5
25: loss=0.592, reward_mean=61.5, reward_bound=74.5
26: loss=0.589, reward_mean=62.6, reward_bound=62.5
27: loss=0.589, reward_mean=65.0, reward_bound=74.5
28: loss=0.607, reward_mean=70.4, reward_bound=82.0
29: loss=0.586, reward_mean=76.9, reward_bound=83.5
30: loss=0.587, reward_mean=63.6, reward_bound=77.0
31: loss=0.587, reward_mean=65.0, reward_bound=64.0
32: loss=0.577, reward_mean=75.9, reward_bound=85.5
33: loss=0.577, reward_mean=64.0, reward_bound=83.5
34: loss=0.581, reward_mean=73.6, reward_bound=80.5
35: loss=0.585, reward_mean=68.0, reward_bound=71.5
36: loss=0.560, reward_mean=71.6, reward_bound=75.5
37: loss=0.571, reward_mean=69.7, reward_bound=81.0
38: loss=0.553, reward_mean=67.6, reward_bound=78.0
39: loss=0.555, reward_mean=65.8, reward_bound=73.0
40: loss=0.569, reward_mean=86.9, reward_bound=106.5
41: loss=0.553, reward_mean=91.4, reward_bound=99.5
42: loss=0.573, reward_mean=79.8, reward_bound=81.5
43: loss=0.558, reward_mean=88.2, reward_bound=94.5
44: loss=0.557, reward_mean=86.3, reward_bound=98.0
45: loss=0.546, reward_mean=87.1, reward_bound=96.0
46: loss=0.557, reward_mean=105.0, reward_bound=115.5
47: loss=0.543, reward_mean=117.6, reward_bound=132.5
48: loss=0.552, reward_mean=102.4, reward_bound=113.5
49: loss=0.532, reward_mean=126.9, reward_bound=159.5
50: loss=0.556, reward_mean=134.4, reward_bound=170.0
51: loss=0.528, reward_mean=149.4, reward_bound=184.0
52: loss=0.543, reward_mean=138.7, reward_bound=157.0
53: loss=0.535, reward_mean=158.8, reward_bound=194.5
54: loss=0.541, reward_mean=169.4, reward_bound=200.0
55: loss=0.550, reward_mean=184.9, reward_bound=200.0
56: loss=0.542, reward_mean=194.4, reward_bound=200.0
57: loss=0.540, reward_mean=195.1, reward_bound=200.0
58: loss=0.550, reward_mean=191.4, reward_bound=200.0
59: loss=0.524, reward_mean=196.6, reward_bound=200.0
60: loss=0.531, reward_mean=194.8, reward_bound=200.0
61: loss=0.525, reward_mean=196.8, reward_bound=200.0
62: loss=0.525, reward_mean=197.7, reward_bound=200.0
63: loss=0.528, reward_mean=198.8, reward_bound=200.0
64: loss=0.523, reward_mean=190.2, reward_bound=200.0
65: loss=0.535, reward_mean=200.0, reward_bound=200.0
Solved!





# num_layers=2

## trial 1
fei@fei-Inspiron-5580:~/Deep-Reinforcement-Learning-Hands-On/Chapter04$ python3 01_cartpole_lstm.py 
0: loss=0.692, reward_mean=24.9, reward_bound=26.0
1: loss=0.689, reward_mean=22.0, reward_bound=25.5
2: loss=0.679, reward_mean=23.7, reward_bound=28.5
3: loss=0.693, reward_mean=18.4, reward_bound=21.5
4: loss=0.686, reward_mean=19.3, reward_bound=21.5
5: loss=0.697, reward_mean=19.9, reward_bound=21.0
6: loss=0.684, reward_mean=18.9, reward_bound=21.5
7: loss=0.693, reward_mean=22.1, reward_bound=26.5
8: loss=0.691, reward_mean=22.1, reward_bound=28.0
9: loss=0.685, reward_mean=24.9, reward_bound=26.0
10: loss=0.688, reward_mean=21.7, reward_bound=23.0
11: loss=0.684, reward_mean=22.1, reward_bound=23.0
12: loss=0.683, reward_mean=24.9, reward_bound=27.0
13: loss=0.673, reward_mean=31.4, reward_bound=35.5
14: loss=0.671, reward_mean=29.7, reward_bound=36.5
15: loss=0.654, reward_mean=32.1, reward_bound=38.5
16: loss=0.638, reward_mean=35.4, reward_bound=38.0
17: loss=0.619, reward_mean=36.2, reward_bound=44.0
18: loss=0.581, reward_mean=44.7, reward_bound=48.5
19: loss=0.589, reward_mean=47.1, reward_bound=53.0
20: loss=0.561, reward_mean=57.0, reward_bound=63.5
21: loss=0.521, reward_mean=61.6, reward_bound=69.5
22: loss=0.504, reward_mean=57.3, reward_bound=60.5
23: loss=0.460, reward_mean=55.2, reward_bound=60.5
24: loss=0.460, reward_mean=67.1, reward_bound=69.0
25: loss=0.438, reward_mean=69.2, reward_bound=84.0
26: loss=0.376, reward_mean=67.9, reward_bound=78.0
27: loss=0.374, reward_mean=78.6, reward_bound=93.5
28: loss=0.353, reward_mean=80.3, reward_bound=96.0
29: loss=0.308, reward_mean=78.6, reward_bound=87.5
30: loss=0.348, reward_mean=65.7, reward_bound=64.5
31: loss=0.256, reward_mean=63.8, reward_bound=71.5
32: loss=0.262, reward_mean=55.4, reward_bound=60.0
33: loss=0.237, reward_mean=57.0, reward_bound=64.5
34: loss=0.205, reward_mean=50.9, reward_bound=56.0
35: loss=0.206, reward_mean=57.8, reward_bound=63.0
36: loss=0.232, reward_mean=68.6, reward_bound=61.0
37: loss=0.185, reward_mean=60.6, reward_bound=61.5
38: loss=0.189, reward_mean=96.4, reward_bound=115.5
39: loss=0.190, reward_mean=79.2, reward_bound=80.0
40: loss=0.193, reward_mean=90.8, reward_bound=95.5
41: loss=0.189, reward_mean=98.9, reward_bound=99.0
42: loss=0.190, reward_mean=108.3, reward_bound=119.0
43: loss=0.189, reward_mean=107.4, reward_bound=105.0
44: loss=0.115, reward_mean=95.2, reward_bound=99.5
45: loss=0.107, reward_mean=82.6, reward_bound=93.5
46: loss=0.072, reward_mean=81.4, reward_bound=94.0
47: loss=0.088, reward_mean=81.0, reward_bound=85.5
48: loss=0.147, reward_mean=110.1, reward_bound=130.0
49: loss=0.121, reward_mean=100.9, reward_bound=103.0
50: loss=0.186, reward_mean=121.0, reward_bound=130.5
51: loss=0.155, reward_mean=112.8, reward_bound=132.0
52: loss=0.140, reward_mean=116.9, reward_bound=125.0
53: loss=0.139, reward_mean=107.9, reward_bound=113.5
54: loss=0.057, reward_mean=77.4, reward_bound=78.5
55: loss=0.128, reward_mean=82.7, reward_bound=75.0
56: loss=0.085, reward_mean=85.3, reward_bound=83.0
57: loss=0.099, reward_mean=73.4, reward_bound=75.0
58: loss=0.094, reward_mean=68.8, reward_bound=79.5
59: loss=0.088, reward_mean=89.4, reward_bound=100.5
60: loss=0.169, reward_mean=110.4, reward_bound=122.0
61: loss=0.191, reward_mean=146.5, reward_bound=194.0
62: loss=0.147, reward_mean=123.4, reward_bound=132.5
63: loss=0.144, reward_mean=110.4, reward_bound=114.5
64: loss=0.100, reward_mean=90.9, reward_bound=103.0
65: loss=0.090, reward_mean=82.6, reward_bound=88.5
66: loss=0.077, reward_mean=99.7, reward_bound=109.0
67: loss=0.059, reward_mean=94.4, reward_bound=109.0
68: loss=0.095, reward_mean=108.9, reward_bound=132.0
69: loss=0.077, reward_mean=112.9, reward_bound=121.5
70: loss=0.103, reward_mean=120.2, reward_bound=140.5
71: loss=0.111, reward_mean=123.7, reward_bound=151.5
72: loss=0.116, reward_mean=122.9, reward_bound=129.5
73: loss=0.081, reward_mean=112.8, reward_bound=120.5
74: loss=0.093, reward_mean=116.1, reward_bound=120.5
75: loss=0.118, reward_mean=123.7, reward_bound=116.5
76: loss=0.060, reward_mean=96.5, reward_bound=95.5
77: loss=0.091, reward_mean=107.8, reward_bound=106.5
78: loss=0.091, reward_mean=105.9, reward_bound=103.5
79: loss=0.069, reward_mean=92.4, reward_bound=96.5
80: loss=0.051, reward_mean=79.6, reward_bound=81.5
81: loss=0.061, reward_mean=71.4, reward_bound=74.5
82: loss=0.063, reward_mean=76.6, reward_bound=82.0
83: loss=0.067, reward_mean=68.3, reward_bound=70.5
84: loss=0.079, reward_mean=60.9, reward_bound=66.5
85: loss=0.046, reward_mean=56.0, reward_bound=61.0
86: loss=0.073, reward_mean=58.1, reward_bound=65.0
87: loss=0.071, reward_mean=49.5, reward_bound=53.5
88: loss=0.065, reward_mean=46.5, reward_bound=48.0
89: loss=0.083, reward_mean=41.1, reward_bound=43.5
90: loss=0.070, reward_mean=36.6, reward_bound=39.0
91: loss=0.051, reward_mean=35.9, reward_bound=39.0
92: loss=0.049, reward_mean=36.3, reward_bound=39.0
93: loss=0.042, reward_mean=40.4, reward_bound=43.0
94: loss=0.049, reward_mean=38.3, reward_bound=43.0
95: loss=0.048, reward_mean=37.4, reward_bound=39.0
96: loss=0.077, reward_mean=41.1, reward_bound=44.0
97: loss=0.044, reward_mean=44.1, reward_bound=48.0
98: loss=0.041, reward_mean=47.2, reward_bound=51.5
99: loss=0.029, reward_mean=48.8, reward_bound=52.0
100: loss=0.032, reward_mean=60.4, reward_bound=65.5
101: loss=0.040, reward_mean=62.8, reward_bound=63.0
102: loss=0.029, reward_mean=74.9, reward_bound=76.5
103: loss=0.045, reward_mean=97.2, reward_bound=116.0
104: loss=0.027, reward_mean=97.1, reward_bound=96.5
105: loss=0.035, reward_mean=103.7, reward_bound=104.0
106: loss=0.063, reward_mean=147.1, reward_bound=167.0
107: loss=0.112, reward_mean=171.1, reward_bound=200.0
108: loss=0.109, reward_mean=193.8, reward_bound=200.0
109: loss=0.095, reward_mean=179.7, reward_bound=200.0
110: loss=0.035, reward_mean=153.2, reward_bound=158.5
111: loss=0.027, reward_mean=139.5, reward_bound=145.0
112: loss=0.032, reward_mean=135.5, reward_bound=140.0
113: loss=0.051, reward_mean=138.9, reward_bound=142.5
114: loss=0.047, reward_mean=141.2, reward_bound=156.5
115: loss=0.040, reward_mean=137.1, reward_bound=137.5
116: loss=0.054, reward_mean=130.6, reward_bound=148.0
117: loss=0.056, reward_mean=131.2, reward_bound=145.0
118: loss=0.039, reward_mean=122.1, reward_bound=126.0
119: loss=0.043, reward_mean=116.2, reward_bound=117.5
120: loss=0.053, reward_mean=119.1, reward_bound=131.5
121: loss=0.032, reward_mean=127.0, reward_bound=137.5
122: loss=0.048, reward_mean=117.2, reward_bound=118.5
123: loss=0.054, reward_mean=123.4, reward_bound=128.5
124: loss=0.061, reward_mean=118.3, reward_bound=117.5
125: loss=0.070, reward_mean=128.9, reward_bound=141.5
126: loss=0.039, reward_mean=130.8, reward_bound=136.5
127: loss=0.074, reward_mean=131.8, reward_bound=139.0
128: loss=0.050, reward_mean=124.2, reward_bound=131.5
129: loss=0.051, reward_mean=122.1, reward_bound=128.0
130: loss=0.046, reward_mean=138.1, reward_bound=148.5
131: loss=0.054, reward_mean=147.6, reward_bound=153.5
132: loss=0.055, reward_mean=177.7, reward_bound=200.0
133: loss=0.052, reward_mean=200.0, reward_bound=200.0
Solved!

## trial2
fei@fei-Inspiron-5580:~/Deep-Reinforcement-Learning-Hands-On/Chapter04$ python3 01_cartpole_lstm.py 
0: loss=0.693, reward_mean=22.2, reward_bound=23.0
1: loss=0.693, reward_mean=24.8, reward_bound=29.5
2: loss=0.689, reward_mean=24.2, reward_bound=26.0
3: loss=0.681, reward_mean=20.8, reward_bound=21.0
4: loss=0.694, reward_mean=22.9, reward_bound=29.5
5: loss=0.681, reward_mean=25.0, reward_bound=27.5
6: loss=0.690, reward_mean=21.2, reward_bound=21.0
7: loss=0.679, reward_mean=30.8, reward_bound=35.5
8: loss=0.677, reward_mean=34.2, reward_bound=41.0
9: loss=0.670, reward_mean=26.0, reward_bound=33.0
10: loss=0.678, reward_mean=24.1, reward_bound=25.5
11: loss=0.657, reward_mean=24.7, reward_bound=27.5
12: loss=0.670, reward_mean=39.0, reward_bound=41.0
13: loss=0.657, reward_mean=34.2, reward_bound=33.0
14: loss=0.648, reward_mean=39.1, reward_bound=41.0
15: loss=0.629, reward_mean=40.2, reward_bound=40.0
16: loss=0.623, reward_mean=43.8, reward_bound=43.0
17: loss=0.616, reward_mean=54.8, reward_bound=60.0
18: loss=0.589, reward_mean=60.1, reward_bound=66.0
19: loss=0.575, reward_mean=74.4, reward_bound=76.0
20: loss=0.567, reward_mean=61.8, reward_bound=72.0
21: loss=0.536, reward_mean=59.4, reward_bound=58.5
22: loss=0.511, reward_mean=76.2, reward_bound=87.5
23: loss=0.474, reward_mean=74.5, reward_bound=83.0
24: loss=0.467, reward_mean=73.6, reward_bound=84.5
25: loss=0.414, reward_mean=86.8, reward_bound=83.5
26: loss=0.401, reward_mean=86.8, reward_bound=98.5
27: loss=0.371, reward_mean=95.1, reward_bound=127.0
28: loss=0.364, reward_mean=76.1, reward_bound=83.5
29: loss=0.323, reward_mean=73.6, reward_bound=83.5
30: loss=0.290, reward_mean=68.6, reward_bound=79.0
31: loss=0.333, reward_mean=64.0, reward_bound=69.5
32: loss=0.228, reward_mean=69.2, reward_bound=75.0
33: loss=0.263, reward_mean=90.4, reward_bound=86.5
34: loss=0.251, reward_mean=80.7, reward_bound=80.5
35: loss=0.221, reward_mean=142.9, reward_bound=163.5
36: loss=0.198, reward_mean=119.8, reward_bound=128.0
37: loss=0.206, reward_mean=113.4, reward_bound=122.0
38: loss=0.193, reward_mean=98.1, reward_bound=94.5
39: loss=0.192, reward_mean=95.8, reward_bound=98.5
40: loss=0.146, reward_mean=89.3, reward_bound=94.5
41: loss=0.130, reward_mean=119.8, reward_bound=123.5
42: loss=0.191, reward_mean=165.8, reward_bound=196.5
43: loss=0.172, reward_mean=192.9, reward_bound=200.0
44: loss=0.109, reward_mean=170.2, reward_bound=194.0
45: loss=0.143, reward_mean=194.9, reward_bound=200.0
46: loss=0.157, reward_mean=199.7, reward_bound=200.0
Solved!


## trial3
fei@fei-Inspiron-5580:~/Deep-Reinforcement-Learning-Hands-On/Chapter04$ python3 01_cartpole_lstm.py 
0: loss=0.693, reward_mean=27.4, reward_bound=31.5
1: loss=0.688, reward_mean=20.1, reward_bound=21.5
2: loss=0.689, reward_mean=24.4, reward_bound=31.0
3: loss=0.682, reward_mean=20.9, reward_bound=26.5
4: loss=0.685, reward_mean=28.1, reward_bound=28.5
5: loss=0.685, reward_mean=31.2, reward_bound=36.0
6: loss=0.664, reward_mean=23.4, reward_bound=29.0
7: loss=0.661, reward_mean=31.0, reward_bound=37.5
8: loss=0.656, reward_mean=26.4, reward_bound=30.5
9: loss=0.645, reward_mean=38.4, reward_bound=52.5
10: loss=0.636, reward_mean=38.3, reward_bound=38.5
11: loss=0.608, reward_mean=53.2, reward_bound=63.0
12: loss=0.595, reward_mean=53.2, reward_bound=57.5
13: loss=0.577, reward_mean=47.6, reward_bound=58.0
14: loss=0.567, reward_mean=50.8, reward_bound=51.0
15: loss=0.539, reward_mean=50.1, reward_bound=46.5
16: loss=0.516, reward_mean=52.9, reward_bound=58.5
17: loss=0.493, reward_mean=56.8, reward_bound=61.0
18: loss=0.491, reward_mean=68.9, reward_bound=76.5
19: loss=0.455, reward_mean=72.4, reward_bound=76.5
20: loss=0.486, reward_mean=67.4, reward_bound=70.5
21: loss=0.421, reward_mean=65.1, reward_bound=71.5
22: loss=0.437, reward_mean=53.9, reward_bound=53.0
23: loss=0.435, reward_mean=65.5, reward_bound=74.0
24: loss=0.466, reward_mean=48.8, reward_bound=47.5
25: loss=0.418, reward_mean=61.0, reward_bound=69.5
26: loss=0.442, reward_mean=74.9, reward_bound=74.5
27: loss=0.426, reward_mean=90.1, reward_bound=103.0
28: loss=0.439, reward_mean=98.1, reward_bound=105.5
29: loss=0.430, reward_mean=97.2, reward_bound=100.0
30: loss=0.451, reward_mean=105.9, reward_bound=127.0
31: loss=0.455, reward_mean=100.3, reward_bound=115.5
32: loss=0.453, reward_mean=90.5, reward_bound=102.0
33: loss=0.435, reward_mean=104.3, reward_bound=112.5
34: loss=0.440, reward_mean=115.3, reward_bound=122.0
35: loss=0.441, reward_mean=114.2, reward_bound=125.5
36: loss=0.455, reward_mean=117.7, reward_bound=122.5
37: loss=0.444, reward_mean=118.9, reward_bound=140.0
38: loss=0.431, reward_mean=94.2, reward_bound=105.5
39: loss=0.440, reward_mean=88.2, reward_bound=90.0
40: loss=0.422, reward_mean=91.7, reward_bound=104.5
41: loss=0.414, reward_mean=81.9, reward_bound=100.5
42: loss=0.419, reward_mean=108.5, reward_bound=127.0
43: loss=0.425, reward_mean=100.6, reward_bound=110.0
44: loss=0.431, reward_mean=106.7, reward_bound=116.5
45: loss=0.398, reward_mean=110.5, reward_bound=131.0
46: loss=0.398, reward_mean=116.6, reward_bound=114.0
47: loss=0.385, reward_mean=100.4, reward_bound=111.5
48: loss=0.400, reward_mean=108.9, reward_bound=136.0
49: loss=0.414, reward_mean=80.1, reward_bound=87.5
50: loss=0.414, reward_mean=100.7, reward_bound=103.5
51: loss=0.394, reward_mean=95.9, reward_bound=102.5
52: loss=0.390, reward_mean=104.1, reward_bound=115.5
53: loss=0.381, reward_mean=105.9, reward_bound=120.5
54: loss=0.376, reward_mean=139.0, reward_bound=158.0
55: loss=0.379, reward_mean=120.6, reward_bound=136.0
56: loss=0.388, reward_mean=134.6, reward_bound=149.0
57: loss=0.375, reward_mean=162.8, reward_bound=183.5
58: loss=0.360, reward_mean=156.9, reward_bound=185.5
59: loss=0.372, reward_mean=173.8, reward_bound=200.0
60: loss=0.365, reward_mean=185.3, reward_bound=200.0
61: loss=0.362, reward_mean=189.2, reward_bound=200.0
62: loss=0.338, reward_mean=197.4, reward_bound=200.0
63: loss=0.363, reward_mean=200.0, reward_bound=200.0
Solved!


# init hidden every episode -> loss decreases fast abruptly and then early stop occurs with low reward

## it's not occasional!
fei@fei-Inspiron-5580:~/Deep-Reinforcement-Learning-Hands-On/Chapter04$ python3 01_cartpole_lstm.py 
0: loss=0.691, reward_mean=19.2, reward_bound=22.0
1: loss=0.692, reward_mean=21.8, reward_bound=24.5
2: loss=0.685, reward_mean=24.6, reward_bound=29.5
3: loss=0.678, reward_mean=26.5, reward_bound=31.0
4: loss=0.679, reward_mean=30.6, reward_bound=36.0
5: loss=0.676, reward_mean=24.7, reward_bound=30.5
6: loss=0.666, reward_mean=27.7, reward_bound=27.0
7: loss=0.660, reward_mean=35.2, reward_bound=32.0
8: loss=0.655, reward_mean=32.6, reward_bound=36.5
9: loss=0.639, reward_mean=40.7, reward_bound=46.5
10: loss=0.629, reward_mean=49.0, reward_bound=61.5
11: loss=0.628, reward_mean=68.0, reward_bound=80.0
12: loss=0.610, reward_mean=50.4, reward_bound=52.0
13: loss=0.606, reward_mean=53.9, reward_bound=67.0
14: loss=0.590, reward_mean=46.9, reward_bound=55.0
15: loss=0.585, reward_mean=65.1, reward_bound=69.5
16: loss=0.588, reward_mean=59.5, reward_bound=66.0
17: loss=0.566, reward_mean=51.6, reward_bound=54.5
18: loss=0.556, reward_mean=56.4, reward_bound=61.0
19: loss=0.553, reward_mean=62.9, reward_bound=75.5
20: loss=0.544, reward_mean=63.1, reward_bound=71.0
21: loss=0.542, reward_mean=71.5, reward_bound=74.0
22: loss=0.540, reward_mean=59.9, reward_bound=66.5
23: loss=0.535, reward_mean=62.6, reward_bound=68.0
24: loss=0.500, reward_mean=56.4, reward_bound=67.0
25: loss=0.488, reward_mean=50.6, reward_bound=57.0
26: loss=0.537, reward_mean=44.8, reward_bound=50.5
27: loss=0.513, reward_mean=44.8, reward_bound=50.0
28: loss=0.484, reward_mean=41.0, reward_bound=45.5
29: loss=0.501, reward_mean=43.0, reward_bound=47.0
30: loss=0.480, reward_mean=45.2, reward_bound=52.0
31: loss=0.491, reward_mean=42.6, reward_bound=44.5
32: loss=0.505, reward_mean=41.5, reward_bound=45.0
33: loss=0.511, reward_mean=47.8, reward_bound=53.5
34: loss=0.564, reward_mean=44.6, reward_bound=45.5
35: loss=0.470, reward_mean=43.2, reward_bound=50.0
36: loss=0.518, reward_mean=42.6, reward_bound=48.5
37: loss=0.500, reward_mean=38.7, reward_bound=42.0
38: loss=0.521, reward_mean=42.1, reward_bound=48.0
39: loss=0.514, reward_mean=40.9, reward_bound=42.5
40: loss=0.534, reward_mean=39.6, reward_bound=42.0
41: loss=0.523, reward_mean=46.0, reward_bound=48.5
42: loss=0.528, reward_mean=44.3, reward_bound=49.0
43: loss=0.528, reward_mean=53.1, reward_bound=60.0
44: loss=0.555, reward_mean=59.5, reward_bound=69.0
45: loss=0.532, reward_mean=59.2, reward_bound=61.5
46: loss=0.528, reward_mean=82.4, reward_bound=78.5
47: loss=0.536, reward_mean=78.8, reward_bound=82.0
48: loss=0.537, reward_mean=87.0, reward_bound=89.5
49: loss=0.534, reward_mean=82.9, reward_bound=88.5
50: loss=0.556, reward_mean=74.1, reward_bound=86.5
51: loss=0.532, reward_mean=83.6, reward_bound=92.0
52: loss=0.546, reward_mean=80.6, reward_bound=92.0
53: loss=0.534, reward_mean=74.6, reward_bound=71.0
54: loss=0.543, reward_mean=77.8, reward_bound=78.0
55: loss=0.525, reward_mean=56.2, reward_bound=61.0
56: loss=0.551, reward_mean=57.0, reward_bound=61.5
57: loss=0.513, reward_mean=51.8, reward_bound=54.0
58: loss=0.516, reward_mean=52.2, reward_bound=58.0
59: loss=0.540, reward_mean=48.2, reward_bound=55.0
60: loss=0.532, reward_mean=46.2, reward_bound=51.5
61: loss=0.514, reward_mean=44.8, reward_bound=48.5
62: loss=0.515, reward_mean=41.4, reward_bound=44.0
63: loss=0.512, reward_mean=47.2, reward_bound=53.0
64: loss=0.524, reward_mean=47.1, reward_bound=47.0
65: loss=0.521, reward_mean=48.9, reward_bound=49.5
66: loss=0.517, reward_mean=48.0, reward_bound=51.5
67: loss=0.509, reward_mean=50.3, reward_bound=56.0
68: loss=0.506, reward_mean=49.6, reward_bound=53.0
69: loss=0.508, reward_mean=51.8, reward_bound=54.5
70: loss=0.525, reward_mean=50.5, reward_bound=51.5
71: loss=0.500, reward_mean=49.1, reward_bound=52.0
72: loss=0.483, reward_mean=47.8, reward_bound=53.5
73: loss=0.507, reward_mean=46.3, reward_bound=50.5
74: loss=0.405, reward_mean=32.0, reward_bound=45.0
75: loss=0.388, reward_mean=24.6, reward_bound=36.0
76: loss=0.209, reward_mean=12.4, reward_bound=10.0
77: loss=0.207, reward_mean=9.4, reward_bound=10.0
78: loss=0.069, reward_mean=9.6, reward_bound=10.0
79: loss=0.005, reward_mean=9.2, reward_bound=10.0
80: loss=0.000, reward_mean=9.3, reward_bound=10.0
81: loss=0.000, reward_mean=9.3, reward_bound=9.5
82: loss=0.000, reward_mean=9.0, reward_bound=9.0
83: loss=0.000, reward_mean=9.4, reward_bound=10.0
84: loss=0.000, reward_mean=9.4, reward_bound=10.0
85: loss=0.000, reward_mean=9.1, reward_bound=10.0
86: loss=0.000, reward_mean=9.1, reward_bound=9.5
87: loss=0.000, reward_mean=9.2, reward_bound=10.0
88: loss=0.000, reward_mean=9.6, reward_bound=10.0
89: loss=0.000, reward_mean=9.5, reward_bound=10.0
90: loss=0.000, reward_mean=9.6, reward_bound=10.0
91: loss=0.000, reward_mean=9.3, reward_bound=10.0
92: loss=0.000, reward_mean=9.0, reward_bound=9.0
93: loss=0.000, reward_mean=9.2, reward_bound=10.0
94: loss=0.000, reward_mean=9.2, reward_bound=10.0
95: loss=0.000, reward_mean=9.1, reward_bound=9.5
96: loss=0.000, reward_mean=9.4, reward_bound=10.0
97: loss=0.000, reward_mean=9.5, reward_bound=10.0
98: loss=0.000, reward_mean=9.3, reward_bound=10.0
99: loss=0.000, reward_mean=9.2, reward_bound=10.0
100: loss=0.000, reward_mean=9.6, reward_bound=10.0
101: loss=0.000, reward_mean=9.2, reward_bound=10.0
102: loss=0.000, reward_mean=9.4, reward_bound=10.0
103: loss=0.000, reward_mean=9.1, reward_bound=10.0
104: loss=0.000, reward_mean=9.1, reward_bound=9.0
105: loss=0.000, reward_mean=9.4, reward_bound=10.0
106: loss=0.000, reward_mean=9.2, reward_bound=9.0
107: loss=0.000, reward_mean=9.2, reward_bound=9.5
108: loss=0.000, reward_mean=9.3, reward_bound=9.5
109: loss=0.000, reward_mean=9.2, reward_bound=10.0
110: loss=0.000, reward_mean=9.3, reward_bound=10.0
111: loss=0.000, reward_mean=9.6, reward_bound=10.0
112: loss=0.000, reward_mean=9.4, reward_bound=10.0
113: loss=0.000, reward_mean=9.5, reward_bound=10.0
114: loss=0.000, reward_mean=9.4, reward_bound=10.0
115: loss=0.000, reward_mean=9.3, reward_bound=10.0
116: loss=0.000, reward_mean=9.2, reward_bound=10.0
117: loss=0.000, reward_mean=9.6, reward_bound=10.0
118: loss=0.000, reward_mean=9.3, reward_bound=9.5
119: loss=0.000, reward_mean=9.3, reward_bound=10.0
120: loss=0.000, reward_mean=9.5, reward_bound=10.0
121: loss=0.000, reward_mean=9.5, reward_bound=10.0


